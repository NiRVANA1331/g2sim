{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1D Gradient Descent Localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gaussian_grad_mu(x, sigma, mu):\n",
    "    dgdmu = 1/(sigma*(2*np.pi)**0.5)*np.exp(-1/2*((x-mu)/sigma)**2)*(x-mu)/sigma**2\n",
    "    return dgdmu\n",
    "\n",
    "def get_gaussian_grad_sigma(x, sigma, mu):\n",
    "    dgdsigma = (np.exp(-1/2*(x-mu)**2/sigma**2)*(x-mu)**2)/(np.sqrt(2*np.pi)*sigma**4)-(np.exp(-1/2*(x-mu)**2/sigma**2))/(np.sqrt(2*np.pi)*sigma**2)\n",
    "    return dgdsigma\n",
    "\n",
    "def gaussian(x, sigma, mu):\n",
    "    gaussian = 1/(sigma*(2*np.pi)**0.5)*np.exp(-1/2*((x-mu)/sigma)**2)\n",
    "    return gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, loss is 0.09471764910168139 with sigma: 1.9968846014314046 and mu: 1.993865540975709\n",
      "1, loss is 0.09424294579736024 with sigma: 1.9937350441049624 and mu: 1.9877398888984235\n",
      "2, loss is 0.09376714618810877 with sigma: 1.9905513917232178 and mu: 1.981622978187535\n",
      "3, loss is 0.09329022176276577 with sigma: 1.9873337063156908 and mu: 1.97551474504313\n",
      "4, loss is 0.092812144284509 with sigma: 1.9840820483143204 and mu: 1.9694151274550158\n",
      "5, loss is 0.09233288579115294 with sigma: 1.9807964766296298 and mu: 1.963324065212671\n",
      "6, loss is 0.09185241859590525 with sigma: 1.9774770487276887 and mu: 1.9572414999161356\n",
      "7, loss is 0.09137071528858942 with sigma: 1.9741238207079546 and mu: 1.9511673749878473\n",
      "8, loss is 0.09088774873734067 with sigma: 1.9707368473820714 and mu: 1.9451016356854416\n",
      "9, loss is 0.09040349209078312 with sigma: 1.9673161823537093 and mu: 1.9390442291155232\n",
      "10, loss is 0.08991791878069773 with sigma: 1.9638618780995256 and mu: 1.9329951042484261\n",
      "11, loss is 0.08943100252518836 with sigma: 1.960373986051335 and mu: 1.9269542119339718\n",
      "12, loss is 0.08894271733235821 with sigma: 1.956852556679572 and mu: 1.920921504918244\n",
      "13, loss is 0.08845303750450484 with sigma: 1.9532976395781356 and mu: 1.9148969378613925\n",
      "14, loss is 0.0879619376428462 with sigma: 1.9497092835507035 and mu: 1.9088804673564803\n",
      "15, loss is 0.08746939265278872 with sigma: 1.9460875366986086 and mu: 1.9028720519493931\n",
      "16, loss is 0.08697537774974975 with sigma: 1.9424324465103695 and mu: 1.8968716521598241\n",
      "17, loss is 0.08647986846554753 with sigma: 1.9387440599529708 and mu: 1.8908792305033533\n",
      "18, loss is 0.08598284065537151 with sigma: 1.9350224235649893 and mu: 1.8848947515146368\n",
      "19, loss is 0.08548427050534799 with sigma: 1.9312675835516633 and mu: 1.878918181771726\n",
      "20, loss is 0.0849841345407151 with sigma: 1.9274795858820102 and mu: 1.872949489921533\n",
      "21, loss is 0.08448240963462288 with sigma: 1.9236584763880895 and mu: 1.866988646706462\n",
      "22, loss is 0.0839790730175742 with sigma: 1.9198043008665215 and mu: 1.8610356249922246\n",
      "23, loss is 0.08347410228752355 with sigma: 1.9159171051823662 and mu: 1.8550903997968622\n",
      "24, loss is 0.08296747542065047 with sigma: 1.911996935375472 and mu: 1.8491529483209896\n",
      "25, loss is 0.08245917078282594 with sigma: 1.908043837769408 and mu: 1.8432232499792869\n",
      "26, loss is 0.08194916714179006 with sigma: 1.9040578590830934 and mu: 1.8373012864332536\n",
      "27, loss is 0.08143744368006026 with sigma: 1.9000390465452404 and mu: 1.8313870416252536\n",
      "28, loss is 0.08092398000858965 with sigma: 1.8959874480117307 and mu: 1.825480501813865\n",
      "29, loss is 0.08040875618119646 with sigma: 1.8919031120860472 and mu: 1.8195816556105615\n",
      "30, loss is 0.07989175270978476 with sigma: 1.8877860882428863 and mu: 1.8136904940177467\n",
      "31, loss is 0.07937295058037887 with sigma: 1.883636426955075 and mu: 1.8078070104681605\n",
      "32, loss is 0.07885233126999311 with sigma: 1.8794541798239266 and mu: 1.8019312008656834\n",
      "33, loss is 0.07832987676436007 with sigma: 1.8752393997131642 and mu: 1.7960630636275603\n",
      "34, loss is 0.07780556957654046 with sigma: 1.8709921408865469 and mu: 1.7902025997280646\n",
      "35, loss is 0.0772793927664385 with sigma: 1.8667124591493367 and mu: 1.7843498127436275\n",
      "36, loss is 0.07675132996124714 with sigma: 1.862400411993748 and mu: 1.7785047088994532\n",
      "37, loss is 0.07622136537684844 with sigma: 1.8580560587485175 and mu: 1.7726672971176445\n",
      "38, loss is 0.0756894838401933 with sigma: 1.8536794607327436 and mu: 1.7668375890668586\n",
      "39, loss is 0.07515567081268792 with sigma: 1.8492706814141402 and mu: 1.7610155992135181\n",
      "40, loss is 0.0746199124146112 with sigma: 1.8448297865718564 and mu: 1.7552013448745953\n",
      "41, loss is 0.07408219545059101 with sigma: 1.8403568444640122 and mu: 1.7493948462719946\n",
      "42, loss is 0.07354250743616528 with sigma: 1.8358519260001045 and mu: 1.7435961265885525\n",
      "43, loss is 0.07300083662545465 with sigma: 1.8313151049184417 and mu: 1.7378052120256744\n",
      "44, loss is 0.07245717203997432 with sigma: 1.8267464579687611 and mu: 1.7320221318626294\n",
      "45, loss is 0.07191150349861178 with sigma: 1.822146065100192 and mu: 1.726246918517521\n",
      "46, loss is 0.07136382164879726 with sigma: 1.8175140096547233 and mu: 1.7204796076099516\n",
      "47, loss is 0.0708141179988948 with sigma: 1.8128503785663406 and mu: 1.714720238025397\n",
      "48, loss is 0.07026238495183958 with sigma: 1.8081552625659931 and mu: 1.7089688519813084\n",
      "49, loss is 0.06970861584004903 with sigma: 1.803428756392557 and mu: 1.7032254950949526\n",
      "50, loss is 0.06915280496163329 with sigma: 1.7986709590099592 and mu: 1.6974902164530057\n",
      "51, loss is 0.06859494761793025 with sigma: 1.7938819738306253 and mu: 1.6917630686829104\n",
      "52, loss is 0.06803504015239134 with sigma: 1.789061908945419 and mu: 1.6860441080260056\n",
      "53, loss is 0.06747307999083994 with sigma: 1.7842108773602332 and mu: 1.6803333944124346\n",
      "54, loss is 0.06690906568312789 with sigma: 1.779328997239398 and mu: 1.6746309915378375\n",
      "55, loss is 0.06634299694620988 with sigma: 1.7744163921560663 and mu: 1.6689369669418288\n",
      "56, loss is 0.06577487470865719 with sigma: 1.7694731913497346 and mu: 1.6632513920882601\n",
      "57, loss is 0.06520470115662981 with sigma: 1.7644995299910562 and mu: 1.657574342447263\n",
      "58, loss is 0.06463247978132315 with sigma: 1.7594955494540985 and mu: 1.651905897579066\n",
      "59, loss is 0.06405821542790523 with sigma: 1.7544613975961931 and mu: 1.6462461412195724\n",
      "60, loss is 0.06348191434595651 with sigma: 1.7493972290455213 and mu: 1.6405951613676888\n",
      "61, loss is 0.06290358424142257 with sigma: 1.7443032054965726 and mu: 1.6349530503743792\n",
      "62, loss is 0.06232323433008696 with sigma: 1.7391794960136067 and mu: 1.6293199050334255\n",
      "63, loss is 0.06174087539256775 with sigma: 1.734026277342241 and mu: 1.623695826673864\n",
      "64, loss is 0.061156519830839036 with sigma: 1.7288437342292788 and mu: 1.6180809212540634\n",
      "65, loss is 0.06057018172627268 with sigma: 1.7236320597508799 and mu: 1.612475299457407\n",
      "66, loss is 0.05998187689919333 with sigma: 1.7183914556491662 and mu: 1.6068790767895282\n",
      "67, loss is 0.05939162296993376 with sigma: 1.713122132677344 and mu: 1.6012923736770528\n",
      "68, loss is 0.05879943942137262 with sigma: 1.7078243109534064 and mu: 1.5957153155677832\n",
      "69, loss is 0.0582053476629312 with sigma: 1.702498220322464 and mu: 1.5901480330322608\n",
      "70, loss is 0.057609371095999506 with sigma: 1.6971441007277408 and mu: 1.584590661866628\n",
      "71, loss is 0.0570115351807557 with sigma: 1.6917622025902455 and mu: 1.5790433431967086\n",
      "72, loss is 0.05641186750433461 with sigma: 1.6863527871971091 and mu: 1.573506223583212\n",
      "73, loss is 0.05581039785029503 with sigma: 1.6809161270985624 and mu: 1.5679794551279578\n",
      "74, loss is 0.05520715826932483 with sigma: 1.6754525065134933 and mu: 1.5624631955810069\n",
      "75, loss is 0.05460218315111656 with sigma: 1.669962221743504 and mu: 1.5569576084485777\n",
      "76, loss is 0.053995509297333606 with sigma: 1.6644455815953518 and mu: 1.5514628631016065\n",
      "77, loss is 0.05338717599557926 with sigma: 1.658902907811632 and mu: 1.5459791348848078\n",
      "78, loss is 0.052777225094268417 with sigma: 1.6533345355095193 and mu: 1.5405066052260703\n",
      "79, loss is 0.05216570107828972 with sigma: 1.6477408136273521 and mu: 1.5350454617460154\n",
      "80, loss is 0.051552651145334714 with sigma: 1.6421221053788013 and mu: 1.5295958983675264\n",
      "81, loss is 0.050938125282755986 with sigma: 1.6364787887143186 and mu: 1.5241581154250456\n",
      "82, loss is 0.050322176344802474 with sigma: 1.63081125678952 and mu: 1.518732319773417\n",
      "83, loss is 0.049704860130065726 with sigma: 1.6251199184401015 and mu: 1.5133187248960387\n",
      "84, loss is 0.04908623545895442 with sigma: 1.6194051986628353 and mu: 1.5079175510120681\n",
      "85, loss is 0.04846636425099872 with sigma: 1.613667539102138 and mu: 1.5025290251824097\n",
      "86, loss is 0.0478453116017677 with sigma: 1.6079073985416374 and mu: 1.49715338141419\n",
      "87, loss is 0.047223145859166364 with sigma: 1.6021252534001043 and mu: 1.491790860763411\n",
      "88, loss is 0.04659993869885823 with sigma: 1.5963215982310426 and mu: 1.4864417114354487\n",
      "89, loss is 0.045975765198540956 with sigma: 1.5904969462251648 and mu: 1.4811061888830424\n",
      "90, loss is 0.04535070391078218 with sigma: 1.5846518297148935 and mu: 1.4757845559014018\n",
      "91, loss is 0.04472483693410004 with sigma: 1.57878680067996 and mu: 1.470477082720032\n",
      "92, loss is 0.04409824998195356 with sigma: 1.5729024312530755 and mu: 1.4651840470908575\n",
      "93, loss is 0.04347103244928377 with sigma: 1.5669993142245708 and mu: 1.4599057343721986\n",
      "94, loss is 0.04284327747622437 with sigma: 1.5610780635447976 and mu: 1.4546424376081328\n",
      "95, loss is 0.04221508200857811 with sigma: 1.5551393148229953 and mu: 1.449394457602748\n",
      "96, loss is 0.0415865468546306 with sigma: 1.549183725821221 and mu: 1.4441621029887663\n",
      "97, loss is 0.04095777673785027 with sigma: 1.5432119769418362 and mu: 1.438945690289999\n",
      "98, loss is 0.040328880344999554 with sigma: 1.5372247717069327 and mu: 1.4337455439770581\n",
      "99, loss is 0.03969997036915846 with sigma: 1.531222837227974 and mu: 1.428561996515734\n",
      "100, loss is 0.03907116354713901 with sigma: 1.5252069246638023 and mu: 1.4233953884074158\n",
      "101, loss is 0.03844258069074592 with sigma: 1.5191778096650521 and mu: 1.4182460682209115\n",
      "102, loss is 0.037814346711317434 with sigma: 1.5131362928028833 and mu: 1.4131143926149943\n",
      "103, loss is 0.03718659063695902 with sigma: 1.507083199979826 and mu: 1.408000726350984\n",
      "104, loss is 0.03655944562186299 with sigma: 1.5010193828204046 and mu: 1.4029054422946423\n",
      "105, loss is 0.035933048947089506 with sigma: 1.4949457190390796 and mu: 1.3978289214066453\n",
      "106, loss is 0.035307542012167764 with sigma: 1.4888631127829228 and mu: 1.3927715527208684\n",
      "107, loss is 0.03468307031686258 with sigma: 1.4827724949463132 and mu: 1.3877337333097046\n",
      "108, loss is 0.034059783432440024 with sigma: 1.476674823454816 and mu: 1.382715868235617\n",
      "109, loss is 0.033437834961757944 with sigma: 1.4705710835152863 and mu: 1.377718370488112\n",
      "110, loss is 0.03281738248750167 with sigma: 1.4644622878291205 and mu: 1.3727416609053023\n",
      "111, loss is 0.03219858750788479 with sigma: 1.4583494767654614 and mu: 1.367786168079228\n",
      "112, loss is 0.03158161535913768 with sigma: 1.4522337184910565 and mu: 1.362852328244084\n",
      "113, loss is 0.03096663512411456 with sigma: 1.4461161090533674 and mu: 1.3579405851465085\n",
      "114, loss is 0.030353819526363474 with sigma: 1.439997772413436 and mu: 1.3530513898970828\n",
      "115, loss is 0.029743344809021705 with sigma: 1.4338798604249292 and mu: 1.348185200802198\n",
      "116, loss is 0.029135390597925418 with sigma: 1.4277635527557158 and mu: 1.3433424831754528\n",
      "117, loss is 0.028530139748352612 with sigma: 1.4216500567482713 and mu: 1.3385237091277644\n",
      "118, loss is 0.02792777817485903 with sigma: 1.415540607215168 and mu: 1.333729357335387\n",
      "119, loss is 0.02732849466371164 with sigma: 1.4094364661658814 and mu: 1.328959912785069\n",
      "120, loss is 0.02673248066747955 with sigma: 1.4033389224611474 and mu: 1.3242158664956025\n",
      "121, loss is 0.026139930081405163 with sigma: 1.3972492913911179 and mu: 1.319497715215065\n",
      "122, loss is 0.02555103900124891 with sigma: 1.3911689141736092 and mu: 1.3148059610930993\n",
      "123, loss is 0.024966005462382278 with sigma: 1.3850991573688123 and mu: 1.3101411113276267\n",
      "124, loss is 0.024385029159992907 with sigma: 1.3790414122069243 and mu: 1.3055036777854614\n",
      "125, loss is 0.023808311150364272 with sigma: 1.3729970938253013 and mu: 1.3008941765963558\n",
      "126, loss is 0.023236053533300924 with sigma: 1.3669676404118911 and mu: 1.296313127720092\n",
      "127, loss is 0.02266845911588679 with sigma: 1.3609545122519053 and mu: 1.2917610544863247\n",
      "128, loss is 0.022105731057891192 with sigma: 1.3549591906749325 and mu: 1.2872384831069719\n",
      "129, loss is 0.02154807249927103 with sigma: 1.3489831768999645 and mu: 1.282745942161071\n",
      "130, loss is 0.020995686170361405 with sigma: 1.3430279907761347 and mu: 1.2782839620521194\n",
      "131, loss is 0.02044877398549661 with sigma: 1.3370951694173239 and mu: 1.2738530744380574\n",
      "132, loss is 0.019907536620960897 with sigma: 1.3311862657292002 and mu: 1.2694538116341805\n",
      "133, loss is 0.01937217307833081 with sigma: 1.3253028468277055 and mu: 1.265086705989415\n",
      "134, loss is 0.018842880234438118 with sigma: 1.319446492348505 and mu: 1.260752289236544\n",
      "135, loss is 0.018319852379352134 with sigma: 1.3136187926474516 and mu: 1.256451091817126\n",
      "136, loss is 0.017803280743952366 with sigma: 1.3078213468927105 and mu: 1.252183642182029\n",
      "137, loss is 0.017293353018833044 with sigma: 1.3020557610498165 and mu: 1.2479504660686582\n",
      "138, loss is 0.01679025286645098 with sigma: 1.296323645761612 and mu: 1.2437520857561555\n",
      "139, loss is 0.01629415942859219 with sigma: 1.2906266141257257 and mu: 1.239589019300013\n",
      "140, loss is 0.015805246831391475 with sigma: 1.2849662793729972 and mu: 1.2354617797477438\n",
      "141, loss is 0.015323683690288241 with sigma: 1.279344252451043 and mu: 1.2313708743374308\n",
      "142, loss is 0.014849632617439476 with sigma: 1.273762139517952 and mu: 1.2273168036811652\n",
      "143, loss is 0.014383249734234686 with sigma: 1.2682215393519427 and mu: 1.22330006093557\n",
      "144, loss is 0.013924684191664786 with sigma: 1.2627240406836466 and mu: 1.2193211309617822\n",
      "145, loss is 0.01347407770138474 with sigma: 1.2572712194585365 and mu: 1.2153804894774438\n",
      "146, loss is 0.013031564080375884 with sigma: 1.2518646360378651 and mu: 1.2114786022034134\n",
      "147, loss is 0.012597268812156386 with sigma: 1.2465058323473188 and mu: 1.2076159240080675\n",
      "148, loss is 0.012171308627503399 with sigma: 1.2411963289834036 and mu: 1.2037928980521992\n",
      "149, loss is 0.011753791107638406 with sigma: 1.2359376222883678 and mu: 1.200009954937652\n",
      "150, loss is 0.011344814312784269 with sigma: 1.2307311814052078 and mu: 1.1962675118629293\n",
      "151, loss is 0.010944466438928354 with sigma: 1.225578445324989 and mu: 1.1925659717891177\n",
      "152, loss is 0.010552825505519902 with sigma: 1.2204808199393378 and mu: 1.188905722619519\n",
      "153, loss is 0.010169959076690088 with sigma: 1.2154396751115066 and mu: 1.1852871363964428\n",
      "154, loss is 0.009795924018411416 with sigma: 1.210456341779867 and mu: 1.1817105685186198\n",
      "155, loss is 0.009430766293808419 with sigma: 1.2055321091080458 and mu: 1.1781763569826984\n",
      "156, loss is 0.009074520798596048 with sigma: 1.2006682216961653 and mu: 1.174684821652246\n",
      "157, loss is 0.008727211238357426 with sigma: 1.19586587686778 and mu: 1.171236263557621\n",
      "158, loss is 0.008388850049080061 with sigma: 1.1911262220471004 and mu: 1.1678309642299871\n",
      "159, loss is 0.008059438362054187 with sigma: 1.186450352240972 and mu: 1.164469185072627\n",
      "160, loss is 0.007738966013898888 with sigma: 1.1818393076398006 and mu: 1.161151166772564\n",
      "161, loss is 0.007427411602128861 with sigma: 1.1772940713512183 and mu: 1.1578771287553304\n",
      "162, loss is 0.007124742586307757 with sigma: 1.1728155672797282 and mu: 1.1546472686855203\n",
      "163, loss is 0.006830915434460638 with sigma: 1.168404658164882 and mu: 1.1514617620155456\n",
      "164, loss is 0.006545875814041566 with sigma: 1.1640621437897216 and mu: 1.1483207615847713\n",
      "165, loss is 0.00626955882637844 with sigma: 1.1597887593702638 and mu: 1.1452243972709355\n",
      "166, loss is 0.006001889283151468 with sigma: 1.1555851741357293 and mu: 1.1421727756954918\n",
      "167, loss is 0.005742782023108928 with sigma: 1.1514519901080387 and mu: 1.139165979984205\n",
      "168, loss is 0.005492142266889634 with sigma: 1.1473897410878122 and mu: 1.136204069584037\n",
      "169, loss is 0.005249866007510097 with sigma: 1.1433988918527422 and mu: 1.1332870801370392\n",
      "170, loss is 0.005015840433791041 with sigma: 1.1394798375727748 and mu: 1.1304150234116583\n",
      "171, loss is 0.004789944383745673 with sigma: 1.1356329034450519 and mu: 1.1275878872915381\n",
      "172, loss is 0.0045720488247354 with sigma: 1.1318583445500425 and mu: 1.1248056358215905\n",
      "173, loss is 0.004362017357019601 with sigma: 1.128156345928769 and mu: 1.1220682093107948\n",
      "174, loss is 0.0041597067371865115 with sigma: 1.1245270228794946 and mu: 1.1193755244908878\n",
      "175, loss is 0.0039649674178549475 with sigma: 1.1209704214707505 and mu: 1.1167274747298144\n",
      "176, loss is 0.003777644099980109 with sigma: 1.1174865192661074 and mu: 1.1141239302985313\n",
      "177, loss is 0.0035975762940829215 with sigma: 1.114075226254706 and mu: 1.111564738689506\n",
      "178, loss is 0.0034245988867485913 with sigma: 1.1107363859802315 and mu: 1.1090497249849998\n",
      "179, loss is 0.0032585427088065314 with sigma: 1.1074697768597872 and mu: 1.1065786922730139\n",
      "180, loss is 0.0030992351017065604 with sigma: 1.1042751136829938 and mu: 1.104151422108573\n",
      "181, loss is 0.0029465004787440035 with sigma: 1.1011520492806262 and mu: 1.1017676750178456\n",
      "182, loss is 0.00280016087795479 with sigma: 1.098100176351214 and mu: 1.0994271910424438\n",
      "183, loss is 0.0026600365036978566 with sigma: 1.0951190294332707 and mu: 1.0971296903211238\n",
      "184, loss is 0.0025259462541615987 with sigma: 1.092208087010199 and mu: 1.0948748737059912\n",
      "185, loss is 0.0023977082322700505 with sigma: 1.0893667737344315 and mu: 1.0926624234102387\n",
      "186, loss is 0.0022751402377187723 with sigma: 1.0865944627570263 and mu: 1.090492003684385\n",
      "187, loss is 0.0021580602381349903 with sigma: 1.0838904781487202 and mu: 1.0883632615179428\n",
      "188, loss is 0.0020462868176283006 with sigma: 1.0812540973983729 and mu: 1.086275827363429\n",
      "189, loss is 0.0019396396012724233 with sigma: 1.0786845539747825 and mu: 1.0842293158796354\n",
      "190, loss is 0.0018379396543313853 with sigma: 1.0761810399380203 and mu: 1.0822233266911034\n",
      "191, loss is 0.0017410098553119417 with sigma: 1.0737427085867186 and mu: 1.0802574451607827\n",
      "192, loss is 0.0016486752421844188 with sigma: 1.0713686771281252 and mu: 1.0783312431729188\n",
      "193, loss is 0.001560763331363874 with sigma: 1.069058029358214 and mu: 1.0764442799232836\n",
      "194, loss is 0.0014771044092801173 with sigma: 1.0668098183396961 and mu: 1.0745961027139512\n",
      "195, loss is 0.0013975317965865815 with sigma: 1.0646230690664023 and mu: 1.0727862477499206\n",
      "196, loss is 0.0013218820852627512 with sigma: 1.062496781103187 and mu: 1.0710142409349972\n",
      "197, loss is 0.001249995349051751 with sigma: 1.06042993119124 and mu: 1.069279598664464\n",
      "198, loss is 0.00118171532784241 with sigma: 1.0584214758094508 and mu: 1.0675818286121999\n",
      "199, loss is 0.0011168895867542086 with sigma: 1.0564703536832671 and mu: 1.0659204305100354\n",
      "200, loss is 0.001055369650812696 with sigma: 1.054575488233292 and mu: 1.0642948969172783\n",
      "201, loss is 0.0009970111162131187 with sigma: 1.0527357899566787 and mu: 1.0627047139784758\n",
      "202, loss is 0.000941673739261609 with sigma: 1.0509501587351882 and mu: 1.0611493621676342\n",
      "203, loss is 0.0008892215041564805 with sigma: 1.0492174860645764 and mu: 1.0596283170172547\n",
      "204, loss is 0.0008395226708283354 with sigma: 1.0475366572007572 and mu: 1.058141049830695\n",
      "205, loss is 0.0007924498040976605 with sigma: 1.0459065532189427 and mu: 1.056687028376511\n",
      "206, loss is 0.0007478797854334245 with sigma: 1.0443260529826959 and mu: 1.0552657175635778\n",
      "207, loss is 0.0007056938086071455 with sigma: 1.0427940350205178 and mu: 1.0538765800959244\n",
      "208, loss is 0.0006657773605355361 with sigma: 1.0413093793082564 and mu: 1.0525190771063682\n",
      "209, loss is 0.0006280201885919443 with sigma: 1.0398709689562369 and mu: 1.0511926687681543\n",
      "210, loss is 0.0005923162556441536 with sigma: 1.038477691800592 and mu: 1.0498968148839485\n",
      "211, loss is 0.0005585636840448888 with sigma: 1.0371284418988034 and mu: 1.048630975451648\n",
      "212, loss is 0.0005266646897626368 with sigma: 1.0358221209299534 and mu: 1.0473946112065995\n",
      "213, loss is 0.0004965255077955862 with sigma: 1.0345576395006337 and mu: 1.0461871841399262\n",
      "214, loss is 0.00046805630996180276 with sigma: 1.0333339183578558 and mu: 1.0450081579927752\n",
      "215, loss is 0.00044117111610475355 with sigma: 1.0321498895106682 and mu: 1.043856998726395\n",
      "216, loss is 0.0004157876996969254 with sigma: 1.0310044972625032 and mu: 1.0427331749680513\n",
      "217, loss is 0.0003918274887652738 with sigma: 1.0298966991565486 and mu: 1.0416361584328788\n",
      "218, loss is 0.0003692154630024963 with sigma: 1.0288254668366823 and mu: 1.0405654243218447\n",
      "219, loss is 0.0003478800478675811 with sigma: 1.027789786826704 and mu: 1.0395204516960808\n",
      "220, loss is 0.0003277530064189008 with sigma: 1.0267886612307664 and mu: 1.038500723827905\n",
      "221, loss is 0.00030876932956351257 with sigma: 1.025821108358042 and mu: 1.0375057285289202\n",
      "222, loss is 0.00029086712534812505 with sigma: 1.024886163274767 and mu: 1.0365349584556331\n",
      "223, loss is 0.0002739875078603456 with sigma: 1.0239828782868745 and mu: 1.035587911393083\n",
      "224, loss is 0.0002580744862542308 with sigma: 1.0231103233564824 and mu: 1.0346640905170217\n",
      "225, loss is 0.00024307485436154898 with sigma: 1.0222675864555297 and mu: 1.0337630046352173\n",
      "226, loss is 0.00022893808130011072 with sigma: 1.0214537738598546 and mu: 1.0328841684084928\n",
      "227, loss is 0.00021561620344311545 with sigma: 1.020668010387 and mu: 1.0320271025521344\n",
      "228, loss is 0.00020306371806857074 with sigma: 1.0199094395809962 and mu: 1.0311913340183319\n",
      "229, loss is 0.00019123747896596167 with sigma: 1.019177223847329 and mu: 1.0303763961603265\n",
      "230, loss is 0.00018009659423807707 with sigma: 1.0184705445412394 and mu: 1.0295818288789615\n",
      "231, loss is 0.00016960232649948498 with sigma: 1.017788602012435 and mu: 1.0288071787523343\n",
      "232, loss is 0.00015971799563951937 with sigma: 1.0171306156092061 and mu: 1.0280519991492596\n",
      "233, loss is 0.00015040888428669748 with sigma: 1.0164958236448633 and mu: 1.0273158503272557\n",
      "234, loss is 0.00014164214608309087 with sigma: 1.0158834833293047 and mu: 1.026598299515761\n",
      "235, loss is 0.00013338671685141976 with sigma: 1.0152928706684337 and mu: 1.0258989209852885\n",
      "236, loss is 0.00012561322871426547 with sigma: 1.0147232803340374 and mu: 1.0252172961032189\n",
      "237, loss is 0.00011829392720365129 with sigma: 1.0141740255066278 and mu: 1.0245530133769234\n",
      "238, loss is 0.00011140259138045123 with sigma: 1.0136444376936447 and mu: 1.0239056684848957\n",
      "239, loss is 0.00010491445696616683 with sigma: 1.0131338665253016 and mu: 1.023274864296564\n",
      "240, loss is 9.88061424747926e-05 with sigma: 1.0126416795302522 and mu: 1.022660210881434\n",
      "241, loss is 9.305557831933183e-05 with sigma: 1.012167261893139 and mu: 1.0220613255082043\n",
      "242, loss is 8.764193885616354e-05 with sigma: 1.011710016195978 and mu: 1.021477832634472\n",
      "243, loss is 8.254557732056847e-05 with sigma: 1.0112693621452287 and mu: 1.0209093638876348\n",
      "244, loss is 7.774796359825798e-05 with sigma: 1.0108447362862858 and mu: 1.0203555580375718\n",
      "245, loss is 7.323162477068436e-05 with sigma: 1.010435591707033 and mu: 1.0198160609616718\n",
      "246, loss is 6.898008836589718e-05 with sigma: 1.0100413977319906 and mu: 1.0192905256027491\n",
      "247, loss is 6.497782824190613e-05 with sigma: 1.0096616396084985 and mu: 1.0187786119203768\n",
      "248, loss is 6.121021302563254e-05 with sigma: 1.0092958181862723 and mu: 1.0182799868361387\n",
      "249, loss is 5.766345702753967e-05 with sigma: 1.0089434495915877 and mu: 1.0177943241732854\n",
      "250, loss is 5.432457354984378e-05 with sigma: 1.0086040648972523 and mu: 1.0173213045912564\n",
      "251, loss is 5.118133050472849e-05 with sigma: 1.0082772097894468 and mu: 1.016860615515511\n",
      "252, loss is 4.8222208258138037e-05 with sigma: 1.007962444232428 and mu: 1.0164119510630916\n",
      "253, loss is 4.543635961440647e-05 with sigma: 1.0076593421320177 and mu: 1.0159750119643176\n",
      "254, loss is 4.281357185718223e-05 with sigma: 1.0073674909987207 and mu: 1.0155495054809967\n",
      "255, loss is 4.0344230762716436e-05 with sigma: 1.0070864916112505 and mu: 1.0151351453215114\n",
      "256, loss is 3.8019286502556356e-05 with sigma: 1.006815957681171 and mu: 1.0147316515531286\n",
      "257, loss is 3.583022135396772e-05 with sigma: 1.0065555155193013 and mu: 1.0143387505118537\n",
      "258, loss is 3.376901913797501e-05 with sigma: 1.0063048037044717 and mu: 1.013956174710138\n",
      "259, loss is 3.182813630668681e-05 with sigma: 1.006063472755163 and mu: 1.013583662742728\n",
      "260, loss is 3.000047460352284e-05 with sigma: 1.0058311848045065 and mu: 1.013220959190929\n",
      "261, loss is 2.8279355222069232e-05 with sigma: 1.0056076132790763 and mu: 1.0128678145255392\n",
      "262, loss is 2.6658494391529697e-05 with sigma: 1.0053924425818548 and mu: 1.0125239850086944\n",
      "263, loss is 2.513198031903372e-05 with sigma: 1.0051853677797133 and mu: 1.012189232594847\n",
      "264, loss is 2.3694251421443232e-05 with sigma: 1.0049860942957054 and mu: 1.01186332483109\n",
      "265, loss is 2.234007578173108e-05 with sigma: 1.0047943376064343 and mu: 1.0115460347570238\n",
      "266, loss is 2.1064531767440923e-05 with sigma: 1.0046098229447227 and mu: 1.0112371408043457\n",
      "267, loss is 1.9862989751169806e-05 with sigma: 1.0044322850077747 and mu: 1.0109364266963343\n",
      "268, loss is 1.873109487547874e-05 with sigma: 1.004261467670997 and mu: 1.010643681347384\n",
      "269, loss is 1.7664750807036127e-05 with sigma: 1.0040971237076126 and mu: 1.0103586987627389\n",
      "270, loss is 1.6660104427191872e-05 with sigma: 1.0039390145141747 and mu: 1.0100812779385562\n",
      "271, loss is 1.571353140851783e-05 with sigma: 1.0037869098420709 and mu: 1.0098112227624285\n",
      "272, loss is 1.4821622629154954e-05 with sigma: 1.0036405875350767 and mu: 1.0095483419144753\n",
      "273, loss is 1.3981171379038238e-05 with sigma: 1.0034998332730036 and mu: 1.0092924487691093\n",
      "274, loss is 1.3189161314251721e-05 with sigma: 1.0033644403214679 and mu: 1.0090433612975747\n",
      "275, loss is 1.244275511789423e-05 with sigma: 1.0032342092877857 and mu: 1.0088009019713433\n",
      "276, loss is 1.1739283827858638e-05 with sigma: 1.0031089478829902 and mu: 1.0085648976664476\n",
      "277, loss is 1.1076236793944369e-05 with sigma: 1.0029884706899481 and mu: 1.0083351795688231\n",
      "278, loss is 1.0451252228587853e-05 with sigma: 1.0028725989375429 and mu: 1.0081115830807241\n",
      "279, loss is 9.862108317374042e-06 with sigma: 1.0027611602808801 and mu: 1.0078939477282713\n",
      "280, loss is 9.30671485722359e-06 with sigma: 1.0026539885874597 and mu: 1.0076821170701813\n",
      "281, loss is 8.783105391858554e-06 with sigma: 1.0025509237292505 and mu: 1.0074759386077257\n",
      "282, loss is 8.289429815770703e-06 with sigma: 1.0024518113805974 and mu: 1.007275263695958\n",
      "283, loss is 7.823947419462196e-06 with sigma: 1.002356502821879 and mu: 1.007079947456246\n",
      "284, loss is 7.385020350203744e-06 with sigma: 1.002264854748833 and mu: 1.0068898486901348\n",
      "285, loss is 6.971107463986168e-06 with sigma: 1.002176729087457 and mu: 1.0067048297945735\n",
      "286, loss is 6.5807585456619025e-06 with sigma: 1.0020919928143888 and mu: 1.0065247566785196\n",
      "287, loss is 6.212608875580119e-06 with sigma: 1.0020105177826677 and mu: 1.0063494986809431\n",
      "288, loss is 5.865374122224341e-06 with sigma: 1.0019321805527739 and mu: 1.0061789284902445\n",
      "289, loss is 5.537845541515933e-06 with sigma: 1.0018568622288389 and mu: 1.0060129220650933\n",
      "290, loss is 5.228885464561485e-06 with sigma: 1.0017844482999188 and mu: 1.0058513585566993\n",
      "291, loss is 4.937423056654645e-06 with sigma: 1.0017148284862216 and mu: 1.0056941202325185\n",
      "292, loss is 4.662450331333679e-06 with sigma: 1.0016478965901767 and mu: 1.0055410924013954\n",
      "293, loss is 4.403018404232905e-06 with sigma: 1.0015835503522332 and mu: 1.005392163340143\n",
      "294, loss is 4.158233972363925e-06 with sigma: 1.0015216913112757 and mu: 1.0052472242215567\n",
      "295, loss is 3.927256005278194e-06 with sigma: 1.0014622246695424 and mu: 1.0051061690438554\n",
      "296, loss is 3.709292635384583e-06 with sigma: 1.0014050591619352 and mu: 1.0049688945615485\n",
      "297, loss is 3.503598235422691e-06 with sigma: 1.0013501069296058 and mu: 1.0048353002177126\n",
      "298, loss is 3.3094706718135996e-06 with sigma: 1.0012972833977072 and mu: 1.0047052880776761\n",
      "299, loss is 3.126248723275641e-06 with sigma: 1.0012465071571994 and mu: 1.0045787627640932\n",
      "300, loss is 2.953309654719834e-06 with sigma: 1.0011976998505983 and mu: 1.0044556313933994\n",
      "301, loss is 2.790066937042872e-06 with sigma: 1.001150786061557 and mu: 1.0043358035136327\n",
      "302, loss is 2.6359681039882383e-06 with sigma: 1.001105693208175 and mu: 1.0042191910436045\n",
      "303, loss is 2.490492737782232e-06 with sigma: 1.001062351439926 and mu: 1.0041057082134073\n",
      "304, loss is 2.3531505757451202e-06 with sigma: 1.001020693538099 and mu: 1.0039952715062395\n",
      "305, loss is 2.223479730549389e-06 with sigma: 1.0009806548196523 and mu: 1.0038877996015314\n",
      "306, loss is 2.1010450172395803e-06 with sigma: 1.0009421730443762 and mu: 1.0037832133193547\n",
      "307, loss is 1.9854363805436794e-06 with sigma: 1.000905188325265 and mu: 1.003681435566095\n",
      "308, loss is 1.8762674163940608e-06 with sigma: 1.0008696430420039 and mu: 1.0035823912813702\n",
      "309, loss is 1.7731739819536833e-06 with sigma: 1.0008354817574692 and mu: 1.0034860073861736\n",
      "310, loss is 1.6758128887783086e-06 with sigma: 1.0008026511371544 and mu: 1.0033922127322235\n",
      "311, loss is 1.5838606740794748e-06 with sigma: 1.0007710998714259 and mu: 1.0033009380524978\n",
      "312, loss is 1.4970124453574773e-06 with sigma: 1.0007407786005214 and mu: 1.0032121159129335\n",
      "313, loss is 1.4149807939572454e-06 with sigma: 1.000711639842202 and mu: 1.00312568066527\n",
      "314, loss is 1.3374947733791706e-06 with sigma: 1.0006836379219743 and mu: 1.0030415684010174\n",
      "315, loss is 1.2642989384223034e-06 with sigma: 1.000656728905797 and mu: 1.0029597169065274\n",
      "316, loss is 1.1951524414813093e-06 with sigma: 1.0006308705351934 and mu: 1.0028800656191446\n",
      "317, loss is 1.129828182544103e-06 with sigma: 1.0006060221646886 and mu: 1.0028025555844213\n",
      "318, loss is 1.068112009643164e-06 with sigma: 1.0005821447014962 and mu: 1.0027271294143723\n",
      "319, loss is 1.0098019667146383e-06 with sigma: 1.0005592005473787 and mu: 1.0026537312467474\n",
      "320, loss is 9.547075860076616e-07 with sigma: 1.0005371535426084 and mu: 1.0025823067053063\n",
      "321, loss is 9.026492223538323e-07 with sigma: 1.00051596891196 and mu: 1.002512802861069\n",
      "322, loss is 8.534574267787726e-07 with sigma: 1.0004956132126637 and mu: 1.0024451681945261\n",
      "323, loss is 8.069723570864882e-07 with sigma: 1.0004760542842535 and mu: 1.002379352558787\n",
      "324, loss is 7.630432231916753e-07 with sigma: 1.000457261200246 and mu: 1.002315307143645\n",
      "325, loss is 7.215277651160982e-07 with sigma: 1.0004392042215862 and mu: 1.0022529844405423\n",
      "326, loss is 6.822917616837704e-07 with sigma: 1.0004218547517985 and mu: 1.0021923382084115\n",
      "327, loss is 6.452085680783619e-07 with sigma: 1.0004051852937865 and mu: 1.0021333234403778\n",
      "328, loss is 6.10158680530847e-07 with sigma: 1.0003891694082219 and mu: 1.0020758963313008\n",
      "329, loss is 5.770293265163638e-07 with sigma: 1.000373781673466 and mu: 1.002020014246137\n",
      "330, loss is 5.457140789334835e-07 with sigma: 1.0003589976469738 and mu: 1.0019656356891056\n",
      "331, loss is 5.161124928355219e-07 with sigma: 1.0003447938281247 and mu: 1.001912720273638\n",
      "332, loss is 4.881297633683686e-07 with sigma: 1.0003311476224317 and mu: 1.0018612286930937\n",
      "333, loss is 4.616764036511873e-07 with sigma: 1.000318037307079 and mu: 1.0018111226922248\n",
      "334, loss is 4.3666794141374664e-07 with sigma: 1.0003054419977409 and mu: 1.0017623650393708\n",
      "335, loss is 4.130246332763976e-07 with sigma: 1.0002933416166369 and mu: 1.0017149194993678\n",
      "336, loss is 3.906711956238548e-07 with sigma: 1.000281716861779 and mu: 1.0016687508071542\n",
      "337, loss is 3.695365510911926e-07 with sigma: 1.0002705491773665 and mu: 1.0016238246420575\n",
      "338, loss is 3.495535897352843e-07 with sigma: 1.0002598207252884 and mu: 1.0015801076027437\n",
      "339, loss is 3.3065894402559845e-07 with sigma: 1.0002495143576944 and mu: 1.0015375671828164\n",
      "340, loss is 3.127927768365223e-07 with sigma: 1.0002396135905935 and mu: 1.0014961717470463\n",
      "341, loss is 2.958985816751137e-07 with sigma: 1.0002301025784448 and mu: 1.00145589050822\n",
      "342, loss is 2.7992299442357374e-07 with sigma: 1.000220966089703 and mu: 1.0014166935045894\n",
      "343, loss is 2.6481561591865963e-07 with sigma: 1.0002121894832854 and mu: 1.001378551577908\n",
      "344, loss is 2.505288447316658e-07 with sigma: 1.0002037586859251 and mu: 1.0013414363520412\n",
      "345, loss is 2.370177195502874e-07 with sigma: 1.0001956601703792 and mu: 1.0013053202121345\n",
      "346, loss is 2.242397705998681e-07 with sigma: 1.0001878809344598 and mu: 1.0012701762843264\n",
      "347, loss is 2.1215487957475333e-07 with sigma: 1.0001804084808577 and mu: 1.001235978415992\n",
      "348, loss is 2.0072514758293336e-07 with sigma: 1.0001732307977307 and mu: 1.0012027011565066\n",
      "349, loss is 1.8991477063576946e-07 with sigma: 1.0001663363400262 and mu: 1.001170319738511\n",
      "350, loss is 1.7968992224316608e-07 with sigma: 1.000159714011513 and mu: 1.0011388100596716\n",
      "351, loss is 1.700186427009588e-07 with sigma: 1.000153353147495 and mu: 1.0011081486649203\n",
      "352, loss is 1.6087073468089088e-07 with sigma: 1.000147243498181 and mu: 1.0010783127291594\n",
      "353, loss is 1.5221766475780956e-07 with sigma: 1.0001413752126878 and mu: 1.001049280040426\n",
      "354, loss is 1.4403247052959508e-07 with sigma: 1.0001357388236516 and mu: 1.0010210289834978\n",
      "355, loss is 1.3628967300597475e-07 with sigma: 1.0001303252324263 and mu: 1.0009935385239328\n",
      "356, loss is 1.2896519396171645e-07 with sigma: 1.0001251256948447 and mu: 1.0009667881925317\n",
      "357, loss is 1.2203627796757716e-07 with sigma: 1.0001201318075243 and mu: 1.0009407580702094\n",
      "358, loss is 1.1548141882886052e-07 with sigma: 1.0001153354946954 and mu: 1.000915428773269\n",
      "359, loss is 1.092802901781178e-07 with sigma: 1.0001107289955322 and mu: 1.000890781439064\n",
      "360, loss is 1.0341367998303322e-07 with sigma: 1.000106304851969 and mu: 1.0008667977120427\n",
      "361, loss is 9.786342874404662e-08 with sigma: 1.0001020558969818 and mu: 1.0008434597301612\n",
      "362, loss is 9.261237117086971e-08 with sigma: 1.0000979752433192 and mu: 1.000820750111658\n",
      "363, loss is 8.764428113773706e-08 with sigma: 1.0000940562726652 and mu: 1.0007986519421794\n",
      "364, loss is 8.294381973024517e-08 with sigma: 1.0000902926252162 and mu: 1.000777148762248\n",
      "365, loss is 7.84964862071794e-08 with sigma: 1.0000866781896598 and mu: 1.0007562245550636\n",
      "366, loss is 7.428857171022315e-08 with sigma: 1.000083207093537 and mu: 1.000735863734629\n",
      "367, loss is 7.03071155657193e-08 with sigma: 1.0000798736939744 and mu: 1.0007160511341926\n",
      "368, loss is 6.653986403038534e-08 with sigma: 1.0000766725687738 and mu: 1.0006967719949982\n",
      "369, loss is 6.297523134230948e-08 with sigma: 1.0000735985078428 and mu: 1.0006780119553351\n",
      "370, loss is 5.960226294566144e-08 with sigma: 1.0000706465049574 and mu: 1.0006597570398799\n",
      "371, loss is 5.6410600766670114e-08 with sigma: 1.0000678117498383 and mu: 1.000641993649323\n",
      "372, loss is 5.339045042392757e-08 with sigma: 1.0000650896205365 and mu: 1.0006247085502717\n",
      "373, loss is 5.0532550263585995e-08 with sigma: 1.0000624756761087 and mu: 1.0006078888654233\n",
      "374, loss is 4.782814211693176e-08 with sigma: 1.0000599656495772 and mu: 1.000591522064\n",
      "375, loss is 4.526894368208153e-08 with sigma: 1.0000575554411608 and mu: 1.0005755959524407\n",
      "376, loss is 4.284712243887392e-08 with sigma: 1.000055241111767 and mu: 1.0005600986653398\n",
      "377, loss is 4.055527101038921e-08 with sigma: 1.0000530188767347 and mu: 1.00054501865663\n",
      "378, loss is 3.838638388965136e-08 with sigma: 1.0000508850998204 and mu: 1.0005303446910008\n",
      "379, loss is 3.633383545458165e-08 with sigma: 1.0000488362874147 and mu: 1.000516065835545\n",
      "380, loss is 3.439135919934311e-08 with sigma: 1.000046869082984 and mu: 1.0005021714516311\n",
      "381, loss is 3.255302811314774e-08 with sigma: 1.0000449802617262 and mu: 1.000488651186992\n",
      "382, loss is 3.0813236142824514e-08 with sigma: 1.0000431667254337 and mu: 1.0004754949680252\n",
      "383, loss is 2.9166680678182286e-08 with sigma: 1.0000414254975551 and mu: 1.0004626929923015\n",
      "384, loss is 2.7608346002886234e-08 with sigma: 1.0000397537184487 and mu: 1.000450235721271\n",
      "385, loss is 2.613348765731591e-08 with sigma: 1.0000381486408185 and mu: 1.0004381138731682\n",
      "386, loss is 2.473761766175992e-08 with sigma: 1.0000366076253284 and mu: 1.0004263184161046\n",
      "387, loss is 2.3416490552878595e-08 with sigma: 1.000035128136386 and mu: 1.0004148405613484\n",
      "388, loss is 2.216609018744249e-08 with sigma: 1.0000337077380894 and mu: 1.0004036717567832\n",
      "389, loss is 2.098261727076627e-08 with sigma: 1.000032344090333 and mu: 1.0003928036805427\n",
      "390, loss is 1.9862477570011767e-08 with sigma: 1.0000310349450616 and mu: 1.0003822282348165\n",
      "391, loss is 1.880227077361709e-08 with sigma: 1.000029778142673 and mu: 1.000371937539822\n",
      "392, loss is 1.7798779961393326e-08 with sigma: 1.000028571608558 and mu: 1.0003619239279369\n",
      "393, loss is 1.6848961651522098e-08 with sigma: 1.0000274133497755 and mu: 1.000352179937992\n",
      "394, loss is 1.5949936392190806e-08 with sigma: 1.0000263014518582 and mu: 1.0003426983097143\n",
      "395, loss is 1.5098979867847652e-08 with sigma: 1.0000252340757403 and mu: 1.0003334719783212\n",
      "396, loss is 1.4293514491716568e-08 with sigma: 1.0000242094548057 and mu: 1.000324494069259\n",
      "397, loss is 1.3531101457547997e-08 with sigma: 1.000023225892052 and mu: 1.0003157578930835\n",
      "398, loss is 1.2809433225358595e-08 with sigma: 1.0000222817573627 and mu: 1.0003072569404774\n",
      "399, loss is 1.212632641704035e-08 with sigma: 1.0000213754848877 and mu: 1.0002989848774022\n",
      "400, loss is 1.1479715099583329e-08 with sigma: 1.0000205055705245 and mu: 1.0002909355403802\n",
      "401, loss is 1.0867644434146096e-08 with sigma: 1.0000196705694977 and mu: 1.000283102931903\n",
      "402, loss is 1.0288264671190116e-08 with sigma: 1.0000188690940335 and mu: 1.0002754812159642\n",
      "403, loss is 9.73982547239219e-09 with sigma: 1.0000180998111239 and mu: 1.0002680647137108\n",
      "404, loss is 9.220670541559754e-09 with sigma: 1.000017361440379 and mu: 1.0002608478992134\n",
      "405, loss is 8.72923254747541e-09 with sigma: 1.0000166527519618 and mu: 1.000253825395349\n",
      "406, loss is 8.264028322584684e-09 with sigma: 1.0000159725646054 and mu: 1.000246991969794\n",
      "407, loss is 7.823654322741528e-09 with sigma: 1.000015319743705 and mu: 1.0002403425311268\n",
      "408, loss is 7.40678233312588e-09 with sigma: 1.000014693199487 and mu: 1.0002338721250332\n",
      "409, loss is 7.012155407427442e-09 with sigma: 1.0000140918852485 and mu: 1.0002275759306154\n",
      "410, loss is 6.638584027187043e-09 with sigma: 1.0000135147956641 and mu: 1.0002214492567991\n",
      "411, loss is 6.284942469353056e-09 with sigma: 1.0000129609651616 and mu: 1.0002154875388385\n",
      "412, loss is 5.950165370706025e-09 with sigma: 1.000012429466359 and mu: 1.0002096863349144\n",
      "413, loss is 5.633244478317645e-09 with sigma: 1.0000119194085635 and mu: 1.000204041322824\n",
      "414, loss is 5.333225575961158e-09 with sigma: 1.0000114299363287 and mu: 1.00019854829676\n",
      "415, loss is 5.049205576849794e-09 with sigma: 1.0000109602280693 and mu: 1.0001932031641765\n",
      "416, loss is 4.780329773645952e-09 with sigma: 1.000010509494728 and mu: 1.0001880019427392\n",
      "417, loss is 4.5257892370991275e-09 with sigma: 1.0000100769784965 and mu: 1.0001829407573568\n",
      "418, loss is 4.284818355321765e-09 with sigma: 1.0000096619515855 and mu: 1.0001780158372937\n",
      "419, loss is 4.056692506022327e-09 with sigma: 1.000009263715043 and mu: 1.0001732235133594\n",
      "420, loss is 3.840725854419743e-09 with sigma: 1.0000088815976194 and mu: 1.000168560215174\n",
      "421, loss is 3.6362692699858008e-09 with sigma: 1.0000085149546756 and mu: 1.0001640224685073\n",
      "422, loss is 3.4427083557110835e-09 with sigma: 1.000008163167136 and mu: 1.0001596068926897\n",
      "423, loss is 3.259461583564953e-09 with sigma: 1.0000078256404805 and mu: 1.0001553101980918\n",
      "424, loss is 3.08597853054737e-09 with sigma: 1.0000075018037768 and mu: 1.000151129183673\n",
      "425, loss is 2.9217382098432344e-09 with sigma: 1.0000071911087516 and mu: 1.0001470607345966\n",
      "426, loss is 2.766247491839522e-09 with sigma: 1.000006893028896 and mu: 1.0001431018199063\n",
      "427, loss is 2.6190396102538793e-09 with sigma: 1.0000066070586078 and mu: 1.0001392494902688\n",
      "428, loss is 2.4796727486707373e-09 with sigma: 1.0000063327123676 and mu: 1.0001355008757753\n",
      "429, loss is 2.347728703176837e-09 with sigma: 1.000006069523945 and mu: 1.0001318531838017\n",
      "430, loss is 2.2228116169446453e-09 with sigma: 1.0000058170456387 and mu: 1.0001283036969282\n",
      "431, loss is 2.1045467829474644e-09 with sigma: 1.0000055748475445 and mu: 1.000124849770913\n",
      "432, loss is 1.9925795109760767e-09 with sigma: 1.000005342516853 and mu: 1.0001214888327221\n",
      "433, loss is 1.8865740556470897e-09 with sigma: 1.0000051196571738 and mu: 1.0001182183786113\n",
      "434, loss is 1.7862126019874505e-09 with sigma: 1.0000049058878882 and mu: 1.00011503597226\n",
      "435, loss is 1.6911943055436408e-09 with sigma: 1.000004700843525 and mu: 1.0001119392429554\n",
      "436, loss is 1.601234384052241e-09 with sigma: 1.0000045041731631 and mu: 1.0001089258838258\n",
      "437, loss is 1.5160632578706957e-09 with sigma: 1.0000043155398548 and mu: 1.0001059936501209\n",
      "438, loss is 1.435425736597909e-09 with sigma: 1.0000041346200748 and mu: 1.0001031403575387\n",
      "439, loss is 1.3590802492923798e-09 with sigma: 1.0000039611031886 and mu: 1.0001003638805976\n",
      "440, loss is 1.286798116088659e-09 with sigma: 1.000003794690943 and mu: 1.0000976621510524\n",
      "441, loss is 1.2183628587793517e-09 with sigma: 1.0000036350969763 and mu: 1.0000950331563525\n",
      "442, loss is 1.153569548473487e-09 with sigma: 1.0000034820463475 and mu: 1.0000924749381424\n",
      "443, loss is 1.0922241881811147e-09 with sigma: 1.0000033352750841 and mu: 1.0000899855908012\n",
      "444, loss is 1.0341431285002417e-09 with sigma: 1.0000031945297485 and mu: 1.0000875632600237\n",
      "445, loss is 9.791525146373777e-10 with sigma: 1.0000030595670197 and mu: 1.000085206141437\n",
      "446, loss is 9.270877630468314e-10 with sigma: 1.000002930153294 and mu: 1.0000829124792563\n",
      "447, loss is 8.777930661379471e-10 with sigma: 1.0000028060642987 and mu: 1.000080680564977\n",
      "448, loss is 8.311209234572304e-10 with sigma: 1.0000026870847232 and mu: 1.0000785087360997\n",
      "449, loss is 7.869316980420698e-10 with sigma: 1.000002573007863 and mu: 1.0000763953748932\n",
      "450, loss is 7.450931964613315e-10 with sigma: 1.0000024636352791 and mu: 1.000074338907187\n",
      "451, loss is 7.054802713949156e-10 with sigma: 1.00000235877647 and mu: 1.0000723378011998\n",
      "452, loss is 6.679744454520578e-10 with sigma: 1.0000022582485564 and mu: 1.0000703905663961\n",
      "453, loss is 6.324635551154319e-10 with sigma: 1.0000021618759796 and mu: 1.0000684957523769\n",
      "454, loss is 5.988414137608354e-10 with sigma: 1.00000206949021 and mu: 1.000066651947798\n",
      "455, loss is 5.670074926726539e-10 with sigma: 1.000001980929469 and mu: 1.0000648577793187\n",
      "456, loss is 5.368666191421121e-10 with sigma: 1.0000018960384596 and mu: 1.0000631119105778\n",
      "457, loss is 5.083286906933893e-10 with sigma: 1.0000018146681104 and mu: 1.0000614130411978\n",
      "458, loss is 4.813084045968602e-10 with sigma: 1.0000017366753275 and mu: 1.000059759905816\n",
      "459, loss is 4.55725001837425e-10 with sigma: 1.0000016619227567 and mu: 1.000058151273142\n",
      "460, loss is 4.315020247654303e-10 with sigma: 1.0000015902785557 and mu: 1.0000565859450385\n",
      "461, loss is 4.085670877104074e-10 with sigma: 1.0000015216161753 and mu: 1.0000550627556308\n",
      "462, loss is 3.868516598308836e-10 with sigma: 1.0000014558141477 and mu: 1.0000535805704358\n",
      "463, loss is 3.6629085957605266e-10 with sigma: 1.0000013927558855 and mu: 1.0000521382855179\n",
      "464, loss is 3.46823260126847e-10 with sigma: 1.0000013323294872 and mu: 1.0000507348266656\n",
      "465, loss is 3.283907052283001e-10 with sigma: 1.00000127442755 and mu: 1.0000493691485917\n",
      "466, loss is 3.1093813485520134e-10 with sigma: 1.0000012189469913 and mu: 1.000048040234154\n",
      "467, loss is 2.9441342017670853e-10 with sigma: 1.0000011657888768 and mu: 1.0000467470935974\n",
      "468, loss is 2.787672073434867e-10 with sigma: 1.0000011148582542 and mu: 1.0000454887638162\n",
      "469, loss is 2.6395276961778387e-10 with sigma: 1.000001066063996 and mu: 1.0000442643076368\n",
      "470, loss is 2.4992586736390137e-10 with sigma: 1.0000010193186455 and mu: 1.0000430728131193\n",
      "471, loss is 2.366446155617831e-10 with sigma: 1.0000009745382716 and mu: 1.0000419133928775\n",
      "472, loss is 2.2406935833598129e-10 with sigma: 1.0000009316423273 and mu: 1.0000407851834183\n",
      "473, loss is 2.1216255021982085e-10 with sigma: 1.0000008905535154 and mu: 1.0000396873444979\n",
      "474, loss is 2.0088864372888882e-10 with sigma: 1.0000008511976581 and mu: 1.0000386190584958\n",
      "475, loss is 1.9021398295006669e-10 with sigma: 1.000000813503573 and mu: 1.0000375795298058\n",
      "476, loss is 1.8010670278296937e-10 with sigma: 1.000000777402953 and mu: 1.000036567984243\n",
      "477, loss is 1.7053663357573048e-10 with sigma: 1.0000007428302518 and mu: 1.0000355836684665\n",
      "478, loss is 1.6147521084106017e-10 with sigma: 1.0000007097225736 and mu: 1.000034625849419\n",
      "479, loss is 1.5289538977605486e-10 with sigma: 1.000000678019567 and mu: 1.0000336938137804\n",
      "480, loss is 1.447715643458211e-10 with sigma: 1.0000006476633225 and mu: 1.0000327868674352\n",
      "481, loss is 1.3707949069017384e-10 with sigma: 1.0000006185982766 and mu: 1.0000319043349573\n",
      "482, loss is 1.29796214592182e-10 with sigma: 1.000000590771116 and mu: 1.0000310455591046\n",
      "483, loss is 1.229000028345468e-10 with sigma: 1.0000005641306888 and mu: 1.0000302099003313\n",
      "484, loss is 1.1637027819215682e-10 with sigma: 1.0000005386279172 and mu: 1.0000293967363099\n",
      "485, loss is 1.1018755790827829e-10 with sigma: 1.000000514215715 and mu: 1.0000286054614682\n",
      "486, loss is 1.0433339544325585e-10 with sigma: 1.000000490848907 and mu: 1.0000278354865386\n",
      "487, loss is 9.879032531325388e-11 with sigma: 1.000000468484154 and mu: 1.000027086238118\n",
      "488, loss is 9.354181088846259e-11 with sigma: 1.000000447079877 and mu: 1.000026357158241\n",
      "489, loss is 8.857219495980383e-11 with sigma: 1.000000426596188 and mu: 1.000025647703965\n",
      "490, loss is 8.38666529398532e-11 with sigma: 1.000000406994822 and mu: 1.0000249573469646\n",
      "491, loss is 7.941114855978236e-11 with sigma: 1.0000003882390716 and mu: 1.0000242855731383\n",
      "492, loss is 7.519239192597468e-11 with sigma: 1.0000003702937241 and mu: 1.000023631882226\n",
      "493, loss is 7.119779980202235e-11 with sigma: 1.0000003531250024 and mu: 1.0000229957874358\n",
      "494, loss is 6.741545801667586e-11 with sigma: 1.0000003367005064 and mu: 1.0000223768150813\n",
      "495, loss is 6.383408587438667e-11 with sigma: 1.000000320989158 and mu: 1.0000217745042295\n",
      "496, loss is 6.044300244192241e-11 with sigma: 1.0000003059611478 and mu: 1.0000211884063561\n",
      "497, loss is 5.723209465347778e-11 with sigma: 1.0000002915878845 and mu: 1.0000206180850126\n",
      "498, loss is 5.419178710226108e-11 with sigma: 1.0000002778419452 and mu: 1.0000200631155003\n",
      "499, loss is 5.131301343814105e-11 with sigma: 1.000000264697029 and mu: 1.0000195230845546\n",
      "500, loss is 4.8587189294009597e-11 with sigma: 1.000000252127911 and mu: 1.0000189975900364\n",
      "501, loss is 4.600618665002953e-11 with sigma: 1.0000002401103998 and mu: 1.0000184862406336\n",
      "502, loss is 4.35623095624136e-11 with sigma: 1.000000228621295 and mu: 1.0000179886555685\n",
      "503, loss is 4.1248271182068356e-11 with sigma: 1.0000002176383478 and mu: 1.0000175044643145\n",
      "504, loss is 3.905717200119831e-11 with sigma: 1.0000002071402225 and mu: 1.0000170333063203\n",
      "505, loss is 3.698247925564692e-11 with sigma: 1.0000001971064598 and mu: 1.0000165748307412\n",
      "506, loss is 3.501800741825314e-11 with sigma: 1.0000001875174405 and mu: 1.000016128696178\n",
      "507, loss is 3.3157899737748566e-11 with sigma: 1.0000001783543528 and mu: 1.000015694570422\n",
      "508, loss is 3.13966107550282e-11 with sigma: 1.0000001695991587 and mu: 1.000015272130208\n",
      "509, loss is 2.9728889752944786e-11 with sigma: 1.0000001612345633 and mu: 1.000014861060974\n",
      "510, loss is 2.814976508234601e-11 with sigma: 1.0000001532439844 and mu: 1.0000144610566262\n",
      "511, loss is 2.6654529324460768e-11 with sigma: 1.0000001456115235 and mu: 1.0000140718193105\n",
      "512, loss is 2.5238725244156018e-11 with sigma: 1.0000001383219388 and mu: 1.000013693059192\n",
      "513, loss is 2.3898132488911968e-11 with sigma: 1.0000001313606177 and mu: 1.0000133244942384\n",
      "514, loss is 2.2628754992870226e-11 with sigma: 1.000000124713552 and mu: 1.0000129658500094\n",
      "515, loss is 2.1426809055189284e-11 with sigma: 1.0000001183673128 and mu: 1.0000126168594534\n",
      "516, loss is 2.0288712051431953e-11 with sigma: 1.0000001123090276 and mu: 1.0000122772627076\n",
      "517, loss is 1.921107174053114e-11 with sigma: 1.000000106526357 and mu: 1.000011946806905\n",
      "518, loss is 1.819067614871658e-11 with sigma: 1.0000001010074737 and mu: 1.000011625245986\n",
      "519, loss is 1.7224483983837317e-11 with sigma: 1.000000095741041 and mu: 1.000011312340515\n",
      "520, loss is 1.6309615563974237e-11 with sigma: 1.000000090716194 and mu: 1.0000110078575015\n",
      "521, loss is 1.5443344229396915e-11 with sigma: 1.0000000859225187 and mu: 1.0000107115702281\n",
      "522, loss is 1.462308820404134e-11 with sigma: 1.0000000813500352 and mu: 1.00001042325808\n",
      "523, loss is 1.3846402898597949e-11 with sigma: 1.0000000769891793 and mu: 1.0000101427063817\n",
      "524, loss is 1.3110973617957064e-11 with sigma: 1.0000000728307854 and mu: 1.0000098697062365\n",
      "525, loss is 1.2414608656393919e-11 with sigma: 1.0000000688660706 and mu: 1.0000096040543713\n",
      "526, loss is 1.1755232763273095e-11 with sigma: 1.000000065086619 and mu: 1.0000093455529853\n",
      "527, loss is 1.1130880950813155e-11 with sigma: 1.0000000614843665 and mu: 1.000009094009602\n",
      "528, loss is 1.0539692635895643e-11 with sigma: 1.0000000580515869 and mu: 1.0000088492369268\n",
      "529, loss is 9.979906090815203e-12 with sigma: 1.0000000547808774 and mu: 1.0000086110527064\n",
      "530, loss is 9.449853191145787e-12 with sigma: 1.000000051665146 and mu: 1.0000083792795944\n",
      "531, loss is 8.947954438922837e-12 with sigma: 1.0000000486975982 and mu: 1.000008153745018\n",
      "532, loss is 8.47271425497313e-12 with sigma: 1.0000000458717255 and mu: 1.0000079342810502\n",
      "533, loss is 8.022716517961228e-12 with sigma: 1.0000000431812932 and mu: 1.0000077207242841\n",
      "534, loss is 7.596620342658214e-12 with sigma: 1.000000040620329 and mu: 1.0000075129157122\n",
      "535, loss is 7.193156082739466e-12 with sigma: 1.000000038183113 and mu: 1.0000073107006069\n",
      "536, loss is 6.811121543537071e-12 with sigma: 1.0000000358641659 and mu: 1.000007113928406\n",
      "537, loss is 6.449378398979489e-12 with sigma: 1.0000000336582409 and mu: 1.0000069224525998\n",
      "538, loss is 6.106848797337076e-12 with sigma: 1.000000031560313 and mu: 1.0000067361306233\n",
      "539, loss is 5.782512148687448e-12 with sigma: 1.0000000295655702 and mu: 1.0000065548237487\n",
      "540, loss is 5.4754020812634846e-12 with sigma: 1.0000000276694043 and mu: 1.0000063783969826\n",
      "541, loss is 5.184603560682105e-12 with sigma: 1.0000000258674033 and mu: 1.0000062067189655\n",
      "542, loss is 4.9092501634453394e-12 with sigma: 1.0000000241553426 and mu: 1.000006039661874\n",
      "543, loss is 4.648521493381066e-12 with sigma: 1.0000000225291776 and mu: 1.0000058771013258\n",
      "544, loss is 4.401640735331923e-12 with sigma: 1.0000000209850362 and mu: 1.0000057189162863\n",
      "545, loss is 4.167872340463367e-12 with sigma: 1.0000000195192114 and mu: 1.0000055649889794\n",
      "546, loss is 3.946519833888647e-12 with sigma: 1.000000018128155 and mu: 1.0000054152047992\n",
      "547, loss is 3.736923738149299e-12 with sigma: 1.0000000168084706 and mu: 1.0000052694522248\n",
      "548, loss is 3.5384596082139306e-12 with sigma: 1.0000000155569078 and mu: 1.0000051276227373\n",
      "549, loss is 3.350536169248649e-12 with sigma: 1.0000000143703551 and mu: 1.0000049896107388\n",
      "550, loss is 3.1725935553299794e-12 with sigma: 1.0000000132458353 and mu: 1.0000048553134742\n",
      "551, loss is 3.0041016407990566e-12 with sigma: 1.0000000121804993 and mu: 1.0000047246309542\n",
      "552, loss is 2.84455845945823e-12 with sigma: 1.0000000111716207 and mu: 1.0000045974658813\n",
      "553, loss is 2.693488709032402e-12 with sigma: 1.0000000102165914 and mu: 1.000004473723577\n",
      "554, loss is 2.5504423344810997e-12 with sigma: 1.0000000093129153 and mu: 1.0000043533119107\n",
      "555, loss is 2.4149931867847293e-12 with sigma: 1.0000000084582055 and mu: 1.0000042361412327\n",
      "556, loss is 2.2867377534827013e-12 with sigma: 1.000000007650178 and mu: 1.0000041221243061\n",
      "557, loss is 2.165293955270483e-12 with sigma: 1.0000000068866486 and mu: 1.0000040111762423\n",
      "558, loss is 2.050300007551099e-12 with sigma: 1.0000000061655279 and mu: 1.0000039032144374\n",
      "559, loss is 1.941413343214556e-12 with sigma: 1.0000000054848175 and mu: 1.0000037981585117\n",
      "560, loss is 1.838309590511535e-12 with sigma: 1.000000004842607 and mu: 1.0000036959302485\n",
      "561, loss is 1.740681607307449e-12 with sigma: 1.0000000042370691 and mu: 1.000003596453537\n",
      "562, loss is 1.6482385654181601e-12 with sigma: 1.0000000036664571 and mu: 1.0000034996543148\n",
      "563, loss is 1.5607050841893862e-12 with sigma: 1.0000000031291008 and mu: 1.0000034054605131\n",
      "564, loss is 1.4778204097558627e-12 with sigma: 1.0000000026234033 and mu: 1.0000033138020032\n",
      "565, loss is 1.3993376383341848e-12 with sigma: 1.0000000021478388 and mu: 1.0000032246105441\n",
      "566, loss is 1.3250229804181425e-12 with sigma: 1.0000000017009487 and mu: 1.0000031378197316\n",
      "567, loss is 1.2546550638500539e-12 with sigma: 1.000000001281339 and mu: 1.0000030533649489\n",
      "568, loss is 1.188024274365403e-12 with sigma: 1.0000000008876775 and mu: 1.0000029711833185\n",
      "569, loss is 1.124932131520152e-12 with sigma: 1.0000000005186915 and mu: 1.0000028912136556\n",
      "570, loss is 1.0651906964485166e-12 with sigma: 1.000000000173165 and mu: 1.000002813396422\n",
      "571, loss is 1.0086220124541894e-12 with sigma: 0.9999999998499364 and mu: 1.0000027376736824\n",
      "572, loss is 9.550575747609442e-13 with sigma: 0.9999999995478959 and mu: 1.000002663989061\n",
      "573, loss is 9.043378284985101e-13 with sigma: 0.9999999992659837 and mu: 1.0000025922876992\n",
      "574, loss is 8.563116928787954e-13 with sigma: 0.9999999990031878 and mu: 1.0000025225162152\n",
      "575, loss is 8.10836111376124e-13 with sigma: 0.9999999987585418 and mu: 1.0000024546226642\n",
      "576, loss is 7.67775625708356e-13 with sigma: 0.9999999985311231 and mu: 1.0000023885564995\n",
      "577, loss is 7.270019720107677e-13 with sigma: 0.9999999983200506 and mu: 1.0000023242685347\n",
      "578, loss is 6.883936984233086e-13 with sigma: 0.9999999981244837 and mu: 1.000002261710908\n",
      "579, loss is 6.518358041022285e-13 with sigma: 0.9999999979436199 and mu: 1.000002200837045\n",
      "580, loss is 6.17219395577687e-13 with sigma: 0.9999999977766936 and mu: 1.0000021416016258\n",
      "581, loss is 5.844413631496505e-13 with sigma: 0.999999997622974 and mu: 1.00000208396055\n",
      "582, loss is 5.534040732659054e-13 with sigma: 0.999999997481764 and mu: 1.000002027870904\n",
      "583, loss is 5.240150777368639e-13 with sigma: 0.9999999973523989 and mu: 1.0000019732909302\n",
      "584, loss is 4.961868385266322e-13 with sigma: 0.9999999972342444 and mu: 1.000001920179994\n",
      "585, loss is 4.698364663152083e-13 with sigma: 0.9999999971266958 and mu: 1.0000018684985545\n",
      "586, loss is 4.4488547472981587e-13 with sigma: 0.9999999970291767 and mu: 1.0000018182081363\n",
      "587, loss is 4.2125954523836233e-13 with sigma: 0.9999999969411375 and mu: 1.0000017692712984\n",
      "588, loss is 3.988883066340633e-13 with sigma: 0.9999999968620541 and mu: 1.000001721651608\n",
      "589, loss is 3.777051250055885e-13 with sigma: 0.9999999967914274 and mu: 1.000001675313613\n",
      "590, loss is 3.576469054669154e-13 with sigma: 0.9999999967287817 and mu: 1.0000016302228156\n",
      "591, loss is 3.386539039456154e-13 with sigma: 0.9999999966736638 and mu: 1.0000015863456466\n",
      "592, loss is 3.2066954949265397e-13 with sigma: 0.9999999966256421 and mu: 1.0000015436494403\n",
      "593, loss is 3.0364027546842673e-13 with sigma: 0.9999999965843056 and mu: 1.0000015021024102\n",
      "594, loss is 2.875153601407003e-13 with sigma: 0.999999996549263 and mu: 1.0000014616736255\n",
      "595, loss is 2.7224677544559976e-13 with sigma: 0.9999999965201417 and mu: 1.0000014223329876\n",
      "596, loss is 2.5778904415314867e-13 with sigma: 0.9999999964965872 and mu: 1.0000013840512083\n",
      "597, loss is 2.440991042728136e-13 with sigma: 0.9999999964782622 and mu: 1.000001346799788\n",
      "598, loss is 2.311361808053138e-13 with sigma: 0.9999999964648458 and mu: 1.0000013105509937\n",
      "599, loss is 2.1886166412753394e-13 with sigma: 0.9999999964560328 and mu: 1.0000012752778393\n",
      "600, loss is 2.0723899517259933e-13 with sigma: 0.9999999964515329 and mu: 1.0000012409540648\n",
      "601, loss is 1.9623355641714503e-13 with sigma: 0.9999999964510703 and mu: 1.0000012075541171\n",
      "602, loss is 1.8581256891230106e-13 with sigma: 0.9999999964543828 and mu: 1.000001175053131\n",
      "603, loss is 1.7594499444583738e-13 with sigma: 0.9999999964612212 and mu: 1.0000011434269103\n",
      "604, loss is 1.66601443101128e-13 with sigma: 0.999999996471349 and mu: 1.0000011126519102\n",
      "605, loss is 1.5775408594843659e-13 with sigma: 0.9999999964845413 and mu: 1.0000010827052197\n",
      "606, loss is 1.4937657200050629e-13 with sigma: 0.999999996500585 and mu: 1.0000010535645447\n",
      "607, loss is 1.4144394956495847e-13 with sigma: 0.9999999965192776 and mu: 1.0000010252081908\n",
      "608, loss is 1.3393259209556087e-13 with sigma: 0.9999999965404269 and mu: 1.0000009976150475\n",
      "609, loss is 1.268201279316862e-13 with sigma: 0.999999996563851 and mu: 1.000000970764573\n",
      "610, loss is 1.2008537337312511e-13 with sigma: 0.9999999965893769 and mu: 1.0000009446367777\n",
      "611, loss is 1.1370826966411724e-13 with sigma: 0.999999996616841 and mu: 1.0000009192122106\n",
      "612, loss is 1.0766982352275787e-13 with sigma: 0.9999999966460883 and mu: 1.000000894471944\n",
      "613, loss is 1.0195205017349679e-13 with sigma: 0.9999999966769718 and mu: 1.0000008703975598\n",
      "614, loss is 9.653792006714299e-14 with sigma: 0.9999999967093525 and mu: 1.0000008469711354\n",
      "615, loss is 9.141130789045474e-14 with sigma: 0.9999999967430988 and mu: 1.000000824175231\n",
      "616, loss is 8.655694487245231e-14 with sigma: 0.9999999967780863 and mu: 1.0000008019928757\n",
      "617, loss is 8.196037302310927e-14 with sigma: 0.9999999968141972 and mu: 1.000000780407556\n",
      "618, loss is 7.760790217495936e-14 with sigma: 0.9999999968513203 and mu: 1.000000759403202\n",
      "619, loss is 7.348656912324922e-14 with sigma: 0.9999999968893508 and mu: 1.0000007389641774\n",
      "620, loss is 6.958409928471104e-14 with sigma: 0.9999999969281893 and mu: 1.000000719075266\n",
      "621, loss is 6.588886973524917e-14 with sigma: 0.9999999969677423 and mu: 1.0000006997216613\n",
      "622, loss is 6.238987489616186e-14 with sigma: 0.9999999970079216 and mu: 1.0000006808889554\n",
      "623, loss is 5.907669365394386e-14 with sigma: 0.9999999970486441 and mu: 1.0000006625631284\n",
      "624, loss is 5.593945830763072e-14 with sigma: 0.9999999970898313 and mu: 1.0000006447305374\n",
      "625, loss is 5.2968825206325185e-14 with sigma: 0.9999999971314097 and mu: 1.000000627377907\n",
      "626, loss is 5.015594687367329e-14 with sigma: 0.9999999971733099 and mu: 1.000000610492319\n",
      "627, loss is 4.749244571373229e-14 with sigma: 0.9999999972154667 and mu: 1.0000005940612027\n",
      "628, loss is 4.497038899558575e-14 with sigma: 0.999999997257819 and mu: 1.000000578072326\n",
      "629, loss is 4.2582265331425864e-14 with sigma: 0.9999999973003092 and mu: 1.0000005625137862\n",
      "630, loss is 4.0320962156137784e-14 with sigma: 0.9999999973428837 and mu: 1.0000005473740006\n",
      "631, loss is 3.8179744655940313e-14 with sigma: 0.9999999973854921 and mu: 1.0000005326416983\n",
      "632, loss is 3.615223569423792e-14 with sigma: 0.999999997428087 and mu: 1.000000518305912\n",
      "633, loss is 3.423239673731294e-14 with sigma: 0.9999999974706245 and mu: 1.0000005043559692\n",
      "634, loss is 3.2414510026005506e-14 with sigma: 0.9999999975130635 and mu: 1.0000004907814852\n",
      "635, loss is 3.0693161338718784e-14 with sigma: 0.9999999975553655 and mu: 1.0000004775723546\n",
      "636, loss is 2.90632240432958e-14 with sigma: 0.9999999975974948 and mu: 1.0000004647187435\n",
      "637, loss is 2.7519843765491935e-14 with sigma: 0.9999999976394183 and mu: 1.0000004522110832\n",
      "638, loss is 2.6058423902032896e-14 with sigma: 0.9999999976811049 and mu: 1.0000004400400628\n",
      "639, loss is 2.467461194116603e-14 with sigma: 0.9999999977225262 and mu: 1.0000004281966213\n",
      "640, loss is 2.336428656300105e-14 with sigma: 0.9999999977636558 and mu: 1.000000416671942\n",
      "641, loss is 2.212354524783848e-14 with sigma: 0.9999999978044691 and mu: 1.0000004054574456\n",
      "642, loss is 2.0948692754185657e-14 with sigma: 0.9999999978449438 and mu: 1.0000003945447833\n",
      "643, loss is 1.9836230094111924e-14 with sigma: 0.999999997885059 and mu: 1.0000003839258313\n",
      "644, loss is 1.8782844033389897e-14 with sigma: 0.999999997924796 and mu: 1.0000003735926846\n",
      "645, loss is 1.778539737682285e-14 with sigma: 0.9999999979641373 and mu: 1.0000003635376504\n",
      "646, loss is 1.684091946136798e-14 with sigma: 0.9999999980030673 and mu: 1.0000003537532438\n",
      "647, loss is 1.594659740414467e-14 with sigma: 0.9999999980415715 and mu: 1.0000003442321805\n",
      "648, loss is 1.509976767886318e-14 with sigma: 0.999999998079637 and mu: 1.000000334967373\n",
      "649, loss is 1.4297908265120765e-14 with sigma: 0.9999999981172523 and mu: 1.000000325951924\n",
      "650, loss is 1.3538630984091681e-14 with sigma: 0.9999999981544069 and mu: 1.0000003171791219\n",
      "651, loss is 1.2819674572856389e-14 with sigma: 0.9999999981910915 and mu: 1.000000308642436\n",
      "652, loss is 1.2138897803896587e-14 with sigma: 0.9999999982272981 and mu: 1.0000003003355116\n",
      "653, loss is 1.1494273155441951e-14 with sigma: 0.9999999982630196 and mu: 1.0000002922521642\n",
      "654, loss is 1.0883880780375099e-14 with sigma: 0.9999999982982497 and mu: 1.0000002843863767\n",
      "655, loss is 1.0305902817188482e-14 with sigma: 0.9999999983329834 and mu: 1.0000002767322933\n",
      "656, loss is 9.758617907013954e-15 with sigma: 0.9999999983672162 and mu: 1.000000269284216\n",
      "657, loss is 9.240396109797567e-15 with sigma: 0.9999999984009447 and mu: 1.0000002620366004\n",
      "658, loss is 8.749694046233803e-15 with sigma: 0.999999998434166 and mu: 1.000000254984051\n",
      "659, loss is 8.285050301076229e-15 with sigma: 0.999999998466878 and mu: 1.0000002481213175\n",
      "660, loss is 7.845081058738045e-15 with sigma: 0.9999999984990795 and mu: 1.0000002414432911\n",
      "661, loss is 7.428475995222494e-15 with sigma: 0.9999999985307696 and mu: 1.0000002349450006\n",
      "662, loss is 7.033994379906752e-15 with sigma: 0.9999999985619482 and mu: 1.0000002286216083\n",
      "663, loss is 6.6604613629742296e-15 with sigma: 0.9999999985926157 and mu: 1.000000222468407\n",
      "664, loss is 6.3067644689213636e-15 with sigma: 0.9999999986227729 and mu: 1.000000216480816\n",
      "665, loss is 5.9718503289622465e-15 with sigma: 0.9999999986524212 and mu: 1.000000210654378\n",
      "666, loss is 5.654721488049533e-15 with sigma: 0.9999999986815624 and mu: 1.0000002049847554\n",
      "667, loss is 5.3544334969612414e-15 with sigma: 0.9999999987101988 and mu: 1.000000199467728\n",
      "668, loss is 5.070092010903724e-15 with sigma: 0.9999999987383331 and mu: 1.0000001940991883\n",
      "669, loss is 4.800850209419328e-15 with sigma: 0.9999999987659681 and mu: 1.00000018887514\n",
      "670, loss is 4.545906226007553e-15 with sigma: 0.9999999987931073 and mu: 1.000000183791694\n",
      "671, loss is 4.3045007892093e-15 with sigma: 0.9999999988197542 and mu: 1.0000001788450663\n",
      "672, loss is 4.075914964120591e-15 with sigma: 0.9999999988459127 and mu: 1.0000001740315743\n",
      "673, loss is 3.859467965182944e-15 with sigma: 0.9999999988715871 and mu: 1.0000001693476348\n",
      "674, loss is 3.654515159493658e-15 with sigma: 0.9999999988967817 and mu: 1.000000164789761\n",
      "675, loss is 3.460446171582958e-15 with sigma: 0.9999999989215012 and mu: 1.0000001603545596\n",
      "676, loss is 3.2766830257960483e-15 with sigma: 0.9999999989457503 and mu: 1.0000001560387293\n",
      "677, loss is 3.1026784214894712e-15 with sigma: 0.9999999989695342 and mu: 1.0000001518390569\n",
      "678, loss is 2.937914165670071e-15 with sigma: 0.999999998992858 and mu: 1.0000001477524163\n",
      "679, loss is 2.781899541701943e-15 with sigma: 0.9999999990157269 and mu: 1.0000001437757653\n",
      "680, loss is 2.6341699151949295e-15 with sigma: 0.9999999990381465 and mu: 1.0000001399061436\n",
      "681, loss is 2.4942853108299947e-15 with sigma: 0.9999999990601224 and mu: 1.0000001361406703\n",
      "682, loss is 2.3618291288862248e-15 with sigma: 0.9999999990816602 and mu: 1.0000001324765424\n",
      "683, loss is 2.2364068885045526e-15 with sigma: 0.9999999991027657 and mu: 1.0000001289110323\n",
      "684, loss is 2.117645073866439e-15 with sigma: 0.9999999991234447 and mu: 1.0000001254414859\n",
      "685, loss is 2.0051899737978132e-15 with sigma: 0.9999999991437033 and mu: 1.00000012206532\n",
      "686, loss is 1.898706677520589e-15 with sigma: 0.9999999991635473 and mu: 1.0000001187800216\n",
      "687, loss is 1.7978780594791935e-15 with sigma: 0.9999999991829829 and mu: 1.0000001155831448\n",
      "688, loss is 1.7024038355743094e-15 with sigma: 0.999999999202016 and mu: 1.0000001124723101\n",
      "689, loss is 1.6119996712580348e-15 with sigma: 0.9999999992206527 and mu: 1.0000001094452016\n",
      "690, loss is 1.5263963140472242e-15 with sigma: 0.9999999992388993 and mu: 1.0000001064995656\n",
      "691, loss is 1.4453388329162813e-15 with sigma: 0.9999999992567618 and mu: 1.0000001036332096\n",
      "692, loss is 1.3685858139635728e-15 with sigma: 0.9999999992742463 and mu: 1.0000001008439996\n",
      "693, loss is 1.2959086845189897e-15 with sigma: 0.9999999992913591 and mu: 1.0000000981298596\n",
      "694, loss is 1.2270909898233898e-15 with sigma: 0.9999999993081061 and mu: 1.0000000954887687\n",
      "695, loss is 1.161927778780865e-15 with sigma: 0.9999999993244936 and mu: 1.0000000929187611\n",
      "696, loss is 1.1002249906387583e-15 with sigma: 0.9999999993405276 and mu: 1.0000000904179236\n",
      "697, loss is 1.0417988588786538e-15 with sigma: 0.9999999993562143 and mu: 1.0000000879843944\n",
      "698, loss is 9.86475374975567e-16 with sigma: 0.9999999993715597 and mu: 1.000000085616362\n",
      "699, loss is 9.340897835921263e-16 with sigma: 0.9999999993865698 and mu: 1.0000000833120637\n",
      "700, loss is 8.844860723502235e-16 with sigma: 0.9999999994012505 and mu: 1.000000081069784\n",
      "701, loss is 8.375165091548396e-16 with sigma: 0.9999999994156079 and mu: 1.0000000788878538\n",
      "702, loss is 7.930412055571549e-16 with sigma: 0.9999999994296478 and mu: 1.0000000767646486\n",
      "703, loss is 7.509277149687707e-16 with sigma: 0.999999999443376 and mu: 1.0000000746985882\n",
      "704, loss is 7.110506112553367e-16 with sigma: 0.9999999994567984 and mu: 1.0000000726881342\n",
      "705, loss is 6.732911328139465e-16 with sigma: 0.9999999994699206 and mu: 1.0000000707317902\n",
      "706, loss is 6.375368279206327e-16 with sigma: 0.9999999994827483 and mu: 1.0000000688280999\n",
      "707, loss is 6.036812136593818e-16 with sigma: 0.9999999994952873 and mu: 1.000000066975646\n",
      "708, loss is 5.716234619433438e-16 with sigma: 0.9999999995075429 and mu: 1.0000000651730496\n",
      "709, loss is 5.412680993193873e-16 with sigma: 0.9999999995195209 and mu: 1.0000000634189687\n",
      "710, loss is 5.125247228469413e-16 with sigma: 0.9999999995312265 and mu: 1.0000000617120979\n",
      "711, loss is 4.853077265742497e-16 with sigma: 0.9999999995426652 and mu: 1.000000060051166\n",
      "712, loss is 4.595360581373235e-16 with sigma: 0.9999999995538421 and mu: 1.0000000584349371\n",
      "713, loss is 4.351329630424086e-16 with sigma: 0.9999999995647626 and mu: 1.0000000568622078\n",
      "714, loss is 4.1202576594458253e-16 with sigma: 0.9999999995754318 and mu: 1.0000000553318074\n",
      "715, loss is 3.9014564843780754e-16 with sigma: 0.999999999585855 and mu: 1.0000000538425966\n",
      "716, loss is 3.69427446742246e-16 with sigma: 0.9999999995960368 and mu: 1.0000000523934667\n",
      "717, loss is 3.498094615643848e-16 with sigma: 0.9999999996059825 and mu: 1.000000050983339\n",
      "718, loss is 3.312332641636492e-16 with sigma: 0.9999999996156969 and mu: 1.000000049611164\n",
      "719, loss is 3.136435345971288e-16 with sigma: 0.9999999996251846 and mu: 1.0000000482759202\n",
      "720, loss is 2.9698788509289434e-16 with sigma: 0.9999999996344506 and mu: 1.0000000469766133\n",
      "721, loss is 2.812167148952714e-16 with sigma: 0.9999999996434995 and mu: 1.0000000457122762\n",
      "722, loss is 2.6628305297745106e-16 with sigma: 0.9999999996523358 and mu: 1.0000000444819679\n",
      "723, loss is 2.5214242478203255e-16 with sigma: 0.999999999660964 and mu: 1.0000000432847724\n",
      "724, loss is 2.3875271821504575e-16 with sigma: 0.9999999996693886 and mu: 1.0000000421197985\n",
      "725, loss is 2.2607405446468027e-16 with sigma: 0.9999999996776139 and mu: 1.0000000409861791\n",
      "726, loss is 2.140686769181344e-16 with sigma: 0.9999999996856441 and mu: 1.0000000398830702\n",
      "727, loss is 2.0270082894389964e-16 with sigma: 0.9999999996934836 and mu: 1.0000000388096506\n",
      "728, loss is 1.9193665798893562e-16 with sigma: 0.9999999997011365 and mu: 1.0000000377651213\n",
      "729, loss is 1.8174410260308094e-16 with sigma: 0.9999999997086068 and mu: 1.0000000367487045\n",
      "730, loss is 1.7209281238991889e-16 with sigma: 0.9999999997158985 and mu: 1.000000035759644\n",
      "731, loss is 1.629540409718132e-16 with sigma: 0.9999999997230156 and mu: 1.0000000347972031\n",
      "732, loss is 1.5430057241676002e-16 with sigma: 0.9999999997299619 and mu: 1.0000000338606656\n",
      "733, loss is 1.4610663630635207e-16 with sigma: 0.9999999997367411 and mu: 1.0000000329493344\n",
      "734, loss is 1.3834782868933146e-16 with sigma: 0.9999999997433571 and mu: 1.0000000320625309\n",
      "735, loss is 1.3100104169705218e-16 with sigma: 0.9999999997498134 and mu: 1.000000031199595\n",
      "736, loss is 1.2404439787769407e-16 with sigma: 0.9999999997561135 and mu: 1.0000000303598842\n",
      "737, loss is 1.1745717620294847e-16 with sigma: 0.9999999997622612 and mu: 1.0000000295427736\n",
      "738, loss is 1.1121976212342692e-16 with sigma: 0.9999999997682597 and mu: 1.000000028747655\n",
      "739, loss is 1.053135782200286e-16 with sigma: 0.9999999997741125 and mu: 1.0000000279739363\n",
      "740, loss is 9.972103498208588e-17 with sigma: 0.9999999997798228 and mu: 1.0000000272210416\n",
      "741, loss is 9.442547617187181e-17 with sigma: 0.9999999997853939 and mu: 1.0000000264884106\n",
      "742, loss is 8.941113209642231e-17 with sigma: 0.999999999790829 and mu: 1.0000000257754977\n",
      "743, loss is 8.466306855844413e-17 with sigma: 0.9999999997961312 and mu: 1.0000000250817724\n",
      "744, loss is 8.016714520897471e-17 with sigma: 0.9999999998013035 and mu: 1.0000000244067182\n",
      "745, loss is 7.590997100249461e-17 with sigma: 0.9999999998063489 and mu: 1.0000000237498323\n",
      "746, loss is 7.187886885507043e-17 with sigma: 0.9999999998112704 and mu: 1.000000023110626\n",
      "747, loss is 6.80618341950168e-17 with sigma: 0.9999999998160708 and mu: 1.0000000224886236\n",
      "748, loss is 6.444749761255009e-17 with sigma: 0.9999999998207529 and mu: 1.0000000218833618\n",
      "749, loss is 6.102509573785413e-17 with sigma: 0.9999999998253196 and mu: 1.00000002129439\n",
      "750, loss is 5.778443658310428e-17 with sigma: 0.9999999998297735 and mu: 1.00000002072127\n",
      "751, loss is 5.471586783560164e-17 with sigma: 0.9999999998341172 and mu: 1.000000020163575\n",
      "752, loss is 5.1810252876256116e-17 with sigma: 0.9999999998383534 and mu: 1.00000001962089\n",
      "753, loss is 4.905893543192034e-17 with sigma: 0.9999999998424844 and mu: 1.0000000190928109\n",
      "754, loss is 4.645372434805626e-17 with sigma: 0.9999999998465129 and mu: 1.0000000185789446\n",
      "755, loss is 4.3986859539186076e-17 with sigma: 0.9999999998504412 and mu: 1.0000000180789086\n",
      "756, loss is 4.165099385364451e-17 with sigma: 0.9999999998542718 and mu: 1.0000000175923307\n",
      "757, loss is 3.9439171386139514e-17 with sigma: 0.9999999998580069 and mu: 1.0000000171188486\n",
      "758, loss is 3.7344805055926045e-17 with sigma: 0.9999999998616488 and mu: 1.0000000166581098\n",
      "759, loss is 3.536165661326121e-17 with sigma: 0.9999999998651997 and mu: 1.0000000162097713\n",
      "760, loss is 3.348382171936924e-17 with sigma: 0.9999999998686618 and mu: 1.0000000157734996\n",
      "761, loss is 3.1705706864469e-17 with sigma: 0.9999999998720372 and mu: 1.0000000153489699\n",
      "762, loss is 3.002201629369733e-17 with sigma: 0.9999999998753281 and mu: 1.0000000149358659\n",
      "763, loss is 2.842773644307129e-17 with sigma: 0.9999999998785364 and mu: 1.0000000145338803\n",
      "764, loss is 2.691811823646822e-17 with sigma: 0.9999999998816641 and mu: 1.0000000141427139\n",
      "765, loss is 2.5488666683681878e-17 with sigma: 0.9999999998847132 and mu: 1.0000000137620753\n",
      "766, loss is 2.4135124162656824e-17 with sigma: 0.9999999998876856 and mu: 1.0000000133916813\n",
      "767, loss is 2.285345949552038e-17 with sigma: 0.9999999998905831 and mu: 1.000000013031256\n",
      "768, loss is 2.1639856306433806e-17 with sigma: 0.9999999998934075 and mu: 1.0000000126805315\n",
      "769, loss is 2.049069969265322e-17 with sigma: 0.9999999998961606 and mu: 1.0000000123392463\n",
      "770, loss is 1.9402567396202577e-17 with sigma: 0.9999999998988441 and mu: 1.0000000120071464\n",
      "771, loss is 1.8372218860654716e-17 with sigma: 0.9999999999014598 and mu: 1.0000000116839847\n",
      "772, loss is 1.7396586205137364e-17 with sigma: 0.9999999999040093 and mu: 1.0000000113695207\n",
      "773, loss is 1.647276259891516e-17 with sigma: 0.9999999999064942 and mu: 1.00000001106352\n",
      "774, loss is 1.55979980151044e-17 with sigma: 0.9999999999089161 and mu: 1.0000000107657554\n",
      "775, loss is 1.4769686425971383e-17 with sigma: 0.9999999999112765 and mu: 1.0000000104760047\n",
      "776, loss is 1.3985361511674207e-17 with sigma: 0.999999999913577 and mu: 1.0000000101940525\n",
      "777, loss is 1.3242686517531687e-17 with sigma: 0.999999999915819 and mu: 1.0000000099196886\n",
      "778, loss is 1.2539450967826324e-17 with sigma: 0.9999999999180039 and mu: 1.000000009652709\n",
      "779, loss is 1.1873559554549316e-17 with sigma: 0.9999999999201332 and mu: 1.0000000093929151\n",
      "780, loss is 1.1243029754801237e-17 with sigma: 0.9999999999222082 and mu: 1.0000000091401133\n",
      "781, loss is 1.064598352226998e-17 with sigma: 0.9999999999242303 and mu: 1.0000000088941154\n",
      "782, loss is 1.0080642108183327e-17 with sigma: 0.9999999999262007 and mu: 1.0000000086547383\n",
      "783, loss is 9.545322263974757e-18 with sigma: 0.9999999999281208 and mu: 1.0000000084218037\n",
      "784, loss is 9.038430854659912e-18 with sigma: 0.9999999999299919 and mu: 1.0000000081951386\n",
      "785, loss is 8.558456677400521e-18 with sigma: 0.9999999999318151 and mu: 1.000000007974574\n",
      "786, loss is 8.103970953013125e-18 with sigma: 0.9999999999335916 and mu: 1.0000000077599456\n",
      "787, loss is 7.673620523679921e-18 with sigma: 0.9999999999353225 and mu: 1.0000000075510938\n",
      "788, loss is 7.26612297751973e-18 with sigma: 0.9999999999370092 and mu: 1.000000007347863\n",
      "789, loss is 6.8802648527392245e-18 with sigma: 0.9999999999386525 and mu: 1.0000000071501018\n",
      "790, loss is 6.514897080300793e-18 with sigma: 0.9999999999402537 and mu: 1.0000000069576633\n",
      "791, loss is 6.168932352128434e-18 with sigma: 0.9999999999418137 and mu: 1.0000000067704042\n",
      "792, loss is 5.84133904862468e-18 with sigma: 0.9999999999433336 and mu: 1.0000000065881849\n",
      "793, loss is 5.531142163617714e-18 with sigma: 0.9999999999448144 and mu: 1.0000000064108698\n",
      "794, loss is 5.237418091926532e-18 with sigma: 0.9999999999462571 and mu: 1.0000000062383272\n",
      "795, loss is 4.959291984408174e-18 with sigma: 0.9999999999476626 and mu: 1.0000000060704284\n",
      "796, loss is 4.695935375152275e-18 with sigma: 0.999999999949032 and mu: 1.0000000059070484\n",
      "797, loss is 4.446563874823146e-18 with sigma: 0.999999999950366 and mu: 1.0000000057480656\n",
      "798, loss is 4.210434473934542e-18 with sigma: 0.9999999999516657 and mu: 1.0000000055933616\n",
      "799, loss is 3.98684494253675e-18 with sigma: 0.9999999999529317 and mu: 1.0000000054428213\n",
      "800, loss is 3.775128588208147e-18 with sigma: 0.999999999954165 and mu: 1.0000000052963327\n",
      "801, loss is 3.5746552900541334e-18 with sigma: 0.9999999999553665 and mu: 1.0000000051537867\n",
      "802, loss is 3.3848277994332747e-18 with sigma: 0.9999999999565369 and mu: 1.0000000050150772\n",
      "803, loss is 3.2050807624681263e-18 with sigma: 0.999999999957677 and mu: 1.000000004880101\n",
      "804, loss is 3.0348792639386052e-18 with sigma: 0.9999999999587875 and mu: 1.0000000047487576\n",
      "805, loss is 2.873716080177254e-18 with sigma: 0.9999999999598693 and mu: 1.0000000046209492\n",
      "806, loss is 2.721111129143701e-18 with sigma: 0.999999999960923 and mu: 1.0000000044965807\n",
      "807, loss is 2.576609941223557e-18 with sigma: 0.9999999999619494 and mu: 1.0000000043755592\n",
      "808, loss is 2.439782330690404e-18 with sigma: 0.9999999999629492 and mu: 1.000000004257795\n",
      "809, loss is 2.3102210274096763e-18 with sigma: 0.999999999963923 and mu: 1.0000000041432004\n",
      "810, loss is 2.1875397790520615e-18 with sigma: 0.9999999999648715 and mu: 1.00000000403169\n",
      "811, loss is 2.0713733137428754e-18 with sigma: 0.9999999999657955 and mu: 1.000000003923181\n",
      "812, loss is 1.9613756288960692e-18 with sigma: 0.9999999999666953 and mu: 1.000000003817592\n",
      "813, loss is 1.8572193809692346e-18 with sigma: 0.9999999999675717 and mu: 1.000000003714845\n",
      "814, loss is 1.7585941821464213e-18 with sigma: 0.9999999999684254 and mu: 1.0000000036148635\n",
      "815, loss is 1.6652064949264676e-18 with sigma: 0.9999999999692568 and mu: 1.000000003517573\n",
      "816, loss is 1.5767777930825687e-18 with sigma: 0.9999999999700666 and mu: 1.0000000034229006\n",
      "817, loss is 1.4930451420580283e-18 with sigma: 0.9999999999708553 and mu: 1.0000000033307765\n",
      "818, loss is 1.4137590149329809e-18 with sigma: 0.9999999999716234 and mu: 1.0000000032411318\n",
      "819, loss is 1.33868317758185e-18 with sigma: 0.9999999999723714 and mu: 1.0000000031538998\n",
      "820, loss is 1.267594217868775e-18 with sigma: 0.9999999999731 and mu: 1.0000000030690155\n",
      "821, loss is 1.20028019049255e-18 with sigma: 0.9999999999738095 and mu: 1.0000000029864158\n",
      "822, loss is 1.136540933900702e-18 with sigma: 0.9999999999745005 and mu: 1.0000000029060392\n",
      "823, loss is 1.0761863642759909e-18 with sigma: 0.9999999999751734 and mu: 1.0000000028278258\n",
      "824, loss is 1.0190368030544008e-18 with sigma: 0.9999999999758288 and mu: 1.0000000027517175\n",
      "825, loss is 9.649222933122484e-19 with sigma: 0.999999999976467 and mu: 1.0000000026776577\n",
      "826, loss is 9.13681366692746e-19 with sigma: 0.9999999999770885 and mu: 1.000000002605591\n",
      "827, loss is 8.651616324060926e-19 with sigma: 0.9999999999776938 and mu: 1.000000002535464\n",
      "828, loss is 8.192183369656138e-19 with sigma: 0.9999999999782833 and mu: 1.0000000024672244\n",
      "829, loss is 7.75714784402713e-19 with sigma: 0.9999999999788572 and mu: 1.0000000024008213\n",
      "830, loss is 7.3452147088956535e-19 with sigma: 0.9999999999794162 and mu: 1.0000000023362055\n",
      "831, loss is 6.95515587912042e-19 with sigma: 0.9999999999799606 and mu: 1.0000000022733286\n",
      "832, loss is 6.585810709446796e-19 with sigma: 0.9999999999804906 and mu: 1.000000002212144\n",
      "833, loss is 6.236080419978839e-19 with sigma: 0.9999999999810067 and mu: 1.0000000021526063\n",
      "834, loss is 5.9049215268468525e-19 with sigma: 0.9999999999815093 and mu: 1.0000000020946709\n",
      "835, loss is 5.591348720948391e-19 with sigma: 0.9999999999819987 and mu: 1.0000000020382949\n",
      "836, loss is 5.294427453859449e-19 with sigma: 0.9999999999824752 and mu: 1.000000001983436\n",
      "837, loss is 5.013273644987112e-19 with sigma: 0.9999999999829393 and mu: 1.0000000019300537\n",
      "838, loss is 4.747050461692377e-19 with sigma: 0.9999999999833912 and mu: 1.0000000018781081\n",
      "839, loss is 4.4949640470024555e-19 with sigma: 0.9999999999838312 and mu: 1.0000000018275605\n",
      "840, loss is 4.256265009936906e-19 with sigma: 0.9999999999842596 and mu: 1.0000000017783734\n",
      "841, loss is 4.0302416300874867e-19 with sigma: 0.9999999999846767 and mu: 1.0000000017305102\n",
      "842, loss is 3.816221365664248e-19 with sigma: 0.9999999999850828 and mu: 1.0000000016839352\n",
      "843, loss is 3.61356587458096e-19 with sigma: 0.9999999999854783 and mu: 1.0000000016386137\n",
      "844, loss is 3.421671591770844e-19 with sigma: 0.9999999999858634 and mu: 1.0000000015945119\n",
      "845, loss is 3.2399680360004963e-19 with sigma: 0.9999999999862383 and mu: 1.000000001551597\n",
      "846, loss is 3.067914286840776e-19 with sigma: 0.9999999999866034 and mu: 1.0000000015098374\n",
      "847, loss is 2.904996428855267e-19 with sigma: 0.9999999999869589 and mu: 1.0000000014692014\n",
      "848, loss is 2.7507303381863396e-19 with sigma: 0.9999999999873049 and mu: 1.0000000014296593\n",
      "849, loss is 2.6046568090382844e-19 with sigma: 0.9999999999876419 and mu: 1.0000000013911814\n",
      "850, loss is 2.466340194707528e-19 with sigma: 0.99999999998797 and mu: 1.0000000013537391\n",
      "851, loss is 2.3353680187072806e-19 with sigma: 0.9999999999882894 and mu: 1.0000000013173045\n",
      "852, loss is 2.2113509847943696e-19 with sigma: 0.9999999999886003 and mu: 1.0000000012818504\n",
      "853, loss is 2.093920539635706e-19 with sigma: 0.9999999999889031 and mu: 1.0000000012473507\n",
      "854, loss is 1.9827251022789566e-19 with sigma: 0.9999999999891979 and mu: 1.0000000012137793\n",
      "855, loss is 1.8774356209934187e-19 with sigma: 0.9999999999894849 and mu: 1.0000000011811117\n",
      "856, loss is 1.777736452376007e-19 with sigma: 0.9999999999897643 and mu: 1.000000001149323\n",
      "857, loss is 1.6833318760845918e-19 with sigma: 0.9999999999900364 and mu: 1.00000000111839\n",
      "858, loss is 1.5939406642869155e-19 with sigma: 0.9999999999903013 and mu: 1.0000000010882897\n",
      "859, loss is 1.5092964088002859e-19 with sigma: 0.9999999999905592 and mu: 1.0000000010589993\n",
      "860, loss is 1.4291474341011087e-19 with sigma: 0.9999999999908102 and mu: 1.0000000010304975\n",
      "861, loss is 1.3532543359841134e-19 with sigma: 0.9999999999910547 and mu: 1.0000000010027625\n",
      "862, loss is 1.2813915341440333e-19 with sigma: 0.9999999999912926 and mu: 1.0000000009757741\n",
      "863, loss is 1.213344996437539e-19 with sigma: 0.9999999999915243 and mu: 1.000000000949512\n",
      "864, loss is 1.148911882085034e-19 with sigma: 0.9999999999917498 and mu: 1.000000000923957\n",
      "865, loss is 1.0879003868964652e-19 with sigma: 0.9999999999919694 and mu: 1.0000000008990895\n",
      "866, loss is 1.0301286633650196e-19 with sigma: 0.9999999999921831 and mu: 1.0000000008748913\n",
      "867, loss is 9.754250731049837e-20 with sigma: 0.9999999999923912 and mu: 1.0000000008513443\n",
      "868, loss is 9.236260093841695e-20 with sigma: 0.9999999999925938 and mu: 1.000000000828431\n",
      "869, loss is 8.745781223587259e-20 with sigma: 0.999999999992791 and mu: 1.0000000008061347\n",
      "870, loss is 8.28134853195639e-20 with sigma: 0.999999999992983 and mu: 1.0000000007844383\n",
      "871, loss is 7.841578467497043e-20 with sigma: 0.9999999999931698 and mu: 1.0000000007633258\n",
      "872, loss is 7.42515893951309e-20 with sigma: 0.9999999999933518 and mu: 1.0000000007427816\n",
      "873, loss is 7.030853608544046e-20 with sigma: 0.9999999999935288 and mu: 1.0000000007227903\n",
      "874, loss is 6.657492505125372e-20 with sigma: 0.9999999999937013 and mu: 1.0000000007033372\n",
      "875, loss is 6.3039533860652e-20 with sigma: 0.9999999999938691 and mu: 1.0000000006844074\n",
      "876, loss is 5.969189879200677e-20 with sigma: 0.9999999999940326 and mu: 1.0000000006659873\n",
      "877, loss is 5.652205977138071e-20 with sigma: 0.9999999999941916 and mu: 1.000000000648063\n",
      "878, loss is 5.352051463599405e-20 with sigma: 0.9999999999943465 and mu: 1.0000000006306209\n",
      "879, loss is 5.0678367854436554e-20 with sigma: 0.9999999999944973 and mu: 1.0000000006136482\n",
      "880, loss is 4.798716130210863e-20 with sigma: 0.9999999999946441 and mu: 1.0000000005971326\n",
      "881, loss is 4.5438908844785803e-20 with sigma: 0.999999999994787 and mu: 1.0000000005810614\n",
      "882, loss is 4.302590116115643e-20 with sigma: 0.999999999994926 and mu: 1.0000000005654226\n",
      "883, loss is 4.0741054859962196e-20 with sigma: 0.9999999999950613 and mu: 1.0000000005502048\n",
      "884, loss is 3.857757312118292e-20 with sigma: 0.9999999999951931 and mu: 1.0000000005353966\n",
      "885, loss is 3.652897450260114e-20 with sigma: 0.9999999999953213 and mu: 1.000000000520987\n",
      "886, loss is 3.458915460647047e-20 with sigma: 0.9999999999954462 and mu: 1.0000000005069651\n",
      "887, loss is 3.2752352003457116e-20 with sigma: 0.9999999999955678 and mu: 1.0000000004933207\n",
      "888, loss is 3.10130865859866e-20 with sigma: 0.999999999995686 and mu: 1.0000000004800436\n",
      "889, loss is 2.9366184294728e-20 with sigma: 0.9999999999958011 and mu: 1.0000000004671237\n",
      "890, loss is 2.780673923670861e-20 with sigma: 0.9999999999959133 and mu: 1.0000000004545515\n",
      "891, loss is 2.6330107435542536e-20 with sigma: 0.9999999999960224 and mu: 1.0000000004423177\n",
      "892, loss is 2.4931879894770173e-20 with sigma: 0.9999999999961287 and mu: 1.0000000004304133\n",
      "893, loss is 2.3607923652841048e-20 with sigma: 0.999999999996232 and mu: 1.0000000004188292\n",
      "894, loss is 2.2354255301522654e-20 with sigma: 0.9999999999963326 and mu: 1.0000000004075569\n",
      "895, loss is 2.1167164191991118e-20 with sigma: 0.9999999999964305 and mu: 1.0000000003965879\n",
      "896, loss is 2.0043131831009746e-20 with sigma: 0.9999999999965259 and mu: 1.0000000003859142\n",
      "897, loss is 1.89787539166798e-20 with sigma: 0.9999999999966187 and mu: 1.0000000003755276\n",
      "898, loss is 1.7970906672090554e-20 with sigma: 0.9999999999967091 and mu: 1.0000000003654206\n",
      "899, loss is 1.701657128812928e-20 with sigma: 0.999999999996797 and mu: 1.0000000003555856\n",
      "900, loss is 1.6112921602126666e-20 with sigma: 0.9999999999968826 and mu: 1.0000000003460152\n",
      "901, loss is 1.5257255791367522e-20 with sigma: 0.9999999999969659 and mu: 1.0000000003367024\n",
      "902, loss is 1.444703435603884e-20 with sigma: 0.9999999999970469 and mu: 1.0000000003276404\n",
      "903, loss is 1.367985522641727e-20 with sigma: 0.9999999999971259 and mu: 1.0000000003188223\n",
      "904, loss is 1.295341226757251e-20 with sigma: 0.9999999999972027 and mu: 1.0000000003102416\n",
      "905, loss is 1.2265537362069374e-20 with sigma: 0.9999999999972775 and mu: 1.0000000003018918\n",
      "906, loss is 1.161420233186432e-20 with sigma: 0.9999999999973503 and mu: 1.0000000002937668\n",
      "907, loss is 1.099745481355972e-20 with sigma: 0.9999999999974212 and mu: 1.0000000002858604\n",
      "908, loss is 1.0413449221314105e-20 with sigma: 0.9999999999974901 and mu: 1.0000000002781668\n",
      "909, loss is 9.860455227853458e-21 with sigma: 0.9999999999975573 and mu: 1.0000000002706801\n",
      "910, loss is 9.33682851667754e-21 with sigma: 0.9999999999976226 and mu: 1.000000000263395\n",
      "911, loss is 8.84100919299263e-21 with sigma: 0.9999999999976862 and mu: 1.000000000256306\n",
      "912, loss is 8.371515927623932e-21 with sigma: 0.999999999997748 and mu: 1.0000000002494078\n",
      "913, loss is 7.926958887514914e-21 with sigma: 0.9999999999978083 and mu: 1.0000000002426952\n",
      "914, loss is 7.506007454261936e-21 with sigma: 0.9999999999978669 and mu: 1.0000000002361633\n",
      "915, loss is 7.1074186221262e-21 with sigma: 0.999999999997924 and mu: 1.0000000002298073\n",
      "916, loss is 6.729984147618892e-21 with sigma: 0.9999999999979795 and mu: 1.0000000002236222\n",
      "917, loss is 6.372603562740487e-21 with sigma: 0.9999999999980336 and mu: 1.0000000002176037\n",
      "918, loss is 6.034188856647836e-21 with sigma: 0.9999999999980862 and mu: 1.000000000211747\n",
      "919, loss is 5.7137536586728036e-21 with sigma: 0.9999999999981374 and mu: 1.000000000206048\n",
      "920, loss is 5.410330242531078e-21 with sigma: 0.9999999999981872 and mu: 1.0000000002005025\n",
      "921, loss is 5.1230185641526286e-21 with sigma: 0.9999999999982357 and mu: 1.0000000001951062\n",
      "922, loss is 4.8509671296324675e-21 with sigma: 0.9999999999982829 and mu: 1.000000000189855\n",
      "923, loss is 4.593368928814724e-21 with sigma: 0.9999999999983289 and mu: 1.0000000001847453\n",
      "924, loss is 4.349446462490311e-21 with sigma: 0.9999999999983736 and mu: 1.000000000179773\n",
      "925, loss is 4.118474694118737e-21 with sigma: 0.9999999999984172 and mu: 1.0000000001749347\n",
      "926, loss is 3.899767543345914e-21 with sigma: 0.9999999999984596 and mu: 1.0000000001702265\n",
      "927, loss is 3.69267360721356e-21 with sigma: 0.9999999999985009 and mu: 1.000000000165645\n",
      "928, loss is 3.496581426894046e-21 with sigma: 0.9999999999985411 and mu: 1.0000000001611868\n",
      "929, loss is 3.3109049398284304e-21 with sigma: 0.9999999999985801 and mu: 1.0000000001568488\n",
      "930, loss is 3.1350763425339885e-21 with sigma: 0.9999999999986182 and mu: 1.0000000001526272\n",
      "931, loss is 2.968594108816836e-21 with sigma: 0.9999999999986552 and mu: 1.0000000001485194\n",
      "932, loss is 2.810955335441491e-21 with sigma: 0.9999999999986912 and mu: 1.0000000001445222\n",
      "933, loss is 2.661677182356977e-21 with sigma: 0.9999999999987262 and mu: 1.0000000001406324\n",
      "934, loss is 2.520331458426195e-21 with sigma: 0.9999999999987603 and mu: 1.0000000001368474\n",
      "935, loss is 2.3864941120768754e-21 with sigma: 0.9999999999987935 and mu: 1.0000000001331644\n",
      "936, loss is 2.2597628167386162e-21 with sigma: 0.9999999999988258 and mu: 1.0000000001295803\n",
      "937, loss is 2.1397615444273156e-21 with sigma: 0.9999999999988572 and mu: 1.000000000126093\n",
      "938, loss is 2.0261324272993927e-21 with sigma: 0.9999999999988879 and mu: 1.0000000001226992\n",
      "939, loss is 1.918537653346703e-21 with sigma: 0.9999999999989176 and mu: 1.000000000119397\n",
      "940, loss is 1.8166605211857194e-21 with sigma: 0.9999999999989466 and mu: 1.0000000001161835\n",
      "941, loss is 1.7201847506256624e-21 with sigma: 0.9999999999989748 and mu: 1.0000000001130565\n",
      "942, loss is 1.6288345564903447e-21 with sigma: 0.9999999999990024 and mu: 1.0000000001100136\n",
      "943, loss is 1.5423363574907098e-21 with sigma: 0.9999999999990291 and mu: 1.0000000001070526\n",
      "944, loss is 1.4604320118539463e-21 with sigma: 0.9999999999990551 and mu: 1.0000000001041713\n",
      "945, loss is 1.3828743107917442e-21 with sigma: 0.9999999999990804 and mu: 1.0000000001013676\n",
      "946, loss is 1.3094394982749484e-21 with sigma: 0.999999999999105 and mu: 1.0000000000986393\n",
      "947, loss is 1.239900402194932e-21 with sigma: 0.999999999999129 and mu: 1.0000000000959846\n",
      "948, loss is 1.1740585106630446e-21 with sigma: 0.9999999999991523 and mu: 1.0000000000934013\n",
      "949, loss is 1.1117149945426552e-21 with sigma: 0.9999999999991751 and mu: 1.0000000000908875\n",
      "950, loss is 1.052680530154773e-21 with sigma: 0.9999999999991972 and mu: 1.0000000000884415\n",
      "951, loss is 9.96777857723958e-22 with sigma: 0.9999999999992187 and mu: 1.0000000000860612\n",
      "952, loss is 9.438472298534228e-22 with sigma: 0.9999999999992397 and mu: 1.000000000083745\n",
      "953, loss is 8.93726916963524e-22 with sigma: 0.9999999999992601 and mu: 1.000000000081491\n",
      "954, loss is 8.46263480860741e-22 with sigma: 0.99999999999928 and mu: 1.0000000000792977\n",
      "955, loss is 8.013217105912439e-22 with sigma: 0.9999999999992993 and mu: 1.0000000000771634\n",
      "956, loss is 7.587672787208836e-22 with sigma: 0.9999999999993181 and mu: 1.0000000000750866\n",
      "957, loss is 7.184751492562431e-22 with sigma: 0.9999999999993364 and mu: 1.0000000000730658\n",
      "958, loss is 6.803236685993512e-22 with sigma: 0.9999999999993542 and mu: 1.0000000000710993\n",
      "959, loss is 6.441960459137901e-22 with sigma: 0.9999999999993715 and mu: 1.0000000000691858\n",
      "960, loss is 6.0998704610130925e-22 with sigma: 0.9999999999993884 and mu: 1.0000000000673237\n",
      "961, loss is 5.775952750020914e-22 with sigma: 0.9999999999994048 and mu: 1.0000000000655118\n",
      "962, loss is 5.469218788057517e-22 with sigma: 0.9999999999994208 and mu: 1.0000000000637486\n",
      "963, loss is 5.178786769858663e-22 with sigma: 0.9999999999994363 and mu: 1.0000000000620328\n",
      "964, loss is 4.903777007060885e-22 with sigma: 0.9999999999994514 and mu: 1.0000000000603633\n",
      "965, loss is 4.643357185751973e-22 with sigma: 0.9999999999994662 and mu: 1.0000000000587386\n",
      "966, loss is 4.396774687358982e-22 with sigma: 0.9999999999994805 and mu: 1.0000000000571576\n",
      "967, loss is 4.163292818275653e-22 with sigma: 0.9999999999994945 and mu: 1.0000000000556193\n",
      "968, loss is 3.9421755218645655e-22 with sigma: 0.9999999999995081 and mu: 1.0000000000541223\n",
      "969, loss is 3.732845205051327e-22 with sigma: 0.9999999999995213 and mu: 1.0000000000526656\n",
      "970, loss is 3.5346079838344997e-22 with sigma: 0.9999999999995342 and mu: 1.0000000000512481\n",
      "971, loss is 3.34689925027235e-22 with sigma: 0.9999999999995467 and mu: 1.0000000000498688\n",
      "972, loss is 3.169151900923769e-22 with sigma: 0.9999999999995589 and mu: 1.0000000000485265\n",
      "973, loss is 3.000848077232415e-22 with sigma: 0.9999999999995708 and mu: 1.0000000000472204\n",
      "974, loss is 2.8414808177297514e-22 with sigma: 0.9999999999995823 and mu: 1.0000000000459495\n",
      "975, loss is 2.690567544641188e-22 with sigma: 0.9999999999995935 and mu: 1.0000000000447127\n",
      "976, loss is 2.5476862756443943e-22 with sigma: 0.9999999999996044 and mu: 1.0000000000435092\n",
      "977, loss is 2.4123976729353733e-22 with sigma: 0.9999999999996151 and mu: 1.0000000000423381\n",
      "978, loss is 2.2842901610532713e-22 with sigma: 0.9999999999996254 and mu: 1.0000000000411986\n",
      "979, loss is 2.162968639145336e-22 with sigma: 0.9999999999996355 and mu: 1.0000000000400897\n",
      "980, loss is 2.048118984336913e-22 with sigma: 0.9999999999996453 and mu: 1.0000000000390108\n",
      "981, loss is 1.9393507563368987e-22 with sigma: 0.9999999999996548 and mu: 1.0000000000379607\n",
      "982, loss is 1.8363468706845724e-22 with sigma: 0.999999999999664 and mu: 1.0000000000369391\n",
      "983, loss is 1.7388504792586273e-22 with sigma: 0.999999999999673 and mu: 1.000000000035945\n",
      "984, loss is 1.6465074338339013e-22 with sigma: 0.9999999999996818 and mu: 1.0000000000349776\n",
      "985, loss is 1.5590680407866872e-22 with sigma: 0.9999999999996904 and mu: 1.000000000034036\n",
      "986, loss is 1.4762688681617e-22 with sigma: 0.9999999999996987 and mu: 1.00000000003312\n",
      "987, loss is 1.3978818591022862e-22 with sigma: 0.9999999999997068 and mu: 1.0000000000322287\n",
      "988, loss is 1.3236518913286502e-22 with sigma: 0.9999999999997147 and mu: 1.0000000000313614\n",
      "989, loss is 1.253370378037615e-22 with sigma: 0.9999999999997223 and mu: 1.0000000000305174\n",
      "990, loss is 1.1868148239489044e-22 with sigma: 0.9999999999997298 and mu: 1.000000000029696\n",
      "991, loss is 1.1237960676593361e-22 with sigma: 0.999999999999737 and mu: 1.0000000000288969\n",
      "992, loss is 1.06410941243858e-22 with sigma: 0.9999999999997441 and mu: 1.000000000028119\n",
      "993, loss is 1.0076089331341562e-22 with sigma: 0.999999999999751 and mu: 1.0000000000273623\n",
      "994, loss is 9.540925675150797e-23 with sigma: 0.9999999999997576 and mu: 1.0000000000266258\n",
      "995, loss is 9.034309678212549e-23 with sigma: 0.9999999999997642 and mu: 1.0000000000259093\n",
      "996, loss is 8.554645956673247e-23 with sigma: 0.9999999999997705 and mu: 1.000000000025212\n",
      "997, loss is 8.100292814638737e-23 with sigma: 0.9999999999997766 and mu: 1.0000000000245335\n",
      "998, loss is 7.670197808388809e-23 with sigma: 0.9999999999997826 and mu: 1.0000000000238731\n",
      "999, loss is 7.26276681157548e-23 with sigma: 0.9999999999997885 and mu: 1.0000000000232305\n",
      "1000, loss is 6.877108285182022e-23 with sigma: 0.9999999999997942 and mu: 1.0000000000226053\n",
      "1001, loss is 6.51189705982543e-23 with sigma: 0.9999999999997997 and mu: 1.0000000000219968\n",
      "1002, loss is 6.166085996622047e-23 with sigma: 0.999999999999805 and mu: 1.0000000000214049\n",
      "1003, loss is 5.838719369880382e-23 with sigma: 0.9999999999998103 and mu: 1.000000000020829\n",
      "1004, loss is 5.528612482649495e-23 with sigma: 0.9999999999998154 and mu: 1.0000000000202682\n",
      "1005, loss is 5.2350156364783615e-23 with sigma: 0.9999999999998204 and mu: 1.0000000000197227\n",
      "1006, loss is 4.95696563437802e-23 with sigma: 0.9999999999998251 and mu: 1.0000000000191918\n",
      "1007, loss is 4.693724228782214e-23 with sigma: 0.9999999999998298 and mu: 1.0000000000186753\n",
      "1008, loss is 4.4444479692891835e-23 with sigma: 0.9999999999998344 and mu: 1.0000000000181726\n",
      "1009, loss is 4.2083725250122455e-23 with sigma: 0.9999999999998388 and mu: 1.0000000000176834\n",
      "1010, loss is 3.9849572207295726e-23 with sigma: 0.9999999999998431 and mu: 1.0000000000172076\n",
      "1011, loss is 3.773289523947849e-23 with sigma: 0.9999999999998473 and mu: 1.0000000000167444\n",
      "1012, loss is 3.572885004450915e-23 with sigma: 0.9999999999998515 and mu: 1.0000000000162936\n",
      "1013, loss is 3.383155232510864e-23 with sigma: 0.9999999999998554 and mu: 1.000000000015855\n",
      "1014, loss is 3.203475891422172e-23 with sigma: 0.9999999999998593 and mu: 1.0000000000154283\n",
      "1015, loss is 3.033385769697369e-23 with sigma: 0.9999999999998631 and mu: 1.000000000015013\n",
      "1016, loss is 2.872302339945076e-23 with sigma: 0.9999999999998668 and mu: 1.000000000014609\n",
      "1017, loss is 2.7197029977783307e-23 with sigma: 0.9999999999998703 and mu: 1.0000000000142157\n",
      "1018, loss is 2.5753320578466324e-23 with sigma: 0.9999999999998738 and mu: 1.0000000000138332\n",
      "1019, loss is 2.438516535117348e-23 with sigma: 0.9999999999998772 and mu: 1.0000000000134608\n",
      "1020, loss is 2.308973363346019e-23 with sigma: 0.9999999999998805 and mu: 1.0000000000130984\n",
      "1021, loss is 2.1863546119086457e-23 with sigma: 0.9999999999998838 and mu: 1.0000000000127458\n",
      "1022, loss is 2.070241294536808e-23 with sigma: 0.9999999999998869 and mu: 1.0000000000124027\n",
      "1023, loss is 1.960354116045892e-23 with sigma: 0.9999999999998899 and mu: 1.000000000012069\n",
      "1024, loss is 1.8562218549823798e-23 with sigma: 0.9999999999998929 and mu: 1.0000000000117442\n",
      "1025, loss is 1.7576305386681734e-23 with sigma: 0.9999999999998958 and mu: 1.000000000011428\n",
      "1026, loss is 1.6642915263327304e-23 with sigma: 0.9999999999998985 and mu: 1.0000000000111204\n",
      "1027, loss is 1.5758959243539006e-23 with sigma: 0.9999999999999013 and mu: 1.0000000000108211\n",
      "1028, loss is 1.4921942941054582e-23 with sigma: 0.999999999999904 and mu: 1.0000000000105298\n",
      "1029, loss is 1.4129844006992828e-23 with sigma: 0.9999999999999065 and mu: 1.0000000000102465\n",
      "1030, loss is 1.3379356017375057e-23 with sigma: 0.9999999999999091 and mu: 1.0000000000099707\n",
      "1031, loss is 1.266859745807158e-23 with sigma: 0.9999999999999115 and mu: 1.0000000000097022\n",
      "1032, loss is 1.1995767806080241e-23 with sigma: 0.9999999999999138 and mu: 1.0000000000094411\n",
      "1033, loss is 1.1358963378011832e-23 with sigma: 0.9999999999999162 and mu: 1.000000000009187\n",
      "1034, loss is 1.0755611776927791e-23 with sigma: 0.9999999999999184 and mu: 1.0000000000089397\n",
      "1035, loss is 1.0184593418828122e-23 with sigma: 0.9999999999999206 and mu: 1.000000000008699\n",
      "1036, loss is 9.643516438172064e-24 with sigma: 0.9999999999999227 and mu: 1.000000000008465\n",
      "1037, loss is 9.131801997934723e-24 with sigma: 0.9999999999999248 and mu: 1.0000000000082372\n",
      "1038, loss is 8.646744394057938e-24 with sigma: 0.9999999999999268 and mu: 1.0000000000080156\n",
      "1039, loss is 8.187507874430824e-24 with sigma: 0.9999999999999288 and mu: 1.0000000000077998\n",
      "1040, loss is 7.752679682669525e-24 with sigma: 0.9999999999999307 and mu: 1.00000000000759\n",
      "1041, loss is 7.341122988126052e-24 with sigma: 0.9999999999999326 and mu: 1.0000000000073856\n",
      "1042, loss is 6.951600037610827e-24 with sigma: 0.9999999999999344 and mu: 1.000000000007187\n",
      "1043, loss is 6.5823101785320926e-24 with sigma: 0.9999999999999362 and mu: 1.0000000000069935\n",
      "1044, loss is 6.232673033270972e-24 with sigma: 0.9999999999999378 and mu: 1.0000000000068052\n",
      "1045, loss is 5.901415442244378e-24 with sigma: 0.9999999999999395 and mu: 1.000000000006622\n",
      "1046, loss is 5.587983032975768e-24 with sigma: 0.9999999999999412 and mu: 1.0000000000064437\n",
      "1047, loss is 5.291416531038873e-24 with sigma: 0.9999999999999427 and mu: 1.0000000000062703\n",
      "1048, loss is 5.010300455470454e-24 with sigma: 0.9999999999999443 and mu: 1.0000000000061016\n",
      "1049, loss is 4.744071318452397e-24 with sigma: 0.9999999999999458 and mu: 1.0000000000059373\n",
      "1050, loss is 4.4922450021627966e-24 with sigma: 0.9999999999999473 and mu: 1.0000000000057774\n",
      "1051, loss is 4.253769169243351e-24 with sigma: 0.9999999999999487 and mu: 1.000000000005622\n",
      "1052, loss is 4.027981254965605e-24 with sigma: 0.99999999999995 and mu: 1.0000000000054707\n",
      "1053, loss is 3.814070703990976e-24 with sigma: 0.9999999999999514 and mu: 1.0000000000053235\n",
      "1054, loss is 3.611555656801125e-24 with sigma: 0.9999999999999527 and mu: 1.0000000000051803\n",
      "1055, loss is 3.41972031670118e-24 with sigma: 0.9999999999999539 and mu: 1.0000000000050409\n",
      "1056, loss is 3.238117726775575e-24 with sigma: 0.9999999999999551 and mu: 1.0000000000049052\n",
      "1057, loss is 3.0659940824405444e-24 with sigma: 0.9999999999999564 and mu: 1.000000000004773\n",
      "1058, loss is 2.9031230204030606e-24 with sigma: 0.9999999999999576 and mu: 1.0000000000046445\n",
      "1059, loss is 2.74901075602425e-24 with sigma: 0.9999999999999587 and mu: 1.0000000000045195\n",
      "1060, loss is 2.6029745026641916e-24 with sigma: 0.9999999999999598 and mu: 1.0000000000043978\n",
      "1061, loss is 2.4647340066071207e-24 with sigma: 0.9999999999999609 and mu: 1.0000000000042795\n",
      "1062, loss is 2.3336786223313926e-24 with sigma: 0.9999999999999619 and mu: 1.0000000000041642\n",
      "1063, loss is 2.2099088699736017e-24 with sigma: 0.9999999999999629 and mu: 1.000000000004052\n",
      "1064, loss is 2.0925050709198485e-24 with sigma: 0.9999999999999639 and mu: 1.000000000003943\n",
      "1065, loss is 1.9814094406501392e-24 with sigma: 0.9999999999999649 and mu: 1.000000000003837\n",
      "1066, loss is 1.876081228047823e-24 with sigma: 0.9999999999999658 and mu: 1.0000000000037337\n",
      "1067, loss is 1.7763452961388353e-24 with sigma: 0.9999999999999667 and mu: 1.000000000003633\n",
      "1068, loss is 1.6821996578502723e-24 with sigma: 0.9999999999999676 and mu: 1.0000000000035354\n",
      "1069, loss is 1.5926274755469759e-24 with sigma: 0.9999999999999685 and mu: 1.0000000000034401\n",
      "1070, loss is 1.5080942060617172e-24 with sigma: 0.9999999999999694 and mu: 1.0000000000033475\n",
      "1071, loss is 1.4279629220076966e-24 with sigma: 0.9999999999999701 and mu: 1.0000000000032574\n",
      "1072, loss is 1.3521173058112677e-24 with sigma: 0.9999999999999709 and mu: 1.0000000000031697\n",
      "1073, loss is 1.280406977589046e-24 with sigma: 0.9999999999999717 and mu: 1.0000000000030844\n",
      "1074, loss is 1.2123229185522387e-24 with sigma: 0.9999999999999725 and mu: 1.0000000000030014\n",
      "1075, loss is 1.1479325618482117e-24 with sigma: 0.9999999999999732 and mu: 1.0000000000029206\n",
      "1076, loss is 1.0869820367391349e-24 with sigma: 0.9999999999999739 and mu: 1.000000000002842\n",
      "1077, loss is 1.0292747109684866e-24 with sigma: 0.9999999999999746 and mu: 1.0000000000027656\n",
      "1078, loss is 9.746658660823787e-25 with sigma: 0.9999999999999752 and mu: 1.0000000000026912\n",
      "1079, loss is 9.229578653970144e-25 with sigma: 0.9999999999999759 and mu: 1.0000000000026188\n",
      "1080, loss is 8.740532097021104e-25 with sigma: 0.9999999999999766 and mu: 1.0000000000025484\n",
      "1081, loss is 8.276270535169817e-25 with sigma: 0.9999999999999772 and mu: 1.0000000000024798\n",
      "1082, loss is 7.836488563314801e-25 with sigma: 0.9999999999999778 and mu: 1.000000000002413\n",
      "1083, loss is 7.420410231933656e-25 with sigma: 0.9999999999999784 and mu: 1.0000000000023481\n",
      "1084, loss is 7.025886613492719e-25 with sigma: 0.9999999999999789 and mu: 1.0000000000022848\n",
      "1085, loss is 6.652939818375323e-25 with sigma: 0.9999999999999795 and mu: 1.0000000000022233\n",
      "1086, loss is 6.300149882302957e-25 with sigma: 0.99999999999998 and mu: 1.0000000000021636\n",
      "1087, loss is 5.966049999065188e-25 with sigma: 0.9999999999999806 and mu: 1.0000000000021054\n",
      "1088, loss is 5.649109034064422e-25 with sigma: 0.9999999999999811 and mu: 1.0000000000020488\n",
      "1089, loss is 5.3499416378944855e-25 with sigma: 0.9999999999999817 and mu: 1.0000000000019937\n",
      "1090, loss is 5.065194644727563e-25 with sigma: 0.9999999999999821 and mu: 1.00000000000194\n",
      "1091, loss is 4.796507328676963e-25 with sigma: 0.9999999999999826 and mu: 1.0000000000018878\n",
      "1092, loss is 4.54178500571949e-25 with sigma: 0.999999999999983 and mu: 1.000000000001837\n",
      "1093, loss is 4.299789734804183e-25 with sigma: 0.9999999999999835 and mu: 1.0000000000017875\n",
      "1094, loss is 4.0713708256721356e-25 with sigma: 0.9999999999999839 and mu: 1.0000000000017393\n",
      "1095, loss is 3.855040165558129e-25 with sigma: 0.9999999999999843 and mu: 1.0000000000016924\n",
      "1096, loss is 3.6506223455584326e-25 with sigma: 0.9999999999999848 and mu: 1.000000000001647\n",
      "1097, loss is 3.456302139827788e-25 with sigma: 0.9999999999999852 and mu: 1.0000000000016025\n",
      "1098, loss is 3.272703755552421e-25 with sigma: 0.9999999999999857 and mu: 1.0000000000015594\n",
      "1099, loss is 3.098865180548292e-25 with sigma: 0.999999999999986 and mu: 1.0000000000015175\n",
      "1100, loss is 2.9344677079818467e-25 with sigma: 0.9999999999999863 and mu: 1.0000000000014766\n",
      "1101, loss is 2.778574309741539e-25 with sigma: 0.9999999999999867 and mu: 1.0000000000014369\n",
      "1102, loss is 2.6311595048129054e-25 with sigma: 0.999999999999987 and mu: 1.0000000000013982\n",
      "1103, loss is 2.491903374732014e-25 with sigma: 0.9999999999999873 and mu: 1.0000000000013607\n",
      "1104, loss is 2.3595889971115727e-25 with sigma: 0.9999999999999877 and mu: 1.000000000001324\n",
      "1105, loss is 2.234515139180512e-25 with sigma: 0.999999999999988 and mu: 1.0000000000012885\n",
      "1106, loss is 2.115974615527547e-25 with sigma: 0.9999999999999883 and mu: 1.0000000000012539\n",
      "1107, loss is 2.0035338748547581e-25 with sigma: 0.9999999999999887 and mu: 1.0000000000012201\n",
      "1108, loss is 1.8974010366350462e-25 with sigma: 0.999999999999989 and mu: 1.0000000000011873\n",
      "1109, loss is 1.7962218295914335e-25 with sigma: 0.9999999999999893 and mu: 1.0000000000011553\n",
      "1110, loss is 1.7010263228695842e-25 with sigma: 0.9999999999999897 and mu: 1.0000000000011242\n",
      "1111, loss is 1.61065808061689e-25 with sigma: 0.9999999999999899 and mu: 1.000000000001094\n",
      "1112, loss is 1.5251142095387348e-25 with sigma: 0.9999999999999901 and mu: 1.0000000000010645\n",
      "1113, loss is 1.4439195073343387e-25 with sigma: 0.9999999999999903 and mu: 1.0000000000010358\n",
      "1114, loss is 1.3673064107914309e-25 with sigma: 0.9999999999999906 and mu: 1.0000000000010079\n",
      "1115, loss is 1.2945652901689819e-25 with sigma: 0.9999999999999908 and mu: 1.0000000000009808\n",
      "1116, loss is 1.2258814474146591e-25 with sigma: 0.999999999999991 and mu: 1.0000000000009543\n",
      "1117, loss is 1.1605213179180113e-25 with sigma: 0.9999999999999912 and mu: 1.0000000000009286\n",
      "1118, loss is 1.0985213940194373e-25 with sigma: 0.9999999999999915 and mu: 1.0000000000009035\n",
      "1119, loss is 1.040075057261021e-25 with sigma: 0.9999999999999917 and mu: 1.000000000000879\n",
      "1120, loss is 9.846499387087577e-26 with sigma: 0.9999999999999919 and mu: 1.0000000000008553\n",
      "1121, loss is 9.320105400627747e-26 with sigma: 0.9999999999999921 and mu: 1.0000000000008322\n",
      "1122, loss is 8.825385430623433e-26 with sigma: 0.9999999999999923 and mu: 1.0000000000008098\n",
      "1123, loss is 8.356734512066197e-26 with sigma: 0.9999999999999926 and mu: 1.000000000000788\n",
      "1124, loss is 7.91116838638759e-26 with sigma: 0.9999999999999928 and mu: 1.0000000000007667\n",
      "1125, loss is 7.490753303444176e-26 with sigma: 0.999999999999993 and mu: 1.000000000000746\n",
      "1126, loss is 7.09584536790124e-26 with sigma: 0.9999999999999932 and mu: 1.000000000000726\n",
      "1127, loss is 6.719649280373902e-26 with sigma: 0.9999999999999934 and mu: 1.0000000000007065\n",
      "1128, loss is 6.360870318701516e-26 with sigma: 0.9999999999999937 and mu: 1.0000000000006875\n",
      "1129, loss is 6.02498947296561e-26 with sigma: 0.9999999999999939 and mu: 1.000000000000669\n",
      "1130, loss is 5.704847871925813e-26 with sigma: 0.999999999999994 and mu: 1.000000000000651\n",
      "1131, loss is 5.400071064704572e-26 with sigma: 0.9999999999999941 and mu: 1.0000000000006335\n",
      "1132, loss is 5.115412757579856e-26 with sigma: 0.9999999999999942 and mu: 1.0000000000006164\n",
      "1133, loss is 4.840525370785946e-26 with sigma: 0.9999999999999943 and mu: 1.0000000000005997\n",
      "1134, loss is 4.5828054298050497e-26 with sigma: 0.9999999999999944 and mu: 1.0000000000005835\n",
      "1135, loss is 4.337647815690315e-26 with sigma: 0.9999999999999946 and mu: 1.0000000000005678\n",
      "1136, loss is 4.1088957847027546e-26 with sigma: 0.9999999999999947 and mu: 1.0000000000005524\n",
      "1137, loss is 3.889948453214792e-26 with sigma: 0.9999999999999948 and mu: 1.0000000000005376\n",
      "1138, loss is 3.682717199818469e-26 with sigma: 0.9999999999999949 and mu: 1.0000000000005231\n",
      "1139, loss is 3.488951117735063e-26 with sigma: 0.999999999999995 and mu: 1.0000000000005091\n",
      "1140, loss is 3.304029905204888e-26 with sigma: 0.9999999999999951 and mu: 1.0000000000004954\n",
      "1141, loss is 3.1281509451487314e-26 with sigma: 0.9999999999999952 and mu: 1.000000000000482\n",
      "1142, loss is 2.9645317473382585e-26 with sigma: 0.9999999999999953 and mu: 1.0000000000004692\n",
      "1143, loss is 2.8047870720224203e-26 with sigma: 0.9999999999999954 and mu: 1.0000000000004565\n",
      "1144, loss is 2.6576557082743233e-26 with sigma: 0.9999999999999956 and mu: 1.0000000000004443\n",
      "1145, loss is 2.5155614594159883e-26 with sigma: 0.9999999999999957 and mu: 1.0000000000004323\n",
      "1146, loss is 2.382673219278535e-26 with sigma: 0.9999999999999958 and mu: 1.0000000000004208\n",
      "1147, loss is 2.25747436530372e-26 with sigma: 0.9999999999999959 and mu: 1.0000000000004095\n",
      "1148, loss is 2.1355501202341796e-26 with sigma: 0.999999999999996 and mu: 1.0000000000003983\n",
      "1149, loss is 2.0235492160626502e-26 with sigma: 0.9999999999999961 and mu: 1.0000000000003877\n",
      "1150, loss is 1.9153949123252718e-26 with sigma: 0.9999999999999962 and mu: 1.0000000000003773\n",
      "1151, loss is 1.8131372540650553e-26 with sigma: 0.9999999999999963 and mu: 1.000000000000367\n",
      "1152, loss is 1.7177281866794673e-26 with sigma: 0.9999999999999964 and mu: 1.0000000000003573\n",
      "1153, loss is 1.6280768638662153e-26 with sigma: 0.9999999999999966 and mu: 1.0000000000003477\n",
      "1154, loss is 1.541494092661272e-26 with sigma: 0.9999999999999967 and mu: 1.0000000000003384\n",
      "1155, loss is 1.4591958089014397e-26 with sigma: 0.9999999999999968 and mu: 1.0000000000003293\n",
      "1156, loss is 1.3815817396122623e-26 with sigma: 0.9999999999999969 and mu: 1.0000000000003204\n",
      "1157, loss is 1.30804775286757e-26 with sigma: 0.999999999999997 and mu: 1.0000000000003118\n",
      "1158, loss is 1.2383399238205989e-26 with sigma: 0.9999999999999971 and mu: 1.0000000000003033\n",
      "1159, loss is 1.1729604586499008e-26 with sigma: 0.9999999999999972 and mu: 1.000000000000295\n",
      "1160, loss is 1.1087209723004445e-26 with sigma: 0.9999999999999973 and mu: 1.000000000000287\n",
      "1161, loss is 1.0503146290854863e-26 with sigma: 0.9999999999999974 and mu: 1.0000000000002793\n",
      "1162, loss is 9.939526129508323e-27 with sigma: 0.9999999999999976 and mu: 1.0000000000002718\n",
      "1163, loss is 9.417768820598943e-27 with sigma: 0.9999999999999977 and mu: 1.0000000000002645\n",
      "1164, loss is 8.915391634976057e-27 with sigma: 0.9999999999999978 and mu: 1.0000000000002573\n",
      "1165, loss is 8.44408565466413e-27 with sigma: 0.9999999999999979 and mu: 1.0000000000002505\n",
      "1166, loss is 8.005488457603736e-27 with sigma: 0.9999999999999979 and mu: 1.0000000000002438\n",
      "1167, loss is 7.566925218882973e-27 with sigma: 0.999999999999998 and mu: 1.0000000000002371\n",
      "1168, loss is 7.167436350014121e-27 with sigma: 0.999999999999998 and mu: 1.0000000000002307\n",
      "1169, loss is 6.78206539509891e-27 with sigma: 0.999999999999998 and mu: 1.0000000000002245\n",
      "1170, loss is 6.428830399609591e-27 with sigma: 0.999999999999998 and mu: 1.0000000000002185\n",
      "1171, loss is 6.089432464029762e-27 with sigma: 0.999999999999998 and mu: 1.0000000000002127\n",
      "1172, loss is 5.767659892744923e-27 with sigma: 0.999999999999998 and mu: 1.000000000000207\n",
      "1173, loss is 5.457893469288833e-27 with sigma: 0.999999999999998 and mu: 1.0000000000002014\n",
      "1174, loss is 5.175207638023993e-27 with sigma: 0.999999999999998 and mu: 1.000000000000196\n",
      "1175, loss is 4.8948709078516165e-27 with sigma: 0.9999999999999981 and mu: 1.0000000000001907\n",
      "1176, loss is 4.6376954191060095e-27 with sigma: 0.9999999999999981 and mu: 1.0000000000001856\n",
      "1177, loss is 4.38489918907492e-27 with sigma: 0.9999999999999981 and mu: 1.0000000000001805\n",
      "1178, loss is 4.152762227827442e-27 with sigma: 0.9999999999999981 and mu: 1.0000000000001756\n",
      "1179, loss is 3.932390948364094e-27 with sigma: 0.9999999999999981 and mu: 1.000000000000171\n",
      "1180, loss is 3.7238587215004876e-27 with sigma: 0.9999999999999981 and mu: 1.0000000000001663\n",
      "1181, loss is 3.524076436593101e-27 with sigma: 0.9999999999999981 and mu: 1.0000000000001619\n",
      "1182, loss is 3.3349490097655524e-27 with sigma: 0.9999999999999981 and mu: 1.0000000000001574\n",
      "1183, loss is 3.161147916207133e-27 with sigma: 0.9999999999999981 and mu: 1.0000000000001532\n",
      "1184, loss is 2.9854393530970726e-27 with sigma: 0.9999999999999982 and mu: 1.000000000000149\n",
      "1185, loss is 2.8283508385956965e-27 with sigma: 0.9999999999999982 and mu: 1.000000000000145\n",
      "1186, loss is 2.6798759893180995e-27 with sigma: 0.9999999999999982 and mu: 1.000000000000141\n",
      "1187, loss is 2.5330836778283412e-27 with sigma: 0.9999999999999982 and mu: 1.0000000000001372\n",
      "1188, loss is 2.3960587400555376e-27 with sigma: 0.9999999999999982 and mu: 1.0000000000001334\n",
      "1189, loss is 2.2733411186820234e-27 with sigma: 0.9999999999999982 and mu: 1.00000000000013\n",
      "1190, loss is 2.1500490812131828e-27 with sigma: 0.9999999999999982 and mu: 1.0000000000001263\n",
      "1191, loss is 2.0361236495829193e-27 with sigma: 0.9999999999999982 and mu: 1.000000000000123\n",
      "1192, loss is 1.9301568169562595e-27 with sigma: 0.9999999999999983 and mu: 1.0000000000001197\n",
      "1193, loss is 1.8214856548366676e-27 with sigma: 0.9999999999999983 and mu: 1.0000000000001164\n",
      "1194, loss is 1.7268525752194242e-27 with sigma: 0.9999999999999983 and mu: 1.0000000000001132\n",
      "1195, loss is 1.632842137629103e-27 with sigma: 0.9999999999999983 and mu: 1.0000000000001101\n",
      "1196, loss is 1.5480249675196754e-27 with sigma: 0.9999999999999983 and mu: 1.0000000000001072\n",
      "1197, loss is 1.4672138372794715e-27 with sigma: 0.9999999999999983 and mu: 1.0000000000001044\n",
      "1198, loss is 1.3849327766975828e-27 with sigma: 0.9999999999999983 and mu: 1.0000000000001015\n",
      "1199, loss is 1.3139287353293995e-27 with sigma: 0.9999999999999983 and mu: 1.0000000000000988\n",
      "1200, loss is 1.2447931856446929e-27 with sigma: 0.9999999999999983 and mu: 1.0000000000000961\n",
      "1201, loss is 1.1754461787611478e-27 with sigma: 0.9999999999999983 and mu: 1.0000000000000935\n",
      "1202, loss is 1.1145483437451726e-27 with sigma: 0.9999999999999983 and mu: 1.000000000000091\n",
      "1203, loss is 1.0563321096288735e-27 with sigma: 0.9999999999999983 and mu: 1.0000000000000886\n",
      "1204, loss is 1.0009717348685543e-27 with sigma: 0.9999999999999983 and mu: 1.0000000000000862\n",
      "1205, loss is 9.473207459700435e-28 with sigma: 0.9999999999999983 and mu: 1.000000000000084\n",
      "1206, loss is 8.990131793671346e-28 with sigma: 0.9999999999999983 and mu: 1.0000000000000817\n",
      "1207, loss is 8.493335716702191e-28 with sigma: 0.9999999999999983 and mu: 1.0000000000000795\n",
      "1208, loss is 8.0653343396604825e-28 with sigma: 0.9999999999999983 and mu: 1.0000000000000773\n",
      "1209, loss is 7.619159821019389e-28 with sigma: 0.9999999999999983 and mu: 1.0000000000000753\n",
      "1210, loss is 7.238060779157793e-28 with sigma: 0.9999999999999983 and mu: 1.0000000000000733\n",
      "1211, loss is 6.826443873167208e-28 with sigma: 0.9999999999999983 and mu: 1.0000000000000713\n",
      "1212, loss is 6.459273727004083e-28 with sigma: 0.9999999999999983 and mu: 1.0000000000000693\n",
      "1213, loss is 6.138963524662002e-28 with sigma: 0.9999999999999983 and mu: 1.0000000000000675\n",
      "1214, loss is 5.817345671446176e-28 with sigma: 0.9999999999999983 and mu: 1.0000000000000657\n",
      "1215, loss is 5.513970853778322e-28 with sigma: 0.9999999999999983 and mu: 1.000000000000064\n",
      "1216, loss is 5.196112547922e-28 with sigma: 0.9999999999999983 and mu: 1.0000000000000622\n",
      "1217, loss is 4.936704862020383e-28 with sigma: 0.9999999999999984 and mu: 1.0000000000000604\n",
      "1218, loss is 4.671886267038884e-28 with sigma: 0.9999999999999984 and mu: 1.0000000000000588\n",
      "1219, loss is 4.42121928105624e-28 with sigma: 0.9999999999999984 and mu: 1.0000000000000573\n",
      "1220, loss is 4.187751643275163e-28 with sigma: 0.9999999999999984 and mu: 1.0000000000000557\n",
      "1221, loss is 3.945303474608166e-28 with sigma: 0.9999999999999986 and mu: 1.0000000000000542\n",
      "1222, loss is 3.726367288238811e-28 with sigma: 0.9999999999999986 and mu: 1.0000000000000526\n",
      "1223, loss is 3.540164131828267e-28 with sigma: 0.9999999999999986 and mu: 1.0000000000000513\n",
      "1224, loss is 3.3627281698638517e-28 with sigma: 0.9999999999999986 and mu: 1.00000000000005\n",
      "1225, loss is 3.183153808431403e-28 with sigma: 0.9999999999999986 and mu: 1.0000000000000486\n",
      "1226, loss is 3.01523837467247e-28 with sigma: 0.9999999999999986 and mu: 1.0000000000000473\n",
      "1227, loss is 2.8545847619408033e-28 with sigma: 0.9999999999999986 and mu: 1.000000000000046\n",
      "1228, loss is 2.6858534134290715e-28 with sigma: 0.9999999999999986 and mu: 1.0000000000000446\n",
      "1229, loss is 2.548544928900445e-28 with sigma: 0.9999999999999986 and mu: 1.0000000000000435\n",
      "1230, loss is 2.4173094956147676e-28 with sigma: 0.9999999999999986 and mu: 1.0000000000000424\n",
      "1231, loss is 2.291633265225252e-28 with sigma: 0.9999999999999986 and mu: 1.0000000000000413\n",
      "1232, loss is 2.16738285214347e-28 with sigma: 0.9999999999999986 and mu: 1.0000000000000402\n",
      "1233, loss is 2.0642447456675216e-28 with sigma: 0.9999999999999986 and mu: 1.000000000000039\n",
      "1234, loss is 1.9422619298056952e-28 with sigma: 0.9999999999999986 and mu: 1.000000000000038\n",
      "1235, loss is 1.8314617878944376e-28 with sigma: 0.9999999999999986 and mu: 1.0000000000000369\n",
      "1236, loss is 1.742219058691e-28 with sigma: 0.9999999999999986 and mu: 1.000000000000036\n",
      "1237, loss is 1.658541052282206e-28 with sigma: 0.9999999999999986 and mu: 1.000000000000035\n",
      "1238, loss is 1.5753515919818097e-28 with sigma: 0.9999999999999986 and mu: 1.0000000000000342\n",
      "1239, loss is 1.4924539410536677e-28 with sigma: 0.9999999999999986 and mu: 1.0000000000000333\n",
      "1240, loss is 1.4137102516696325e-28 with sigma: 0.9999999999999986 and mu: 1.0000000000000324\n",
      "1241, loss is 1.3435708362894674e-28 with sigma: 0.9999999999999986 and mu: 1.0000000000000315\n",
      "1242, loss is 1.2623645772824114e-28 with sigma: 0.9999999999999986 and mu: 1.0000000000000306\n",
      "1243, loss is 1.1962057445056214e-28 with sigma: 0.9999999999999986 and mu: 1.0000000000000298\n",
      "1244, loss is 1.1199313447866714e-28 with sigma: 0.9999999999999986 and mu: 1.0000000000000289\n",
      "1245, loss is 1.074987210630118e-28 with sigma: 0.9999999999999986 and mu: 1.0000000000000282\n",
      "1246, loss is 1.023031821237408e-28 with sigma: 0.9999999999999986 and mu: 1.0000000000000275\n",
      "1247, loss is 9.736021172353172e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000269\n",
      "1248, loss is 9.236326231534853e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000262\n",
      "1249, loss is 8.795620801074514e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000255\n",
      "1250, loss is 8.367156141690542e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000249\n",
      "1251, loss is 7.857649262016287e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000242\n",
      "1252, loss is 7.471476488093515e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000235\n",
      "1253, loss is 7.028225905746769e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000229\n",
      "1254, loss is 6.658573270140716e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000222\n",
      "1255, loss is 6.253288107505417e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000215\n",
      "1256, loss is 5.836827389654123e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000209\n",
      "1257, loss is 5.504817625039148e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000202\n",
      "1258, loss is 5.260117962109884e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000198\n",
      "1259, loss is 5.0429693608802223e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000193\n",
      "1260, loss is 4.8506936488733977e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000189\n",
      "1261, loss is 4.6093168489433454e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000184\n",
      "1262, loss is 4.3556626644918904e-29 with sigma: 0.9999999999999986 and mu: 1.000000000000018\n",
      "1263, loss is 4.195617886113311e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000175\n",
      "1264, loss is 4.0220105877547446e-29 with sigma: 0.9999999999999986 and mu: 1.000000000000017\n",
      "1265, loss is 3.751147800376124e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000167\n",
      "1266, loss is 3.5396029687359146e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000162\n",
      "1267, loss is 3.393617478951362e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000158\n",
      "1268, loss is 3.185042623645544e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000153\n",
      "1269, loss is 3.027443776296337e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000149\n",
      "1270, loss is 2.83165413733263e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000144\n",
      "1271, loss is 2.6393500323855646e-29 with sigma: 0.9999999999999986 and mu: 1.000000000000014\n",
      "1272, loss is 2.5034793112110755e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000135\n",
      "1273, loss is 2.3438774967197053e-29 with sigma: 0.9999999999999986 and mu: 1.000000000000013\n",
      "1274, loss is 2.1876241402233671e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000127\n",
      "1275, loss is 2.0333956702768373e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000122\n",
      "1276, loss is 1.947263706798239e-29 with sigma: 0.9999999999999986 and mu: 1.000000000000012\n",
      "1277, loss is 1.887036878137792e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000118\n",
      "1278, loss is 1.8252337862224056e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000115\n",
      "1279, loss is 1.758789203141046e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000113\n",
      "1280, loss is 1.6703707505228616e-29 with sigma: 0.9999999999999986 and mu: 1.000000000000011\n",
      "1281, loss is 1.6144698557097013e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000109\n",
      "1282, loss is 1.5397052552685888e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000107\n",
      "1283, loss is 1.496699239610422e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000104\n",
      "1284, loss is 1.4376898851683063e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000102\n",
      "1285, loss is 1.3719657562031138e-29 with sigma: 0.9999999999999986 and mu: 1.00000000000001\n",
      "1286, loss is 1.291808551917717e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000098\n",
      "1287, loss is 1.2469151249140506e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000095\n",
      "1288, loss is 1.1913933995900367e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000093\n",
      "1289, loss is 1.1386067983842449e-29 with sigma: 0.9999999999999986 and mu: 1.000000000000009\n",
      "1290, loss is 1.0730674023767473e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000089\n",
      "1291, loss is 1.0318525015668604e-29 with sigma: 0.9999999999999986 and mu: 1.0000000000000087\n",
      "1292, loss is 9.707926770804353e-30 with sigma: 0.9999999999999986 and mu: 1.0000000000000084\n",
      "1293, loss is 9.3145640976803e-30 with sigma: 0.9999999999999986 and mu: 1.0000000000000082\n",
      "1294, loss is 9.12004517329719e-30 with sigma: 0.9999999999999986 and mu: 1.000000000000008\n",
      "1295, loss is 8.320976839370926e-30 with sigma: 0.9999999999999986 and mu: 1.0000000000000078\n",
      "1296, loss is 7.971555560082671e-30 with sigma: 0.9999999999999986 and mu: 1.0000000000000075\n",
      "1297, loss is 7.510925826550914e-30 with sigma: 0.9999999999999986 and mu: 1.0000000000000073\n",
      "1298, loss is 7.057754510636597e-30 with sigma: 0.9999999999999986 and mu: 1.000000000000007\n",
      "1299, loss is 6.857650389414763e-30 with sigma: 0.9999999999999986 and mu: 1.0000000000000069\n",
      "1300, loss is 6.388540886490531e-30 with sigma: 0.9999999999999986 and mu: 1.0000000000000067\n",
      "1301, loss is 5.917068148949708e-30 with sigma: 0.9999999999999986 and mu: 1.0000000000000064\n",
      "1302, loss is 5.526874742216854e-30 with sigma: 0.9999999999999986 and mu: 1.0000000000000062\n",
      "1303, loss is 5.12011833796227e-30 with sigma: 0.9999999999999986 and mu: 1.000000000000006\n",
      "1304, loss is 4.941205624465032e-30 with sigma: 0.9999999999999986 and mu: 1.0000000000000058\n",
      "1305, loss is 4.566278068991853e-30 with sigma: 0.9999999999999986 and mu: 1.0000000000000056\n",
      "1306, loss is 4.2042032394470526e-30 with sigma: 0.9999999999999986 and mu: 1.0000000000000053\n",
      "1307, loss is 3.794365347281449e-30 with sigma: 0.9999999999999986 and mu: 1.000000000000005\n",
      "1308, loss is 3.4916779617077114e-30 with sigma: 0.9999999999999986 and mu: 1.0000000000000049\n",
      "1309, loss is 3.294654727339371e-30 with sigma: 0.9999999999999986 and mu: 1.0000000000000047\n",
      "1310, loss is 2.9511410501425774e-30 with sigma: 0.9999999999999987 and mu: 1.0000000000000044\n",
      "1311, loss is 2.6437626310183745e-30 with sigma: 0.9999999999999987 and mu: 1.0000000000000042\n",
      "1312, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1313, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1314, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1315, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1316, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1317, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1318, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1319, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1320, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1321, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1322, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1323, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1324, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1325, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1326, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1327, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1328, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1329, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1330, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1331, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1332, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1333, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1334, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1335, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1336, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1337, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1338, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1339, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1340, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1341, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1342, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1343, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1344, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1345, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1346, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1347, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1348, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1349, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1350, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1351, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1352, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1353, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1354, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1355, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1356, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1357, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1358, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1359, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1360, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1361, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1362, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1363, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1364, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1365, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1366, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1367, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1368, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1369, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1370, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1371, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1372, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1373, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1374, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1375, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1376, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1377, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1378, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1379, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1380, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1381, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1382, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1383, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1384, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1385, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1386, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1387, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1388, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1389, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1390, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1391, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1392, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1393, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1394, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1395, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1396, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1397, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1398, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1399, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1400, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1401, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1402, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1403, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1404, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1405, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1406, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1407, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1408, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1409, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1410, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1411, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1412, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1413, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1414, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1415, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1416, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1417, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1418, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1419, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1420, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1421, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1422, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1423, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1424, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1425, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1426, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1427, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1428, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1429, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1430, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1431, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1432, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1433, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1434, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1435, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1436, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1437, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1438, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1439, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1440, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1441, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1442, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1443, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1444, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1445, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1446, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1447, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1448, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1449, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1450, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1451, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1452, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1453, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1454, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1455, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1456, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1457, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1458, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1459, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1460, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1461, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1462, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1463, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1464, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1465, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1466, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1467, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1468, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1469, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1470, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1471, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1472, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1473, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1474, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1475, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1476, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1477, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1478, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1479, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1480, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1481, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1482, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1483, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1484, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1485, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1486, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1487, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1488, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1489, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1490, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1491, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1492, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1493, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1494, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1495, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1496, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1497, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1498, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1499, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1500, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1501, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1502, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1503, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1504, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1505, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1506, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1507, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1508, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1509, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1510, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1511, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1512, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1513, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1514, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1515, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1516, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1517, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1518, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1519, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1520, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1521, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1522, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1523, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1524, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1525, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1526, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1527, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1528, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1529, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1530, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1531, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1532, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1533, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1534, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1535, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1536, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1537, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1538, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1539, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1540, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1541, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1542, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1543, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1544, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1545, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1546, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1547, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1548, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1549, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1550, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1551, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1552, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1553, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1554, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1555, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1556, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1557, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1558, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1559, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1560, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1561, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1562, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1563, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1564, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1565, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1566, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1567, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1568, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1569, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1570, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1571, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1572, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1573, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1574, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1575, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1576, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1577, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1578, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1579, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1580, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1581, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1582, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1583, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1584, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1585, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1586, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1587, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1588, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1589, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1590, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1591, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1592, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1593, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1594, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1595, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1596, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1597, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1598, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1599, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1600, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1601, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1602, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1603, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1604, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1605, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1606, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1607, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1608, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1609, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1610, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1611, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1612, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1613, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1614, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1615, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1616, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1617, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1618, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1619, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1620, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1621, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1622, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1623, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1624, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1625, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1626, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1627, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1628, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1629, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1630, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1631, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1632, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1633, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1634, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1635, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1636, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1637, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1638, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1639, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1640, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1641, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1642, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1643, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1644, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1645, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1646, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1647, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1648, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1649, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1650, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1651, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1652, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1653, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1654, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1655, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1656, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1657, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1658, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1659, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1660, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1661, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1662, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1663, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1664, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1665, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1666, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1667, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1668, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1669, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1670, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1671, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1672, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1673, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1674, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1675, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1676, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1677, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1678, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1679, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1680, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1681, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1682, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1683, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1684, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1685, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1686, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1687, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1688, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1689, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1690, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1691, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1692, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1693, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1694, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1695, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1696, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1697, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1698, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1699, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1700, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1701, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1702, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1703, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1704, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1705, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1706, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1707, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1708, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1709, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1710, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1711, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1712, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1713, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1714, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1715, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1716, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1717, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1718, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1719, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1720, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1721, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1722, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1723, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1724, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1725, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1726, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1727, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1728, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1729, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1730, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1731, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1732, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1733, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1734, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1735, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1736, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1737, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1738, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1739, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1740, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1741, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1742, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1743, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1744, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1745, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1746, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1747, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1748, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1749, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1750, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1751, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1752, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1753, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1754, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1755, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1756, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1757, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1758, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1759, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1760, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1761, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1762, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1763, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1764, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1765, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1766, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1767, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1768, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1769, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1770, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1771, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1772, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1773, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1774, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1775, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1776, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1777, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1778, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1779, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1780, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1781, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1782, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1783, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1784, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1785, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1786, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1787, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1788, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1789, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1790, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1791, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1792, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1793, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1794, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1795, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1796, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1797, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1798, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1799, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1800, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1801, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1802, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1803, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1804, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1805, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1806, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1807, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1808, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1809, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1810, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1811, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1812, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1813, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1814, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1815, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1816, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1817, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1818, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1819, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1820, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1821, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1822, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1823, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1824, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1825, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1826, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1827, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1828, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1829, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1830, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1831, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1832, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1833, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1834, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1835, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1836, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1837, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1838, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1839, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1840, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1841, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1842, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1843, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1844, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1845, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1846, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1847, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1848, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1849, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1850, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1851, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1852, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1853, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1854, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1855, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1856, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1857, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1858, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1859, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1860, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1861, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1862, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1863, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1864, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1865, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1866, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1867, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1868, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1869, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1870, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1871, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1872, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1873, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1874, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1875, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1876, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1877, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1878, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1879, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1880, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1881, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1882, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1883, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1884, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1885, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1886, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1887, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1888, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1889, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1890, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1891, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1892, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1893, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1894, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1895, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1896, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1897, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1898, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1899, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1900, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1901, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1902, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1903, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1904, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1905, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1906, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1907, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1908, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1909, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1910, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1911, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1912, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1913, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1914, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1915, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1916, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1917, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1918, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1919, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1920, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1921, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1922, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1923, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1924, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1925, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1926, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1927, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1928, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1929, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1930, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1931, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1932, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1933, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1934, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1935, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1936, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1937, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1938, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1939, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1940, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1941, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1942, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1943, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1944, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1945, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1946, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1947, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1948, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1949, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1950, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1951, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1952, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1953, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1954, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1955, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1956, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1957, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1958, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1959, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1960, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1961, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1962, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1963, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1964, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1965, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1966, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1967, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1968, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1969, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1970, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1971, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1972, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1973, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1974, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1975, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1976, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1977, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1978, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1979, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1980, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1981, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1982, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1983, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1984, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1985, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1986, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1987, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1988, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1989, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1990, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1991, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1992, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1993, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1994, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1995, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1996, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1997, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1998, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "1999, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2000, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2001, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2002, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2003, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2004, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2005, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2006, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2007, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2008, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2009, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2010, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2011, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2012, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2013, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2014, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2015, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2016, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2017, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2018, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2019, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2020, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2021, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2022, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2023, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2024, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2025, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2026, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2027, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2028, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2029, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2030, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2031, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2032, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2033, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2034, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2035, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2036, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2037, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2038, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2039, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2040, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2041, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2042, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2043, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2044, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2045, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2046, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2047, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2048, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2049, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2050, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2051, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2052, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2053, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2054, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2055, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2056, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2057, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2058, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2059, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2060, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2061, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2062, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2063, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2064, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2065, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2066, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2067, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2068, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2069, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2070, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2071, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2072, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2073, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2074, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2075, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2076, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2077, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2078, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2079, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2080, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2081, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2082, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2083, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2084, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2085, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2086, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2087, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2088, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2089, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2090, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2091, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2092, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2093, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2094, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2095, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2096, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2097, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2098, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2099, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2100, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2101, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2102, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2103, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2104, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2105, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2106, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2107, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2108, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2109, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2110, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2111, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2112, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2113, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2114, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2115, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2116, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2117, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2118, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2119, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2120, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2121, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2122, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2123, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2124, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2125, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2126, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2127, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2128, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2129, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2130, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2131, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2132, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2133, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2134, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2135, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2136, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2137, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2138, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2139, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2140, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2141, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2142, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2143, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2144, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2145, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2146, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2147, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2148, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2149, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2150, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2151, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2152, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2153, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2154, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2155, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2156, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2157, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2158, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2159, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2160, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2161, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2162, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2163, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2164, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2165, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2166, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2167, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2168, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2169, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2170, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2171, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2172, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2173, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2174, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2175, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2176, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2177, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2178, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2179, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2180, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2181, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2182, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2183, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2184, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2185, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2186, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2187, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2188, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2189, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2190, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2191, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2192, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2193, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2194, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2195, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2196, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2197, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2198, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2199, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2200, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2201, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2202, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2203, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2204, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2205, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2206, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2207, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2208, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2209, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2210, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2211, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2212, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2213, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2214, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2215, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2216, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2217, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2218, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2219, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2220, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2221, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2222, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2223, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2224, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2225, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2226, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2227, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2228, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2229, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2230, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2231, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2232, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2233, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2234, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2235, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2236, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2237, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2238, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2239, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2240, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2241, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2242, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2243, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2244, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2245, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2246, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2247, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2248, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2249, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2250, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2251, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2252, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2253, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2254, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2255, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2256, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2257, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2258, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2259, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2260, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2261, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2262, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2263, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2264, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2265, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2266, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2267, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2268, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2269, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2270, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2271, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2272, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2273, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2274, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2275, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2276, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2277, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2278, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2279, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2280, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2281, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2282, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2283, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2284, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2285, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2286, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2287, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2288, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2289, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2290, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2291, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2292, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2293, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2294, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2295, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2296, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2297, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2298, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2299, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2300, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2301, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2302, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2303, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2304, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2305, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2306, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2307, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2308, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2309, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2310, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2311, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2312, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2313, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2314, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2315, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2316, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2317, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2318, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2319, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2320, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2321, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2322, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2323, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2324, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2325, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2326, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2327, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2328, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2329, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2330, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2331, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2332, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2333, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2334, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2335, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2336, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2337, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2338, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2339, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2340, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2341, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2342, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2343, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2344, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2345, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2346, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2347, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2348, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2349, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2350, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2351, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2352, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2353, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2354, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2355, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2356, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2357, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2358, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2359, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2360, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2361, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2362, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2363, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2364, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2365, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2366, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2367, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2368, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2369, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2370, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2371, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2372, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2373, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2374, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2375, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2376, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2377, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2378, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2379, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2380, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2381, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2382, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2383, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2384, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2385, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2386, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2387, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2388, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2389, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2390, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2391, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2392, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2393, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2394, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2395, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2396, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2397, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2398, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2399, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2400, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2401, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2402, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2403, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2404, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2405, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2406, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2407, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2408, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2409, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2410, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2411, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2412, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2413, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2414, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2415, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2416, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2417, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2418, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2419, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2420, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2421, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2422, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2423, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2424, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2425, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2426, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2427, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2428, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2429, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2430, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2431, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2432, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2433, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2434, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2435, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2436, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2437, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2438, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2439, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2440, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2441, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2442, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2443, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2444, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2445, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2446, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2447, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2448, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2449, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2450, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2451, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2452, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2453, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2454, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2455, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2456, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2457, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2458, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2459, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2460, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2461, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2462, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2463, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2464, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2465, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2466, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2467, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2468, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2469, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2470, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2471, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2472, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2473, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2474, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2475, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2476, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2477, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2478, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2479, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2480, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2481, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2482, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2483, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2484, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2485, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2486, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2487, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2488, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2489, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2490, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2491, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2492, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2493, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2494, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2495, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2496, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2497, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2498, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2499, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2500, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2501, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2502, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2503, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2504, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2505, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2506, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2507, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2508, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2509, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2510, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2511, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2512, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2513, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2514, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2515, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2516, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2517, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2518, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2519, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2520, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2521, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2522, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2523, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2524, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2525, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2526, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2527, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2528, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2529, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2530, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2531, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2532, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2533, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2534, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2535, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2536, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2537, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2538, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2539, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2540, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2541, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2542, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2543, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2544, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2545, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2546, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2547, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2548, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2549, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2550, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2551, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2552, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2553, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2554, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2555, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2556, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2557, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2558, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2559, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2560, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2561, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2562, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2563, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2564, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2565, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2566, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2567, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2568, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2569, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2570, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2571, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2572, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2573, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2574, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2575, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2576, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2577, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2578, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2579, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2580, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2581, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2582, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2583, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2584, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2585, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2586, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2587, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2588, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2589, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2590, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2591, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2592, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2593, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2594, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2595, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2596, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2597, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2598, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2599, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2600, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2601, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2602, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2603, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2604, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2605, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2606, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2607, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2608, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2609, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2610, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2611, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2612, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2613, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2614, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2615, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2616, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2617, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2618, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2619, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2620, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2621, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2622, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2623, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2624, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2625, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2626, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2627, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2628, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2629, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2630, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2631, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2632, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2633, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2634, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2635, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2636, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2637, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2638, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2639, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2640, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2641, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2642, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2643, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2644, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2645, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2646, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2647, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2648, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2649, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2650, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2651, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2652, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2653, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2654, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2655, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2656, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2657, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2658, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2659, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2660, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2661, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2662, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2663, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2664, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2665, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2666, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2667, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2668, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2669, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2670, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2671, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2672, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2673, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2674, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2675, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2676, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2677, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2678, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2679, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2680, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2681, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2682, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2683, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2684, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2685, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2686, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2687, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2688, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2689, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2690, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2691, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2692, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2693, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2694, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2695, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2696, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2697, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2698, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2699, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2700, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2701, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2702, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2703, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2704, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2705, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2706, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2707, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2708, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2709, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2710, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2711, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2712, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2713, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2714, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2715, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2716, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2717, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2718, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2719, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2720, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2721, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2722, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2723, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2724, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2725, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2726, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2727, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2728, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2729, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2730, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2731, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2732, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2733, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2734, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2735, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2736, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2737, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2738, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2739, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2740, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2741, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2742, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2743, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2744, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2745, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2746, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2747, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2748, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2749, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2750, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2751, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2752, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2753, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2754, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2755, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2756, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2757, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2758, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2759, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2760, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2761, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2762, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2763, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2764, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2765, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2766, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2767, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2768, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2769, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2770, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2771, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2772, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2773, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2774, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2775, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2776, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2777, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2778, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2779, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2780, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2781, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2782, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2783, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2784, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2785, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2786, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2787, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2788, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2789, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2790, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2791, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2792, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2793, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2794, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2795, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2796, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2797, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2798, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2799, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2800, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2801, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2802, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2803, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2804, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2805, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2806, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2807, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2808, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2809, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2810, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2811, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2812, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2813, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2814, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2815, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2816, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2817, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2818, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2819, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2820, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2821, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2822, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2823, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2824, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2825, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2826, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2827, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2828, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2829, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2830, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2831, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2832, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2833, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2834, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2835, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2836, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2837, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2838, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2839, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2840, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2841, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2842, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2843, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2844, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2845, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2846, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2847, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2848, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2849, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2850, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2851, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2852, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2853, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2854, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2855, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2856, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2857, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2858, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2859, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2860, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2861, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2862, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2863, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2864, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2865, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2866, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2867, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2868, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2869, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2870, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2871, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2872, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2873, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2874, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2875, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2876, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2877, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2878, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2879, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2880, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2881, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2882, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2883, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2884, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2885, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2886, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2887, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2888, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2889, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2890, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2891, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2892, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2893, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2894, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2895, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2896, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2897, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2898, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2899, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2900, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2901, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2902, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2903, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2904, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2905, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2906, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2907, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2908, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2909, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2910, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2911, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2912, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2913, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2914, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2915, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2916, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2917, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2918, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2919, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2920, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2921, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2922, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2923, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2924, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2925, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2926, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2927, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2928, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2929, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2930, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2931, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2932, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2933, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2934, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2935, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2936, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2937, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2938, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2939, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2940, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2941, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2942, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2943, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2944, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2945, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2946, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2947, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2948, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2949, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2950, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2951, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2952, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2953, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2954, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2955, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2956, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2957, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2958, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2959, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2960, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2961, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2962, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2963, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2964, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2965, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2966, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2967, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2968, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2969, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2970, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2971, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2972, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2973, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2974, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2975, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2976, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2977, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2978, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2979, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2980, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2981, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2982, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2983, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2984, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2985, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2986, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2987, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2988, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2989, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2990, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2991, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2992, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2993, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2994, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2995, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2996, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2997, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2998, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "2999, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3000, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3001, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3002, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3003, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3004, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3005, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3006, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3007, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3008, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3009, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3010, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3011, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3012, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3013, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3014, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3015, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3016, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3017, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3018, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3019, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3020, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3021, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3022, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3023, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3024, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3025, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3026, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3027, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3028, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3029, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3030, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3031, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3032, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3033, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3034, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3035, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3036, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3037, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3038, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3039, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3040, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3041, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3042, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3043, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3044, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3045, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3046, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3047, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3048, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3049, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3050, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3051, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3052, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3053, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3054, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3055, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3056, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3057, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3058, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3059, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3060, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3061, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3062, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3063, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3064, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3065, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3066, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3067, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3068, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3069, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3070, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3071, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3072, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3073, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3074, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3075, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3076, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3077, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3078, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3079, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3080, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3081, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3082, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3083, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3084, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3085, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3086, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3087, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3088, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3089, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3090, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3091, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3092, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3093, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3094, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3095, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3096, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3097, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3098, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3099, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3100, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3101, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3102, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3103, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3104, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3105, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3106, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3107, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3108, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3109, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3110, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3111, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3112, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3113, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3114, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3115, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3116, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3117, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3118, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3119, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3120, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3121, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3122, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3123, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3124, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3125, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3126, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3127, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3128, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3129, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3130, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3131, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3132, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3133, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3134, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3135, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3136, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3137, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3138, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3139, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3140, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3141, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3142, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3143, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3144, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3145, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3146, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3147, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3148, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3149, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3150, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3151, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3152, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3153, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3154, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3155, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3156, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3157, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3158, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3159, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3160, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3161, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3162, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3163, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3164, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3165, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3166, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3167, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3168, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3169, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3170, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3171, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3172, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3173, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3174, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3175, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3176, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3177, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3178, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3179, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3180, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3181, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3182, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3183, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3184, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3185, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3186, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3187, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3188, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3189, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3190, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3191, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3192, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3193, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3194, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3195, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3196, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3197, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3198, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3199, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3200, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3201, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3202, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3203, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3204, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3205, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3206, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3207, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3208, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3209, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3210, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3211, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3212, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3213, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3214, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3215, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3216, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3217, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3218, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3219, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3220, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3221, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3222, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3223, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3224, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3225, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3226, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3227, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3228, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3229, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3230, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3231, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3232, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3233, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3234, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3235, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3236, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3237, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3238, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3239, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3240, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3241, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3242, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3243, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3244, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3245, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3246, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3247, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3248, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3249, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3250, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3251, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3252, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3253, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3254, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3255, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3256, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3257, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3258, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3259, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3260, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3261, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3262, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3263, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3264, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3265, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3266, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3267, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3268, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3269, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3270, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3271, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3272, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3273, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3274, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3275, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3276, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3277, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3278, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3279, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3280, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3281, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3282, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3283, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3284, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3285, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3286, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3287, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3288, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3289, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3290, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3291, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3292, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3293, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3294, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3295, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3296, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3297, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3298, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3299, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3300, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3301, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3302, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3303, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3304, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3305, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3306, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3307, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3308, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3309, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3310, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3311, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3312, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3313, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3314, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3315, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3316, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3317, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3318, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3319, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3320, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3321, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3322, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3323, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3324, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3325, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3326, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3327, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3328, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3329, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3330, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3331, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3332, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3333, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3334, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3335, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3336, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3337, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3338, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3339, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3340, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3341, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3342, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3343, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3344, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3345, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3346, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3347, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3348, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3349, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3350, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3351, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3352, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3353, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3354, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3355, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3356, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3357, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3358, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3359, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3360, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3361, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3362, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3363, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3364, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3365, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3366, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3367, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3368, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3369, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3370, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3371, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3372, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3373, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3374, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3375, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3376, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3377, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3378, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3379, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3380, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3381, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3382, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3383, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3384, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3385, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3386, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3387, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3388, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3389, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3390, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3391, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3392, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3393, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3394, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3395, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3396, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3397, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3398, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3399, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3400, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3401, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3402, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3403, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3404, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3405, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3406, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3407, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3408, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3409, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3410, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3411, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3412, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3413, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3414, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3415, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3416, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3417, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3418, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3419, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3420, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3421, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3422, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3423, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3424, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3425, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3426, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3427, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3428, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3429, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3430, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3431, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3432, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3433, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3434, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3435, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3436, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3437, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3438, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3439, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3440, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3441, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3442, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3443, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3444, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3445, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3446, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3447, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3448, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3449, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3450, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3451, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3452, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3453, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3454, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3455, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3456, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3457, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3458, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3459, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3460, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3461, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3462, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3463, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3464, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3465, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3466, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3467, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3468, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3469, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3470, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3471, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3472, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3473, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3474, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3475, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3476, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3477, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3478, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3479, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3480, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3481, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3482, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3483, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3484, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3485, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3486, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3487, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3488, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3489, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3490, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3491, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3492, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3493, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3494, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3495, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3496, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3497, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3498, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3499, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3500, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3501, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3502, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3503, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3504, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3505, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3506, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3507, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3508, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3509, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3510, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3511, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3512, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3513, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3514, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3515, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3516, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3517, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3518, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3519, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3520, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3521, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3522, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3523, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3524, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3525, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3526, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3527, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3528, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3529, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3530, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3531, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3532, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3533, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3534, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3535, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3536, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3537, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3538, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3539, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3540, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3541, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3542, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3543, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3544, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3545, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3546, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3547, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3548, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3549, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3550, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3551, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3552, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3553, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3554, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3555, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3556, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3557, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3558, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3559, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3560, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3561, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3562, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3563, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3564, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3565, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3566, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3567, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3568, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3569, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3570, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3571, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3572, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3573, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3574, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3575, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3576, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3577, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3578, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3579, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3580, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3581, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3582, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3583, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3584, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3585, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3586, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3587, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3588, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3589, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3590, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3591, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3592, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3593, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3594, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3595, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3596, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3597, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3598, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3599, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3600, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3601, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3602, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3603, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3604, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3605, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3606, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3607, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3608, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3609, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3610, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3611, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3612, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3613, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3614, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3615, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3616, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3617, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3618, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3619, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3620, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3621, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3622, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3623, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3624, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3625, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3626, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3627, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3628, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3629, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3630, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3631, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3632, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3633, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3634, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3635, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3636, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3637, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3638, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3639, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3640, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3641, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3642, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3643, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3644, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3645, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3646, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3647, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3648, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3649, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3650, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3651, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3652, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3653, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3654, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3655, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3656, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3657, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3658, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3659, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3660, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3661, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3662, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3663, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3664, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3665, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3666, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3667, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3668, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3669, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3670, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3671, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3672, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3673, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3674, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3675, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3676, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3677, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3678, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3679, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3680, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3681, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3682, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3683, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3684, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3685, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3686, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3687, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3688, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3689, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3690, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3691, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3692, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3693, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3694, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3695, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3696, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3697, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3698, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3699, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3700, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3701, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3702, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3703, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3704, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3705, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3706, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3707, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3708, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3709, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3710, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3711, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3712, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3713, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3714, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3715, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3716, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3717, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3718, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3719, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3720, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3721, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3722, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3723, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3724, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3725, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3726, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3727, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3728, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3729, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3730, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3731, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3732, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3733, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3734, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3735, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3736, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3737, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3738, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3739, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3740, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3741, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3742, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3743, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3744, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3745, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3746, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3747, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3748, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3749, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3750, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3751, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3752, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3753, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3754, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3755, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3756, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3757, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3758, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3759, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3760, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3761, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3762, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3763, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3764, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3765, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3766, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3767, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3768, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3769, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3770, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3771, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3772, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3773, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3774, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3775, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3776, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3777, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3778, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3779, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3780, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3781, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3782, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3783, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3784, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3785, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3786, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3787, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3788, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3789, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3790, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3791, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3792, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3793, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3794, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3795, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3796, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3797, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3798, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3799, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3800, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3801, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3802, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3803, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3804, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3805, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3806, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3807, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3808, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3809, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3810, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3811, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3812, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3813, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3814, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3815, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3816, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3817, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3818, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3819, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3820, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3821, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3822, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3823, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3824, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3825, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3826, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3827, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3828, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3829, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3830, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3831, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3832, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3833, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3834, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3835, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3836, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3837, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3838, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3839, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3840, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3841, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3842, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3843, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3844, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3845, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3846, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3847, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3848, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3849, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3850, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3851, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3852, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3853, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3854, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3855, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3856, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3857, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3858, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3859, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3860, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3861, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3862, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3863, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3864, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3865, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3866, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3867, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3868, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3869, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3870, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3871, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3872, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3873, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3874, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3875, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3876, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3877, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3878, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3879, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3880, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3881, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3882, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3883, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3884, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3885, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3886, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3887, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3888, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3889, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3890, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3891, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3892, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3893, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3894, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3895, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3896, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3897, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3898, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3899, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3900, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3901, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3902, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3903, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3904, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3905, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3906, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3907, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3908, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3909, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3910, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3911, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3912, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3913, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3914, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3915, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3916, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3917, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3918, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3919, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3920, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3921, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3922, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3923, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3924, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3925, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3926, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3927, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3928, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3929, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3930, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3931, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3932, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3933, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3934, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3935, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3936, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3937, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3938, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3939, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3940, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3941, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3942, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3943, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3944, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3945, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3946, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3947, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3948, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3949, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3950, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3951, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3952, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3953, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3954, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3955, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3956, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3957, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3958, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3959, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3960, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3961, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3962, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3963, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3964, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3965, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3966, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3967, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3968, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3969, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3970, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3971, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3972, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3973, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3974, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3975, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3976, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3977, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3978, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3979, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3980, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3981, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3982, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3983, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3984, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3985, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3986, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3987, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3988, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3989, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3990, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3991, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3992, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3993, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3994, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3995, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3996, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3997, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3998, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "3999, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4000, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4001, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4002, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4003, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4004, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4005, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4006, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4007, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4008, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4009, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4010, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4011, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4012, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4013, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4014, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4015, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4016, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4017, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4018, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4019, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4020, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4021, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4022, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4023, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4024, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4025, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4026, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4027, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4028, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4029, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4030, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4031, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4032, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4033, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4034, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4035, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4036, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4037, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4038, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4039, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4040, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4041, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4042, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4043, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4044, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4045, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4046, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4047, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4048, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4049, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4050, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4051, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4052, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4053, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4054, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4055, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4056, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4057, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4058, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4059, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4060, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4061, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4062, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4063, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4064, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4065, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4066, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4067, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4068, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4069, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4070, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4071, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4072, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4073, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4074, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4075, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4076, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4077, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4078, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4079, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4080, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4081, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4082, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4083, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4084, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4085, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4086, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4087, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4088, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4089, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4090, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4091, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4092, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4093, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4094, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4095, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4096, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4097, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4098, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4099, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4100, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4101, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4102, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4103, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4104, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4105, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4106, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4107, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4108, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4109, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4110, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4111, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4112, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4113, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4114, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4115, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4116, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4117, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4118, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4119, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4120, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4121, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4122, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4123, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4124, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4125, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4126, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4127, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4128, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4129, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4130, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4131, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4132, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4133, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4134, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4135, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4136, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4137, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4138, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4139, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4140, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4141, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4142, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4143, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4144, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4145, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4146, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4147, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4148, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4149, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4150, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4151, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4152, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4153, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4154, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4155, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4156, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4157, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4158, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4159, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4160, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4161, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4162, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4163, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4164, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4165, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4166, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4167, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4168, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4169, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4170, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4171, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4172, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4173, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4174, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4175, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4176, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4177, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4178, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4179, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4180, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4181, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4182, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4183, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4184, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4185, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4186, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4187, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4188, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4189, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4190, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4191, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4192, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4193, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4194, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4195, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4196, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4197, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4198, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4199, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4200, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4201, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4202, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4203, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4204, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4205, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4206, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4207, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4208, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4209, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4210, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4211, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4212, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4213, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4214, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4215, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4216, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4217, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4218, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4219, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4220, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4221, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4222, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4223, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4224, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4225, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4226, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4227, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4228, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4229, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4230, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4231, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4232, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4233, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4234, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4235, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4236, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4237, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4238, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4239, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4240, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4241, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4242, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4243, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4244, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4245, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4246, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4247, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4248, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4249, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4250, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4251, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4252, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4253, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4254, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4255, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4256, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4257, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4258, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4259, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4260, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4261, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4262, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4263, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4264, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4265, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4266, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4267, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4268, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4269, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4270, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4271, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4272, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4273, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4274, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4275, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4276, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4277, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4278, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4279, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4280, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4281, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4282, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4283, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4284, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4285, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4286, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4287, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4288, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4289, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4290, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4291, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4292, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4293, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4294, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4295, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4296, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4297, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4298, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4299, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4300, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4301, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4302, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4303, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4304, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4305, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4306, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4307, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4308, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4309, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4310, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4311, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4312, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4313, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4314, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4315, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4316, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4317, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4318, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4319, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4320, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4321, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4322, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4323, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4324, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4325, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4326, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4327, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4328, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4329, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4330, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4331, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4332, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4333, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4334, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4335, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4336, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4337, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4338, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4339, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4340, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4341, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4342, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4343, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4344, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4345, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4346, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4347, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4348, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4349, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4350, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4351, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4352, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4353, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4354, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4355, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4356, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4357, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4358, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4359, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4360, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4361, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4362, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4363, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4364, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4365, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4366, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4367, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4368, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4369, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4370, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4371, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4372, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4373, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4374, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4375, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4376, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4377, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4378, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4379, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4380, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4381, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4382, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4383, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4384, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4385, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4386, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4387, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4388, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4389, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4390, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4391, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4392, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4393, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4394, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4395, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4396, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4397, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4398, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4399, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4400, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4401, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4402, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4403, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4404, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4405, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4406, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4407, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4408, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4409, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4410, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4411, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4412, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4413, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4414, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4415, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4416, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4417, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4418, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4419, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4420, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4421, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4422, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4423, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4424, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4425, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4426, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4427, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4428, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4429, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4430, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4431, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4432, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4433, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4434, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4435, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4436, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4437, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4438, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4439, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4440, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4441, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4442, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4443, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4444, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4445, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4446, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4447, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4448, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4449, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4450, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4451, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4452, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4453, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4454, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4455, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4456, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4457, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4458, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4459, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4460, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4461, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4462, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4463, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4464, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4465, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4466, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4467, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4468, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4469, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4470, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4471, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4472, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4473, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4474, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4475, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4476, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4477, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4478, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4479, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4480, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4481, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4482, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4483, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4484, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4485, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4486, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4487, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4488, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4489, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4490, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4491, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4492, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4493, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4494, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4495, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4496, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4497, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4498, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4499, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4500, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4501, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4502, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4503, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4504, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4505, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4506, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4507, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4508, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4509, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4510, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4511, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4512, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4513, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4514, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4515, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4516, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4517, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4518, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4519, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4520, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4521, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4522, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4523, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4524, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4525, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4526, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4527, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4528, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4529, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4530, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4531, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4532, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4533, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4534, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4535, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4536, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4537, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4538, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4539, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4540, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4541, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4542, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4543, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4544, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4545, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4546, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4547, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4548, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4549, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4550, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4551, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4552, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4553, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4554, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4555, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4556, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4557, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4558, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4559, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4560, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4561, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4562, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4563, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4564, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4565, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4566, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4567, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4568, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4569, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4570, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4571, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4572, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4573, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4574, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4575, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4576, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4577, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4578, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4579, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4580, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4581, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4582, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4583, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4584, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4585, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4586, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4587, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4588, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4589, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4590, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4591, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4592, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4593, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4594, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4595, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4596, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4597, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4598, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4599, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4600, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4601, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4602, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4603, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4604, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4605, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4606, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4607, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4608, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4609, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4610, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4611, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4612, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4613, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4614, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4615, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4616, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4617, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4618, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4619, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4620, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4621, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4622, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4623, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4624, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4625, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4626, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4627, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4628, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4629, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4630, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4631, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4632, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4633, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4634, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4635, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4636, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4637, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4638, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4639, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4640, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4641, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4642, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4643, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4644, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4645, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4646, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4647, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4648, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4649, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4650, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4651, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4652, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4653, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4654, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4655, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4656, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4657, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4658, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4659, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4660, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4661, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4662, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4663, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4664, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4665, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4666, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4667, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4668, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4669, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4670, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4671, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4672, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4673, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4674, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4675, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4676, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4677, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4678, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4679, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4680, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4681, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4682, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4683, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4684, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4685, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4686, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4687, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4688, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4689, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4690, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4691, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4692, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4693, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4694, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4695, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4696, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4697, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4698, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4699, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4700, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4701, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4702, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4703, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4704, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4705, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4706, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4707, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4708, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4709, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4710, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4711, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4712, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4713, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4714, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4715, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4716, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4717, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4718, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4719, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4720, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4721, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4722, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4723, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4724, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4725, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4726, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4727, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4728, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4729, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4730, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4731, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4732, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4733, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4734, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4735, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4736, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4737, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4738, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4739, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4740, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4741, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4742, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4743, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4744, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4745, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4746, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4747, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4748, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4749, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4750, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4751, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4752, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4753, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4754, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4755, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4756, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4757, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4758, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4759, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4760, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4761, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4762, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4763, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4764, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4765, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4766, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4767, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4768, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4769, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4770, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4771, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4772, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4773, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4774, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4775, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4776, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4777, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4778, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4779, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4780, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4781, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4782, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4783, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4784, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4785, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4786, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4787, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4788, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4789, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4790, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4791, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4792, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4793, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4794, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4795, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4796, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4797, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4798, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4799, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4800, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4801, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4802, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4803, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4804, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4805, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4806, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4807, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4808, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4809, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4810, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4811, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4812, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4813, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4814, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4815, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4816, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4817, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4818, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4819, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4820, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4821, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4822, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4823, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4824, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4825, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4826, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4827, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4828, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4829, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4830, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4831, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4832, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4833, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4834, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4835, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4836, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4837, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4838, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4839, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4840, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4841, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4842, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4843, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4844, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4845, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4846, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4847, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4848, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4849, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4850, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4851, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4852, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4853, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4854, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4855, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4856, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4857, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4858, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4859, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4860, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4861, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4862, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4863, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4864, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4865, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4866, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4867, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4868, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4869, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4870, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4871, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4872, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4873, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4874, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4875, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4876, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4877, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4878, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4879, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4880, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4881, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4882, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4883, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4884, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4885, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4886, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4887, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4888, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4889, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4890, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4891, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4892, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4893, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4894, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4895, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4896, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4897, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4898, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4899, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4900, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4901, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4902, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4903, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4904, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4905, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4906, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4907, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4908, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4909, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4910, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4911, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4912, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4913, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4914, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4915, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4916, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4917, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4918, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4919, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4920, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4921, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4922, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4923, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4924, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4925, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4926, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4927, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4928, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4929, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4930, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4931, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4932, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4933, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4934, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4935, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4936, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4937, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4938, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4939, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4940, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4941, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4942, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4943, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4944, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4945, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4946, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4947, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4948, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4949, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4950, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4951, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4952, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4953, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4954, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4955, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4956, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4957, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4958, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4959, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4960, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4961, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4962, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4963, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4964, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4965, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4966, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4967, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4968, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4969, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4970, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4971, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4972, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4973, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4974, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4975, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4976, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4977, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4978, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4979, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4980, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4981, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4982, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4983, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4984, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4985, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4986, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4987, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4988, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4989, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4990, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4991, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4992, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4993, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4994, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4995, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4996, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4997, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4998, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "4999, loss is 2.4187964917310777e-30 with sigma: 0.9999999999999987 and mu: 1.000000000000004\n",
      "Approximated sigma: 0.9999999999999987\n",
      "Approximated mu: 1.000000000000004\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## create data\n",
    "x = np.linspace(-10,10,20)\n",
    "y = gaussian(x, 1,1)\n",
    "# y = gaussian(x, 1, 5) + np.random.randn(len(x))/100\n",
    "# plt.scatter(x,y)\n",
    "\n",
    "sigma = 2\n",
    "mu = 2\n",
    "lr = 0.1\n",
    "\n",
    "def descend(x, y, sigma, mu, lr):\n",
    "    dldmu = 0.0\n",
    "    dldsigma = 0.0\n",
    "    N = x.shape[0]\n",
    "    #loss = (y-yhat)^2\n",
    "    for xi, yi in zip(x,y):\n",
    "        dldmu += 2*(yi-gaussian(xi, sigma, mu))*-1*get_gaussian_grad_mu(xi, sigma, mu)\n",
    "        dldsigma += 2*(yi-gaussian(xi, sigma, mu))*-1*get_gaussian_grad_sigma(xi, sigma, mu)\n",
    "\n",
    "    sigma = sigma - lr*dldsigma\n",
    "    mu = mu - lr*dldmu\n",
    "\n",
    "    return sigma, mu\n",
    "\n",
    "loss_array = np.array([])\n",
    "for epoch in range(5000):\n",
    "    sigma, mu = descend(x,y,sigma, mu, lr)\n",
    "    yhat = gaussian(x, sigma, mu)\n",
    "    loss = np.sum((y-yhat)**2,axis=0)\n",
    "    loss_array = np.append(loss_array, loss)\n",
    "    print(f'{epoch}, loss is {loss} with sigma: {sigma} and mu: {mu}')\n",
    "\n",
    "# plt.plot(x, gaussian(x, sigma, mu))\n",
    "loss_x = np.linspace(0,len(loss_array)-1, len(loss_array))\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(121)\n",
    "plt.plot(loss_x, loss_array)\n",
    "plt.title(\"Gradient Approximation Loss\")\n",
    "\n",
    "\n",
    "x_new = np.linspace(-10,10,100)\n",
    "plt.subplot(122)\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x_new, gaussian(x_new, sigma, mu))\n",
    "print(f'Approximated sigma: {sigma}')\n",
    "print(f'Approximated mu: {mu}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D Gradient Descent Localization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_2D(x, y, sigma_x, sigma_y, mu_x, mu_y):\n",
    "    return np.exp(-((x - mu_x)**2 / (2 * sigma_x**2) + (y - mu_y)**2 / (2 * sigma_y**2))) / (2 * np.pi * sigma_x * sigma_y)\n",
    "\n",
    "def get_gaussian_grad_sigma_x(x, y, sigma_x, sigma_y, mu_x, mu_y):\n",
    "    return np.exp(-((x - mu_x)**2 / (2 * sigma_x**2) + (y - mu_y)**2 / (2 * sigma_y**2)))*(x-mu_x)**2 / (2 * np.pi * sigma_x**4 * sigma_y) - np.exp(-((x - mu_x)**2 / (2 * sigma_x**2) + (y - mu_y)**2 / (2 * sigma_y**2))) / (2 * np.pi * sigma_x**2 * sigma_y)\n",
    "\n",
    "def get_gaussian_grad_sigma_y(x, y, sigma_x, sigma_y, mu_x, mu_y):\n",
    "    return np.exp(-((x - mu_x)**2 / (2 * sigma_x**2) + (y - mu_y)**2 / (2 * sigma_y**2)))*(y-mu_y)**2 / (2 * np.pi * sigma_x * sigma_y**4) - np.exp(-((x - mu_x)**2 / (2 * sigma_x**2) + (y - mu_y)**2 / (2 * sigma_y**2))) / (2 * np.pi * sigma_x * sigma_y**2)\n",
    "\n",
    "def get_gaussian_grad_mu_x(x, y, sigma_x, sigma_y, mu_x, mu_y):\n",
    "    return np.exp(-((x - mu_x)**2 / (2 * sigma_x**2) + (y - mu_y)**2 / (2 * sigma_y**2)))*(x-mu_x) / (2 * np.pi * sigma_x**3 * sigma_y)\n",
    "\n",
    "def get_gaussian_grad_mu_y(x, y, sigma_x, sigma_y, mu_x, mu_y):\n",
    "    return np.exp(-((x - mu_x)**2 / (2 * sigma_x**2) + (y - mu_y)**2 / (2 * sigma_y**2)))*(y-mu_y) / (2 * np.pi * sigma_x * sigma_y**3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, loss is 0.01570260317490343 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9986533056425364 and mu_y: 0.9984380488248747\n",
      "1, loss is 0.01566009940284108 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9973065771225496 and mu_y: 0.996876866293533\n",
      "2, loss is 0.015617619569177512 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9959598274295067 and mu_y: 0.9953164634269166\n",
      "3, loss is 0.015575164357555803 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9946130695911058 and mu_y: 0.9937568512720882\n",
      "4, loss is 0.015532734452868544 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.993266316672196 and mu_y: 0.9921980409013168\n",
      "5, loss is 0.015490330541180661 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9919195817736932 and mu_y: 0.990640043411157\n",
      "6, loss is 0.01544795330965179 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.99057287803149 and mu_y: 0.9890828699215228\n",
      "7, loss is 0.01540560344645837 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9892262186153603 and mu_y: 0.9875265315747563\n",
      "8, loss is 0.015363281640715263 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.987879616727859 and mu_y: 0.9859710395346902\n",
      "9, loss is 0.015320988582397135 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9865330856032165 and mu_y: 0.9844164049857058\n",
      "10, loss is 0.015278724962259455 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9851866385062288 and mu_y: 0.9828626391317857\n",
      "11, loss is 0.015236491471759227 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9838402887311427 and mu_y: 0.9813097531955621\n",
      "12, loss is 0.015194288802975409 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9824940496005373 and mu_y: 0.9797577584173601\n",
      "13, loss is 0.015152117648529096 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9811479344642007 and mu_y: 0.9782066660542368\n",
      "14, loss is 0.015109978701503443 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9798019566980026 and mu_y: 0.9766564873790158\n",
      "15, loss is 0.015067872655363357 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9784561297027645 and mu_y: 0.9751072336793182\n",
      "16, loss is 0.015025800203875003 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9771104669031246 and mu_y: 0.9735589162565894\n",
      "17, loss is 0.014983762041025094 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9757649817464004 and mu_y: 0.9720115464251223\n",
      "18, loss is 0.014941758860940051 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9744196877014476 and mu_y: 0.970465135511077\n",
      "19, loss is 0.01489979135780496 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.973074598257517 and mu_y: 0.9689196948514971\n",
      "20, loss is 0.014857860225782482 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9717297269231071 and mu_y: 0.9673752357933231\n",
      "21, loss is 0.014815966158931538 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9703850872248156 and mu_y: 0.9658317696924027\n",
      "22, loss is 0.014774109851126045 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9690406927061879 and mu_y: 0.9642893079124989\n",
      "23, loss is 0.014732291995973468 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.967696556926563 and mu_y: 0.9627478618242947\n",
      "24, loss is 0.01469051328673338 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9663526934599186 and mu_y: 0.9612074428043963\n",
      "25, loss is 0.014648774416235986 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9650091158937136 and mu_y: 0.9596680622343338\n",
      "26, loss is 0.014607076076800615 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9636658378277293 and mu_y: 0.9581297314995599\n",
      "27, loss is 0.01456541896015428 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9623228728729091 and mu_y: 0.9565924619884476\n",
      "28, loss is 0.014523803757350188 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9609802346501979 and mu_y: 0.9550562650912853\n",
      "29, loss is 0.014482231158686394 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9596379367893795 and mu_y: 0.9535211521992714\n",
      "30, loss is 0.014440701853624428 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.958295992927914 and mu_y: 0.9519871347035074\n",
      "31, loss is 0.014399216530708133 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9569544167097748 and mu_y: 0.9504542239939907\n",
      "32, loss is 0.014357775877482498 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9556132217842849 and mu_y: 0.9489224314586058\n",
      "33, loss is 0.014316380580412699 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9542724218049533 and mu_y: 0.9473917684821155\n",
      "34, loss is 0.014275031324803284 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.952932030428312 and mu_y: 0.945862246445152\n",
      "35, loss is 0.014233728794717503 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9515920613127528 and mu_y: 0.9443338767232078\n",
      "36, loss is 0.014192473672896859 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9502525281173649 and mu_y: 0.9428066706856261\n",
      "37, loss is 0.014151266640680862 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9489134445007739 and mu_y: 0.9412806396945925\n",
      "38, loss is 0.014110108377927016 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9475748241199802 and mu_y: 0.939755795104127\n",
      "39, loss is 0.014068999562931077 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9462366806292006 and mu_y: 0.9382321482590757\n",
      "40, loss is 0.014027940872347553 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9448990276787106 and mu_y: 0.9367097104941052\n",
      "41, loss is 0.01398693298111053 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9435618789136873 and mu_y: 0.9351884931326964\n",
      "42, loss is 0.013945976562354788 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9422252479730557 and mu_y: 0.9336685074861408\n",
      "43, loss is 0.013905072287337278 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9408891484883368 and mu_y: 0.9321497648525384\n",
      "44, loss is 0.013864220825358896 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.939553594082497 and mu_y: 0.9306322765157962\n",
      "45, loss is 0.013823422843686707 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9382185983688008 and mu_y: 0.9291160537446297\n",
      "46, loss is 0.013782679007476498 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9368841749496667 and mu_y: 0.9276011077915665\n",
      "47, loss is 0.013741989979695763 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9355503374155246 and mu_y: 0.9260874498919516\n",
      "48, loss is 0.013701356421047122 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9342170993436777 and mu_y: 0.9245750912629561\n",
      "49, loss is 0.01366077898989217 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9328844742971668 and mu_y: 0.9230640431025879\n",
      "50, loss is 0.01362025834217582 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9315524758236391 and mu_y: 0.9215543165887058\n",
      "51, loss is 0.013579795131351111 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9302211174542195 and mu_y: 0.9200459228780365\n",
      "52, loss is 0.013539390008304513 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.928890412702387 and mu_y: 0.9185388731051953\n",
      "53, loss is 0.013499043621281771 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9275603750628548 and mu_y: 0.91703317838171\n",
      "54, loss is 0.013458756615814287 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9262310180104544 and mu_y: 0.9155288497950482\n",
      "55, loss is 0.01341852963464605 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.924902354999025 and mu_y: 0.9140258984076501\n",
      "56, loss is 0.01337836331766112 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.923574399460307 and mu_y: 0.9125243352559631\n",
      "57, loss is 0.013338258301811769 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.922247164802841 and mu_y: 0.9110241713494824\n",
      "58, loss is 0.01329821522104715 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9209206644108714 and mu_y: 0.9095254176697958\n",
      "59, loss is 0.013258234706242643 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9195949116432559 and mu_y: 0.9080280851696323\n",
      "60, loss is 0.013218317385129833 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.91826991983238 and mu_y: 0.906532184771917\n",
      "61, loss is 0.013178463882227135 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9169457022830777 and mu_y: 0.9050377273688299\n",
      "62, loss is 0.013138674818771102 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9156222722715578 and mu_y: 0.9035447238208703\n",
      "63, loss is 0.013098950812648419 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9142996430443365 and mu_y: 0.9020531849559263\n",
      "64, loss is 0.013059292478328608 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9129778278171763 and mu_y: 0.9005631215683513\n",
      "65, loss is 0.013019700426797447 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.911656839774031 and mu_y: 0.8990745444180437\n",
      "66, loss is 0.012980175265491126 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9103366920659978 and mu_y: 0.8975874642295352\n",
      "67, loss is 0.012940717598231153 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9090173978102762 and mu_y: 0.8961018916910832\n",
      "68, loss is 0.012901328025160048 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9076989700891337 and mu_y: 0.8946178374537711\n",
      "69, loss is 0.012862007142677753 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9063814219488786 and mu_y: 0.8931353121306133\n",
      "70, loss is 0.012822755543378915 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9050647663988406 and mu_y: 0.8916543262956683\n",
      "71, loss is 0.012783573815990913 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9037490164103585 and mu_y: 0.8901748904831582\n",
      "72, loss is 0.012744462545312734 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.902434184915776 and mu_y: 0.8886970151865944\n",
      "73, loss is 0.012705422312154688 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.9011202848074445 and mu_y: 0.8872207108579113\n",
      "74, loss is 0.01266645369327892 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8998073289367354 and mu_y: 0.8857459879066069\n",
      "75, loss is 0.012627557261340853 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8984953301130589 and mu_y: 0.8842728566988904\n",
      "76, loss is 0.012588733584831431 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8971843011028927 and mu_y: 0.8828013275568385\n",
      "77, loss is 0.012549983228020279 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8958742546288179 and mu_y: 0.8813314107575578\n",
      "78, loss is 0.012511306750899759 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8945652033685643 and mu_y: 0.8798631165323565\n",
      "79, loss is 0.012472704709129888 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8932571599540644 and mu_y: 0.878396455065923\n",
      "80, loss is 0.01243417765398423 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8919501369705163 and mu_y: 0.8769314364955136\n",
      "81, loss is 0.012395726132296659 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8906441469554554 and mu_y: 0.8754680709101476\n",
      "82, loss is 0.012357350686409072 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8893392023978355 and mu_y: 0.874006368349811\n",
      "83, loss is 0.012319051854120059 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8880353157371197 and mu_y: 0.8725463388046698\n",
      "84, loss is 0.012280830168634498 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8867324993623802 and mu_y: 0.87108799221429\n",
      "85, loss is 0.012242686158514147 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.885430765611408 and mu_y: 0.869631338466868\n",
      "86, loss is 0.01220462034762916 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8841301267698323 and mu_y: 0.8681763873984693\n",
      "87, loss is 0.012166633255110599 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8828305950702497 and mu_y: 0.8667231487922761\n",
      "88, loss is 0.012128725395303965 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8815321826913641 and mu_y: 0.8652716323778445\n",
      "89, loss is 0.012090897277723665 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8802349017571353 and mu_y: 0.8638218478303709\n",
      "90, loss is 0.012053149407008504 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8789387643359392 and mu_y: 0.8623738047699667\n",
      "91, loss is 0.012015482282878196 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8776437824397378 and mu_y: 0.8609275127609445\n",
      "92, loss is 0.011977896400090856 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8763499680232598 and mu_y: 0.8594829813111118\n",
      "93, loss is 0.01194039224840153 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8750573329831915 and mu_y: 0.8580402198710758\n",
      "94, loss is 0.011902970312521749 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8737658891573787 and mu_y: 0.8565992378335578\n",
      "95, loss is 0.011865631072080118 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8724756483240395 and mu_y: 0.8551600445327165\n",
      "96, loss is 0.011828375001583888 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8711866222009871 and mu_y: 0.8537226492434826\n",
      "97, loss is 0.011791202570381649 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8698988224448649 and mu_y: 0.8522870611809026\n",
      "98, loss is 0.011754114242626977 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.868612260650392 and mu_y: 0.8508532894994928\n",
      "99, loss is 0.011717110477243203 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.867326948349619 and mu_y: 0.8494213432926043\n",
      "100, loss is 0.011680191727889179 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8660428970111969 and mu_y: 0.8479912315917975\n",
      "101, loss is 0.01164335844292611 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8647601180396555 and mu_y: 0.8465629633662268\n",
      "102, loss is 0.011606611065385445 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8634786227746946 and mu_y: 0.8451365475220372\n",
      "103, loss is 0.011569950032937816 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8621984224904855 and mu_y: 0.8437119929017692\n",
      "104, loss is 0.011533375777863059 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.860919528394985 and mu_y: 0.842289308283777\n",
      "105, loss is 0.011496888727021239 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8596419516292603 and mu_y: 0.8408685023816548\n",
      "106, loss is 0.011460489301824804 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8583657032668259 and mu_y: 0.8394495838436753\n",
      "107, loss is 0.011424177918211757 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8570907943129926 and mu_y: 0.8380325612522388\n",
      "108, loss is 0.01138795498661989 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8558172357042271 and mu_y: 0.836617443123333\n",
      "109, loss is 0.0113518209119621 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8545450383075247 and mu_y: 0.8352042379060033\n",
      "110, loss is 0.011315776093602755 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8532742129197934 and mu_y: 0.8337929539818347\n",
      "111, loss is 0.011279820925335115 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8520047702672499 and mu_y: 0.8323835996644445\n",
      "112, loss is 0.011243955795359842 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8507367210048273 and mu_y: 0.8309761831989857\n",
      "113, loss is 0.011208181086264502 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8494700757155957 and mu_y: 0.8295707127616616\n",
      "114, loss is 0.011172497175004214 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8482048449101937 and mu_y: 0.8281671964592519\n",
      "115, loss is 0.011136904432883284 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8469410390262728 and mu_y: 0.826765642328649\n",
      "116, loss is 0.01110140322553792 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8456786684279541 and mu_y: 0.825366058336407\n",
      "117, loss is 0.01106599391291998 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8444177434052961 and mu_y: 0.8239684523783\n",
      "118, loss is 0.011030676849281813 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8431582741737754 and mu_y: 0.8225728322788929\n",
      "119, loss is 0.01099545238316206 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8419002708737802 and mu_y: 0.8211792057911231\n",
      "120, loss is 0.010960320857372589 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8406437435701144 and mu_y: 0.8197875805958935\n",
      "121, loss is 0.010925282608986389 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8393887022515155 and mu_y: 0.8183979643016763\n",
      "122, loss is 0.010890337969326555 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8381351568301838 and mu_y: 0.8170103644441287\n",
      "123, loss is 0.010855487263956243 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.836883117141324 and mu_y: 0.8156247884857191\n",
      "124, loss is 0.010820730812669703 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8356325929426995 and mu_y: 0.8142412438153658\n",
      "125, loss is 0.0107860689294843 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8343835939141983 and mu_y: 0.8128597377480854\n",
      "126, loss is 0.010751501922633537 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8331361296574115 and mu_y: 0.8114802775246538\n",
      "127, loss is 0.010717030094561111 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8318902096952241 and mu_y: 0.8101028703112777\n",
      "128, loss is 0.010682653741915953 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.830645843471418 and mu_y: 0.8087275231992777\n",
      "129, loss is 0.010648373155548264 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.829403040350287 and mu_y: 0.8073542432047821\n",
      "130, loss is 0.010614188620506546 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.828161809616264 and mu_y: 0.8059830372684331\n",
      "131, loss is 0.010580100416035607 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8269221604735607 and mu_y: 0.8046139122551028\n",
      "132, loss is 0.010546108815575522 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8256841020458195 and mu_y: 0.8032468749536212\n",
      "133, loss is 0.010512214086761616 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8244476433757771 and mu_y: 0.8018819320765154\n",
      "134, loss is 0.01047841649142533 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8232127934249404 and mu_y: 0.8005190902597594\n",
      "135, loss is 0.010444716285596112 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8219795610732747 and mu_y: 0.7991583560625358\n",
      "136, loss is 0.010411113719504197 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8207479551189041 and mu_y: 0.7977997359670079\n",
      "137, loss is 0.010377609037584343 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.819517984277823 and mu_y: 0.796443236378103\n",
      "138, loss is 0.010344202478480505 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8182896571836208 and mu_y: 0.7950888636233069\n",
      "139, loss is 0.010310894275051403 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8170629823872179 and mu_y: 0.7937366239524694\n",
      "140, loss is 0.010277684654377015 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8158379683566134 and mu_y: 0.7923865235376204\n",
      "141, loss is 0.010244573837765964 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8146146234766453 and mu_y: 0.7910385684727973\n",
      "142, loss is 0.010211562040763806 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8133929560487617 and mu_y: 0.7896927647738827\n",
      "143, loss is 0.01017864947316218 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.812172974290805 and mu_y: 0.7883491183784539\n",
      "144, loss is 0.010145836339008854 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8109546863368065 and mu_y: 0.7870076351456415\n",
      "145, loss is 0.010113122836618603 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8097381002367929 and mu_y: 0.7856683208560007\n",
      "146, loss is 0.010080509158584978 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8085232239566057 and mu_y: 0.7843311812113914\n",
      "147, loss is 0.010047995491792862 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.80731006537773 and mu_y: 0.7829962218348702\n",
      "148, loss is 0.01001558201743193 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8060986322971367 and mu_y: 0.781663448270592\n",
      "149, loss is 0.009983268911010859 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8048889324271352 and mu_y: 0.7803328659837228\n",
      "150, loss is 0.00995105634237239 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8036809733952373 and mu_y: 0.7790044803603622\n",
      "151, loss is 0.009918944475709186 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8024747627440327 and mu_y: 0.7776782967074769\n",
      "152, loss is 0.00988693346958045 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8012703079310761 and mu_y: 0.776354320252844\n",
      "153, loss is 0.009855023476929365 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.8000676163287844 and mu_y: 0.7750325561450043\n",
      "154, loss is 0.00982321464510126 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.798866695224346 and mu_y: 0.7737130094532264\n",
      "155, loss is 0.009791507115862548 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.79766755181964 and mu_y: 0.7723956851674803\n",
      "156, loss is 0.009759901025420428 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7964701932311677 and mu_y: 0.771080588198421\n",
      "157, loss is 0.00972839650444327 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7952746264899939 and mu_y: 0.7697677233773823\n",
      "158, loss is 0.00969699367808177 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7940808585416987 and mu_y: 0.7684570954563802\n",
      "159, loss is 0.009665692665990771 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7928888962463412 and mu_y: 0.7671487091081257\n",
      "160, loss is 0.009634493582351841 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7916987463784323 and mu_y: 0.765842568926048\n",
      "161, loss is 0.00960339653589644 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7905104156269193 and mu_y: 0.7645386794243263\n",
      "162, loss is 0.009572401629929868 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7893239105951795 and mu_y: 0.7632370450379321\n",
      "163, loss is 0.009541508962355805 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7881392378010258 and mu_y: 0.76193767012268\n",
      "164, loss is 0.009510718625701499 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7869564036767208 and mu_y: 0.7606405589552883\n",
      "165, loss is 0.009480030707143648 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7857754145690021 and mu_y: 0.7593457157334486\n",
      "166, loss is 0.00944944528853484 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7845962767391172 and mu_y: 0.7580531445759047\n",
      "167, loss is 0.009418962446430626 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7834189963628686 and mu_y: 0.75676284952254\n",
      "168, loss is 0.009388582252117233 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7822435795306679 and mu_y: 0.7554748345344747\n",
      "169, loss is 0.0093583047716398 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7810700322476012 and mu_y: 0.7541891034941708\n",
      "170, loss is 0.009328130065831235 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7798983604335022 and mu_y: 0.7529056602055467\n",
      "171, loss is 0.009298058190341628 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7787285699230364 and mu_y: 0.7516245083941001\n",
      "172, loss is 0.009268089195668171 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7775606664657936 and mu_y: 0.750345651707039\n",
      "173, loss is 0.009238223127185693 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7763946557263903 and mu_y: 0.7490690937134221\n",
      "174, loss is 0.00920846002517765 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7752305432845815 and mu_y: 0.7477948379043062\n",
      "175, loss is 0.009178799924867672 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7740683346353807 and mu_y: 0.7465228876929034\n",
      "176, loss is 0.009149242856451576 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7729080351891897 and mu_y: 0.7452532464147451\n",
      "177, loss is 0.009119788845129899 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7717496502719371 and mu_y: 0.7439859173278546\n",
      "178, loss is 0.009090437911140888 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.770593185125225 and mu_y: 0.7427209036129273\n",
      "179, loss is 0.009061190069793942 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7694386449064853 and mu_y: 0.7414582083735196\n",
      "180, loss is 0.009032045331503548 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7682860346891438 and mu_y: 0.7401978346362442\n",
      "181, loss is 0.009003003701823593 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7671353594627929 and mu_y: 0.7389397853509738\n",
      "182, loss is 0.008974065181482152 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7659866241333727 and mu_y: 0.7376840633910521\n",
      "183, loss is 0.008945229766416667 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7648398335233605 and mu_y: 0.7364306715535122\n",
      "184, loss is 0.008916497447809537 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7636949923719678 and mu_y: 0.7351796125593022\n",
      "185, loss is 0.008887868212124058 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7625521053353457 and mu_y: 0.7339308890535182\n",
      "186, loss is 0.008859342041140823 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7614111769867982 and mu_y: 0.7326845036056439\n",
      "187, loss is 0.00883091891199439 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7602722118170031 and mu_y: 0.7314404587097971\n",
      "188, loss is 0.008802598797210367 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7591352142342404 and mu_y: 0.7301987567849842\n",
      "189, loss is 0.008774381664742802 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7580001885646281 and mu_y: 0.7289594001753597\n",
      "190, loss is 0.008746267478011924 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7568671390523662 and mu_y: 0.7277223911504932\n",
      "191, loss is 0.008718256195942187 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.755736069859987 and mu_y: 0.7264877319056432\n",
      "192, loss is 0.008690347773000614 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7546069850686126 and mu_y: 0.7252554245620365\n",
      "193, loss is 0.008662542159235447 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7534798886782202 and mu_y: 0.7240254711671544\n",
      "194, loss is 0.008634839300315061 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.752354784607914 and mu_y: 0.722797873695025\n",
      "195, loss is 0.008607239137567165 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7512316766962033 and mu_y: 0.721572634046521\n",
      "196, loss is 0.008579741608018237 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7501105687012877 and mu_y: 0.7203497540496646\n",
      "197, loss is 0.008552346644433221 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7489914643013492 and mu_y: 0.7191292354599365\n",
      "198, loss is 0.008525054175355451 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7478743670948504 and mu_y: 0.7179110799605922\n",
      "199, loss is 0.008497864125146805 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7467592806008386 and mu_y: 0.7166952891629835\n",
      "200, loss is 0.00847077641402806 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.745646208259257 and mu_y: 0.7154818646068845\n",
      "201, loss is 0.008443790958119451 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7445351534312611 and mu_y: 0.714270807760824\n",
      "202, loss is 0.008416907669481425 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7434261193995417 and mu_y: 0.713062120022423\n",
      "203, loss is 0.008390126456155554 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7423191093686535 and mu_y: 0.7118558027187369\n",
      "204, loss is 0.008363447222205642 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7412141264653492 and mu_y: 0.7106518571066034\n",
      "205, loss is 0.008336869867758978 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7401111737389197 and mu_y: 0.7094502843729944\n",
      "206, loss is 0.008310394289047708 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.739010254161539 and mu_y: 0.7082510856353735\n",
      "207, loss is 0.008284020378450396 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7379113706286158 and mu_y: 0.7070542619420579\n",
      "208, loss is 0.008257748024533648 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7368145259591486 and mu_y: 0.7058598142725846\n",
      "209, loss is 0.008231577112093918 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7357197228960876 and mu_y: 0.7046677435380818\n",
      "210, loss is 0.008205507522199345 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7346269641067001 and mu_y: 0.7034780505816439\n",
      "211, loss is 0.008179539132231746 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7335362521829425 and mu_y: 0.7022907361787109\n",
      "212, loss is 0.00815367181592865 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7324475896418352 and mu_y: 0.7011058010374523\n",
      "213, loss is 0.008127905443425449 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7313609789258436 and mu_y: 0.699923245799155\n",
      "214, loss is 0.008102239881297558 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7302764224032632 and mu_y: 0.6987430710386144\n",
      "215, loss is 0.008076674992602683 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7291939223686089 and mu_y: 0.6975652772645302\n",
      "216, loss is 0.008051210636923111 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7281134810430089 and mu_y: 0.6963898649199055\n",
      "217, loss is 0.008025846670408024 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7270351005746025 and mu_y: 0.6952168343824495\n",
      "218, loss is 0.008000582945815866 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7259587830389428 and mu_y: 0.6940461859649837\n",
      "219, loss is 0.007975419312556704 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7248845304394022 and mu_y: 0.6928779199158513\n",
      "220, loss is 0.007950355616734635 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7238123447075825 and mu_y: 0.6917120364193307\n",
      "221, loss is 0.007925391701190129 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7227422277037289 and mu_y: 0.6905485355960507\n",
      "222, loss is 0.007900527405542429 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.721674181217147 and mu_y: 0.6893874175034105\n",
      "223, loss is 0.007875762566231907 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7206082069666241 and mu_y: 0.6882286821360011\n",
      "224, loss is 0.007851097016562374 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7195443066008533 and mu_y: 0.6870723294260307\n",
      "225, loss is 0.007826530586743407 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7184824816988613 and mu_y: 0.6859183592437522\n",
      "226, loss is 0.007802063103932574 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.717422733770439 and mu_y: 0.6847667713978938\n",
      "227, loss is 0.007777694392277653 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7163650642565759 and mu_y: 0.6836175656360914\n",
      "228, loss is 0.007753424272958784 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7153094745298968 and mu_y: 0.682470741645325\n",
      "229, loss is 0.007729252564230537 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.714255965895102 and mu_y: 0.6813262990523553\n",
      "230, loss is 0.007705179081463936 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7132045395894095 and mu_y: 0.6801842374241647\n",
      "231, loss is 0.007681203637188367 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.712155196783001 and mu_y: 0.679044556268399\n",
      "232, loss is 0.007657326041133438 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7111079385794691 and mu_y: 0.677907255033812\n",
      "233, loss is 0.007633546100270709 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7100627660162683 and mu_y: 0.6767723331107113\n",
      "234, loss is 0.007609863618855353 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7090196800651677 and mu_y: 0.6756397898314068\n",
      "235, loss is 0.007586278398467664 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7079786816327062 and mu_y: 0.6745096244706609\n",
      "236, loss is 0.0075627902380544934 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7069397715606494 and mu_y: 0.6733818362461392\n",
      "237, loss is 0.007539398933970548 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7059029506264494 and mu_y: 0.6722564243188649\n",
      "238, loss is 0.007516104280019538 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7048682195437059 and mu_y: 0.6711333877936727\n",
      "239, loss is 0.007492906067495236 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7038355789626297 and mu_y: 0.6700127257196653\n",
      "240, loss is 0.00746980408522234 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7028050294705076 and mu_y: 0.668894437090671\n",
      "241, loss is 0.007446798119597238 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.701776571592169 and mu_y: 0.6677785208457023\n",
      "242, loss is 0.007423887954628581 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.7007502057904547 and mu_y: 0.666664975869416\n",
      "243, loss is 0.0074010733719777275 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6997259324666862 and mu_y: 0.6655538009925739\n",
      "244, loss is 0.007378354150999005 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6987037519611378 and mu_y: 0.6644449949925052\n",
      "245, loss is 0.00735573006877979 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6976836645535083 and mu_y: 0.6633385565935693\n",
      "246, loss is 0.007333200900180452 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6966656704633958 and mu_y: 0.6622344844676193\n",
      "247, loss is 0.00731076641787408 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6956497698507721 and mu_y: 0.6611327772344668\n",
      "248, loss is 0.007288426392386028 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6946359628164592 and mu_y: 0.6600334334623469\n",
      "249, loss is 0.007266180592133293 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6936242494026063 and mu_y: 0.6589364516683839\n",
      "250, loss is 0.007244028783463664 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6926146295931677 and mu_y: 0.6578418303190575\n",
      "251, loss is 0.0072219707306946995 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6916071033143819 and mu_y: 0.6567495678306697\n",
      "252, loss is 0.007200006196152483 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.690601670435251 and mu_y: 0.6556596625698118\n",
      "253, loss is 0.007178134940210168 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6895983307680209 and mu_y: 0.6545721128538312\n",
      "254, loss is 0.007156356721326313 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6885970840686622 and mu_y: 0.6534869169512996\n",
      "255, loss is 0.007134671296083012 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6875979300373514 and mu_y: 0.65240407308248\n",
      "256, loss is 0.007113078419223781 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6866008683189526 and mu_y: 0.6513235794197951\n",
      "257, loss is 0.007091577843691226 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6856058985034998 and mu_y: 0.6502454340882943\n",
      "258, loss is 0.007070169320664481 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6846130201266789 and mu_y: 0.6491696351661214\n",
      "259, loss is 0.007048852599596426 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6836222326703102 and mu_y: 0.6480961806849822\n",
      "260, loss is 0.0070276274282506275 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6826335355628311 and mu_y: 0.647025068630612\n",
      "261, loss is 0.007006493552738103 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.681646928179779 and mu_y: 0.645956296943242\n",
      "262, loss is 0.006985450717553769 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6806624098442735 and mu_y: 0.6448898635180658\n",
      "263, loss is 0.006964498665612699 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6796799798274991 and mu_y: 0.6438257662057061\n",
      "264, loss is 0.006943637138286098 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6786996373491874 and mu_y: 0.6427640028126799\n",
      "265, loss is 0.0069228658754370434 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6777213815780996 and mu_y: 0.6417045711018639\n",
      "266, loss is 0.006902184615455949 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6767452116325078 and mu_y: 0.6406474687929588\n",
      "267, loss is 0.00688159309529579 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6757711265806766 and mu_y: 0.6395926935629531\n",
      "268, loss is 0.006861091050507051 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6747991254413443 and mu_y: 0.6385402430465865\n",
      "269, loss is 0.006840678215272425 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6738292071842031 and mu_y: 0.637490114836812\n",
      "270, loss is 0.006820354322441231 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6728613707303791 and mu_y: 0.6364423064852571\n",
      "271, loss is 0.006800119103563567 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6718956149529115 and mu_y: 0.6353968155026853\n",
      "272, loss is 0.0067799722889242 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6709319386772312 and mu_y: 0.6343536393594547\n",
      "273, loss is 0.006759913607576174 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6699703406816391 and mu_y: 0.633312775485977\n",
      "274, loss is 0.006739942787374143 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6690108196977822 and mu_y: 0.6322742212731753\n",
      "275, loss is 0.006720059555007435 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6680533744111308 and mu_y: 0.6312379740729404\n",
      "276, loss is 0.006700263636032818 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.667098003461453 and mu_y: 0.6302040311985856\n",
      "277, loss is 0.006680554754907019 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6661447054432893 and mu_y: 0.6291723899253014\n",
      "278, loss is 0.006660932635018918 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6651934789064259 and mu_y: 0.6281430474906082\n",
      "279, loss is 0.006641396998721499 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6642443223563664 and mu_y: 0.6271160010948074\n",
      "280, loss is 0.0066219475673634865 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6632972342548037 and mu_y: 0.6260912479014316\n",
      "281, loss is 0.006602584061320718 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6623522130200888 and mu_y: 0.6250687850376936\n",
      "282, loss is 0.006583306200027202 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6614092570277003 and mu_y: 0.6240486095949337\n",
      "283, loss is 0.006564113702005915 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6604683646107109 and mu_y: 0.6230307186290649\n",
      "284, loss is 0.006545006284899295 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6595295340602542 and mu_y: 0.6220151091610177\n",
      "285, loss is 0.006525983665499441 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6585927636259885 and mu_y: 0.6210017781771824\n",
      "286, loss is 0.006507045559778036 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6576580515165608 and mu_y: 0.6199907226298504\n",
      "287, loss is 0.006488191682915953 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6567253959000676 and mu_y: 0.6189819394376535\n",
      "288, loss is 0.006469421749332602 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6557947949045159 and mu_y: 0.617975425486001\n",
      "289, loss is 0.006450735472714945 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6548662466182812 and mu_y: 0.6169711776275166\n",
      "290, loss is 0.006432132566046255 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.653939749090565 and mu_y: 0.6159691926824719\n",
      "291, loss is 0.006413612741634546 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6530153003318497 and mu_y: 0.6149694674392187\n",
      "292, loss is 0.006395175711140734 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6520928983143529 and mu_y: 0.6139719986546199\n",
      "293, loss is 0.0063768211856064915 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6511725409724787 and mu_y: 0.6129767830544778\n",
      "294, loss is 0.006358548875481798 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6502542262032682 and mu_y: 0.6119838173339608\n",
      "295, loss is 0.006340358490652223 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6493379518668484 and mu_y: 0.6109930981580282\n",
      "296, loss is 0.006322249740465884 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.648423715786878 and mu_y: 0.6100046221618529\n",
      "297, loss is 0.006304222333760124 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6475115157509924 and mu_y: 0.6090183859512425\n",
      "298, loss is 0.006286275978887892 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.646601349511247 and mu_y: 0.6080343861030573\n",
      "299, loss is 0.006268410383743809 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6456932147845574 and mu_y: 0.6070526191656276\n",
      "300, loss is 0.006250625255789993 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6447871092531386 and mu_y: 0.606073081659168\n",
      "301, loss is 0.0062329203020815155 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6438830305649421 and mu_y: 0.6050957700761896\n",
      "302, loss is 0.006215295229291622 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6429809763340903 and mu_y: 0.6041206808819108\n",
      "303, loss is 0.006197749743736634 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6420809441413101 and mu_y: 0.6031478105146648\n",
      "304, loss is 0.0061802835514005484 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6411829315343628 and mu_y: 0.6021771553863057\n",
      "305, loss is 0.006162896357959374 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6402869360284732 and mu_y: 0.6012087118826124\n",
      "306, loss is 0.006145587868805148 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6393929551067561 and mu_y: 0.6002424763636897\n",
      "307, loss is 0.006128357789069664 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6385009862206404 and mu_y: 0.5992784451643675\n",
      "308, loss is 0.006111205823647938 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6376110267902916 and mu_y: 0.5983166145945977\n",
      "309, loss is 0.006094131677221327 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6367230742050309 and mu_y: 0.5973569809398489\n",
      "310, loss is 0.006077135054280419 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6358371258237541 and mu_y: 0.5963995404614981\n",
      "311, loss is 0.006060215659147601 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6349531789753455 and mu_y: 0.5954442893972209\n",
      "312, loss is 0.0060433731959993455 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6340712309590926 and mu_y: 0.5944912239613791\n",
      "313, loss is 0.006026607368888192 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6331912790450953 and mu_y: 0.5935403403454054\n",
      "314, loss is 0.0060099178817645035 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6323133204746757 and mu_y: 0.5925916347181862\n",
      "315, loss is 0.005993304438497848 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6314373524607835 and mu_y: 0.5916451032264421\n",
      "316, loss is 0.0059767667428981715 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6305633721883996 and mu_y: 0.5907007419951055\n",
      "317, loss is 0.0059603044987366575 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6296913768149383 and mu_y: 0.5897585471276956\n",
      "318, loss is 0.0059439174097663024 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.628821363470645 and mu_y: 0.5888185147066921\n",
      "319, loss is 0.005927605179742213 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.627953329258994 and mu_y: 0.5878806407939049\n",
      "320, loss is 0.005911367512441647 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6270872712570819 and mu_y: 0.5869449214308422\n",
      "321, loss is 0.00589520411168373 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6262231865160189 and mu_y: 0.586011352639076\n",
      "322, loss is 0.005879114681348953 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6253610720613191 and mu_y: 0.585079930420605\n",
      "323, loss is 0.005863098925398337 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6245009248932858 and mu_y: 0.5841506507582149\n",
      "324, loss is 0.005847156547892373 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6236427419873968 and mu_y: 0.5832235096158361\n",
      "325, loss is 0.005831287253009667 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6227865202946854 and mu_y: 0.5822985029388992\n",
      "326, loss is 0.005815490745065304 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.62193225674212 and mu_y: 0.5813756266546873\n",
      "327, loss is 0.005799766728528966 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6210799482329805 and mu_y: 0.5804548766726869\n",
      "328, loss is 0.005784114908042769 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6202295916472322 and mu_y: 0.5795362488849344\n",
      "329, loss is 0.005768534988438838 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6193811838418978 and mu_y: 0.578619739166362\n",
      "330, loss is 0.0057530266747566165 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6185347216514258 and mu_y: 0.5777053433751398\n",
      "331, loss is 0.00573758967225991 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6176902018880575 and mu_y: 0.5767930573530153\n",
      "332, loss is 0.005722223686453672 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6168476213421902 and mu_y: 0.5758828769256512\n",
      "333, loss is 0.0057069284231005294 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6160069767827389 and mu_y: 0.5749747979029592\n",
      "334, loss is 0.0056917035882370565 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6151682649574947 and mu_y: 0.5740688160794329\n",
      "335, loss is 0.005676548888189772 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6143314825934809 and mu_y: 0.5731649272344765\n",
      "336, loss is 0.0056614640295909145 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6134966263973064 and mu_y: 0.5722631271327318\n",
      "337, loss is 0.0056464487193939265 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6126636930555165 and mu_y: 0.5713634115244022\n",
      "338, loss is 0.005631502664888731 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6118326792349411 and mu_y: 0.5704657761455745\n",
      "339, loss is 0.005616625573716713 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6110035815830404 and mu_y: 0.5695702167185376\n",
      "340, loss is 0.005601817153885491 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6101763967282474 and mu_y: 0.5686767289520988\n",
      "341, loss is 0.005587077113783428 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.609351121280309 and mu_y: 0.5677853085418972\n",
      "342, loss is 0.005572405162193888 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6085277518306228 and mu_y: 0.5668959511707155\n",
      "343, loss is 0.005557801008309277 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6077062849525727 and mu_y: 0.5660086525087872\n",
      "344, loss is 0.00554326436174482 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6068867172018613 and mu_y: 0.5651234082141033\n",
      "345, loss is 0.005528794932552113 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6060690451168393 and mu_y: 0.5642402139327154\n",
      "346, loss is 0.0055143924312324255 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6052532652188333 and mu_y: 0.5633590652990355\n",
      "347, loss is 0.0055000565687498 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6044393740124694 and mu_y: 0.5624799579361345\n",
      "348, loss is 0.005485787056543885 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6036273679859959 and mu_y: 0.5616028874560375\n",
      "349, loss is 0.005471583606542538 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6028172436116022 and mu_y: 0.5607278494600161\n",
      "350, loss is 0.005457445931174234 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.602008997345735 and mu_y: 0.5598548395388788\n",
      "351, loss is 0.0054433737433802224 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.601202625629413 and mu_y: 0.5589838532732582\n",
      "352, loss is 0.005429366756626451 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.6003981248885376 and mu_y: 0.5581148862338957\n",
      "353, loss is 0.005415424684915294 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.599595491534202 and mu_y: 0.5572479339819243\n",
      "354, loss is 0.005401547242797041 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5987947219629969 and mu_y: 0.5563829920691474\n",
      "355, loss is 0.005387734145381162 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.597995812557314 and mu_y: 0.5555200560383167\n",
      "356, loss is 0.005373985108347387 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5971987596856473 and mu_y: 0.5546591214234059\n",
      "357, loss is 0.005360299847956536 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5964035597028904 and mu_y: 0.553800183749883\n",
      "358, loss is 0.0053466780810611505 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5956102089506329 and mu_y: 0.5529432385349795\n",
      "359, loss is 0.005333119525115928 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5948187037574528 and mu_y: 0.5520882812879571\n",
      "360, loss is 0.00531962389818791 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5940290404392073 and mu_y: 0.5512353075103715\n",
      "361, loss is 0.005306190918966523 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5932412152993202 and mu_y: 0.5503843126963348\n",
      "362, loss is 0.005292820306773349 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5924552246290671 and mu_y: 0.5495352923327738\n",
      "363, loss is 0.005279511781571749 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5916710647078581 and mu_y: 0.5486882418996867\n",
      "364, loss is 0.005266265063976247 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5908887318035179 and mu_y: 0.5478431568703973\n",
      "365, loss is 0.005253079875261738 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5901082221725626 and mu_y: 0.5470000327118061\n",
      "366, loss is 0.005239955937372497 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5893295320604756 and mu_y: 0.5461588648846394\n",
      "367, loss is 0.005226892972930978 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5885526577019786 and mu_y: 0.5453196488436958\n",
      "368, loss is 0.005213890705246453 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5877775953213025 and mu_y: 0.5444823800380898\n",
      "369, loss is 0.00520094885832341 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5870043411324537 and mu_y: 0.5436470539114935\n",
      "370, loss is 0.005188067156869831 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5862328913394792 and mu_y: 0.5428136659023755\n",
      "371, loss is 0.005175245326305209 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5854632421367285 and mu_y: 0.5419822114442371\n",
      "372, loss is 0.005162483092768446 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5846953897091134 and mu_y: 0.5411526859658465\n",
      "373, loss is 0.005149780183125527 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5839293302323645 and mu_y: 0.5403250848914706\n",
      "374, loss is 0.005137136324977028 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5831650598732865 and mu_y: 0.5394994036411033\n",
      "375, loss is 0.005124551246665452 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5824025747900097 and mu_y: 0.538675637630693\n",
      "376, loss is 0.005112024677282374 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5816418711322399 and mu_y: 0.5378537822723665\n",
      "377, loss is 0.005099556346675426 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5808829450415051 and mu_y: 0.5370338329746505\n",
      "378, loss is 0.005087145985455106 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5801257926514004 and mu_y: 0.5362157851426915\n",
      "379, loss is 0.005074793325001407 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5793704100878302 and mu_y: 0.5353996341784729\n",
      "380, loss is 0.005062498097470284 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5786167934692478 and mu_y: 0.534585375481029\n",
      "381, loss is 0.005050260035799977 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5778649389068925 and mu_y: 0.533773004446658\n",
      "382, loss is 0.005038078873717115 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5771148425050249 and mu_y: 0.5329625164691313\n",
      "383, loss is 0.005025954345742722 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5763665003611587 and mu_y: 0.5321539069399017\n",
      "384, loss is 0.005013886187198019 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5756199085662913 and mu_y: 0.5313471712483082\n",
      "385, loss is 0.0050018741342100735 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5748750632051312 and mu_y: 0.530542304781779\n",
      "386, loss is 0.004989917923717315 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5741319603563229 and mu_y: 0.5297393029260323\n",
      "387, loss is 0.004978017293474872 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5733905960926703 and mu_y: 0.5289381610652745\n",
      "388, loss is 0.004966171982059761 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.572650966481357 and mu_y: 0.5281388745823962\n",
      "389, loss is 0.004954381728875936 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5719130675841646 and mu_y: 0.5273414388591661\n",
      "390, loss is 0.0049426462741591825 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.571176895457688 and mu_y: 0.5265458492764225\n",
      "391, loss is 0.0049309653589818475 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5704424461535494 and mu_y: 0.5257521012142623\n",
      "392, loss is 0.004919338725257463 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5697097157186096 and mu_y: 0.5249601900522285\n",
      "393, loss is 0.0049077661157451834 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5689787001951763 and mu_y: 0.5241701111694945\n",
      "394, loss is 0.004896247274054117 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.568249395621211 and mu_y: 0.5233818599450473\n",
      "395, loss is 0.004884781944647488 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5675217980305337 and mu_y: 0.5225954317578674\n",
      "396, loss is 0.004873369872846685 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5667959034530242 and mu_y: 0.5218108219871073\n",
      "397, loss is 0.004862010804835166 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5660717079148226 and mu_y: 0.5210280260122674\n",
      "398, loss is 0.004850704487662209 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5653492074385266 and mu_y: 0.5202470392133703\n",
      "399, loss is 0.0048394506692465665 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5646283980433865 and mu_y: 0.5194678569711323\n",
      "400, loss is 0.0048282490983799645 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.563909275745499 and mu_y: 0.5186904746671329\n",
      "401, loss is 0.004817099524730483 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5631918365579978 and mu_y: 0.5179148876839829\n",
      "402, loss is 0.004806001698845792 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5624760764912421 and mu_y: 0.5171410914054891\n",
      "403, loss is 0.004794955372156287 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5617619915530037 and mu_y: 0.5163690812168186\n",
      "404, loss is 0.004783960296978091 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.561049577748651 and mu_y: 0.5155988525046591\n",
      "405, loss is 0.004773016226515931 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5603388310813319 and mu_y: 0.5148304006573791\n",
      "406, loss is 0.004762122914865885 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5596297475521529 and mu_y: 0.5140637210651844\n",
      "407, loss is 0.004751280117018044 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5589223231603582 and mu_y: 0.5132988091202737\n",
      "408, loss is 0.004740487588859017 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.558216553903505 and mu_y: 0.5125356602169916\n",
      "409, loss is 0.00472974508717435 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5575124357776376 and mu_y: 0.5117742697519798\n",
      "410, loss is 0.004719052369650816 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5568099647774594 and mu_y: 0.5110146331243265\n",
      "411, loss is 0.004708409194878598 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5561091368965018 and mu_y: 0.5102567457357131\n",
      "412, loss is 0.004697815322353369 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5554099481272928 and mu_y: 0.5095006029905602\n",
      "413, loss is 0.004687270512478244 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5547123944615221 and mu_y: 0.5087462002961703\n",
      "414, loss is 0.004676774526565655 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5540164718902049 and mu_y: 0.5079935330628697\n",
      "415, loss is 0.004666327126839082 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5533221764038434 and mu_y: 0.5072425967041473\n",
      "416, loss is 0.0046559280764347285 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5526295039925865 and mu_y: 0.5064933866367932\n",
      "417, loss is 0.00464557713940304 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5519384506463874 and mu_y: 0.5057458982810336\n",
      "418, loss is 0.004635274080710176 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5512490123551593 and mu_y: 0.5050001270606649\n",
      "419, loss is 0.004625018666239338 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5505611851089293 and mu_y: 0.5042560684031858\n",
      "420, loss is 0.004614810662792026 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5498749648979896 and mu_y: 0.5035137177399274\n",
      "421, loss is 0.004604649838089198 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5491903477130482 and mu_y: 0.5027730705061814\n",
      "422, loss is 0.004594535960772326 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5485073295453764 and mu_y: 0.5020341221413269\n",
      "423, loss is 0.004584468800404351 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5478259063869548 and mu_y: 0.5012968680889549\n",
      "424, loss is 0.004574448127470576 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5471460742306178 and mu_y: 0.5005613037969913\n",
      "425, loss is 0.00456447371337944 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5464678290701956 and mu_y: 0.499827424717818\n",
      "426, loss is 0.00455454533046322 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5457911669006553 and mu_y: 0.49909522630839265\n",
      "427, loss is 0.00454466275197863 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5451160837182387 and mu_y: 0.4983647040303659\n",
      "428, loss is 0.0045348257521073574 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5444425755205998 and mu_y: 0.4976358533501978\n",
      "429, loss is 0.004525034105956493 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5437706383069396 and mu_y: 0.4969086697392716\n",
      "430, loss is 0.004515287589558897 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5431002680781395 and mu_y: 0.4961831486740068\n",
      "431, loss is 0.004505585979873459 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5424314608368923 and mu_y: 0.4954592856359697\n",
      "432, loss is 0.004495929054785303 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5417642125878326 and mu_y: 0.49473707611198264\n",
      "433, loss is 0.004486316593105903 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5410985193376641 and mu_y: 0.4940165155942319\n",
      "434, loss is 0.004476748374573117 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5404343770952863 and mu_y: 0.4932975995803731\n",
      "435, loss is 0.004467224179851153 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5397717818719188 and mu_y: 0.4925803235736361\n",
      "436, loss is 0.00445774379053045 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5391107296812239 and mu_y: 0.49186468308292725\n",
      "437, loss is 0.004448306989127504 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5384512165394281 and mu_y: 0.49115067362293063\n",
      "438, loss is 0.004438913559084592 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5377932384654412 and mu_y: 0.49043829071420775\n",
      "439, loss is 0.004429563284769454 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5371367914809745 and mu_y: 0.4897275298832952\n",
      "440, loss is 0.004420255951474899 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5364818716106561 and mu_y: 0.4890183866628014\n",
      "441, loss is 0.004410991345418324 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5358284748821462 and mu_y: 0.48831085659150125\n",
      "442, loss is 0.00440176925374118 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5351765973262498 and mu_y: 0.4876049352144296\n",
      "443, loss is 0.0043925894645083854 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5345262349770273 and mu_y: 0.48690061808297297\n",
      "444, loss is 0.004383451766707645 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5338773838719051 and mu_y: 0.48619790075496\n",
      "445, loss is 0.004374355950248723 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5332300400517829 and mu_y: 0.4854967787947503\n",
      "446, loss is 0.004365301805962661 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5325841995611407 and mu_y: 0.4847972477733218\n",
      "447, loss is 0.004356289125600912 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5319398584481435 and mu_y: 0.4840993032683568\n",
      "448, loss is 0.004347317701834432 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5312970127647448 and mu_y: 0.4834029408643264\n",
      "449, loss is 0.004338387328252714 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5306556585667886 and mu_y: 0.4827081561525735\n",
      "450, loss is 0.004329497799362746 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5300157919141096 and mu_y: 0.4820149447313946\n",
      "451, loss is 0.004320648910587928 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5293774088706321 and mu_y: 0.4813233022061201\n",
      "452, loss is 0.004311840458266937 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5287405055044676 and mu_y: 0.48063322418919285\n",
      "453, loss is 0.004303072239652518 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5281050778880105 and mu_y: 0.47994470630024616\n",
      "454, loss is 0.0042943440529102424 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5274711220980328 and mu_y: 0.47925774416617956\n",
      "455, loss is 0.004285655697117194 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5268386342157769 and mu_y: 0.4785723334212337\n",
      "456, loss is 0.004277006972260626 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5262076103270474 and mu_y: 0.47788846970706383\n",
      "457, loss is 0.004268397679236548 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5255780465223013 and mu_y: 0.477206148672812\n",
      "458, loss is 0.004259827619848276 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5249499388967366 and mu_y: 0.476525365975178\n",
      "459, loss is 0.004251296596804923 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5243232835503797 and mu_y: 0.47584611727848847\n",
      "460, loss is 0.004242804413719856 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5236980765881718 and mu_y: 0.4751683982547657\n",
      "461, loss is 0.004234350875109101 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5230743141200531 and mu_y: 0.4744922045837944\n",
      "462, loss is 0.004225935786389685 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5224519922610464 and mu_y: 0.47381753195318727\n",
      "463, loss is 0.004217558953877969 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5218311071313388 and mu_y: 0.4731443760584499\n",
      "464, loss is 0.004209220184787911 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5212116548563628 and mu_y: 0.4724727326030437\n",
      "465, loss is 0.004200919287229285 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5205936315668749 and mu_y: 0.47180259729844815\n",
      "466, loss is 0.004192656070205878 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5199770333990344 and mu_y: 0.47113396586422157\n",
      "467, loss is 0.004184430343613634 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5193618564944799 and mu_y: 0.47046683402806083\n",
      "468, loss is 0.004176241918238755 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5187480970004044 and mu_y: 0.46980119752585986\n",
      "469, loss is 0.004168090605755763 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5181357510696301 and mu_y: 0.46913705210176687\n",
      "470, loss is 0.004159976218725547 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5175248148606809 and mu_y: 0.46847439350824066\n",
      "471, loss is 0.004151898570593328 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5169152845378545 and mu_y: 0.4678132175061055\n",
      "472, loss is 0.004143857475686637 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5163071562712925 and mu_y: 0.46715351986460507\n",
      "473, loss is 0.004135852749213216 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5157004262370501 and mu_y: 0.46649529636145537\n",
      "474, loss is 0.004127884207258922 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5150950906171641 and mu_y: 0.4658385427828962\n",
      "475, loss is 0.0041199516667855575 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5144911455997193 and mu_y: 0.4651832549237419\n",
      "476, loss is 0.0041120549456287 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5138885873789153 and mu_y: 0.4645294285874307\n",
      "477, loss is 0.00410419386249549 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5132874121551299 and mu_y: 0.46387705958607317\n",
      "478, loss is 0.004096368236962376 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5126876161349833 and mu_y: 0.4632261437404998\n",
      "479, loss is 0.004088577889472844 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5120891955314002 and mu_y: 0.46257667688030707\n",
      "480, loss is 0.004080822641335106 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5114921465636708 and mu_y: 0.46192865484390283\n",
      "481, loss is 0.004073102314719779 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5108964654575111 and mu_y: 0.46128207347855055\n",
      "482, loss is 0.004065416732657496 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5103021484451216 and mu_y: 0.4606369286404126\n",
      "483, loss is 0.004057765719036538 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5097091917652451 and mu_y: 0.45999321619459255\n",
      "484, loss is 0.004050149098600398 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5091175916632238 and mu_y: 0.4593509320151763\n",
      "485, loss is 0.004042566696945349 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5085273443910548 and mu_y: 0.4587100719852724\n",
      "486, loss is 0.004035018340517972 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5079384462074448 and mu_y: 0.4580706319970515\n",
      "487, loss is 0.004027503856612645 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5073508933778634 and mu_y: 0.45743260795178453\n",
      "488, loss is 0.004020023073369046 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5067646821745961 and mu_y: 0.4567959957598802\n",
      "489, loss is 0.004012575819769597 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5061798088767957 and mu_y: 0.4561607913409216\n",
      "490, loss is 0.0040051619256369015 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5055962697705326 and mu_y: 0.4555269906237014\n",
      "491, loss is 0.0039977812216311515 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5050140611488447 and mu_y: 0.4548945895462569\n",
      "492, loss is 0.003990433539247536 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5044331793117856 and mu_y: 0.4542635840559035\n",
      "493, loss is 0.003983118710813579 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.503853620566472 and mu_y: 0.4536339701092677\n",
      "494, loss is 0.003975836569486525 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.503275381227131 and mu_y: 0.45300574367231894\n",
      "495, loss is 0.00396858694925064 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5026984576151452 and mu_y: 0.4523789007204008\n",
      "496, loss is 0.003961369684914538 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5021228460590973 and mu_y: 0.4517534372382612\n",
      "497, loss is 0.003954184612108473 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.501548542894814 and mu_y: 0.4511293492200818\n",
      "498, loss is 0.003947031567281601 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5009755444654089 and mu_y: 0.4505066326695064\n",
      "499, loss is 0.003939910387699253 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.5004038471213244 and mu_y: 0.44988528359966895\n",
      "500, loss is 0.003932820911440163 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.49983344722037226 and mu_y: 0.4492652980332201\n",
      "501, loss is 0.003925762977393703 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4992643411277744 and mu_y: 0.44864667200235353\n",
      "502, loss is 0.003918736425257083 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4986965252162015 and mu_y: 0.4480294015488312\n",
      "503, loss is 0.003911741095532549 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.49812999586581164 and mu_y: 0.44741348272400766\n",
      "504, loss is 0.0039047768295245614 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4975647494642877 and mu_y: 0.446798911588854\n",
      "505, loss is 0.003897843469336958 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.497000782406874 and mu_y: 0.4461856842139805\n",
      "506, loss is 0.0038909408578701138 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.49643809109641196 and mu_y: 0.4455737966796593\n",
      "507, loss is 0.0038840688388180706 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.49587667194337515 and mu_y: 0.4449632450758451\n",
      "508, loss is 0.003877227256665662 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.49531652136590326 and mu_y: 0.4443540255021965\n",
      "509, loss is 0.0038704159566856364 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.49475763578983556 and mu_y: 0.44374613406809554\n",
      "510, loss is 0.003863634784935762 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4942000116487433 and mu_y: 0.44313956689266715\n",
      "511, loss is 0.003856883588255902 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4936436453839612 and mu_y: 0.44253432010479743\n",
      "512, loss is 0.0038501622142651103 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4930885334446187 and mu_y: 0.4419303898431517\n",
      "513, loss is 0.0038434705113587053 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.49253467228766984 and mu_y: 0.44132777225619135\n",
      "514, loss is 0.003836808328705316 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.49198205837792264 and mu_y: 0.4407264635021904\n",
      "515, loss is 0.0038301755162439507 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4914306881880676 and mu_y: 0.44012645974925124\n",
      "516, loss is 0.0038235719246810266 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4908805581987058 and mu_y: 0.4395277571753195\n",
      "517, loss is 0.0038169974054874257 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.49033166489837565 and mu_y: 0.4389303519681987\n",
      "518, loss is 0.003810451810895499 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4897840047835795 and mu_y: 0.43833424032556373\n",
      "519, loss is 0.0038039349938960945 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.48923757435880905 and mu_y: 0.43773941845497416\n",
      "520, loss is 0.003797446808235585 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4886923701365706 and mu_y: 0.4371458825738866\n",
      "521, loss is 0.0037909871084128555 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4881483886374088 and mu_y: 0.4365536289096665\n",
      "522, loss is 0.003784555749676311 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4876056263899305 and mu_y: 0.4359626536995993\n",
      "523, loss is 0.0037781525880208693 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.48706407993082745 and mu_y: 0.43537295319090125\n",
      "524, loss is 0.0037717774801849617 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4865237458048985 and mu_y: 0.43478452364072906\n",
      "525, loss is 0.003765430283647493 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.48598462056507086 and mu_y: 0.4341973613161896\n",
      "526, loss is 0.0037591108566248426 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4854467007724212 and mu_y: 0.4336114624943485\n",
      "527, loss is 0.003752819058067834 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4849099829961955 and mu_y: 0.4330268234622385\n",
      "528, loss is 0.0037465547476586954 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.48437446381382865 and mu_y: 0.4324434405168669\n",
      "529, loss is 0.003740317785808042 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.48384013981096347 and mu_y: 0.43186130996522293\n",
      "530, loss is 0.0037341080336518273 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.48330700758146866 and mu_y: 0.431280428124284\n",
      "531, loss is 0.0037279253530483137 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4827750637274565 and mu_y: 0.4307007913210218\n",
      "532, loss is 0.003721769606575026 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4822443048592998 and mu_y: 0.4301223958924077\n",
      "533, loss is 0.0037156406575257032 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.48171472759564843 and mu_y: 0.42954523818541773\n",
      "534, loss is 0.0037095383699072703 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4811863285634448 and mu_y: 0.42896931455703674\n",
      "535, loss is 0.003703462608436763 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.48065910439793924 and mu_y: 0.4283946213742625\n",
      "536, loss is 0.003697413238538306 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4801330517427046 and mu_y: 0.42782115501410883\n",
      "537, loss is 0.003691390126340044 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4796081672496501 and mu_y: 0.4272489118636086\n",
      "538, loss is 0.0036853931386711045 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.47908444757903484 and mu_y: 0.4266778883198158\n",
      "539, loss is 0.003679422143058534 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4785618893994808 and mu_y: 0.42610808078980766\n",
      "540, loss is 0.003673477007724257 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.47804048938798493 and mu_y: 0.4255394856906859\n",
      "541, loss is 0.0036675576015820196 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.47752024422993106 and mu_y: 0.42497209944957753\n",
      "542, loss is 0.003661663794234343 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4770011506191012 and mu_y: 0.4244059185036353\n",
      "543, loss is 0.003655795455969466 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.476483205257686 and mu_y: 0.4238409393000376\n",
      "544, loss is 0.0036499524577583015 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.47596640485629516 and mu_y: 0.423277158295988\n",
      "545, loss is 0.0036441346712513907 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.47545074613396693 and mu_y: 0.42271457195871437\n",
      "546, loss is 0.003638341968775845 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4749362258181773 and mu_y: 0.4221531767654672\n",
      "547, loss is 0.0036325742233323174 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4744228406448486 and mu_y: 0.42159296920351796\n",
      "548, loss is 0.003626831308591946 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.47391058735835756 and mu_y: 0.42103394577015674\n",
      "549, loss is 0.003621113098893318 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.47339946271154315 and mu_y: 0.4204761029726895\n",
      "550, loss is 0.0036154194692394346 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4728894634657135 and mu_y: 0.41991943732843506\n",
      "551, loss is 0.0036097502952946647 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.47238058639065267 and mu_y: 0.41936394536472144\n",
      "552, loss is 0.00360410545338173 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.47187282826462684 and mu_y: 0.41880962361888197\n",
      "553, loss is 0.0035984848204786537 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.47136618587439005 and mu_y: 0.41825646863825083\n",
      "554, loss is 0.0035928882742157476 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.47086065601518945 and mu_y: 0.41770447698015845\n",
      "555, loss is 0.0035873156928725863 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.47035623549077 and mu_y: 0.4171536452119263\n",
      "556, loss is 0.003581766955374988 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.46985292111337906 and mu_y: 0.41660396991086146\n",
      "557, loss is 0.0035762419412919957 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.46935070970377013 and mu_y: 0.41605544766425057\n",
      "558, loss is 0.003570740530832869 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4688495980912064 and mu_y: 0.4155080750693536\n",
      "559, loss is 0.003565262604844075 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.46834958311346386 and mu_y: 0.41496184873339736\n",
      "560, loss is 0.003559808044806288 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.46785066161683375 and mu_y: 0.4144167652735684\n",
      "561, loss is 0.00355437673283139 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.467352830456125 and mu_y: 0.4138728213170056\n",
      "562, loss is 0.003548968551659475 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.466856086494666 and mu_y: 0.4133300135007926\n",
      "563, loss is 0.0035435833846558687 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4663604266043057 and mu_y: 0.41278833847194984\n",
      "564, loss is 0.003538221115808135 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4658658476654151 and mu_y: 0.4122477928874258\n",
      "565, loss is 0.0035328816297231095 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.46537234656688753 and mu_y: 0.4117083734140888\n",
      "566, loss is 0.0035275648116239204 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.46487992020613883 and mu_y: 0.4111700767287176\n",
      "567, loss is 0.003522270547347022 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4643885654891074 and mu_y: 0.41063289951799214\n",
      "568, loss is 0.003516998723339236 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.46389827933025346 and mu_y: 0.41009683847848405\n",
      "569, loss is 0.0035117492266548 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4634090586525583 and mu_y: 0.40956189031664636\n",
      "570, loss is 0.0035065219449524217 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.462920900387523 and mu_y: 0.4090280517488034\n",
      "571, loss is 0.00350131676649232 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.46243380147516644 and mu_y: 0.4084953195011402\n",
      "572, loss is 0.003496133580133312 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4619477588640238 and mu_y: 0.40796369030969154\n",
      "573, loss is 0.003490972275329869 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.46146276951114384 and mu_y: 0.4074331609203309\n",
      "574, loss is 0.003485832742129205 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4609788303820865 and mu_y: 0.4069037280887587\n",
      "575, loss is 0.0034807148711683486 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4604959384509195 and mu_y: 0.40637538858049094\n",
      "576, loss is 0.003475618553671248 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.46001409070021543 and mu_y: 0.40584813917084694\n",
      "577, loss is 0.0034705436814458637 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.45953328412104755 and mu_y: 0.40532197664493713\n",
      "578, loss is 0.0034654901468812727 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4590535157129862 and mu_y: 0.4047968977976503\n",
      "579, loss is 0.0034604578429447853 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4585747824840941 and mu_y: 0.4042728994336411\n",
      "580, loss is 0.0034554466631790664 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.45809708145092204 and mu_y: 0.40374997836731663\n",
      "581, loss is 0.003450456501699266 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.45762040963850364 and mu_y: 0.4032281314228233\n",
      "582, loss is 0.0034454872531901478 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.45714476408035015 and mu_y: 0.40270735543403324\n",
      "583, loss is 0.003440538812903244 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.45667014181844495 and mu_y: 0.4021876472445303\n",
      "584, loss is 0.0034356110766539955 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4561965399032375 and mu_y: 0.40166900370759623\n",
      "585, loss is 0.003430703940818926 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4557239553936374 and mu_y: 0.4011514216861961\n",
      "586, loss is 0.0034258173023327962 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.45525238535700785 and mu_y: 0.40063489805296393\n",
      "587, loss is 0.0034209510586857973 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4547818268691588 and mu_y: 0.4001194296901878\n",
      "588, loss is 0.0034161051079207123 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.45431227701434007 and mu_y: 0.39960501348979505\n",
      "589, loss is 0.003411279348630133 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.453843732885234 and mu_y: 0.39909164635333677\n",
      "590, loss is 0.003406473679953653 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.453376191582948 and mu_y: 0.3985793251919727\n",
      "591, loss is 0.003401688001575071 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.45290965021700663 and mu_y: 0.39806804692645525\n",
      "592, loss is 0.0033969222137196177 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4524441059053435 and mu_y: 0.3975578084871139\n",
      "593, loss is 0.003392176217151181 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.45197955577429305 and mu_y: 0.3970486068138391\n",
      "594, loss is 0.0033874499131695494 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4515159969585818 and mu_y: 0.39654043885606577\n",
      "595, loss is 0.0033827432036076443 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4510534266013197 and mu_y: 0.39603330157275723\n",
      "596, loss is 0.00337805599082879 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4505918418539909 and mu_y: 0.39552719193238833\n",
      "597, loss is 0.0033733881777239625 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.45013123987644454 and mu_y: 0.39502210691292866\n",
      "598, loss is 0.003368739667709075 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.44967161783688503 and mu_y: 0.39451804350182545\n",
      "599, loss is 0.003364110364722254 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.44921297291186246 and mu_y: 0.3940149986959865\n",
      "600, loss is 0.003359500173221129 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4487553022862625 and mu_y: 0.3935129695017627\n",
      "601, loss is 0.003354908998180138 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4482986031532961 and mu_y: 0.39301195293493046\n",
      "602, loss is 0.003350336745087831 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.44784287271448914 and mu_y: 0.39251194602067424\n",
      "603, loss is 0.003345783319944202 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4473881081796717 and mu_y: 0.3920129457935682\n",
      "604, loss is 0.0033412486292579984 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.446934306766967 and mu_y: 0.39151494929755865\n",
      "605, loss is 0.0033367325800440794 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4464814657027807 and mu_y: 0.3910179535859453\n",
      "606, loss is 0.003332235079820754 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.44602958222178923 and mu_y: 0.39052195572136345\n",
      "607, loss is 0.0033277560366071347 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4455786535669285 and mu_y: 0.390026952775765\n",
      "608, loss is 0.003323295358920518 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.445128676989382 and mu_y: 0.38953294183039994\n",
      "609, loss is 0.003318852955773753 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4446796497485691 and mu_y: 0.38903991997579757\n",
      "610, loss is 0.0033144287366726247 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4442315691121328 and mu_y: 0.3885478843117475\n",
      "611, loss is 0.0033100226116132667 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.44378443235592757 and mu_y: 0.3880568319472805\n",
      "612, loss is 0.003305634491079547 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4433382367640068 and mu_y: 0.38756676000064927\n",
      "613, loss is 0.003301264286040497 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4428929796286102 and mu_y: 0.387077665599309\n",
      "614, loss is 0.003296911907947746 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.44244865825015095 and mu_y: 0.38658954587989797\n",
      "615, loss is 0.00329257726873294 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.44200526993720274 and mu_y: 0.38610239798821777\n",
      "616, loss is 0.0032882602808052 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.44156281200648656 and mu_y: 0.3856162190792137\n",
      "617, loss is 0.0032839608570485726 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4411212817828574 and mu_y: 0.38513100631695457\n",
      "618, loss is 0.0032796789108195095 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4406806765992908 and mu_y: 0.384646756874613\n",
      "619, loss is 0.0032754143559443243 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4402409937968689 and mu_y: 0.38416346793444517\n",
      "620, loss is 0.003271167106716696 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.439802230724767 and mu_y: 0.38368113668777043\n",
      "621, loss is 0.003266937077895167 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4393643847402393 and mu_y: 0.3831997603349512\n",
      "622, loss is 0.003262724184700633 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.43892745320860505 and mu_y: 0.3827193360853722\n",
      "623, loss is 0.003258528342813884 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.43849143350323394 and mu_y: 0.3822398611574201\n",
      "624, loss is 0.0032543494683731147 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4380563230055319 and mu_y: 0.3817613327784628\n",
      "625, loss is 0.003250187477971472 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4376221191049264 and mu_y: 0.3812837481848285\n",
      "626, loss is 0.003246042288654599 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4371888191988518 and mu_y: 0.3808071046217851\n",
      "627, loss is 0.0032419138179182 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4367564206927345 and mu_y: 0.3803313993435188\n",
      "628, loss is 0.003237801983705603 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.436324920999978 and mu_y: 0.37985662961311345\n",
      "629, loss is 0.00323370670440534 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.43589431754194763 and mu_y: 0.3793827927025291\n",
      "630, loss is 0.0032296278988487447 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4354646077479554 and mu_y: 0.3789098858925809\n",
      "631, loss is 0.0032255654863075412 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4350357890552447 and mu_y: 0.3784379064729177\n",
      "632, loss is 0.003221519386491468 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.43460785890897463 and mu_y: 0.37796685174200056\n",
      "633, loss is 0.003217489519545883 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.43418081476220444 and mu_y: 0.37749671900708137\n",
      "634, loss is 0.0032134758060494077 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4337546540758778 and mu_y: 0.37702750558418124\n",
      "635, loss is 0.0032094781670115695 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4333293743188071 and mu_y: 0.37655920879806876\n",
      "636, loss is 0.0032054965238704444 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.43290497296765706 and mu_y: 0.37609182598223834\n",
      "637, loss is 0.0032015307984903235 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4324814475069291 and mu_y: 0.37562535447888834\n",
      "638, loss is 0.0031975809131593873 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.43205879542894476 and mu_y: 0.3751597916388992\n",
      "639, loss is 0.0031936467905873973 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.43163701423382983 and mu_y: 0.3746951348218115\n",
      "640, loss is 0.0031897283539033734 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.43121610142949746 and mu_y: 0.3742313813958041\n",
      "641, loss is 0.0031858255266533097 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.430796054531632 and mu_y: 0.3737685287376717\n",
      "642, loss is 0.0031819382327978843 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4303768710636723 and mu_y: 0.37330657423280306\n",
      "643, loss is 0.0031780663967101897 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.42995854855679483 and mu_y: 0.37284551527515863\n",
      "644, loss is 0.0031742099431734633 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.42954108454989715 and mu_y: 0.3723853492672483\n",
      "645, loss is 0.0031703687973788333 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.42912447658958086 and mu_y: 0.37192607362010915\n",
      "646, loss is 0.0031665428849230784 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4287087222301346 and mu_y: 0.371467685753283\n",
      "647, loss is 0.003162732131806395 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.42829381903351715 and mu_y: 0.37101018309479394\n",
      "648, loss is 0.003158936464430166 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.42787976456933996 and mu_y: 0.37055356308112614\n",
      "649, loss is 0.003155155809594764 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.42746655641485015 and mu_y: 0.370097823157201\n",
      "650, loss is 0.0031513900944973327 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.42705419215491314 and mu_y: 0.36964296077635483\n",
      "651, loss is 0.003147639246729603 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.42664266938199524 and mu_y: 0.36918897340031603\n",
      "652, loss is 0.0031439031942757157 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.42623198569614607 and mu_y: 0.3687358584991827\n",
      "653, loss is 0.0031401818655100396 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4258221387049811 and mu_y: 0.3682836135513997\n",
      "654, loss is 0.003136475189195024 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.425413126023664 and mu_y: 0.36783223604373605\n",
      "655, loss is 0.0031327830944790354 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4250049452748889 and mu_y: 0.3673817234712622\n",
      "656, loss is 0.0031291055108942267 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4245975940888627 and mu_y: 0.366932073337327\n",
      "657, loss is 0.0031254423683544008 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.42419107010328705 and mu_y: 0.36648328315353534\n",
      "658, loss is 0.0031217935971529017 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4237853709633406 and mu_y: 0.3660353504397247\n",
      "659, loss is 0.0031181591279604882 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.42338049432166097 and mu_y: 0.36558827272394256\n",
      "660, loss is 0.0031145388918232563 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4229764378383267 and mu_y: 0.36514204754242363\n",
      "661, loss is 0.0031109328201605305 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.42257319918083924 and mu_y: 0.3646966724395665\n",
      "662, loss is 0.003107340844762796 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4221707760241046 and mu_y: 0.364252144967911\n",
      "663, loss is 0.0031037628977896325 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.42176916605041526 and mu_y: 0.363808462688115\n",
      "664, loss is 0.003100198911767648 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.42136836694943197 and mu_y: 0.36336562316893156\n",
      "665, loss is 0.0030966488195884358 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.42096837641816537 and mu_y: 0.36292362398718564\n",
      "666, loss is 0.0030931125545065386 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4205691921609575 and mu_y: 0.36248246272775125\n",
      "667, loss is 0.0030895900501374117 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.42017081188946354 and mu_y: 0.3620421369835283\n",
      "668, loss is 0.003086081240455421 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.41977323332263317 and mu_y: 0.36160264435541933\n",
      "669, loss is 0.0030825860597918195 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4193764541866923 and mu_y: 0.3611639824523068\n",
      "670, loss is 0.0030791044428327597 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4189804722151242 and mu_y: 0.3607261488910295\n",
      "671, loss is 0.0030756363246173027 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4185852851486512 and mu_y: 0.36028914129635975\n",
      "672, loss is 0.0030721816405354387 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.41819089073521565 and mu_y: 0.35985295730098\n",
      "673, loss is 0.0030687403263261344 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4177972867299617 and mu_y: 0.35941759454545985\n",
      "674, loss is 0.003065312318075347 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4174044708952162 and mu_y: 0.35898305067823283\n",
      "675, loss is 0.0030618975522141065 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4170124410004701 and mu_y: 0.3585493233555731\n",
      "676, loss is 0.0030584959655165604 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.41662119482235954 and mu_y: 0.3581164102415725\n",
      "677, loss is 0.003055107495098049 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4162307301446472 and mu_y: 0.35768430900811704\n",
      "678, loss is 0.0030517320784131967 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4158410447582031 and mu_y: 0.3572530173348641\n",
      "679, loss is 0.003048369653253987 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4154521364609861 and mu_y: 0.35682253290921884\n",
      "680, loss is 0.0030450201577478823 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.41506400305802466 and mu_y: 0.35639285342631133\n",
      "681, loss is 0.003041683530355926 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.414676642361398 and mu_y: 0.35596397658897316\n",
      "682, loss is 0.0030383597098708665 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.41429005219021714 and mu_y: 0.35553590010771435\n",
      "683, loss is 0.0030350486354152858 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.41390423037060575 and mu_y: 0.3551086217007\n",
      "684, loss is 0.003031750246439741 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4135191747356813 and mu_y: 0.3546821390937273\n",
      "685, loss is 0.0030284644827209216 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.41313488312553576 and mu_y: 0.35425645002020223\n",
      "686, loss is 0.0030251912843597996 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.41275135338721675 and mu_y: 0.3538315522211164\n",
      "687, loss is 0.0030219305917798065 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4123685833747083 and mu_y: 0.35340744344502395\n",
      "688, loss is 0.0030186823457250106 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.41198657094891167 and mu_y: 0.3529841214480183\n",
      "689, loss is 0.0030154464872583016 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.41160531397762645 and mu_y: 0.3525615839937089\n",
      "690, loss is 0.003012222957759603 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.41122481033553104 and mu_y: 0.3521398288531985\n",
      "691, loss is 0.0030090116989240617 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4108450579041637 and mu_y: 0.35171885380505946\n",
      "692, loss is 0.003005812652760274 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4104660545719034 and mu_y: 0.351298656635311\n",
      "693, loss is 0.0030026257615885237 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4100877982339504 and mu_y: 0.35087923513739605\n",
      "694, loss is 0.0029994509680389947 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.40971028679230737 and mu_y: 0.350460587112158\n",
      "695, loss is 0.0029962882150500365 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.40933351815575963 and mu_y: 0.35004271036781776\n",
      "696, loss is 0.0029931374458664166 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.40895749023985645 and mu_y: 0.3496256027199507\n",
      "697, loss is 0.0029899986040375724 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.40858220096689146 and mu_y: 0.3492092619914635\n",
      "698, loss is 0.002986871633415898 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4082076482658835 and mu_y: 0.3487936860125713\n",
      "699, loss is 0.0029837564781550227 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4078338300725574 and mu_y: 0.3483788726207745\n",
      "700, loss is 0.0029806530827081053 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.40746074432932466 and mu_y: 0.3479648196608358\n",
      "701, loss is 0.0029775613918261255 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.40708838898526406 and mu_y: 0.3475515249847574\n",
      "702, loss is 0.0029744813505562105 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.40671676199610257 and mu_y: 0.34713898645175784\n",
      "703, loss is 0.0029714129042399426 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.406345861324196 and mu_y: 0.3467272019282492\n",
      "704, loss is 0.0029683559985116924 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.40597568493850955 and mu_y: 0.34631616928781417\n",
      "705, loss is 0.002965310579296957 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.40560623081459884 and mu_y: 0.3459058864111832\n",
      "706, loss is 0.0029622765928106988 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4052374969345903 and mu_y: 0.3454963511862115\n",
      "707, loss is 0.002959253985555717 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.40486948128716216 and mu_y: 0.34508756150785647\n",
      "708, loss is 0.002956242704321 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4045021818675249 and mu_y: 0.34467951527815455\n",
      "709, loss is 0.0029532426961800984 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4041355966774021 and mu_y: 0.3442722104061988\n",
      "710, loss is 0.002950253908489515 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4037697237250113 and mu_y: 0.343865644808116\n",
      "711, loss is 0.002947276288887095 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4034045610250444 and mu_y: 0.34345981640704376\n",
      "712, loss is 0.002944309785290416 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4030401065986487 and mu_y: 0.3430547231331081\n",
      "713, loss is 0.0029413543458952107 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4026763584734074 and mu_y: 0.3426503629234006\n",
      "714, loss is 0.0029384099191737774 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4023133146833205 and mu_y: 0.34224673372195596\n",
      "715, loss is 0.002935476453873405 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.40195097326878554 and mu_y: 0.34184383347972913\n",
      "716, loss is 0.0029325538990148097 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4015893322765782 and mu_y: 0.3414416601545729\n",
      "717, loss is 0.0029296422038905825 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4012283897598334 and mu_y: 0.34104021171121535\n",
      "718, loss is 0.0029267413180636367 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.4008681437780256 and mu_y: 0.3406394861212374\n",
      "719, loss is 0.0029238511913656697 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.40050859239695 and mu_y: 0.34023948136305016\n",
      "720, loss is 0.0029209717738956304 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.40014973368870327 and mu_y: 0.3398401954218727\n",
      "721, loss is 0.002918103016018204 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3997915657316641 and mu_y: 0.3394416262897095\n",
      "722, loss is 0.00291524486836229 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3994340866104743 and mu_y: 0.33904377196532803\n",
      "723, loss is 0.002912397281819502 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3990772944160197 and mu_y: 0.33864663045423665\n",
      "724, loss is 0.0029095602075426682 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.39872118724541067 and mu_y: 0.33825019976866216\n",
      "725, loss is 0.0029067335969443467 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3983657632019633 and mu_y: 0.33785447792752743\n",
      "726, loss is 0.0029039174016953387 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3980110203951802 and mu_y: 0.3374594629564294\n",
      "727, loss is 0.0029011115737232196 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3976569569407313 and mu_y: 0.33706515288761685\n",
      "728, loss is 0.002898316065210881 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.39730357096043484 and mu_y: 0.336671545759968\n",
      "729, loss is 0.002895530828595066 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.39695086058223844 and mu_y: 0.33627863961896876\n",
      "730, loss is 0.0028927558165649223 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3965988239401999 and mu_y: 0.3358864325166905\n",
      "731, loss is 0.002889990982060575 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3962474591744682 and mu_y: 0.3354949225117679\n",
      "732, loss is 0.002887236278271677 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3958967644312644 and mu_y: 0.3351041076693771\n",
      "733, loss is 0.002884491658636006 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3955467378628631 and mu_y: 0.33471398606121383\n",
      "734, loss is 0.0028817570768380277 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.39519737762757284 and mu_y: 0.3343245557654714\n",
      "735, loss is 0.0028790324868075094 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3948486818897177 and mu_y: 0.3339358148668187\n",
      "736, loss is 0.002876317842718105 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3945006488196181 and mu_y: 0.33354776145637877\n",
      "737, loss is 0.0028736130989859736 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.39415327659357186 and mu_y: 0.33316039363170646\n",
      "738, loss is 0.002870918210268389 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.39380656339383563 and mu_y: 0.3327737094967672\n",
      "739, loss is 0.0028682331314623735 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3934605074086058 and mu_y: 0.3323877071619151\n",
      "740, loss is 0.0028655578177033125 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.39311510683199963 and mu_y: 0.3320023847438713\n",
      "741, loss is 0.002862892224363624 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.39277035986403674 and mu_y: 0.33161774036570224\n",
      "742, loss is 0.002860236307051371 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3924262647106201 and mu_y: 0.33123377215679844\n",
      "743, loss is 0.0028575900216089435 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3920828195835173 and mu_y: 0.3308504782528527\n",
      "744, loss is 0.0028549533241117135 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.391740022700342 and mu_y: 0.3304678567958387\n",
      "745, loss is 0.002852326170866697 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3913978722845351 and mu_y: 0.3300859059339895\n",
      "746, loss is 0.002849708518411249 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.391056366565346 and mu_y: 0.32970462382177645\n",
      "747, loss is 0.002847100323511735 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.39071550377781417 and mu_y: 0.32932400861988753\n",
      "748, loss is 0.002844501543162227 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.39037528216275047 and mu_y: 0.3289440584952062\n",
      "749, loss is 0.002841912134583213 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.39003569996671855 and mu_y: 0.3285647716207902\n",
      "750, loss is 0.0028393320552202944 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.38969675544201626 and mu_y: 0.32818614617585024\n",
      "751, loss is 0.002836761262742908 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3893584468466572 and mu_y: 0.327808180345729\n",
      "752, loss is 0.0028341997150430455 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3890207724443523 and mu_y: 0.32743087232188\n",
      "753, loss is 0.00283164737023399 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3886837305044911 and mu_y: 0.32705422030184644\n",
      "754, loss is 0.0028291041866490368 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.38834731930212374 and mu_y: 0.32667822248924033\n",
      "755, loss is 0.002826570122840266 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3880115371179422 and mu_y: 0.3263028770937216\n",
      "756, loss is 0.00282404513757727 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.387676382238262 and mu_y: 0.32592818233097687\n",
      "757, loss is 0.0028215291898459243 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3873418529550042 and mu_y: 0.3255541364226991\n",
      "758, loss is 0.0028190222388471487 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.38700794756567664 and mu_y: 0.32518073759656635\n",
      "759, loss is 0.002816524243995683 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.386674664373356 and mu_y: 0.3248079840862213\n",
      "760, loss is 0.0028140351649188714 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3863420016866695 and mu_y: 0.3244358741312504\n",
      "761, loss is 0.0028115549614554473 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.38600995781977654 and mu_y: 0.32406440597716335\n",
      "762, loss is 0.0028090835936543223 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3856785310923508 and mu_y: 0.3236935778753724\n",
      "763, loss is 0.002806621021773394 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3853477198295619 and mu_y: 0.32332338808317174\n",
      "764, loss is 0.0028041672062783566 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3850175223620575 and mu_y: 0.32295383486371726\n",
      "765, loss is 0.0028017221078415087 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3846879370259451 and mu_y: 0.3225849164860059\n",
      "766, loss is 0.002799285687340584 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3843589621627741 and mu_y: 0.3222166312248553\n",
      "767, loss is 0.002796857905857573 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3840305961195177 and mu_y: 0.3218489773608834\n",
      "768, loss is 0.0027944387246775625 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3837028372485551 and mu_y: 0.3214819531804884\n",
      "769, loss is 0.0027920281052875766 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.38337568390765353 and mu_y: 0.3211155569758281\n",
      "770, loss is 0.002789626009375431 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3830491344599504 and mu_y: 0.32074978704480017\n",
      "771, loss is 0.0027872323988285823 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.38272318727393545 and mu_y: 0.3203846416910217\n",
      "772, loss is 0.0027848472357329943 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.38239784072343286 and mu_y: 0.3200201192238093\n",
      "773, loss is 0.0027824704823720065 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.38207309318758365 and mu_y: 0.31965621795815896\n",
      "774, loss is 0.00278010210122521 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.38174894305082785 and mu_y: 0.3192929362147262\n",
      "775, loss is 0.002777742054967333 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3814253887028869 and mu_y: 0.31893027231980603\n",
      "776, loss is 0.0027753903064671208 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3811024285387458 and mu_y: 0.3185682246053131\n",
      "777, loss is 0.002773046818786245 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.38078006095863587 and mu_y: 0.31820679140876196\n",
      "778, loss is 0.002770711555178192 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3804582843680168 and mu_y: 0.3178459710732473\n",
      "779, loss is 0.0027683844790871784 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3801370971775594 and mu_y: 0.31748576194742417\n",
      "780, loss is 0.0027660655541470623 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3798164978031278 and mu_y: 0.31712616238548846\n",
      "781, loss is 0.002763754744180275 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3794964846657625 and mu_y: 0.3167671707471571\n",
      "782, loss is 0.002761452013196725 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3791770561916624 and mu_y: 0.3164087853976487\n",
      "783, loss is 0.002759157325392761 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.37885821081216786 and mu_y: 0.3160510047076641\n",
      "784, loss is 0.0027568706451500864 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3785399469637431 and mu_y: 0.3156938270533667\n",
      "785, loss is 0.0027545919370347213 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.37822226308795903 and mu_y: 0.3153372508163632\n",
      "786, loss is 0.0027523211657959467 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.37790515763147603 and mu_y: 0.3149812743836845\n",
      "787, loss is 0.002750058296365269 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3775886290460267 and mu_y: 0.3146258961477661\n",
      "788, loss is 0.002747803293855372 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3772726757883986 and mu_y: 0.314271114506429\n",
      "789, loss is 0.0027455561235591075 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.37695729632041736 and mu_y: 0.3139169278628606\n",
      "790, loss is 0.0027433167509484544 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.37664248910892933 and mu_y: 0.3135633346255956\n",
      "791, loss is 0.002741085141673508 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3763282526257848 and mu_y: 0.3132103332084969\n",
      "792, loss is 0.002738861261561469 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.37601458534782073 and mu_y: 0.3128579220307366\n",
      "793, loss is 0.0027366450766156355 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.37570148575684403 and mu_y: 0.3125060995167771\n",
      "794, loss is 0.0027344365530144084 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.37538895233961456 and mu_y: 0.3121548640963523\n",
      "795, loss is 0.00273223565711029 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3750769835878282 and mu_y: 0.3118042142044485\n",
      "796, loss is 0.002730042355428903 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3747655779981001 and mu_y: 0.3114541482812859\n",
      "797, loss is 0.0027278566146680073 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.37445473407194785 and mu_y: 0.3111046647722999\n",
      "798, loss is 0.0027256784016965164 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3741444503157747 and mu_y: 0.3107557621281222\n",
      "799, loss is 0.002723507683553542 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.37383472524085304 and mu_y: 0.3104074388045624\n",
      "800, loss is 0.002721344427447407 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3735255573633075 and mu_y: 0.3100596932625893\n",
      "801, loss is 0.002719188600754713 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3732169452040985 and mu_y: 0.3097125239683126\n",
      "802, loss is 0.0027170401710193627 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3729088872890055 and mu_y: 0.30936592939296437\n",
      "803, loss is 0.0027148991059516275 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3726013821486108 and mu_y: 0.3090199080128806\n",
      "804, loss is 0.002712765373427199 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.37229442831828286 and mu_y: 0.3086744583094829\n",
      "805, loss is 0.0027106389414862523 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3719880243381596 and mu_y: 0.3083295787692604\n",
      "806, loss is 0.00270851977833252 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3716821687531325 and mu_y: 0.3079852678837513\n",
      "807, loss is 0.002706407852332356 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.37137686011282994 and mu_y: 0.30764152414952484\n",
      "808, loss is 0.002704303132013827 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.37107209697160093 and mu_y: 0.3072983460681632\n",
      "809, loss is 0.0027022055860657914 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.37076787788849896 and mu_y: 0.30695573214624344\n",
      "810, loss is 0.002700115183336989 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3704642014272656 and mu_y: 0.3066136808953195\n",
      "811, loss is 0.0026980318928351405 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3701610661563145 and mu_y: 0.30627219083190427\n",
      "812, loss is 0.0026959556837260487 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.36985847064871513 and mu_y: 0.3059312604774517\n",
      "813, loss is 0.0026938865253326996 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.36955641348217677 and mu_y: 0.3055908883583391\n",
      "814, loss is 0.0026918243871343816 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.36925489323903243 and mu_y: 0.3052510730058491\n",
      "815, loss is 0.0026897692387658004 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3689539085062229 and mu_y: 0.3049118129561523\n",
      "816, loss is 0.002687721050016199 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3686534578752807 and mu_y: 0.30457310675028926\n",
      "817, loss is 0.0026856797908284876 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.36835353994231435 and mu_y: 0.30423495293415326\n",
      "818, loss is 0.002683645431298374 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3680541533079923 and mu_y: 0.30389735005847246\n",
      "819, loss is 0.0026816179416735055 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.36775529657752726 and mu_y: 0.30356029667879264\n",
      "820, loss is 0.002679597292352609 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.36745696836066033 and mu_y: 0.3032237913554595\n",
      "821, loss is 0.0026775834538846376 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3671591672716454 and mu_y: 0.30288783265360164\n",
      "822, loss is 0.0026755763969679293 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.36686189192923324 and mu_y: 0.3025524191431129\n",
      "823, loss is 0.002673576092449359 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3665651409566562 and mu_y: 0.30221754939863543\n",
      "824, loss is 0.0026715825113235066 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3662689129816123 and mu_y: 0.30188322199954215\n",
      "825, loss is 0.00266959562473182 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.36597320663624977 and mu_y: 0.30154943552991986\n",
      "826, loss is 0.0026676154039617945 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.36567802055715176 and mu_y: 0.30121618857855204\n",
      "827, loss is 0.002665641820446141 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3653833533853206 and mu_y: 0.3008834797389018\n",
      "828, loss is 0.0026636748457619847 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3650892037661624 and mu_y: 0.30055130760909493\n",
      "829, loss is 0.0026617144516300336 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.364795570349472 and mu_y: 0.30021967079190304\n",
      "830, loss is 0.0026597606099137876 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.36450245178941737 and mu_y: 0.2998885678947265\n",
      "831, loss is 0.0026578132926187202 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3642098467445243 and mu_y: 0.29955799752957785\n",
      "832, loss is 0.0026558724718914995 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.36391775387766134 and mu_y: 0.2992279583130649\n",
      "833, loss is 0.0026539381200191767 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.36362617185602464 and mu_y: 0.29889844886637407\n",
      "834, loss is 0.002652010209428407 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.36333509935112257 and mu_y: 0.2985694678152537\n",
      "835, loss is 0.002650088712684666 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.36304453503876083 and mu_y: 0.29824101378999746\n",
      "836, loss is 0.0026481736024914684 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3627544775990274 and mu_y: 0.297913085425428\n",
      "837, loss is 0.0026462648516895884 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3624649257162775 and mu_y: 0.29758568136088015\n",
      "838, loss is 0.0026443624332563023 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3621758780791185 and mu_y: 0.29725880024018475\n",
      "839, loss is 0.002642466320304612 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.36188733338039525 and mu_y: 0.29693244071165215\n",
      "840, loss is 0.0026405764860824863 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3615992903171751 and mu_y: 0.29660660142805595\n",
      "841, loss is 0.002638692903972109 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.361311747590733 and mu_y: 0.2962812810466167\n",
      "842, loss is 0.002636815547489123 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.36102470390653685 and mu_y: 0.2959564782289857\n",
      "843, loss is 0.002634944390281887 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3607381579742328 and mu_y: 0.29563219164122884\n",
      "844, loss is 0.002633079406130721 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.36045210850763043 and mu_y: 0.29530841995381063\n",
      "845, loss is 0.002631220568947189 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.36016655422468813 and mu_y: 0.2949851618415779\n",
      "846, loss is 0.0026293678527733407 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3598814938474986 and mu_y: 0.2946624159837441\n",
      "847, loss is 0.0026275212317810022 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.35959692610227434 and mu_y: 0.2943401810638731\n",
      "848, loss is 0.002625680680271034 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3593128497193329 and mu_y: 0.2940184557698635\n",
      "849, loss is 0.0026238461726726245 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3590292634330828 and mu_y: 0.2936972387939328\n",
      "850, loss is 0.0026220176835425645 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3587461659820087 and mu_y: 0.29337652883260146\n",
      "851, loss is 0.0026201951875645304 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3584635561086575 and mu_y: 0.29305632458667746\n",
      "852, loss is 0.0026183786595483896 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.35818143255962354 and mu_y: 0.29273662476124035\n",
      "853, loss is 0.002616568074429488 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3578997940855347 and mu_y: 0.29241742806562576\n",
      "854, loss is 0.0026147634072679437 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.35761863944103794 and mu_y: 0.29209873321340996\n",
      "855, loss is 0.002612964633247964 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3573379673847853 and mu_y: 0.29178053892239425\n",
      "856, loss is 0.0026111717276771492 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3570577766794196 and mu_y: 0.29146284391458943\n",
      "857, loss is 0.002609384665985797 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.35677806609156054 and mu_y: 0.2911456469162006\n",
      "858, loss is 0.0026076034237262325 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.35649883439179036 and mu_y: 0.29082894665761166\n",
      "859, loss is 0.002605827976572118 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.35622008035464015 and mu_y: 0.2905127418733701\n",
      "860, loss is 0.0026040583003177843 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3559418027585756 and mu_y: 0.29019703130217184\n",
      "861, loss is 0.0026022943708775555 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3556640003859835 and mu_y: 0.2898818136868459\n",
      "862, loss is 0.0026005361642850826 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3553866720231573 and mu_y: 0.2895670877743393\n",
      "863, loss is 0.0025987836566926828 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3551098164602839 and mu_y: 0.2892528523157022\n",
      "864, loss is 0.002597036824370671 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.35483343249142935 and mu_y: 0.28893910606607254\n",
      "865, loss is 0.0025952956437067195 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3545575189145255 and mu_y: 0.2886258477846613\n",
      "866, loss is 0.002593560091205193 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.35428207453135613 and mu_y: 0.2883130762347377\n",
      "867, loss is 0.0025918301434865064 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3540070981475432 and mu_y: 0.2880007901836139\n",
      "868, loss is 0.0025901057772864796 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.35373258857253365 and mu_y: 0.2876889884026307\n",
      "869, loss is 0.0025883869694556996 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3534585446195853 and mu_y: 0.28737766966714245\n",
      "870, loss is 0.0025866736969588793 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.35318496510575387 and mu_y: 0.2870668327565025\n",
      "871, loss is 0.002584965936874232 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.35291184885187915 and mu_y: 0.28675647645404856\n",
      "872, loss is 0.002583263666392836 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.35263919468257177 and mu_y: 0.28644659954708784\n",
      "873, loss is 0.002581566862818016 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.35236700142619976 and mu_y: 0.286137200826883\n",
      "874, loss is 0.0025798755035647118 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3520952679148752 and mu_y: 0.2858282790886371\n",
      "875, loss is 0.0025781895661588744 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.351823992984441 and mu_y: 0.28551983313147966\n",
      "876, loss is 0.002576509028236838 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3515531754744576 and mu_y: 0.2852118617584518\n",
      "877, loss is 0.0025748338675447226 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.35128281422818974 and mu_y: 0.28490436377649236\n",
      "878, loss is 0.002573164061937817 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3510129080925935 and mu_y: 0.2845973379964233\n",
      "879, loss is 0.0025714995893799794 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.35074345591830297 and mu_y: 0.2842907832329355\n",
      "880, loss is 0.0025698404279430433 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.35047445655961723 and mu_y: 0.28398469830457473\n",
      "881, loss is 0.002568186555806212 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3502059088744875 and mu_y: 0.2836790820337274\n",
      "882, loss is 0.002566537951255469 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3499378117245039 and mu_y: 0.28337393324660637\n",
      "883, loss is 0.0025648945926829998 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3496701639748827 and mu_y: 0.28306925077323725\n",
      "884, loss is 0.0025632564585865883 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.34940296449445346 and mu_y: 0.282765033447444\n",
      "885, loss is 0.002561623527569048 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.349136212155646 and mu_y: 0.28246128010683547\n",
      "886, loss is 0.0025599957783376394 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.34886990583447774 and mu_y: 0.28215798959279104\n",
      "887, loss is 0.0025583731897034965 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.348604044410541 and mu_y: 0.2818551607504471\n",
      "888, loss is 0.0025567557405810504 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.34833862676699007 and mu_y: 0.28155279242868314\n",
      "889, loss is 0.00255514340998747 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.34807365179052874 and mu_y: 0.2812508834801082\n",
      "890, loss is 0.002553536177042088 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3478091183713976 and mu_y: 0.28094943276104695\n",
      "891, loss is 0.00255193402096584 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3475450254033614 and mu_y: 0.2806484391315262\n",
      "892, loss is 0.002550336921080719 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.34728137178369667 and mu_y: 0.2803479014552613\n",
      "893, loss is 0.0025487448568092003 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.347018156413179 and mu_y: 0.28004781859964256\n",
      "894, loss is 0.0025471578076737074 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3467553781960708 and mu_y: 0.27974818943572194\n",
      "895, loss is 0.0025455757532960544 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3464930360401086 and mu_y: 0.27944901283819934\n",
      "896, loss is 0.0025439986733969033 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3462311288564912 and mu_y: 0.2791502876854095\n",
      "897, loss is 0.002542426547795223 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.34596965555986675 and mu_y: 0.2788520128593085\n",
      "898, loss is 0.0025408593564077504 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3457086150683208 and mu_y: 0.2785541872454605\n",
      "899, loss is 0.002539297079248449 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.345448006303364 and mu_y: 0.2782568097330246\n",
      "900, loss is 0.002537739696427991 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.34518782818991983 and mu_y: 0.27795987921474147\n",
      "901, loss is 0.0025361871881532123 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3449280796563126 and mu_y: 0.27766339458692046\n",
      "902, loss is 0.002534639534726595 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.34466875963425525 and mu_y: 0.2773673547494263\n",
      "903, loss is 0.0025330967165457423 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3444098670588372 and mu_y: 0.2770717586056662\n",
      "904, loss is 0.0025315587141028642 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.34415140086851237 and mu_y: 0.2767766050625767\n",
      "905, loss is 0.0025300255079842467 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3438933600050873 and mu_y: 0.2764818930306109\n",
      "906, loss is 0.002528497078869757 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.34363574341370906 and mu_y: 0.2761876214237255\n",
      "907, loss is 0.0025269734075323144 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3433785500428534 and mu_y: 0.27589378915936796\n",
      "908, loss is 0.0025254544748373976 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3431217788443129 and mu_y: 0.27560039515846363\n",
      "909, loss is 0.0025239402617425306 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.34286542877318515 and mu_y: 0.2753074383454031\n",
      "910, loss is 0.002522430749296788 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.34260949878786096 and mu_y: 0.2750149176480295\n",
      "911, loss is 0.0025209259186402865 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.34235398785001264 and mu_y: 0.27472283199762565\n",
      "912, loss is 0.002519425751003705 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.34209889492458223 and mu_y: 0.2744311803289017\n",
      "913, loss is 0.002517930227707771 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.34184421897976996 and mu_y: 0.27413996157998244\n",
      "914, loss is 0.002516439330162789 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.34158995898702255 and mu_y: 0.27384917469239484\n",
      "915, loss is 0.0025149530398681473 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3413361139210217 and mu_y: 0.2735588186110555\n",
      "916, loss is 0.0025134713384118274 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.34108268275967246 and mu_y: 0.2732688922842584\n",
      "917, loss is 0.0025119942074699323 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3408296644840919 and mu_y: 0.27297939466366217\n",
      "918, loss is 0.0025105216288062067 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.34057705807859756 and mu_y: 0.2726903247042782\n",
      "919, loss is 0.0025090535842715506 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.34032486253069594 and mu_y: 0.27240168136445797\n",
      "920, loss is 0.0025075900558035637 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3400730768310713 and mu_y: 0.2721134636058812\n",
      "921, loss is 0.0025061310254260614 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.33982169997357436 and mu_y: 0.2718256703935433\n",
      "922, loss is 0.002504676475248614 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3395707309552108 and mu_y: 0.27153830069574336\n",
      "923, loss is 0.00250322638746608 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3393201687761302 and mu_y: 0.27125135348407226\n",
      "924, loss is 0.0025017807443581484 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.33907001243961477 and mu_y: 0.27096482773340014\n",
      "925, loss is 0.002500339528288872 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.33882026095206813 and mu_y: 0.27067872242186486\n",
      "926, loss is 0.002498902721706218 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3385709133230044 and mu_y: 0.27039303653085983\n",
      "927, loss is 0.0024974703071416133 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.33832196856503666 and mu_y: 0.27010776904502204\n",
      "928, loss is 0.002496042267209489 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3380734256938665 and mu_y: 0.2698229189522203\n",
      "929, loss is 0.002494618584606838 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.33782528372827253 and mu_y: 0.2695384852435434\n",
      "930, loss is 0.0024931992421127654 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3375775416900997 and mu_y: 0.26925446691328825\n",
      "931, loss is 0.0024917842225880473 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.33733019860424807 and mu_y: 0.2689708629589482\n",
      "932, loss is 0.00249037350897469 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.33708325349866236 and mu_y: 0.2686876723812012\n",
      "933, loss is 0.0024889670842954906 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.33683670540432065 and mu_y: 0.26840489418389857\n",
      "934, loss is 0.0024875649316536035 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.33659055335522386 and mu_y: 0.26812252737405284\n",
      "935, loss is 0.0024861670342321085 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.33634479638838494 and mu_y: 0.2678405709618266\n",
      "936, loss is 0.002484773375293577 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.336099433543818 and mu_y: 0.2675590239605208\n",
      "937, loss is 0.00248338393817965 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3358544638645277 and mu_y: 0.26727788538656316\n",
      "938, loss is 0.0024819987063106046 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3356098863964987 and mu_y: 0.2669971542594971\n",
      "939, loss is 0.002480617663184943 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.33536570018868483 and mu_y: 0.2667168296019701\n",
      "940, loss is 0.0024792407923789604 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3351219042929987 and mu_y: 0.26643691043972223\n",
      "941, loss is 0.0024778680775463333 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.334878497764301 and mu_y: 0.2661573958015752\n",
      "942, loss is 0.002476499502417708 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3346354796603902 and mu_y: 0.2658782847194208\n",
      "943, loss is 0.002475135050800278 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3343928490419919 and mu_y: 0.2655995762282099\n",
      "944, loss is 0.00247377470657738 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3341506049727485 and mu_y: 0.2653212693659411\n",
      "945, loss is 0.002472418453708088 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3339087465192088 and mu_y: 0.2650433631736496\n",
      "946, loss is 0.0024710662762268028 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3336672727508176 and mu_y: 0.26476585669539643\n",
      "947, loss is 0.002469718158242849 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.33342618273990543 and mu_y: 0.2644887489782569\n",
      "948, loss is 0.002468374083940077 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3331854755616784 and mu_y: 0.26421203907231006\n",
      "949, loss is 0.0024670340375764653 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3329451502942076 and mu_y: 0.2639357260306274\n",
      "950, loss is 0.002465698003483717 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3327052060184194 and mu_y: 0.26365980890926216\n",
      "951, loss is 0.0024643659660668745 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3324656418180849 and mu_y: 0.2633842867672383\n",
      "952, loss is 0.002463037909803927 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.33222645677980994 and mu_y: 0.2631091586665398\n",
      "953, loss is 0.0024617138192454167 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.33198764999302505 and mu_y: 0.26283442367209964\n",
      "954, loss is 0.002460393679014048 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3317492205499753 and mu_y: 0.26256008085178945\n",
      "955, loss is 0.002459077473804318 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3315111675457104 and mu_y: 0.2622861292764083\n",
      "956, loss is 0.0024577651883821196 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.33127349007807466 and mu_y: 0.2620125680196725\n",
      "957, loss is 0.0024564568075843684 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.33103618724769707 and mu_y: 0.2617393961582046\n",
      "958, loss is 0.002455152316318621 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3307992581579814 and mu_y: 0.2614666127715229\n",
      "959, loss is 0.0024538516995626994 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.33056270191509624 and mu_y: 0.26119421694203115\n",
      "960, loss is 0.0024525549423643224 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3303265176279654 and mu_y: 0.2609222077550077\n",
      "961, loss is 0.002451262029840729 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3300907044082578 and mu_y: 0.2606505842985952\n",
      "962, loss is 0.0024499729471783097 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.329855261370378 and mu_y: 0.26037934566379023\n",
      "963, loss is 0.0024486876796322404 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3296201876314564 and mu_y: 0.26010849094443267\n",
      "964, loss is 0.0024474062125261166 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.32938548231133935 and mu_y: 0.2598380192371957\n",
      "965, loss is 0.0024461285312515936 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.32915114453257976 and mu_y: 0.25956792964157516\n",
      "966, loss is 0.0024448546212680203 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3289171734204274 and mu_y: 0.25929822125987956\n",
      "967, loss is 0.0024435844681020866 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.32868356810281935 and mu_y: 0.25902889319721967\n",
      "968, loss is 0.0024423180573474607 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3284503277103703 and mu_y: 0.25875994456149837\n",
      "969, loss is 0.002441055374664438 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3282174513763632 and mu_y: 0.2584913744634005\n",
      "970, loss is 0.002439796405779592 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.32798493823673985 and mu_y: 0.2582231820163828\n",
      "971, loss is 0.002438541136485416 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3277527874300912 and mu_y: 0.2579553663366638\n",
      "972, loss is 0.0024372895526399807 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3275209980976482 and mu_y: 0.2576879265432139\n",
      "973, loss is 0.0024360416401665854 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3272895693832723 and mu_y: 0.25742086175774503\n",
      "974, loss is 0.0024347973850534148 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.32705850043344625 and mu_y: 0.2571541711047012\n",
      "975, loss is 0.0024335567733531965 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.32682779039726456 and mu_y: 0.2568878537112481\n",
      "976, loss is 0.002432319791182861 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.32659743842642447 and mu_y: 0.25662190870726365\n",
      "977, loss is 0.0024310864247232013 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3263674436752166 and mu_y: 0.25635633522532775\n",
      "978, loss is 0.0024298566602185393 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3261378053005158 and mu_y: 0.2560911324007128\n",
      "979, loss is 0.0024286304839763895 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.325908522461772 and mu_y: 0.2558262993713738\n",
      "980, loss is 0.002427407882367125 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3256795943210011 and mu_y: 0.2555618352779387\n",
      "981, loss is 0.0024261888418236543 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.32545102004277565 and mu_y: 0.25529773926369853\n",
      "982, loss is 0.0024249733488410814 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.32522279879421623 and mu_y: 0.25503401047459795\n",
      "983, loss is 0.0024237613899763893 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.324994929744982 and mu_y: 0.25477064805922556\n",
      "984, loss is 0.0024225529518481083 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.324767412067262 and mu_y: 0.25450765116880425\n",
      "985, loss is 0.0024213480211359942 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.32454024493576594 and mu_y: 0.2542450189571819\n",
      "986, loss is 0.0024201465845807126 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3243134275277155 and mu_y: 0.2539827505808215\n",
      "987, loss is 0.0024189486289835143 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3240869590228354 and mu_y: 0.25372084519879207\n",
      "988, loss is 0.0024177541412059157 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.32386083860334436 and mu_y: 0.25345930197275895\n",
      "989, loss is 0.0024165631081693867 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.32363506545394655 and mu_y: 0.25319812006697456\n",
      "990, loss is 0.002415375516855043 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.32340963876182255 and mu_y: 0.252937298648269\n",
      "991, loss is 0.002414191354303323 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3231845577166207 and mu_y: 0.2526768368860408\n",
      "992, loss is 0.002413010607613681 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.32295982151044844 and mu_y: 0.25241673395224745\n",
      "993, loss is 0.002411833263944284 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.32273542933786353 and mu_y: 0.2521569890213963\n",
      "994, loss is 0.0024106593105117 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3225113803958654 and mu_y: 0.2518976012705354\n",
      "995, loss is 0.002409488734590595 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.32228767388388657 and mu_y: 0.25163856987924416\n",
      "996, loss is 0.002408321523513429 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3220643090037839 and mu_y: 0.2513798940296243\n",
      "997, loss is 0.0024071576646701558 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3218412849598303 and mu_y: 0.2511215729062908\n",
      "998, loss is 0.002405997145507924 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.32161860095870587 and mu_y: 0.2508636056963627\n",
      "999, loss is 0.0024048399535307736 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3213962562094897 and mu_y: 0.25060599158945424\n",
      "1000, loss is 0.0024036860762993504 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.32117424992365123 and mu_y: 0.25034872977766565\n",
      "1001, loss is 0.0024025355014306027 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3209525813150419 and mu_y: 0.2500918194555744\n",
      "1002, loss is 0.002401388216597489 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.32073124959988664 and mu_y: 0.2498352598202261\n",
      "1003, loss is 0.002400244209528693 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.32051025399677563 and mu_y: 0.24957905007112574\n",
      "1004, loss is 0.0023991034680083266 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3202895937266558 and mu_y: 0.24932318941022868\n",
      "1005, loss is 0.0023979659798756513 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.32006926801282265 and mu_y: 0.249067677041932\n",
      "1006, loss is 0.0023968317330247835 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.319849276080912 and mu_y: 0.24881251217306555\n",
      "1007, loss is 0.0023957007154044104 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.31962961715889165 and mu_y: 0.2485576940128833\n",
      "1008, loss is 0.0023945729150175146 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.31941029047705316 and mu_y: 0.2483032217730546\n",
      "1009, loss is 0.002393448319921087 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.31919129526800366 and mu_y: 0.24804909466765548\n",
      "1010, loss is 0.0023923269182258493 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3189726307666578 and mu_y: 0.24779531191315995\n",
      "1011, loss is 0.002391208698095973 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.31875429621022955 and mu_y: 0.24754187272843145\n",
      "1012, loss is 0.0023900936477488097 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3185362908382241 and mu_y: 0.24728877633471424\n",
      "1013, loss is 0.0023889817554546082 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3183186138924298 and mu_y: 0.24703602195562482\n",
      "1014, loss is 0.0023878730095362485 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.31810126461691024 and mu_y: 0.24678360881714348\n",
      "1015, loss is 0.002386767398368959 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.31788424225799594 and mu_y: 0.2465315361476057\n",
      "1016, loss is 0.0023856649103800665 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.31766754606427683 and mu_y: 0.24627980317769382\n",
      "1017, loss is 0.0023845655340487028 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3174511752865939 and mu_y: 0.24602840914042853\n",
      "1018, loss is 0.0023834692579055576 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.31723512917803154 and mu_y: 0.24577735327116054\n",
      "1019, loss is 0.0023823760705326048 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.31701940699390957 and mu_y: 0.24552663480756215\n",
      "1020, loss is 0.0023812859605628358 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3168040079917754 and mu_y: 0.24527625298961903\n",
      "1021, loss is 0.002380198916680003 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3165889314313961 and mu_y: 0.24502620705962183\n",
      "1022, loss is 0.0023791149276183566 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3163741765747508 and mu_y: 0.24477649626215803\n",
      "1023, loss is 0.002378033982162382 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3161597426860229 and mu_y: 0.24452711984410358\n",
      "1024, loss is 0.0023769560691465474 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3159456290315922 and mu_y: 0.24427807705461482\n",
      "1025, loss is 0.0023758811774550422 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.31573183488002715 and mu_y: 0.24402936714512027\n",
      "1026, loss is 0.0023748092960215236 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3155183595020775 and mu_y: 0.24378098936931253\n",
      "1027, loss is 0.002373740413828866 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3153052021706664 and mu_y: 0.2435329429831401\n",
      "1028, loss is 0.002372674519908905 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.31509236216088266 and mu_y: 0.24328522724479945\n",
      "1029, loss is 0.0023716116033421857 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3148798387499736 and mu_y: 0.24303784141472684\n",
      "1030, loss is 0.0023705516532577186 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.31466763121733704 and mu_y: 0.24279078475559043\n",
      "1031, loss is 0.0023694946588327243 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.31445573884451394 and mu_y: 0.24254405653228225\n",
      "1032, loss is 0.002368440609292396 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.31424416091518104 and mu_y: 0.24229765601191028\n",
      "1033, loss is 0.002367389493909646 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3140328967151431 and mu_y: 0.24205158246379052\n",
      "1034, loss is 0.00236634130200487 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3138219455323258 and mu_y: 0.24180583515943913\n",
      "1035, loss is 0.0023652960229456938 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.31361130665676795 and mu_y: 0.24156041337256456\n",
      "1036, loss is 0.002364253646146743 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.31340097938061434 and mu_y: 0.24131531637905979\n",
      "1037, loss is 0.0023632141610693985 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3131909629981084 and mu_y: 0.2410705434569944\n",
      "1038, loss is 0.0023621775572215584 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.31298125680558464 and mu_y: 0.24082609388660706\n",
      "1039, loss is 0.0023611438241574034 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.31277186010146163 and mu_y: 0.24058196695029754\n",
      "1040, loss is 0.002360112951477156 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3125627721862345 and mu_y: 0.2403381619326192\n",
      "1041, loss is 0.002359084928826854 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.31235399236246786 and mu_y: 0.2400946781202712\n",
      "1042, loss is 0.0023580597458981115 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.31214551993478834 and mu_y: 0.2398515148020909\n",
      "1043, loss is 0.002357037392427888 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.31193735420987767 and mu_y: 0.2396086712690464\n",
      "1044, loss is 0.0023560178581982605 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.31172949449646536 and mu_y: 0.2393661468142287\n",
      "1045, loss is 0.002355001133036192 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3115219401053216 and mu_y: 0.2391239407328443\n",
      "1046, loss is 0.0023539872068133088 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.31131469034925 and mu_y: 0.23888205232220774\n",
      "1047, loss is 0.0023529760694456655 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3111077445430809 and mu_y: 0.238640480881734\n",
      "1048, loss is 0.0023519677108935298 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3109011020036637 and mu_y: 0.2383992257129311\n",
      "1049, loss is 0.002350962121161148 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3106947620498605 and mu_y: 0.23815828611939258\n",
      "1050, loss is 0.0023499592902965338 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3104887240025386 and mu_y: 0.23791766140679027\n",
      "1051, loss is 0.002348959208391239 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.31028298718456365 and mu_y: 0.23767735088286676\n",
      "1052, loss is 0.0023479618655801327 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3100775509207928 and mu_y: 0.23743735385742812\n",
      "1053, loss is 0.0023469672520411923 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30987241453806774 and mu_y: 0.2371976696423366\n",
      "1054, loss is 0.002345975357995271 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3096675773652076 and mu_y: 0.2369582975515033\n",
      "1055, loss is 0.002344986173705894 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30946303873300246 and mu_y: 0.23671923690088095\n",
      "1056, loss is 0.0023439996894790405 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30925879797420613 and mu_y: 0.2364804870084567\n",
      "1057, loss is 0.0023430158956629227 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30905485442352953 and mu_y: 0.23624204719424483\n",
      "1058, loss is 0.0023420347826477806 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3088512074176338 and mu_y: 0.23600391678027965\n",
      "1059, loss is 0.0023410563408656692 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3086478562951236 and mu_y: 0.23576609509060836\n",
      "1060, loss is 0.002340080560790249 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3084448003965404 and mu_y: 0.23552858145128389\n",
      "1061, loss is 0.0023391074329365685 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30824203906435554 and mu_y: 0.23529137519035784\n",
      "1062, loss is 0.0023381369478608677 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30803957164296386 and mu_y: 0.2350544756378734\n",
      "1063, loss is 0.002337169096160363 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3078373974786767 and mu_y: 0.23481788212585838\n",
      "1064, loss is 0.002336203868473048 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3076355159197156 and mu_y: 0.23458159398831807\n",
      "1065, loss is 0.0023352412554774804 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30743392631620536 and mu_y: 0.2343456105612284\n",
      "1066, loss is 0.0023342812478925885 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30723262802016765 and mu_y: 0.23410993118252893\n",
      "1067, loss is 0.0023333238364774624 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3070316203855144 and mu_y: 0.23387455519211586\n",
      "1068, loss is 0.002332369012031154 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3068309027680412 and mu_y: 0.23363948193183526\n",
      "1069, loss is 0.0023314167653924744 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30663047452542086 and mu_y: 0.2334047107454761\n",
      "1070, loss is 0.002330467087439806 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30643033501719685 and mu_y: 0.23317024097876352\n",
      "1071, loss is 0.0023295199690908873 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30623048360477684 and mu_y: 0.23293607197935182\n",
      "1072, loss is 0.002328575401302634 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3060309196514263 and mu_y: 0.23270220309681783\n",
      "1073, loss is 0.0023276333750709304 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30583164252226214 and mu_y: 0.23246863368265414\n",
      "1074, loss is 0.002326693881430437 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30563265158424613 and mu_y: 0.23223536309026227\n",
      "1075, loss is 0.002325756911454409 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30543394620617864 and mu_y: 0.23200239067494605\n",
      "1076, loss is 0.0023248224562544837 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30523552575869234 and mu_y: 0.23176971579390487\n",
      "1077, loss is 0.00232389050698051 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30503738961424576 and mu_y: 0.23153733780622707\n",
      "1078, loss is 0.0023229610548203376 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30483953714711715 and mu_y: 0.23130525607288324\n",
      "1079, loss is 0.00232203409099965 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30464196773339797 and mu_y: 0.23107346995671968\n",
      "1080, loss is 0.0023211096067817564 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3044446807509869 and mu_y: 0.2308419788224518\n",
      "1081, loss is 0.002320187593467418 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30424767557958354 and mu_y: 0.23061078203665755\n",
      "1082, loss is 0.002319268042394653 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.304050951600682 and mu_y: 0.2303798789677709\n",
      "1083, loss is 0.0023183509449385604 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.303854508197565 and mu_y: 0.23014926898607532\n",
      "1084, loss is 0.0023174362925111273 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3036583447552975 and mu_y: 0.22991895146369734\n",
      "1085, loss is 0.0023165240765610543 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30346246066072086 and mu_y: 0.22968892577460004\n",
      "1086, loss is 0.002315614288573565 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3032668553024463 and mu_y: 0.22945919129457665\n",
      "1087, loss is 0.0023147069200702337 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3030715280708492 and mu_y: 0.22922974740124416\n",
      "1088, loss is 0.002313801962608799 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3028764783580628 and mu_y: 0.22900059347403695\n",
      "1089, loss is 0.002312899407782985 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30268170555797236 and mu_y: 0.22877172889420033\n",
      "1090, loss is 0.002311999247222332 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3024872090662089 and mu_y: 0.22854315304478437\n",
      "1091, loss is 0.0023111014725920045 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30229298828014345 and mu_y: 0.2283148653106375\n",
      "1092, loss is 0.0023102060755926307 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3020990425988809 and mu_y: 0.2280868650784002\n",
      "1093, loss is 0.0023093130479601184 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.301905371423254 and mu_y: 0.22785915173649884\n",
      "1094, loss is 0.0023084223814654817 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30171197415581785 and mu_y: 0.2276317246751394\n",
      "1095, loss is 0.002307534067914672 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30151885020084346 and mu_y: 0.2274045832863012\n",
      "1096, loss is 0.002306648099148402 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30132599896431217 and mu_y: 0.22717772696373087\n",
      "1097, loss is 0.002305764467041975 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30113341985390973 and mu_y: 0.226951155102936\n",
      "1098, loss is 0.0023048831635051176 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3009411122790205 and mu_y: 0.2267248671011792\n",
      "1099, loss is 0.002304004180481806 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3007490756507215 and mu_y: 0.2264988623574718\n",
      "1100, loss is 0.0023031275099501024 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.3005573093817768 and mu_y: 0.22627314027256792\n",
      "1101, loss is 0.0023022531439219835 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30036581288663167 and mu_y: 0.22604770024895834\n",
      "1102, loss is 0.0023013810744431764 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.30017458558140675 and mu_y: 0.2258225416908644\n",
      "1103, loss is 0.0023005112935929905 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.29998362688389246 and mu_y: 0.22559766400423212\n",
      "1104, loss is 0.0022996437934841587 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.29979293621354325 and mu_y: 0.22537306659672607\n",
      "1105, loss is 0.0022987785662626674 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.29960251299147184 and mu_y: 0.2251487488777235\n",
      "1106, loss is 0.002297915604107592 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.29941235664044363 and mu_y: 0.2249247102583083\n",
      "1107, loss is 0.002297054899230945 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.29922246658487117 and mu_y: 0.22470095015126518\n",
      "1108, loss is 0.002296196443877505 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.29903284225080823 and mu_y: 0.22447746797107374\n",
      "1109, loss is 0.0022953402303246624 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.29884348306594455 and mu_y: 0.2242542631339025\n",
      "1110, loss is 0.002294486250882255 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2986543884596001 and mu_y: 0.22403133505760317\n",
      "1111, loss is 0.0022936344978924123 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2984655578627194 and mu_y: 0.22380868316170474\n",
      "1112, loss is 0.0022927849637294027 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2982769907078663 and mu_y: 0.22358630686740769\n",
      "1113, loss is 0.0022919376407994655 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2980886864292181 and mu_y: 0.22336420559757822\n",
      "1114, loss is 0.0022910925215406676 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2979006444625604 and mu_y: 0.22314237877674245\n",
      "1115, loss is 0.0022902495984227353 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2977128642452815 and mu_y: 0.22292082583108075\n",
      "1116, loss is 0.002289408863946916 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.29752534521636675 and mu_y: 0.22269954618842192\n",
      "1117, loss is 0.0022885703106458105 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.29733808681639345 and mu_y: 0.22247853927823755\n",
      "1118, loss is 0.002287733931083224 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2971510884875252 and mu_y: 0.22225780453163635\n",
      "1119, loss is 0.002286899717854024 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.29696434967350666 and mu_y: 0.22203734138135847\n",
      "1120, loss is 0.002286067663583975 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2967778698196581 and mu_y: 0.22181714926176987\n",
      "1121, loss is 0.0022852377609296 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.29659164837287005 and mu_y: 0.22159722760885678\n",
      "1122, loss is 0.0022844100025780256 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.296405684781598 and mu_y: 0.22137757586021997\n",
      "1123, loss is 0.0022835843812468353 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.29621997849585713 and mu_y: 0.22115819345506932\n",
      "1124, loss is 0.0022827608896839177 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.29603452896721694 and mu_y: 0.2209390798342182\n",
      "1125, loss is 0.002281939520667328 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.295849335648796 and mu_y: 0.22072023444007802\n",
      "1126, loss is 0.0022811202670051387 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.29566439799525684 and mu_y: 0.22050165671665256\n",
      "1127, loss is 0.002280303121535286 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2954797154628005 and mu_y: 0.2202833461095327\n",
      "1128, loss is 0.002279488077125442 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.29529528750916145 and mu_y: 0.22006530206589087\n",
      "1129, loss is 0.0022786751266728558 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2951111135936024 and mu_y: 0.21984752403447552\n",
      "1130, loss is 0.002277864263104218 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2949271931769092 and mu_y: 0.21963001146560587\n",
      "1131, loss is 0.0022770554793755163 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2947435257213854 and mu_y: 0.21941276381116642\n",
      "1132, loss is 0.002276248768471896 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.29456011069084753 and mu_y: 0.21919578052460154\n",
      "1133, loss is 0.002275444123407522 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.29437694755061966 and mu_y: 0.21897906106091022\n",
      "1134, loss is 0.002274641537225431 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.29419403576752856 and mu_y: 0.21876260487664065\n",
      "1135, loss is 0.0022738410029973987 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2940113748098984 and mu_y: 0.2185464114298849\n",
      "1136, loss is 0.0022730425138238006 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2938289641475459 and mu_y: 0.21833048018027373\n",
      "1137, loss is 0.002272246062833475 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.29364680325177506 and mu_y: 0.21811481058897123\n",
      "1138, loss is 0.002271451643183582 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2934648915953724 and mu_y: 0.21789940211866954\n",
      "1139, loss is 0.0022706592480594744 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2932832286526019 and mu_y: 0.2176842542335837\n",
      "1140, loss is 0.0022698688706745567 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2931018138991999 and mu_y: 0.21746936639944642\n",
      "1141, loss is 0.002269080504270153 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.29292064681237023 and mu_y: 0.21725473808350285\n",
      "1142, loss is 0.002268294142115375 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.29273972687077926 and mu_y: 0.21704036875450541\n",
      "1143, loss is 0.0022675097775069807 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.292559053554551 and mu_y: 0.2168262578827087\n",
      "1144, loss is 0.002266727403769253 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2923786263452621 and mu_y: 0.2166124049398643\n",
      "1145, loss is 0.0022659470142538623 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2921984447259373 and mu_y: 0.21639880939921569\n",
      "1146, loss is 0.0022651686023397372 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.292018508181044 and mu_y: 0.21618547073549316\n",
      "1147, loss is 0.002264392161432929 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.29183881619648794 and mu_y: 0.2159723884249087\n",
      "1148, loss is 0.0022636176849664905 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.29165936825960803 and mu_y: 0.21575956194515106\n",
      "1149, loss is 0.002262845166400341 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2914801638591718 and mu_y: 0.21554699077538053\n",
      "1150, loss is 0.0022620745992211395 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.29130120248537045 and mu_y: 0.21533467439622409\n",
      "1151, loss is 0.0022613059769421625 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.291122483629814 and mu_y: 0.2151226122897703\n",
      "1152, loss is 0.002260539293103167 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2909440067855268 and mu_y: 0.21491080393956447\n",
      "1153, loss is 0.002259774541270273 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2907657714469425 and mu_y: 0.21469924883060354\n",
      "1154, loss is 0.0022590117150358313 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2905877771098995 and mu_y: 0.21448794644933122\n",
      "1155, loss is 0.0022582508080183084 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2904100232716364 and mu_y: 0.2142768962836331\n",
      "1156, loss is 0.002257491813862153 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2902325094307868 and mu_y: 0.2140660978228317\n",
      "1157, loss is 0.0022567347262376753 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2900552350873753 and mu_y: 0.2138555505576816\n",
      "1158, loss is 0.002255979538840924 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.28987819974281226 and mu_y: 0.21364525398036457\n",
      "1159, loss is 0.0022552262453935704 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2897014028998896 and mu_y: 0.21343520758448478\n",
      "1160, loss is 0.002254474839642775 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2895248440627759 and mu_y: 0.21322541086506394\n",
      "1161, loss is 0.0022537253153610782 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.289348522737012 and mu_y: 0.21301586331853645\n",
      "1162, loss is 0.002252977666346273 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2891724384295063 and mu_y: 0.21280656444274465\n",
      "1163, loss is 0.002252231886421287 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2889965906485302 and mu_y: 0.21259751373693409\n",
      "1164, loss is 0.002251487969434066 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.28882097890371367 and mu_y: 0.21238871070174872\n",
      "1165, loss is 0.0022507459092574516 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.28864560270604056 and mu_y: 0.21218015483922623\n",
      "1166, loss is 0.0022500056997890676 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2884704615678443 and mu_y: 0.2119718456527932\n",
      "1167, loss is 0.002249267334951203 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2882955550028031 and mu_y: 0.21176378264726056\n",
      "1168, loss is 0.00224853080869069 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2881208825259359 and mu_y: 0.21155596532881882\n",
      "1169, loss is 0.002247796114978791 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2879464436535974 and mu_y: 0.2113483932050334\n",
      "1170, loss is 0.0022470632478110916 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.28777223790347406 and mu_y: 0.21114106578484007\n",
      "1171, loss is 0.0022463322012073747 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.28759826479457945 and mu_y: 0.21093398257854026\n",
      "1172, loss is 0.0022456029692115077 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.28742452384724987 and mu_y: 0.21072714309779644\n",
      "1173, loss is 0.002244875545891337 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.28725101458313995 and mu_y: 0.21052054685562757\n",
      "1174, loss is 0.0022441499253385675 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.28707773652521834 and mu_y: 0.2103141933664045\n",
      "1175, loss is 0.0022434261016686576 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.28690468919776335 and mu_y: 0.21010808214584545\n",
      "1176, loss is 0.0022427040690206996 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2867318721263585 and mu_y: 0.20990221271101148\n",
      "1177, loss is 0.002241983821557315 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2865592848378882 and mu_y: 0.20969658458030188\n",
      "1178, loss is 0.002241265353464541 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.28638692686053363 and mu_y: 0.20949119727344978\n",
      "1179, loss is 0.002240548658951722 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.28621479772376823 and mu_y: 0.2092860503115176\n",
      "1180, loss is 0.0022398337322514 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2860428969583535 and mu_y: 0.20908114321689258\n",
      "1181, loss is 0.002239120567619206 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.28587122409633475 and mu_y: 0.2088764755132824\n",
      "1182, loss is 0.0022384091593337513 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2856997786710369 and mu_y: 0.20867204672571063\n",
      "1183, loss is 0.002237699501696524 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2855285602170601 and mu_y: 0.20846785638051243\n",
      "1184, loss is 0.0022369915890317732 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2853575682702756 and mu_y: 0.20826390400533004\n",
      "1185, loss is 0.002236285415686414 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2851868023678216 and mu_y: 0.2080601891291085\n",
      "1186, loss is 0.0022355809760299106 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.28501626204809916 and mu_y: 0.20785671128209127\n",
      "1187, loss is 0.0022348782644541834 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2848459468507676 and mu_y: 0.20765346999581574\n",
      "1188, loss is 0.00223417727537349 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2846758563167408 and mu_y: 0.20745046480310908\n",
      "1189, loss is 0.002233478003224334 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.284505989988183 and mu_y: 0.2072476952380838\n",
      "1190, loss is 0.002232780442465353 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.28433634740850444 and mu_y: 0.20704516083613358\n",
      "1191, loss is 0.00223208458757722 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.28416692812235744 and mu_y: 0.2068428611339288\n",
      "1192, loss is 0.0022313904330625383 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2839977316756323 and mu_y: 0.20664079566941243\n",
      "1193, loss is 0.0022306979734457422 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2838287576154531 and mu_y: 0.20643896398179573\n",
      "1194, loss is 0.0022300072032729935 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2836600054901739 and mu_y: 0.20623736561155398\n",
      "1195, loss is 0.0022293181171120792 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2834914748493743 and mu_y: 0.20603600010042228\n",
      "1196, loss is 0.0022286307095523167 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.28332316524385587 and mu_y: 0.2058348669913914\n",
      "1197, loss is 0.0022279449752044475 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.28315507622563774 and mu_y: 0.2056339658287035\n",
      "1198, loss is 0.002227260908700544 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.28298720734795285 and mu_y: 0.20543329615784803\n",
      "1199, loss is 0.0022265785046939024 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2828195581652439 and mu_y: 0.20523285752555756\n",
      "1200, loss is 0.0022258977578589567 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2826521282331592 and mu_y: 0.20503264947980362\n",
      "1201, loss is 0.002225218662891166 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2824849171085491 and mu_y: 0.2048326715697926\n",
      "1202, loss is 0.002224541214506932 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2823179243494617 and mu_y: 0.2046329233459616\n",
      "1203, loss is 0.002223865407443492 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2821511495151389 and mu_y: 0.20443340435997437\n",
      "1204, loss is 0.002223191236458827 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.281984592166013 and mu_y: 0.2042341141647173\n",
      "1205, loss is 0.0022225186963315633 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.28181825186370213 and mu_y: 0.2040350523142952\n",
      "1206, loss is 0.002221847781860882 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2816521281710068 and mu_y: 0.2038362183640274\n",
      "1207, loss is 0.0022211784878664186 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2814862206519059 and mu_y: 0.20363761187044363\n",
      "1208, loss is 0.002220510809188174 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2813205288715529 and mu_y: 0.20343923239128006\n",
      "1209, loss is 0.002219844740686416 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2811550523962718 and mu_y: 0.20324107948547523\n",
      "1210, loss is 0.002219180277241589 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.28098979079355374 and mu_y: 0.20304315271316617\n",
      "1211, loss is 0.0022185174137542233 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2808247436320527 and mu_y: 0.20284545163568435\n",
      "1212, loss is 0.0022178561451448326 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.280659910481582 and mu_y: 0.20264797581555172\n",
      "1213, loss is 0.0022171964663538386 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.28049529091311054 and mu_y: 0.20245072481647683\n",
      "1214, loss is 0.002216538372341467 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2803308844987588 and mu_y: 0.20225369820335085\n",
      "1215, loss is 0.0022158818580876576 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.28016669081179535 and mu_y: 0.20205689554224368\n",
      "1216, loss is 0.0022152269185919784 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.28000270942663286 and mu_y: 0.20186031640040009\n",
      "1217, loss is 0.002214573548873539 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2798389399188246 and mu_y: 0.20166396034623574\n",
      "1218, loss is 0.0022139217439708873 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2796753818650605 and mu_y: 0.20146782694933343\n",
      "1219, loss is 0.0022132714989419374 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27951203484316384 and mu_y: 0.20127191578043918\n",
      "1220, loss is 0.0022126228088638657 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.279348898432087 and mu_y: 0.2010762264114584\n",
      "1221, loss is 0.002211975668833036 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2791859722119083 and mu_y: 0.20088075841545205\n",
      "1222, loss is 0.002211330073964906 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27902325576382797 and mu_y: 0.20068551136663293\n",
      "1223, loss is 0.002210686019393934 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27886074867016486 and mu_y: 0.20049048484036175\n",
      "1224, loss is 0.0022100435002735046 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2786984505143525 and mu_y: 0.20029567841314344\n",
      "1225, loss is 0.0022094025117758345 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27853636088093564 and mu_y: 0.20010109166262338\n",
      "1226, loss is 0.0022087630490918867 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2783744793555666 and mu_y: 0.1999067241675836\n",
      "1227, loss is 0.0022081251074312904 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27821280552500166 and mu_y: 0.19971257550793906\n",
      "1228, loss is 0.002207488682022246 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2780513389770976 and mu_y: 0.19951864526473395\n",
      "1229, loss is 0.002206853768111456 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.277890079300808 and mu_y: 0.19932493302013798\n",
      "1230, loss is 0.0022062203609640244 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2777290260861797 and mu_y: 0.19913143835744268\n",
      "1231, loss is 0.0022055884558633853 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27756817892434943 and mu_y: 0.1989381608610577\n",
      "1232, loss is 0.0022049580481112124 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27740753740754004 and mu_y: 0.19874510011650717\n",
      "1233, loss is 0.002204329133027341 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2772471011290571 and mu_y: 0.198552255710426\n",
      "1234, loss is 0.0022037017059496813 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2770868696832855 and mu_y: 0.19835962723055633\n",
      "1235, loss is 0.002203075762234143 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27692684266568585 and mu_y: 0.1981672142657438\n",
      "1236, loss is 0.002202451297254545 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.276767019672791 and mu_y: 0.19797501640593398\n",
      "1237, loss is 0.002201828306402541 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2766074003022026 and mu_y: 0.19778303324216884\n",
      "1238, loss is 0.002201206785087537 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2764479841525877 and mu_y: 0.19759126436658303\n",
      "1239, loss is 0.0022005867287366097 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2762887708236753 and mu_y: 0.19739970937240042\n",
      "1240, loss is 0.0021999681327944287 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27612975991625294 and mu_y: 0.1972083678539305\n",
      "1241, loss is 0.0021993509927231763 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2759709510321631 and mu_y: 0.19701723940656482\n",
      "1242, loss is 0.002198735304002468 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2758123437743002 and mu_y: 0.19682632362677346\n",
      "1243, loss is 0.002198121062129274 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27565393774660674 and mu_y: 0.19663562011210156\n",
      "1244, loss is 0.002197508262617842 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27549573255407034 and mu_y: 0.19644512846116577\n",
      "1245, loss is 0.0021968969009996168 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2753377278027202 and mu_y: 0.19625484827365075\n",
      "1246, loss is 0.0021962869728231658 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2751799230996237 and mu_y: 0.19606477915030573\n",
      "1247, loss is 0.0021956784736541033 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27502231805288313 and mu_y: 0.19587492069294105\n",
      "1248, loss is 0.002195071399075005 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27486491227163246 and mu_y: 0.1956852725044246\n",
      "1249, loss is 0.0021944657446853456 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27470770536603384 and mu_y: 0.19549583418867855\n",
      "1250, loss is 0.0021938615061014113 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27455069694727446 and mu_y: 0.19530660535067573\n",
      "1251, loss is 0.0021932586789562276 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2743938866275632 and mu_y: 0.1951175855964364\n",
      "1252, loss is 0.0021926572588994876 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2742372740201273 and mu_y: 0.19492877453302476\n",
      "1253, loss is 0.002192057241597476 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27408085873920934 and mu_y: 0.19474017176854552\n",
      "1254, loss is 0.002191458622732989 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2739246404000636 and mu_y: 0.19455177691214062\n",
      "1255, loss is 0.002190861398005269 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27376861861895313 and mu_y: 0.19436358957398575\n",
      "1256, loss is 0.002190265563129926 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2736127930131465 and mu_y: 0.19417560936528713\n",
      "1257, loss is 0.0021896711138388644 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2734571632009144 and mu_y: 0.1939878358982781\n",
      "1258, loss is 0.002189078045880213 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27330172880152664 and mu_y: 0.19380026878621573\n",
      "1259, loss is 0.002188486355018248 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27314648943524883 and mu_y: 0.19361290764337763\n",
      "1260, loss is 0.0021878960370333277 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27299144472333925 and mu_y: 0.1934257520850586\n",
      "1261, loss is 0.0021873070877218123 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2728365942880457 and mu_y: 0.19323880172756733\n",
      "1262, loss is 0.0021867195028960023 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2726819377526023 and mu_y: 0.19305205618822308\n",
      "1263, loss is 0.002186133278384056 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27252747474122646 and mu_y: 0.19286551508535252\n",
      "1264, loss is 0.0021855484100299282 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27237320487911554 and mu_y: 0.19267917803828638\n",
      "1265, loss is 0.002184964893693298 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2722191277924439 and mu_y: 0.19249304466735628\n",
      "1266, loss is 0.002184382725249497 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2720652431083597 and mu_y: 0.19230711459389144\n",
      "1267, loss is 0.0021838019005894394 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27191155045498194 and mu_y: 0.19212138744021548\n",
      "1268, loss is 0.0021832224156195516 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2717580494613972 and mu_y: 0.19193586282964328\n",
      "1269, loss is 0.002182644266261712 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27160473975765664 and mu_y: 0.19175054038647768\n",
      "1270, loss is 0.002182067448453169 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.271451620974773 and mu_y: 0.19156541973600638\n",
      "1271, loss is 0.002181491958146484 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2712986927447174 and mu_y: 0.19138050050449873\n",
      "1272, loss is 0.0021809177913094586 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27114595470041647 and mu_y: 0.19119578231920262\n",
      "1273, loss is 0.002180344943925066 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27099340647574915 and mu_y: 0.19101126480834124\n",
      "1274, loss is 0.0021797734119913875 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2708410477055438 and mu_y: 0.19082694760111008\n",
      "1275, loss is 0.0021792031915215445 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2706888780255751 and mu_y: 0.19064283032767365\n",
      "1276, loss is 0.00217863427854363 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2705368970725612 and mu_y: 0.19045891261916253\n",
      "1277, loss is 0.0021780666691006436 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2703851044841605 and mu_y: 0.19027519410767016\n",
      "1278, loss is 0.0021775003592504273 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.27023349989896883 and mu_y: 0.19009167442624977\n",
      "1279, loss is 0.002176935345065598 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2700820829565166 and mu_y: 0.18990835320891133\n",
      "1280, loss is 0.0021763716226334815 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2699308532972655 and mu_y: 0.18972523009061848\n",
      "1281, loss is 0.0021758091880560524 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2697798105626059 and mu_y: 0.18954230470728547\n",
      "1282, loss is 0.0021752480374498647 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2696289543948538 and mu_y: 0.18935957669577413\n",
      "1283, loss is 0.002174688166945988 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2694782844372477 and mu_y: 0.1891770456938908\n",
      "1284, loss is 0.0021741295726899444 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2693278003339461 and mu_y: 0.18899471134038331\n",
      "1285, loss is 0.002173572250841651 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26917750173002425 and mu_y: 0.18881257327493806\n",
      "1286, loss is 0.0021730161975753452 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2690273882714714 and mu_y: 0.1886306311381769\n",
      "1287, loss is 0.0021724614090795286 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26887745960518794 and mu_y: 0.18844888457165426\n",
      "1288, loss is 0.002171907881556907 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2687277153789825 and mu_y: 0.18826733321785408\n",
      "1289, loss is 0.0021713556112243227 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.268578155241569 and mu_y: 0.18808597672018684\n",
      "1290, loss is 0.002170804594312692 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26842877884256405 and mu_y: 0.18790481472298673\n",
      "1291, loss is 0.0021702548270669483 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2682795858324838 and mu_y: 0.18772384687150856\n",
      "1292, loss is 0.002169706305745981 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2681305758627413 and mu_y: 0.18754307281192492\n",
      "1293, loss is 0.0021691590266225665 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26798174858564366 and mu_y: 0.18736249219132323\n",
      "1294, loss is 0.002168612985983316 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2678331036543893 and mu_y: 0.1871821046577028\n",
      "1295, loss is 0.002168068180128614 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26768464072306497 and mu_y: 0.18700190985997198\n",
      "1296, loss is 0.002167524605372551 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2675363594466431 and mu_y: 0.18682190744794525\n",
      "1297, loss is 0.0021669822580428727 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2673882594809791 and mu_y: 0.18664209707234033\n",
      "1298, loss is 0.002166441134480915 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2672403404828083 and mu_y: 0.18646247838477537\n",
      "1299, loss is 0.002165901231041547 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2670926021097436 and mu_y: 0.18628305103776593\n",
      "1300, loss is 0.0021653625440931075 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26694504402027236 and mu_y: 0.18610381468472237\n",
      "1301, loss is 0.0021648250700173582 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2667976658737538 and mu_y: 0.1859247689799468\n",
      "1302, loss is 0.002164288805209408 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26665046733041636 and mu_y: 0.1857459135786304\n",
      "1303, loss is 0.002163753746077672 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2665034480513549 and mu_y: 0.18556724813685052\n",
      "1304, loss is 0.0021632198890437983 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2663566076985279 and mu_y: 0.1853887723115679\n",
      "1305, loss is 0.0021626872305426257 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26620994593475505 and mu_y: 0.18521048576062388\n",
      "1306, loss is 0.0021621557670221145 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2660634624237142 and mu_y: 0.18503238814273762\n",
      "1307, loss is 0.0021616254949432924 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2659171568299389 and mu_y: 0.1848544791175033\n",
      "1308, loss is 0.002161096410780202 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26577102881881565 and mu_y: 0.1846767583453874\n",
      "1309, loss is 0.0021605685110198418 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2656250780565814 and mu_y: 0.1844992254877259\n",
      "1310, loss is 0.002160041792162108 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26547930421032073 and mu_y: 0.18432188020672152\n",
      "1311, loss is 0.0021595162507197442 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2653337069479631 and mu_y: 0.18414472216544106\n",
      "1312, loss is 0.0021589918832182775 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2651882859382806 and mu_y: 0.1839677510278126\n",
      "1313, loss is 0.002158468686195973 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.265043040850885 and mu_y: 0.18379096645862283\n",
      "1314, loss is 0.002157946656203768 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26489797135622517 and mu_y: 0.18361436812351434\n",
      "1315, loss is 0.0021574257898052283 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2647530771255847 and mu_y: 0.1834379556889829\n",
      "1316, loss is 0.0021569060835764865 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2646083578310791 and mu_y: 0.18326172882237482\n",
      "1317, loss is 0.00215638753410619 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26446381314565326 and mu_y: 0.1830856871918842\n",
      "1318, loss is 0.002155870137995445 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2643194427430789 and mu_y: 0.18290983046655035\n",
      "1319, loss is 0.0021553538918577695 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.264175246297952 and mu_y: 0.18273415831625509\n",
      "1320, loss is 0.002154838792319029 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26403122348569025 and mu_y: 0.18255867041172008\n",
      "1321, loss is 0.0021543248360173925 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2638873739825305 and mu_y: 0.18238336642450426\n",
      "1322, loss is 0.0021538120196032784 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2637436974655261 and mu_y: 0.18220824602700111\n",
      "1323, loss is 0.0021533003397392974 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2636001936125447 and mu_y: 0.18203330889243616\n",
      "1324, loss is 0.0021527897931002023 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2634568621022654 and mu_y: 0.18185855469486428\n",
      "1325, loss is 0.0021522803763728373 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2633137026141763 and mu_y: 0.18168398310916714\n",
      "1326, loss is 0.0021517720862560866 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2631707148285722 and mu_y: 0.18150959381105056\n",
      "1327, loss is 0.0021512649194608195 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26302789842655183 and mu_y: 0.18133538647704203\n",
      "1328, loss is 0.002150758872709841 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26288525309001565 and mu_y: 0.18116136078448805\n",
      "1329, loss is 0.002150253942737841 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2627427785016631 and mu_y: 0.18098751641155159\n",
      "1330, loss is 0.002149750126291343 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26260047434499034 and mu_y: 0.18081385303720957\n",
      "1331, loss is 0.0021492474201286523 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2624583403042876 and mu_y: 0.1806403703412503\n",
      "1332, loss is 0.0021487458210198117 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26231637606463704 and mu_y: 0.1804670680042709\n",
      "1333, loss is 0.0021482453257465404 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2621745813119099 and mu_y: 0.18029394570767487\n",
      "1334, loss is 0.0021477459311021944 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26203295573276447 and mu_y: 0.1801210031336695\n",
      "1335, loss is 0.0021472476338917105 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2618914990146434 and mu_y: 0.17994823996526338\n",
      "1336, loss is 0.0021467504309315593 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26175021084577144 and mu_y: 0.17977565588626393\n",
      "1337, loss is 0.002146254319049698 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26160909091515283 and mu_y: 0.17960325058127488\n",
      "1338, loss is 0.0021457592950855173 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2614681389125692 and mu_y: 0.17943102373569378\n",
      "1339, loss is 0.002145265355889796 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2613273545285769 and mu_y: 0.1792589750357096\n",
      "1340, loss is 0.0021447724983246507 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2611867374545048 and mu_y: 0.17908710416830018\n",
      "1341, loss is 0.00214428071926349 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26104628738245195 and mu_y: 0.17891541082122986\n",
      "1342, loss is 0.0021437900155909634 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2609060040052849 and mu_y: 0.178743894683047\n",
      "1343, loss is 0.002143300384202913 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26076588701663583 and mu_y: 0.17857255544308148\n",
      "1344, loss is 0.002142811822006333 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26062593611089985 and mu_y: 0.1784013927914424\n",
      "1345, loss is 0.0021423243259193134 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26048615098323274 and mu_y: 0.1782304064190156\n",
      "1346, loss is 0.002141837892871 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26034653132954866 and mu_y: 0.1780595960174612\n",
      "1347, loss is 0.0021413525198015395 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26020707684651784 and mu_y: 0.1778889612792113\n",
      "1348, loss is 0.0021408682036620453 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.26006778723156426 and mu_y: 0.17771850189746752\n",
      "1349, loss is 0.0021403849414145387 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2599286621828633 and mu_y: 0.17754821756619865\n",
      "1350, loss is 0.002139902730031908 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2597897013993395 and mu_y: 0.17737810798013826\n",
      "1351, loss is 0.0021394215664978663 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2596509045806642 and mu_y: 0.17720817283478235\n",
      "1352, loss is 0.002138941447806897 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25951227142725336 and mu_y: 0.17703841182638697\n",
      "1353, loss is 0.002138462370964218 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2593738016402652 and mu_y: 0.1768688246519659\n",
      "1354, loss is 0.0021379843329857287 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25923549492159803 and mu_y: 0.1766994110092883\n",
      "1355, loss is 0.0021375073308979686 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25909735097388786 and mu_y: 0.1765301705968763\n",
      "1356, loss is 0.0021370313617380707 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2589593695005063 and mu_y: 0.1763611031140029\n",
      "1357, loss is 0.0021365564225537233 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2588215502055582 and mu_y: 0.17619220826068938\n",
      "1358, loss is 0.002136082510403115 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2586838927938795 and mu_y: 0.17602348573770313\n",
      "1359, loss is 0.0021356096223548956 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.258546396971035 and mu_y: 0.1758549352465554\n",
      "1360, loss is 0.0021351377554881365 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.258409062443316 and mu_y: 0.17568655648949894\n",
      "1361, loss is 0.002134666906892281 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2582718889177384 and mu_y: 0.1755183491695257\n",
      "1362, loss is 0.0021341970736671024 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25813487610204017 and mu_y: 0.17535031299036458\n",
      "1363, loss is 0.002133728252922661 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25799802370467934 and mu_y: 0.17518244765647922\n",
      "1364, loss is 0.002133260441779261 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25786133143483175 and mu_y: 0.17501475287306567\n",
      "1365, loss is 0.0021327936373674063 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.257724799002389 and mu_y: 0.17484722834605015\n",
      "1366, loss is 0.0021323278368277606 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.257588426117956 and mu_y: 0.17467987378208683\n",
      "1367, loss is 0.0021318630373111033 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2574522124928492 and mu_y: 0.1745126888885556\n",
      "1368, loss is 0.002131399235978286 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25731615783909406 and mu_y: 0.1743456733735598\n",
      "1369, loss is 0.0021309364300001925 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2571802618694231 and mu_y: 0.1741788269459241\n",
      "1370, loss is 0.0021304746165576936 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2570445242972738 and mu_y: 0.17401214931519218\n",
      "1371, loss is 0.002130013792841612 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25690894483678633 and mu_y: 0.1738456401916246\n",
      "1372, loss is 0.0021295539560526717 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25677352320280145 and mu_y: 0.17367929928619655\n",
      "1373, loss is 0.002129095103401465 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2566382591108585 and mu_y: 0.17351312631059573\n",
      "1374, loss is 0.002128637232108405 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25650315227719334 and mu_y: 0.17334712097722013\n",
      "1375, loss is 0.0021281803394036913 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25636820241873587 and mu_y: 0.17318128299917585\n",
      "1376, loss is 0.0021277244225272616 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25623340925310845 and mu_y: 0.17301561209027497\n",
      "1377, loss is 0.002127269478728756 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2560987724986234 and mu_y: 0.1728501079650334\n",
      "1378, loss is 0.0021268155052674787 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25596429187428116 and mu_y: 0.17268477033866866\n",
      "1379, loss is 0.0021263624994123514 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25582996709976813 and mu_y: 0.17251959892709787\n",
      "1380, loss is 0.0021259104584418773 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25569579789545466 and mu_y: 0.17235459344693546\n",
      "1381, loss is 0.002125459379644103 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2555617839823928 and mu_y: 0.1721897536154912\n",
      "1382, loss is 0.002125009260316574 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25542792508231466 and mu_y: 0.17202507915076792\n",
      "1383, loss is 0.0021245600977663013 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2552942209176298 and mu_y: 0.1718605697714596\n",
      "1384, loss is 0.002124111889309715 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2551606712114238 and mu_y: 0.17169622519694908\n",
      "1385, loss is 0.0021236646322726335 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25502727568745565 and mu_y: 0.17153204514730605\n",
      "1386, loss is 0.002123218323990217 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2548940340701562 and mu_y: 0.171368029343285\n",
      "1387, loss is 0.0021227729618069338 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25476094608462596 and mu_y: 0.17120417750632305\n",
      "1388, loss is 0.002122328543076521 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25462801145663294 and mu_y: 0.17104048935853797\n",
      "1389, loss is 0.002121885065161944 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2544952299126109 and mu_y: 0.170876964622726\n",
      "1390, loss is 0.0021214425254353613 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2543626011796573 and mu_y: 0.17071360302235994\n",
      "1391, loss is 0.002121000921278083 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25423012498553116 and mu_y: 0.17055040428158696\n",
      "1392, loss is 0.0021205602500805384 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2540978010586512 and mu_y: 0.17038736812522667\n",
      "1393, loss is 0.002120120509242233 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2539656291280939 and mu_y: 0.170224494278769\n",
      "1394, loss is 0.002119681696171714 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25383360892359147 and mu_y: 0.1700617824683722\n",
      "1395, loss is 0.0021192438082865326 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2537017401755299 and mu_y: 0.16989923242086083\n",
      "1396, loss is 0.0021188068430132065 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25357002261494693 and mu_y: 0.16973684386372373\n",
      "1397, loss is 0.002118370797787185 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2534384559735304 and mu_y: 0.16957461652511202\n",
      "1398, loss is 0.0021179356700528067 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25330703998361587 and mu_y: 0.16941255013383713\n",
      "1399, loss is 0.002117501457263273 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2531757743781851 and mu_y: 0.1692506444193687\n",
      "1400, loss is 0.0021170681568806007 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25304465889086386 and mu_y: 0.16908889911183278\n",
      "1401, loss is 0.002116635766375591 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25291369325592006 and mu_y: 0.16892731394200963\n",
      "1402, loss is 0.0021162042832277976 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2527828772082619 and mu_y: 0.16876588864133193\n",
      "1403, loss is 0.0021157737049254813 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25265221048343606 and mu_y: 0.16860462294188272\n",
      "1404, loss is 0.002115344028965584 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25252169281762543 and mu_y: 0.16844351657639342\n",
      "1405, loss is 0.002114915252853685 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25239132394764763 and mu_y: 0.168282569278242\n",
      "1406, loss is 0.0021144873741039735 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25226110361095294 and mu_y: 0.1681217807814509\n",
      "1407, loss is 0.002114060390239205 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25213103154562244 and mu_y: 0.1679611508206852\n",
      "1408, loss is 0.0021136342987906746 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25200110749036614 and mu_y: 0.16780067913125055\n",
      "1409, loss is 0.002113209097298176 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25187133118452104 and mu_y: 0.16764036544909144\n",
      "1410, loss is 0.002112784783309969 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25174170236804944 and mu_y: 0.16748020951078912\n",
      "1411, loss is 0.0021123613543827476 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25161222078153694 and mu_y: 0.16732021105355974\n",
      "1412, loss is 0.0021119388080815997 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2514828861661907 and mu_y: 0.16716036981525242\n",
      "1413, loss is 0.0021115171419799766 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2513536982638374 and mu_y: 0.1670006855343475\n",
      "1414, loss is 0.002111096353659663 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2512246568169217 and mu_y: 0.16684115794995438\n",
      "1415, loss is 0.0021106764407107332 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25109576156850416 and mu_y: 0.16668178680180992\n",
      "1416, loss is 0.0021102574007315256 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2509670122622596 and mu_y: 0.16652257183027636\n",
      "1417, loss is 0.002109839231328606 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25083840864247514 and mu_y: 0.1663635127763395\n",
      "1418, loss is 0.002109421930116735 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25070995045404854 and mu_y: 0.16620460938160694\n",
      "1419, loss is 0.002109005494718836 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2505816374424862 and mu_y: 0.16604586138830604\n",
      "1420, loss is 0.002108589922765956 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2504534693539015 and mu_y: 0.16588726853928223\n",
      "1421, loss is 0.002108175211897241 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25032544593501305 and mu_y: 0.16572883057799706\n",
      "1422, loss is 0.0021077613597598995 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25019756693314277 and mu_y: 0.16557054724852643\n",
      "1423, loss is 0.002107348364009167 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.25006983209621425 and mu_y: 0.16541241829555872\n",
      "1424, loss is 0.002106936222308276 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24994224117275085 and mu_y: 0.16525444346439294\n",
      "1425, loss is 0.0021065249323284295 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24981479391187403 and mu_y: 0.16509662250093698\n",
      "1426, loss is 0.0021061144917487564 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24968749006330157 and mu_y: 0.16493895515170576\n",
      "1427, loss is 0.0021057048982562913 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24956032937734576 and mu_y: 0.1647814411638194\n",
      "1428, loss is 0.002105296149545932 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24943331160491175 and mu_y: 0.16462408028500147\n",
      "1429, loss is 0.00210488824332042 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24930643649749573 and mu_y: 0.16446687226357715\n",
      "1430, loss is 0.0021044811772902967 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24917970380718318 and mu_y: 0.16430981684847146\n",
      "1431, loss is 0.002104074949173882 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24905311328664725 and mu_y: 0.16415291378920746\n",
      "1432, loss is 0.0021036695566972337 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24892666468914693 and mu_y: 0.16399616283590454\n",
      "1433, loss is 0.0021032649975941255 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24880035776852535 and mu_y: 0.16383956373927655\n",
      "1434, loss is 0.002102861269606008 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24867419227920812 and mu_y: 0.16368311625063012\n",
      "1435, loss is 0.0021024583704819834 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24854816797620155 and mu_y: 0.16352682012186284\n",
      "1436, loss is 0.0021020562979787724 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24842228461509103 and mu_y: 0.16337067510546158\n",
      "1437, loss is 0.0021016550498606846 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2482965419520393 and mu_y: 0.16321468095450067\n",
      "1438, loss is 0.0021012546238995855 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2481709397437847 and mu_y: 0.16305883742264024\n",
      "1439, loss is 0.0021008550178748695 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24804547774763963 and mu_y: 0.1629031442641244\n",
      "1440, loss is 0.0021004562295734294 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24792015572148873 and mu_y: 0.16274760123377954\n",
      "1441, loss is 0.002100058256789623 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24779497342378728 and mu_y: 0.1625922080870127\n",
      "1442, loss is 0.002099661097325246 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24766993061355952 and mu_y: 0.1624369645798097\n",
      "1443, loss is 0.0020992647489895015 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.247545027050397 and mu_y: 0.16228187046873355\n",
      "1444, loss is 0.002098869209598974 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2474202624944569 and mu_y: 0.1621269255109227\n",
      "1445, loss is 0.002098474476977592 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2472956367064604 and mu_y: 0.16197212946408934\n",
      "1446, loss is 0.002098080548956605 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24717114944769109 and mu_y: 0.16181748208651775\n",
      "1447, loss is 0.0020976874233745524 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2470468004799932 and mu_y: 0.16166298313706254\n",
      "1448, loss is 0.0020972950980772337 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24692258956577007 and mu_y: 0.161508632375147\n",
      "1449, loss is 0.0020969035709176836 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24679851646798254 and mu_y: 0.16135442956076151\n",
      "1450, loss is 0.002096512839756134 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24667458095014727 and mu_y: 0.16120037445446173\n",
      "1451, loss is 0.0020961229024599962 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24655078277633513 and mu_y: 0.161046466817367\n",
      "1452, loss is 0.0020957337569038267 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24642712171116962 and mu_y: 0.16089270641115877\n",
      "1453, loss is 0.0020953454009692975 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24630359751982525 and mu_y: 0.1607390929980788\n",
      "1454, loss is 0.0020949578325451692 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24618020996802595 and mu_y: 0.16058562634092757\n",
      "1455, loss is 0.002094571049527266 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24605695882204345 and mu_y: 0.1604323062030627\n",
      "1456, loss is 0.0020941850498184442 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24593384384869574 and mu_y: 0.16027913234839727\n",
      "1457, loss is 0.0020937998313285645 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24581086481534542 and mu_y: 0.16012610454139814\n",
      "1458, loss is 0.0020934153919744637 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2456880214898982 and mu_y: 0.1599732225470844\n",
      "1459, loss is 0.0020930317296799297 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24556531364080134 and mu_y: 0.15982048613102576\n",
      "1460, loss is 0.0020926488423756717 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2454427410370419 and mu_y: 0.15966789505934084\n",
      "1461, loss is 0.0020922667279992964 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2453203034481454 and mu_y: 0.15951544909869572\n",
      "1462, loss is 0.002091885384495273 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24519800064417419 and mu_y: 0.15936314801630216\n",
      "1463, loss is 0.0020915048098149136 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24507583239572586 and mu_y: 0.15921099157991614\n",
      "1464, loss is 0.0020911250019163413 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24495379847393176 and mu_y: 0.15905897955783624\n",
      "1465, loss is 0.002090745958764471 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24483189865045535 and mu_y: 0.15890711171890198\n",
      "1466, loss is 0.002090367678330969 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24471013269749078 and mu_y: 0.15875538783249235\n",
      "1467, loss is 0.002089990158594243 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24458850038776134 and mu_y: 0.1586038076685242\n",
      "1468, loss is 0.0020896133975393974 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2444670014945179 and mu_y: 0.1584523709974506\n",
      "1469, loss is 0.0020892373931582237 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24434563579153737 and mu_y: 0.15830107759025938\n",
      "1470, loss is 0.002088862143449165 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24422440305312126 and mu_y: 0.15814992721847151\n",
      "1471, loss is 0.002088487646417288 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24410330305409414 and mu_y: 0.15799891965413956\n",
      "1472, loss is 0.0020881139000742677 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2439823355698021 and mu_y: 0.1578480546698462\n",
      "1473, loss is 0.0020877409024383474 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24386150037611126 and mu_y: 0.15769733203870254\n",
      "1474, loss is 0.0020873686515343252 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24374079724940634 and mu_y: 0.15754675153434675\n",
      "1475, loss is 0.002086997145393518 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2436202259665891 and mu_y: 0.1573963129309424\n",
      "1476, loss is 0.0020866263820537444 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24349978630507693 and mu_y: 0.15724601600317695\n",
      "1477, loss is 0.0020862563595592932 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24337947804280124 and mu_y: 0.15709586052626037\n",
      "1478, loss is 0.0020858870759609023 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24325930095820616 and mu_y: 0.15694584627592342\n",
      "1479, loss is 0.0020855185293157307 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2431392548302469 and mu_y: 0.15679597302841627\n",
      "1480, loss is 0.002085150717687334 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2430193394383884 and mu_y: 0.15664624056050697\n",
      "1481, loss is 0.0020847836391456385 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2428995545626039 and mu_y: 0.15649664864947993\n",
      "1482, loss is 0.00208441729176692 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2427798999833733 and mu_y: 0.1563471970731344\n",
      "1483, loss is 0.002084051673633774 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24266037548168193 and mu_y: 0.1561978856097831\n",
      "1484, loss is 0.002083686782835095 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24254098083901898 and mu_y: 0.15604871403825052\n",
      "1485, loss is 0.002083322617466049 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24242171583737612 and mu_y: 0.1558996821378717\n",
      "1486, loss is 0.002082959175628049 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.242302580259246 and mu_y: 0.15575078968849054\n",
      "1487, loss is 0.0020825964554287354 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24218357388762085 and mu_y: 0.15560203647045848\n",
      "1488, loss is 0.002082234454981946 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2420646965059911 and mu_y: 0.15545342226463288\n",
      "1489, loss is 0.002081873172407694 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24194594789834392 and mu_y: 0.15530494685237575\n",
      "1490, loss is 0.0020815126058321438 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24182732784916175 and mu_y: 0.15515661001555212\n",
      "1491, loss is 0.0020811527533875877 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.241708836143421 and mu_y: 0.15500841153652867\n",
      "1492, loss is 0.0020807936132124227 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2415904725665906 and mu_y: 0.15486035119817232\n",
      "1493, loss is 0.0020804351834511244 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24147223690463054 and mu_y: 0.15471242878384872\n",
      "1494, loss is 0.0020800774622542232 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24135412894399055 and mu_y: 0.15456464407742088\n",
      "1495, loss is 0.0020797204477782873 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24123614847160868 and mu_y: 0.1544169968632476\n",
      "1496, loss is 0.0020793641381858883 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2411182952749099 and mu_y: 0.15426948692618228\n",
      "1497, loss is 0.0020790085316455876 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24100056914180476 and mu_y: 0.15412211405157128\n",
      "1498, loss is 0.0020786536263319093 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2408829698606879 and mu_y: 0.1539748780252526\n",
      "1499, loss is 0.002078299420425315 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24076549722043689 and mu_y: 0.15382777863355446\n",
      "1500, loss is 0.0020779459121121843 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2406481510104106 and mu_y: 0.15368081566329392\n",
      "1501, loss is 0.002077593099584793 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24053093102044804 and mu_y: 0.15353398890177541\n",
      "1502, loss is 0.0020772409810412857 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2404138370408669 and mu_y: 0.1533872981367894\n",
      "1503, loss is 0.0020768895546856543 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24029686886246227 and mu_y: 0.15324074315661093\n",
      "1504, loss is 0.002076538818727718 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.24018002627650512 and mu_y: 0.15309432374999832\n",
      "1505, loss is 0.0020761887713831016 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2400633090747412 and mu_y: 0.15294803970619172\n",
      "1506, loss is 0.0020758394108732056 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23994671704938947 and mu_y: 0.15280189081491177\n",
      "1507, loss is 0.0020754907354251927 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23983024999314093 and mu_y: 0.15265587686635818\n",
      "1508, loss is 0.002075142743271961 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2397139076991572 and mu_y: 0.15250999765120837\n",
      "1509, loss is 0.0020747954326521276 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23959768996106925 and mu_y: 0.15236425296061618\n",
      "1510, loss is 0.002074448801809992 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23948159657297596 and mu_y: 0.15221864258621037\n",
      "1511, loss is 0.002074102848995533 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23936562732944291 and mu_y: 0.1520731663200934\n",
      "1512, loss is 0.0020737575724643752 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23924978202550107 and mu_y: 0.15192782395484003\n",
      "1513, loss is 0.0020734129704777704 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2391340604566454 and mu_y: 0.15178261528349593\n",
      "1514, loss is 0.0020730690413025728 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23901846241883365 and mu_y: 0.1516375400995764\n",
      "1515, loss is 0.0020727257832112256 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23890298770848495 and mu_y: 0.15149259819706498\n",
      "1516, loss is 0.0020723831944817308 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23878763612247858 and mu_y: 0.1513477893704122\n",
      "1517, loss is 0.0020720412733976333 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23867240745815269 and mu_y: 0.15120311341453416\n",
      "1518, loss is 0.002071700018247997 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23855730151330296 and mu_y: 0.15105857012481122\n",
      "1519, loss is 0.0020713594273273853 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23844231808618133 and mu_y: 0.15091415929708676\n",
      "1520, loss is 0.002071019498935839 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23832745697549473 and mu_y: 0.15076988072766576\n",
      "1521, loss is 0.002070680231378854 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23821271798040383 and mu_y: 0.15062573421331352\n",
      "1522, loss is 0.002070341622967365 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2380981009005217 and mu_y: 0.15048171955125444\n",
      "1523, loss is 0.0020700036720177196 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23798360553591255 and mu_y: 0.1503378365391706\n",
      "1524, loss is 0.0020696663768516622 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2378692316870906 and mu_y: 0.15019408497520048\n",
      "1525, loss is 0.002069329735796307 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23775497915501861 and mu_y: 0.15005046465793775\n",
      "1526, loss is 0.002068993747184126 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23764084774110678 and mu_y: 0.14990697538642994\n",
      "1527, loss is 0.002068658409352923 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23752683724721144 and mu_y: 0.14976361696017707\n",
      "1528, loss is 0.002068323720645812 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2374129474756338 and mu_y: 0.14962038917913048\n",
      "1529, loss is 0.002067989679411203 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23729917822911875 and mu_y: 0.14947729184369155\n",
      "1530, loss is 0.0020676562840027737 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23718552931085354 and mu_y: 0.1493343247547103\n",
      "1531, loss is 0.0020673235327794606 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23707200052446664 and mu_y: 0.14919148771348434\n",
      "1532, loss is 0.0020669914241054272 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23695859167402641 and mu_y: 0.14904878052175735\n",
      "1533, loss is 0.0020666599563500493 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23684530256403996 and mu_y: 0.14890620298171806\n",
      "1534, loss is 0.002066329127887898 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2367321329994519 and mu_y: 0.1487637548959988\n",
      "1535, loss is 0.002065998937098719 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23661908278564306 and mu_y: 0.1486214360676744\n",
      "1536, loss is 0.002065669382367404 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2365061517284294 and mu_y: 0.14847924630026083\n",
      "1537, loss is 0.0020653404620839862 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23639333963406067 and mu_y: 0.14833718539771404\n",
      "1538, loss is 0.0020650121746436105 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23628064630921927 and mu_y: 0.14819525316442866\n",
      "1539, loss is 0.002064684518446514 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23616807156101904 and mu_y: 0.14805344940523682\n",
      "1540, loss is 0.002064357491898012 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2360556151970041 and mu_y: 0.14791177392540686\n",
      "1541, loss is 0.0020640310934084785 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23594327702514753 and mu_y: 0.14777022653064215\n",
      "1542, loss is 0.00206370532139332 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23583105685385033 and mu_y: 0.14762880702707984\n",
      "1543, loss is 0.0020633801742729638 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23571895449194014 and mu_y: 0.14748751522128967\n",
      "1544, loss is 0.002063055650472838 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23560696974867004 and mu_y: 0.1473463509202727\n",
      "1545, loss is 0.00206273174842335 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23549510243371746 and mu_y: 0.14720531393146022\n",
      "1546, loss is 0.0020624084665598684 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23538335235718294 and mu_y: 0.14706440406271237\n",
      "1547, loss is 0.0020620858033227048 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23527171932958899 and mu_y: 0.14692362112231708\n",
      "1548, loss is 0.002061763757157096 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23516020316187886 and mu_y: 0.1467829649189888\n",
      "1549, loss is 0.002061442326513184 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23504880366541545 and mu_y: 0.14664243526186732\n",
      "1550, loss is 0.0020611215098460004 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2349375206519801 and mu_y: 0.14650203196051664\n",
      "1551, loss is 0.002060801305615444 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23482635393377146 and mu_y: 0.1463617548249237\n",
      "1552, loss is 0.002060481712286263 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23471530332340437 and mu_y: 0.14622160366549716\n",
      "1553, loss is 0.002060162728328041 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2346043686339086 and mu_y: 0.1460815782930664\n",
      "1554, loss is 0.0020598443522151753 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23449354967872782 and mu_y: 0.14594167851888015\n",
      "1555, loss is 0.002059526582426859 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23438284627171838 and mu_y: 0.14580190415460545\n",
      "1556, loss is 0.0020592094174470632 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23427225822714826 and mu_y: 0.14566225501232638\n",
      "1557, loss is 0.002058892855764521 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2341617853596958 and mu_y: 0.145522730904543\n",
      "1558, loss is 0.002058576895872708 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23405142748444874 and mu_y: 0.14538333164417017\n",
      "1559, loss is 0.0020582615362698207 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2339411844169029 and mu_y: 0.14524405704453625\n",
      "1560, loss is 0.002057946775458768 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23383105597296125 and mu_y: 0.14510490691938216\n",
      "1561, loss is 0.0020576326119471485 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23372104196893265 and mu_y: 0.1449658810828601\n",
      "1562, loss is 0.002057319044247229 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23361114222153082 and mu_y: 0.14482697934953248\n",
      "1563, loss is 0.0020570060708759324 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23350135654787313 and mu_y: 0.14468820153437068\n",
      "1564, loss is 0.0020566936903548194 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2333916847654796 and mu_y: 0.144549547452754\n",
      "1565, loss is 0.0020563819012100735 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23328212669227177 and mu_y: 0.1444110169204685\n",
      "1566, loss is 0.0020560707019724746 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23317268214657152 and mu_y: 0.1442726097537059\n",
      "1567, loss is 0.002055760091177394 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23306335094710004 and mu_y: 0.14413432576906238\n",
      "1568, loss is 0.00205545006736477 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23295413291297673 and mu_y: 0.1439961647835375\n",
      "1569, loss is 0.0020551406290790887 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2328450278637181 and mu_y: 0.14385812661453312\n",
      "1570, loss is 0.002054831774869378 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23273603561923673 and mu_y: 0.14372021107985222\n",
      "1571, loss is 0.0020545235032891768 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23262715599984005 and mu_y: 0.14358241799769783\n",
      "1572, loss is 0.0020542158128965286 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2325183888262294 and mu_y: 0.1434447471866719\n",
      "1573, loss is 0.0020539087022539595 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23240973391949893 and mu_y: 0.14330719846577425\n",
      "1574, loss is 0.0020536021699284644 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23230119110113442 and mu_y: 0.14316977165440134\n",
      "1575, loss is 0.00205329621449149 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23219276019301238 and mu_y: 0.1430324665723453\n",
      "1576, loss is 0.002052990834518915 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2320844410173988 and mu_y: 0.14289528303979285\n",
      "1577, loss is 0.002052686028591038 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23197623339694828 and mu_y: 0.14275822087732407\n",
      "1578, loss is 0.002052381795292559 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23186813715470278 and mu_y: 0.14262127990591142\n",
      "1579, loss is 0.002052078133212563 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2317601521140907 and mu_y: 0.14248445994691866\n",
      "1580, loss is 0.0020517750409445056 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2316522780989258 and mu_y: 0.14234776082209977\n",
      "1581, loss is 0.0020514725170861937 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23154451493340608 and mu_y: 0.14221118235359778\n",
      "1582, loss is 0.0020511705602397723 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2314368624421128 and mu_y: 0.14207472436394383\n",
      "1583, loss is 0.002050869169011708 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23132932045000945 and mu_y: 0.14193838667605604\n",
      "1584, loss is 0.0020505683420127697 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23122188878244065 and mu_y: 0.1418021691132384\n",
      "1585, loss is 0.002050268077858019 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23111456726513116 and mu_y: 0.14166607149917979\n",
      "1586, loss is 0.00204996837516679 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23100735572418485 and mu_y: 0.14153009365795288\n",
      "1587, loss is 0.0020496692325626714 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2309002539860836 and mu_y: 0.14139423541401308\n",
      "1588, loss is 0.0020493706486734973 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2307932618776864 and mu_y: 0.1412584965921975\n",
      "1589, loss is 0.0020490726221313264 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2306863792262282 and mu_y: 0.14112287701772386\n",
      "1590, loss is 0.00204877515157243 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23057960585931897 and mu_y: 0.14098737651618953\n",
      "1591, loss is 0.002048478235637272 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23047294160494264 and mu_y: 0.1408519949135704\n",
      "1592, loss is 0.0020481818729704993 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23036638629145614 and mu_y: 0.14071673203621984\n",
      "1593, loss is 0.002047886062220919 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23025993974758835 and mu_y: 0.1405815877108678\n",
      "1594, loss is 0.002047590802041494 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23015360180243907 and mu_y: 0.1404465617646196\n",
      "1595, loss is 0.0020472960910893133 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.23004737228547806 and mu_y: 0.14031165402495502\n",
      "1596, loss is 0.002047001928025591 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22994125102654403 and mu_y: 0.14017686431972723\n",
      "1597, loss is 0.002046708311515643 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22983523785584364 and mu_y: 0.1400421924771618\n",
      "1598, loss is 0.0020464152402288735 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22972933260395054 and mu_y: 0.13990763832585562\n",
      "1599, loss is 0.0020461227128387607 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22962353510180428 and mu_y: 0.13977320169477597\n",
      "1600, loss is 0.002045830728022842 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22951784518070942 and mu_y: 0.13963888241325942\n",
      "1601, loss is 0.002045539284462698 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2294122626723345 and mu_y: 0.1395046803110109\n",
      "1602, loss is 0.002045248380843941 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2293067874087111 and mu_y: 0.1393705952181027\n",
      "1603, loss is 0.002044958015856195 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2292014192222328 and mu_y: 0.13923662696497333\n",
      "1604, loss is 0.0020446681881930856 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22909615794565427 and mu_y: 0.13910277538242669\n",
      "1605, loss is 0.002044378896552223 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22899100341209028 and mu_y: 0.13896904030163099\n",
      "1606, loss is 0.0020440901396351885 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22888595545501464 and mu_y: 0.1388354215541178\n",
      "1607, loss is 0.002043801916147519 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2287810139082594 and mu_y: 0.13870191897178097\n",
      "1608, loss is 0.002043514224798696 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22867617860601375 and mu_y: 0.13856853238687578\n",
      "1609, loss is 0.0020432270643021247 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22857144938282314 and mu_y: 0.13843526163201786\n",
      "1610, loss is 0.002042940433375128 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22846682607358829 and mu_y: 0.13830210654018224\n",
      "1611, loss is 0.0020426543307389233 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2283623085135642 and mu_y: 0.13816906694470238\n",
      "1612, loss is 0.0020423687551186158 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22825789653835932 and mu_y: 0.13803614267926914\n",
      "1613, loss is 0.0020420837052431817 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22815358998393442 and mu_y: 0.13790333357792994\n",
      "1614, loss is 0.002041799179845452 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22804938868660185 and mu_y: 0.13777063947508766\n",
      "1615, loss is 0.002041515177662102 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22794529248302442 and mu_y: 0.13763806020549973\n",
      "1616, loss is 0.002041231697433635 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2278413012102146 and mu_y: 0.1375055956042772\n",
      "1617, loss is 0.0020409487379043703 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22773741470553344 and mu_y: 0.13737324550688368\n",
      "1618, loss is 0.002040666297822428 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22763363280668983 and mu_y: 0.13724100974913453\n",
      "1619, loss is 0.0020403843759397157 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2275299553517394 and mu_y: 0.13710888816719582\n",
      "1620, loss is 0.0020401029710119135 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22742638217908362 and mu_y: 0.13697688059758337\n",
      "1621, loss is 0.0020398220817984623 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.227322913127469 and mu_y: 0.13684498687716184\n",
      "1622, loss is 0.002039541707062551 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.227219548035986 and mu_y: 0.13671320684314378\n",
      "1623, loss is 0.002039261845571098 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22711628674406828 and mu_y: 0.1365815403330887\n",
      "1624, loss is 0.0020389824960947455 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2270131290914916 and mu_y: 0.1364499871849021\n",
      "1625, loss is 0.002038703657407839 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22691007491837303 and mu_y: 0.13631854723683454\n",
      "1626, loss is 0.0020384253282884164 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2268071240651701 and mu_y: 0.13618722032748076\n",
      "1627, loss is 0.002038147507518195 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22670427637267968 and mu_y: 0.13605600629577877\n",
      "1628, loss is 0.002037870193882562 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22660153168203728 and mu_y: 0.13592490498100876\n",
      "1629, loss is 0.002037593386170553 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2264988898347161 and mu_y: 0.13579391622279238\n",
      "1630, loss is 0.0020373170831748453 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2263963506725261 and mu_y: 0.1356630398610917\n",
      "1631, loss is 0.0020370412836917414 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.226293914037613 and mu_y: 0.13553227573620838\n",
      "1632, loss is 0.002036765986521161 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22619157977245768 and mu_y: 0.13540162368878264\n",
      "1633, loss is 0.0020364911904666213 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.226089347719875 and mu_y: 0.13527108355979245\n",
      "1634, loss is 0.0020362168943352283 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22598721772301303 and mu_y: 0.13514065519055257\n",
      "1635, loss is 0.002035943096937663 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2258851896253522 and mu_y: 0.13501033842271368\n",
      "1636, loss is 0.002035669797088169 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22578326327070436 and mu_y: 0.13488013309826147\n",
      "1637, loss is 0.002035396993604538 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2256814385032119 and mu_y: 0.1347500390595157\n",
      "1638, loss is 0.002035124685308099 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22557971516734693 and mu_y: 0.13462005614912945\n",
      "1639, loss is 0.002034852871023705 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2254780931079104 and mu_y: 0.13449018421008796\n",
      "1640, loss is 0.0020345815495797217 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22537657217003113 and mu_y: 0.134360423085708\n",
      "1641, loss is 0.0020343107198080115 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22527515219916505 and mu_y: 0.13423077261963684\n",
      "1642, loss is 0.002034040380543924 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22517383304109434 and mu_y: 0.13410123265585144\n",
      "1643, loss is 0.002033770530626282 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22507261454192648 and mu_y: 0.1339718030386575\n",
      "1644, loss is 0.002033501168897371 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22497149654809348 and mu_y: 0.13384248361268863\n",
      "1645, loss is 0.0020332322942029253 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22487047890635095 and mu_y: 0.13371327422290546\n",
      "1646, loss is 0.002032963905392115 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2247695614637773 and mu_y: 0.13358417471459477\n",
      "1647, loss is 0.002032696001317537 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22466874406777287 and mu_y: 0.1334551849333686\n",
      "1648, loss is 0.0020324285808351974 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2245680265660591 and mu_y: 0.13332630472516344\n",
      "1649, loss is 0.002032161642804505 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2244674088066776 and mu_y: 0.13319753393623923\n",
      "1650, loss is 0.002031895186088257 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22436689063798945 and mu_y: 0.1330688724131787\n",
      "1651, loss is 0.0020316292095526227 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22426647190867424 and mu_y: 0.1329403200028863\n",
      "1652, loss is 0.002031363712067141 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2241661524677293 and mu_y: 0.13281187655258755\n",
      "1653, loss is 0.0020310986925046997 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22406593216446882 and mu_y: 0.132683541909828\n",
      "1654, loss is 0.002030834149741528 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22396581084852304 and mu_y: 0.1325553159224725\n",
      "1655, loss is 0.0020305700826571825 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22386578836983742 and mu_y: 0.13242719843870426\n",
      "1656, loss is 0.002030306490134536 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22376586457867179 and mu_y: 0.1322991893070241\n",
      "1657, loss is 0.0020300433710597706 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22366603932559959 and mu_y: 0.13217128837624958\n",
      "1658, loss is 0.002029780724322354 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22356631246150693 and mu_y: 0.13204349549551408\n",
      "1659, loss is 0.0020295185488150413 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2234666838375919 and mu_y: 0.13191581051426604\n",
      "1660, loss is 0.0020292568434338546 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22336715330536372 and mu_y: 0.13178823328226813\n",
      "1661, loss is 0.0020289956070780766 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2232677207166418 and mu_y: 0.13166076364959634\n",
      "1662, loss is 0.0020287348386502347 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22316838592355512 and mu_y: 0.13153340146663925\n",
      "1663, loss is 0.002028474537056092 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22306914877854128 and mu_y: 0.13140614658409716\n",
      "1664, loss is 0.0020282147012046373 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22297000913434575 and mu_y: 0.13127899885298122\n",
      "1665, loss is 0.002027955330008068 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22287096684402108 and mu_y: 0.13115195812461267\n",
      "1666, loss is 0.0020276964223817874 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22277202176092603 and mu_y: 0.13102502425062199\n",
      "1667, loss is 0.002027437977244386 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22267317373872486 and mu_y: 0.1308981970829481\n",
      "1668, loss is 0.0020271799935176324 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22257442263138646 and mu_y: 0.1307714764738375\n",
      "1669, loss is 0.002026922470126465 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22247576829318358 and mu_y: 0.13064486227584354\n",
      "1670, loss is 0.002026665405998977 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22237721057869203 and mu_y: 0.13051835434182554\n",
      "1671, loss is 0.0020264088000664063 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22227874934278993 and mu_y: 0.13039195252494798\n",
      "1672, loss is 0.002026152651263127 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2221803844406569 and mu_y: 0.13026565667867976\n",
      "1673, loss is 0.002025896958526635 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22208211572777323 and mu_y: 0.13013946665679332\n",
      "1674, loss is 0.002025641720797536 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22198394305991914 and mu_y: 0.13001338231336393\n",
      "1675, loss is 0.0020253869370195445 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22188586629317403 and mu_y: 0.12988740350276878\n",
      "1676, loss is 0.0020251326061394566 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22178788528391563 and mu_y: 0.12976153007968627\n",
      "1677, loss is 0.0020248787271071526 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22168999988881927 and mu_y: 0.1296357618990952\n",
      "1678, loss is 0.002024625298875582 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22159220996485712 and mu_y: 0.12951009881627398\n",
      "1679, loss is 0.002024372320400749 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22149451536929737 and mu_y: 0.12938454068679983\n",
      "1680, loss is 0.002024119790641709 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2213969159597035 and mu_y: 0.129259087366548\n",
      "1681, loss is 0.0020238677085605518 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22129941159393354 and mu_y: 0.12913373871169098\n",
      "1682, loss is 0.002023616073122394 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2212020021301392 and mu_y: 0.12900849457869773\n",
      "1683, loss is 0.0020233648832953684 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22110468742676526 and mu_y: 0.1288833548243329\n",
      "1684, loss is 0.0020231141380506103 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22100746734254864 and mu_y: 0.1287583193056561\n",
      "1685, loss is 0.002022863836362252 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22091034173651783 and mu_y: 0.128633387880021\n",
      "1686, loss is 0.0020226139772074087 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22081331046799196 and mu_y: 0.1285085604050747\n",
      "1687, loss is 0.002022364559566169 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22071637339658018 and mu_y: 0.12838383673875686\n",
      "1688, loss is 0.0020221155824215855 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22061953038218085 and mu_y: 0.12825921673929905\n",
      "1689, loss is 0.002021867044759664 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22052278128498076 and mu_y: 0.12813470026522386\n",
      "1690, loss is 0.0020216189455693518 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2204261259654545 and mu_y: 0.1280102871753442\n",
      "1691, loss is 0.0020213712838425277 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22032956428436357 and mu_y: 0.12788597732876258\n",
      "1692, loss is 0.0020211240585739972 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22023309610275577 and mu_y: 0.12776177058487026\n",
      "1693, loss is 0.0020208772687614726 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22013672128196438 and mu_y: 0.12763766680334654\n",
      "1694, loss is 0.0020206309134055724 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.22004043968360745 and mu_y: 0.12751366584415805\n",
      "1695, loss is 0.0020203849915098014 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2199442511695871 and mu_y: 0.12738976756755793\n",
      "1696, loss is 0.002020139502080554 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2198481556020887 and mu_y: 0.12726597183408514\n",
      "1697, loss is 0.0020198944441270914 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21975215284358024 and mu_y: 0.1271422785045637\n",
      "1698, loss is 0.002019649816661536 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21965624275681153 and mu_y: 0.12701868744010192\n",
      "1699, loss is 0.002019405618698865 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2195604252048135 and mu_y: 0.1268951985020917\n",
      "1700, loss is 0.002019161849256896 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21946470005089752 and mu_y: 0.12677181155220774\n",
      "1701, loss is 0.0020189185073562813 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21936906715865462 and mu_y: 0.12664852645240687\n",
      "1702, loss is 0.00201867559202049 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21927352639195477 and mu_y: 0.12652534306492727\n",
      "1703, loss is 0.0020184331022758116 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21917807761494623 and mu_y: 0.12640226125228776\n",
      "1704, loss is 0.0020181910371513344 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21908272069205478 and mu_y: 0.12627928087728707\n",
      "1705, loss is 0.002017949395678938 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.218987455487983 and mu_y: 0.12615640180300308\n",
      "1706, loss is 0.002017708176893291 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21889228186770965 and mu_y: 0.12603362389279213\n",
      "1707, loss is 0.002017467379831831 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21879719969648878 and mu_y: 0.12591094701028832\n",
      "1708, loss is 0.0020172270035347627 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21870220883984925 and mu_y: 0.12578837101940274\n",
      "1709, loss is 0.0020169870470450476 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2186073091635939 and mu_y: 0.12566589578432277\n",
      "1710, loss is 0.002016747509408389 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21851250053379878 and mu_y: 0.1255435211695114\n",
      "1711, loss is 0.0020165083896732275 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21841778281681265 and mu_y: 0.12542124703970642\n",
      "1712, loss is 0.0020162696868907333 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2183231558792561 and mu_y: 0.12529907325991985\n",
      "1713, loss is 0.0020160314001147887 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21822861958802098 and mu_y: 0.1251769996954371\n",
      "1714, loss is 0.0020157935284019876 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21813417381026962 and mu_y: 0.12505502621181636\n",
      "1715, loss is 0.002015556070811621 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21803981841343417 and mu_y: 0.12493315267488779\n",
      "1716, loss is 0.0020153190264056717 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21794555326521595 and mu_y: 0.12481137895075295\n",
      "1717, loss is 0.002015082394248799 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2178513782335847 and mu_y: 0.124689704905784\n",
      "1718, loss is 0.002014846173408337 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21775729318677794 and mu_y: 0.12456813040662303\n",
      "1719, loss is 0.002014610362954278 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21766329799330028 and mu_y: 0.12444665532018137\n",
      "1720, loss is 0.0020143749619592703 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21756939252192276 and mu_y: 0.1243252795136389\n",
      "1721, loss is 0.0020141399694986024 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21747557664168207 and mu_y: 0.12420400285444336\n",
      "1722, loss is 0.002013905384650201 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21738185022188003 and mu_y: 0.12408282521030962\n",
      "1723, loss is 0.0020136712064946155 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21728821313208282 and mu_y: 0.12396174644921906\n",
      "1724, loss is 0.002013437434115015 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2171946652421203 and mu_y: 0.12384076643941881\n",
      "1725, loss is 0.0020132040665971724 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2171012064220854 and mu_y: 0.12371988504942115\n",
      "1726, loss is 0.0020129711030294614 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2170078365423334 and mu_y: 0.12359910214800274\n",
      "1727, loss is 0.0020127385425028456 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2169145554734813 and mu_y: 0.12347841760420401\n",
      "1728, loss is 0.0020125063841108714 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2168213630864071 and mu_y: 0.12335783128732847\n",
      "1729, loss is 0.002012274626949654 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21672825925224923 and mu_y: 0.12323734306694199\n",
      "1730, loss is 0.002012043270117874 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21663524384240582 and mu_y: 0.12311695281287219\n",
      "1731, loss is 0.002011812312716768 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21654231672853405 and mu_y: 0.12299666039520771\n",
      "1732, loss is 0.002011581753850114 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21644947778254953 and mu_y: 0.12287646568429758\n",
      "1733, loss is 0.0020113515926242337 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2163567268766256 and mu_y: 0.12275636855075056\n",
      "1734, loss is 0.0020111218281479736 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21626406388319275 and mu_y: 0.12263636886543443\n",
      "1735, loss is 0.002010892459532703 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21617148867493782 and mu_y: 0.12251646649947537\n",
      "1736, loss is 0.0020106634858922984 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21607900112480358 and mu_y: 0.12239666132425729\n",
      "1737, loss is 0.0020104349063431444 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21598660110598783 and mu_y: 0.12227695321142117\n",
      "1738, loss is 0.0020102067200041167 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.215894288491943 and mu_y: 0.12215734203286437\n",
      "1739, loss is 0.0020099789259965797 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21580206315637532 and mu_y: 0.12203782766074002\n",
      "1740, loss is 0.002009751523444375 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21570992497324426 and mu_y: 0.12191840996745634\n",
      "1741, loss is 0.0020095245114738125 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21561787381676192 and mu_y: 0.12179908882567603\n",
      "1742, loss is 0.0020092978892136634 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21552590956139234 and mu_y: 0.12167986410831556\n",
      "1743, loss is 0.002009071655795152 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21543403208185086 and mu_y: 0.12156073568854457\n",
      "1744, loss is 0.0020088458103519474 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21534224125310353 and mu_y: 0.12144170343978519\n",
      "1745, loss is 0.002008620352020153 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21525053695036644 and mu_y: 0.12132276723571145\n",
      "1746, loss is 0.002008395279938303 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21515891904910517 and mu_y: 0.12120392695024856\n",
      "1747, loss is 0.0020081705932473498 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21506738742503403 and mu_y: 0.12108518245757235\n",
      "1748, loss is 0.0020079462910906564 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21497594195411557 and mu_y: 0.12096653363210857\n",
      "1749, loss is 0.00200772237261399 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21488458251255987 and mu_y: 0.12084798034853231\n",
      "1750, loss is 0.002007498836965514 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21479330897682394 and mu_y: 0.12072952248176731\n",
      "1751, loss is 0.002007275683295778 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21470212122361113 and mu_y: 0.1206111599069854\n",
      "1752, loss is 0.002007052910757711 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21461101912987046 and mu_y: 0.12049289249960578\n",
      "1753, loss is 0.0020068305185066125 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21452000257279608 and mu_y: 0.12037472013529446\n",
      "1754, loss is 0.002006608505700147 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21442907142982653 and mu_y: 0.12025664268996362\n",
      "1755, loss is 0.002006386871498333 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21433822557864432 and mu_y: 0.12013866003977097\n",
      "1756, loss is 0.002006165615063537 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2142474648971751 and mu_y: 0.12002077206111915\n",
      "1757, loss is 0.002005944735560464 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21415678926358725 and mu_y: 0.11990297863065508\n",
      "1758, loss is 0.0020057242321561515 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21406619855629108 and mu_y: 0.11978527962526937\n",
      "1759, loss is 0.002005504104019961 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21397569265393843 and mu_y: 0.1196676749220957\n",
      "1760, loss is 0.0020052843503235687 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2138852714354219 and mu_y: 0.11955016439851017\n",
      "1761, loss is 0.002005064970240961 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21379493477987438 and mu_y: 0.11943274793213075\n",
      "1762, loss is 0.002004845962948424 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21370468256666833 and mu_y: 0.11931542540081662\n",
      "1763, loss is 0.0020046273276245344 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21361451467541523 and mu_y: 0.11919819668266755\n",
      "1764, loss is 0.002004409063450159 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21352443098596505 and mu_y: 0.11908106165602338\n",
      "1765, loss is 0.0020041911696084373 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21343443137840554 and mu_y: 0.11896402019946327\n",
      "1766, loss is 0.0020039736452847814 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2133445157330617 and mu_y: 0.11884707219180524\n",
      "1767, loss is 0.0020037564896668637 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21325468393049524 and mu_y: 0.11873021751210548\n",
      "1768, loss is 0.002003539701944614 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21316493585150387 and mu_y: 0.1186134560396578\n",
      "1769, loss is 0.0020033232813102086 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21307527137712082 and mu_y: 0.11849678765399296\n",
      "1770, loss is 0.0020031072269580622 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21298569038861423 and mu_y: 0.11838021223487818\n",
      "1771, loss is 0.0020028915380848208 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2128961927674865 and mu_y: 0.11826372966231645\n",
      "1772, loss is 0.0020026762138893603 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2128067783954738 and mu_y: 0.11814733981654597\n",
      "1773, loss is 0.0020024612535727675 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2127174471545454 and mu_y: 0.11803104257803959\n",
      "1774, loss is 0.0020022466563383457 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2126281989269032 and mu_y: 0.11791483782750417\n",
      "1775, loss is 0.002002032421391595 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21253903359498108 and mu_y: 0.11779872544588\n",
      "1776, loss is 0.0020018185479402156 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21244995104144432 and mu_y: 0.11768270531434029\n",
      "1777, loss is 0.002001605035194092 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21236095114918904 and mu_y: 0.11756677731429045\n",
      "1778, loss is 0.0020013918823652936 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21227203380134166 and mu_y: 0.11745094132736764\n",
      "1779, loss is 0.0020011790886680595 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21218319888125828 and mu_y: 0.11733519723544009\n",
      "1780, loss is 0.0020009666533187974 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21209444627252416 and mu_y: 0.11721954492060657\n",
      "1781, loss is 0.002000754575536074 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2120057758589531 and mu_y: 0.11710398426519585\n",
      "1782, loss is 0.0020005428545406072 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21191718752458696 and mu_y: 0.11698851515176602\n",
      "1783, loss is 0.0020003314895552606 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.211828681153695 and mu_y: 0.11687313746310402\n",
      "1784, loss is 0.002000120479805035 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2117402566307733 and mu_y: 0.11675785108222499\n",
      "1785, loss is 0.001999909824517063 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2116519138405444 and mu_y: 0.11664265589237174\n",
      "1786, loss is 0.0019996995229206 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21156365266795651 and mu_y: 0.11652755177701421\n",
      "1787, loss is 0.0019994895742470177 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21147547299818303 and mu_y: 0.11641253861984881\n",
      "1788, loss is 0.0019992799777297982 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21138737471662208 and mu_y: 0.11629761630479796\n",
      "1789, loss is 0.0019990707326045273 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21129935770889582 and mu_y: 0.11618278471600944\n",
      "1790, loss is 0.001998861838108884 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21121142186084998 and mu_y: 0.1160680437378559\n",
      "1791, loss is 0.001998653293482639 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21112356705855329 and mu_y: 0.11595339325493424\n",
      "1792, loss is 0.0019984450979676437 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21103579318829688 and mu_y: 0.11583883315206508\n",
      "1793, loss is 0.001998237250807822 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21094810013659385 and mu_y: 0.11572436331429223\n",
      "1794, loss is 0.001998029751249171 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2108604877901786 and mu_y: 0.11560998362688205\n",
      "1795, loss is 0.0019978225985397466 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21077295603600638 and mu_y: 0.11549569397532299\n",
      "1796, loss is 0.0019976157919296593 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21068550476125267 and mu_y: 0.11538149424532498\n",
      "1797, loss is 0.00199740933067107 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21059813385331272 and mu_y: 0.11526738432281892\n",
      "1798, loss is 0.0019972032140181764 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21051084319980093 and mu_y: 0.1151533640939561\n",
      "1799, loss is 0.0019969974412272127 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21042363268855038 and mu_y: 0.11503943344510763\n",
      "1800, loss is 0.001996792011556444 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21033650220761224 and mu_y: 0.11492559226286396\n",
      "1801, loss is 0.0019965869242661517 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2102494516452553 and mu_y: 0.11481184043403429\n",
      "1802, loss is 0.001996382178618635 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21016248088996536 and mu_y: 0.11469817784564604\n",
      "1803, loss is 0.0019961777738782003 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.21007558983044478 and mu_y: 0.11458460438494429\n",
      "1804, loss is 0.0019959737093111544 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20998877835561183 and mu_y: 0.1144711199393913\n",
      "1805, loss is 0.001995769984185801 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20990204635460033 and mu_y: 0.11435772439666589\n",
      "1806, loss is 0.001995566597772429 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.209815393716759 and mu_y: 0.11424441764466296\n",
      "1807, loss is 0.0019953635493433117 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20972882033165097 and mu_y: 0.11413119957149295\n",
      "1808, loss is 0.001995160838172696 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20964232608905323 and mu_y: 0.11401807006548129\n",
      "1809, loss is 0.0019949584635368003 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20955591087895617 and mu_y: 0.11390502901516786\n",
      "1810, loss is 0.001994756424713802 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.209469574591563 and mu_y: 0.11379207630930649\n",
      "1811, loss is 0.0019945547209838372 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20938331711728927 and mu_y: 0.11367921183686441\n",
      "1812, loss is 0.0019943533516289893 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20929713834676233 and mu_y: 0.11356643548702175\n",
      "1813, loss is 0.0019941523159332872 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20921103817082082 and mu_y: 0.11345374714917097\n",
      "1814, loss is 0.0019939516131826963 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20912501648051415 and mu_y: 0.11334114671291638\n",
      "1815, loss is 0.0019937512426651113 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20903907316710202 and mu_y: 0.11322863406807358\n",
      "1816, loss is 0.001993551203670352 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20895320812205384 and mu_y: 0.11311620910466898\n",
      "1817, loss is 0.0019933514954901576 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20886742123704832 and mu_y: 0.11300387171293924\n",
      "1818, loss is 0.0019931521174181774 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20878171240397286 and mu_y: 0.11289162178333079\n",
      "1819, loss is 0.001992953068749966 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20869608151492308 and mu_y: 0.11277945920649927\n",
      "1820, loss is 0.001992754348782978 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20861052846220235 and mu_y: 0.11266738387330909\n",
      "1821, loss is 0.0019925559568165652 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20852505313832126 and mu_y: 0.1125553956748328\n",
      "1822, loss is 0.0019923578921519584 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20843965543599707 and mu_y: 0.11244349450235071\n",
      "1823, loss is 0.0019921601540922773 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20835433524815333 and mu_y: 0.11233168024735028\n",
      "1824, loss is 0.001991962741942511 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20826909246791922 and mu_y: 0.11221995280152565\n",
      "1825, loss is 0.0019917656550095214 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2081839269886292 and mu_y: 0.11210831205677714\n",
      "1826, loss is 0.0019915688926020313 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20809883870382243 and mu_y: 0.11199675790521074\n",
      "1827, loss is 0.001991372454030619 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2080138275072423 and mu_y: 0.11188529023913758\n",
      "1828, loss is 0.0019911763386077164 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20792889329283587 and mu_y: 0.11177390895107348\n",
      "1829, loss is 0.001990980545647598 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20784403595475354 and mu_y: 0.11166261393373836\n",
      "1830, loss is 0.0019907850744663794 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20775925538734838 and mu_y: 0.11155140508005586\n",
      "1831, loss is 0.001990589924382004 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20767455148517575 and mu_y: 0.11144028228315275\n",
      "1832, loss is 0.0019903950947142493 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20758992414299277 and mu_y: 0.11132924543635847\n",
      "1833, loss is 0.0019902005847847086 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20750537325575782 and mu_y: 0.1112182944332046\n",
      "1834, loss is 0.0019900063939167923 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20742089871863012 and mu_y: 0.11110742916742444\n",
      "1835, loss is 0.0019898125214357206 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20733650042696916 and mu_y: 0.11099664953295242\n",
      "1836, loss is 0.0019896189666685138 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2072521782763343 and mu_y: 0.1108859554239237\n",
      "1837, loss is 0.001989425728943996 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20716793216248422 and mu_y: 0.1107753467346736\n",
      "1838, loss is 0.001989232807592778 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20708376198137646 and mu_y: 0.11066482335973717\n",
      "1839, loss is 0.0019890402019472576 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20699966762916697 and mu_y: 0.11055438519384869\n",
      "1840, loss is 0.0019888479113416156 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20691564900220963 and mu_y: 0.11044403213194118\n",
      "1841, loss is 0.0019886559351118046 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2068317059970557 and mu_y: 0.11033376406914588\n",
      "1842, loss is 0.0019884642725955487 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20674783851045345 and mu_y: 0.11022358090079186\n",
      "1843, loss is 0.0019882729231323324 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20666404643934763 and mu_y: 0.11011348252240541\n",
      "1844, loss is 0.0019880818860634002 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.206580329680879 and mu_y: 0.11000346882970968\n",
      "1845, loss is 0.0019878911607317472 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20649668813238387 and mu_y: 0.10989353971862414\n",
      "1846, loss is 0.001987700746482117 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20641312169139361 and mu_y: 0.10978369508526412\n",
      "1847, loss is 0.00198751064266099 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20632963025563425 and mu_y: 0.1096739348259403\n",
      "1848, loss is 0.001987320848616586 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2062462137230259 and mu_y: 0.1095642588371583\n",
      "1849, loss is 0.0019871313636988528 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2061628719916824 and mu_y: 0.10945466701561815\n",
      "1850, loss is 0.0019869421872594616 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2060796049599108 and mu_y: 0.10934515925821384\n",
      "1851, loss is 0.0019867533186518046 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20599641252621084 and mu_y: 0.10923573546203286\n",
      "1852, loss is 0.0019865647572309816 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20591329458927465 and mu_y: 0.1091263955243557\n",
      "1853, loss is 0.0019863765023538068 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20583025104798613 and mu_y: 0.10901713934265543\n",
      "1854, loss is 0.0019861885533787936 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2057472818014206 and mu_y: 0.10890796681459719\n",
      "1855, loss is 0.0019860009096661522 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2056643867488442 and mu_y: 0.10879887783803774\n",
      "1856, loss is 0.0019858135705777833 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20558156578971368 and mu_y: 0.108689872311025\n",
      "1857, loss is 0.001985626535477275 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20549881882367563 and mu_y: 0.1085809501317976\n",
      "1858, loss is 0.0019854398037298954 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20541614575056633 and mu_y: 0.10847211119878437\n",
      "1859, loss is 0.001985253374702588 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20533354647041108 and mu_y: 0.10836335541060396\n",
      "1860, loss is 0.001985067247763966 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20525102088342387 and mu_y: 0.1082546826660643\n",
      "1861, loss is 0.0019848814222843078 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2051685688900069 and mu_y: 0.10814609286416221\n",
      "1862, loss is 0.00198469589763555 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20508619039075007 and mu_y: 0.10803758590408288\n",
      "1863, loss is 0.0019845106731912845 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20500388528643065 and mu_y: 0.10792916168519949\n",
      "1864, loss is 0.001984325748326751 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20492165347801272 and mu_y: 0.10782082010707267\n",
      "1865, loss is 0.0019841411224188346 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20483949486664682 and mu_y: 0.10771256106945012\n",
      "1866, loss is 0.0019839567948460547 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20475740935366943 and mu_y: 0.10760438447226615\n",
      "1867, loss is 0.0019837727649885686 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20467539684060257 and mu_y: 0.10749629021564121\n",
      "1868, loss is 0.001983589032228159 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20459345722915334 and mu_y: 0.1073882781998814\n",
      "1869, loss is 0.0019834055959482297 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20451159042121356 and mu_y: 0.10728034832547814\n",
      "1870, loss is 0.001983222455533807 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20442979631885916 and mu_y: 0.10717250049310761\n",
      "1871, loss is 0.001983039610371526 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20434807482434994 and mu_y: 0.10706473460363038\n",
      "1872, loss is 0.0019828570598496315 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.204266425840129 and mu_y: 0.1069570505580909\n",
      "1873, loss is 0.0019826748033579663 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20418484926882233 and mu_y: 0.10684944825771715\n",
      "1874, loss is 0.001982492840287978 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20410334501323843 and mu_y: 0.10674192760392011\n",
      "1875, loss is 0.0019823111700326985 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20402191297636782 and mu_y: 0.10663448849829335\n",
      "1876, loss is 0.0019821297919867514 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20394055306138265 and mu_y: 0.10652713084261264\n",
      "1877, loss is 0.001981948705546344 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20385926517163624 and mu_y: 0.10641985453883544\n",
      "1878, loss is 0.001981767910109255 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20377804921066267 and mu_y: 0.10631265948910051\n",
      "1879, loss is 0.0019815874050748412 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20369690508217636 and mu_y: 0.10620554559572747\n",
      "1880, loss is 0.0019814071898440234 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2036158326900716 and mu_y: 0.10609851276121635\n",
      "1881, loss is 0.001981227263819288 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20353483193842217 and mu_y: 0.10599156088824717\n",
      "1882, loss is 0.0019810476264046743 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20345390273148092 and mu_y: 0.10588468987967953\n",
      "1883, loss is 0.0019808682770057766 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20337304497367933 and mu_y: 0.10577789963855212\n",
      "1884, loss is 0.001980689215029738 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20329225856962707 and mu_y: 0.10567119006808239\n",
      "1885, loss is 0.001980510439885243 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2032115434241116 and mu_y: 0.10556456107166601\n",
      "1886, loss is 0.0019803319509825138 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2031308994420978 and mu_y: 0.10545801255287654\n",
      "1887, loss is 0.001980153747733307 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20305032652872745 and mu_y: 0.10535154441546496\n",
      "1888, loss is 0.0019799758295509047 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2029698245893189 and mu_y: 0.10524515656335923\n",
      "1889, loss is 0.001979798195850117 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20288939352936658 and mu_y: 0.10513884890066391\n",
      "1890, loss is 0.0019796208460472705 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2028090332545407 and mu_y: 0.10503262133165972\n",
      "1891, loss is 0.0019794437795602046 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2027287436706867 and mu_y: 0.10492647376080312\n",
      "1892, loss is 0.0019792669958082704 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20264852468382494 and mu_y: 0.10482040609272589\n",
      "1893, loss is 0.001979090494212319 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20256837620015025 and mu_y: 0.10471441823223471\n",
      "1894, loss is 0.001978914274194708 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20248829812603153 and mu_y: 0.10460851008431077\n",
      "1895, loss is 0.0019787383351792865 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20240829036801133 and mu_y: 0.10450268155410931\n",
      "1896, loss is 0.001978562676591393 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20232835283280545 and mu_y: 0.10439693254695925\n",
      "1897, loss is 0.0019783872978578533 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20224848542730253 and mu_y: 0.10429126296836276\n",
      "1898, loss is 0.001978212198406975 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20216868805856364 and mu_y: 0.10418567272399483\n",
      "1899, loss is 0.00197803737766854 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2020889606338219 and mu_y: 0.1040801617197029\n",
      "1900, loss is 0.001977862835073806 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20200930306048206 and mu_y: 0.10397472986150641\n",
      "1901, loss is 0.0019776885700554937 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20192971524612013 and mu_y: 0.10386937705559643\n",
      "1902, loss is 0.00197751458204779 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20185019709848293 and mu_y: 0.10376410320833522\n",
      "1903, loss is 0.001977340870486338 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20177074852548765 and mu_y: 0.10365890822625584\n",
      "1904, loss is 0.0019771674348082356 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20169136943522162 and mu_y: 0.10355379201606175\n",
      "1905, loss is 0.00197699427445203 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20161205973594176 and mu_y: 0.10344875448462641\n",
      "1906, loss is 0.001976821388857711 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2015328193360742 and mu_y: 0.10334379553899284\n",
      "1907, loss is 0.001976648777466711 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20145364814421396 and mu_y: 0.10323891508637327\n",
      "1908, loss is 0.0019764764397218974 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20137454606912453 and mu_y: 0.10313411303414872\n",
      "1909, loss is 0.0019763043750675694 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2012955130197374 and mu_y: 0.10302938928986861\n",
      "1910, loss is 0.0019761325829494515 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20121654890515175 and mu_y: 0.10292474376125033\n",
      "1911, loss is 0.001975961062814692 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2011376536346341 and mu_y: 0.10282017635617886\n",
      "1912, loss is 0.0019757898141118556 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20105882711761774 and mu_y: 0.10271568698270642\n",
      "1913, loss is 0.001975618836290924 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20098006926370257 and mu_y: 0.10261127554905199\n",
      "1914, loss is 0.0019754481288032826 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20090137998265456 and mu_y: 0.102506941963601\n",
      "1915, loss is 0.0019752776911017276 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20082275918440542 and mu_y: 0.10240268613490487\n",
      "1916, loss is 0.001975107522640451 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2007442067790522 and mu_y: 0.10229850797168069\n",
      "1917, loss is 0.0019749376228750453 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2006657226768569 and mu_y: 0.10219440738281076\n",
      "1918, loss is 0.0019747679912624897 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2005873067882461 and mu_y: 0.10209038427734222\n",
      "1919, loss is 0.0019745986272611564 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20050895902381058 and mu_y: 0.10198643856448672\n",
      "1920, loss is 0.001974429530330796 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20043067929430494 and mu_y: 0.10188257015361994\n",
      "1921, loss is 0.001974260699932542 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.2003524675106472 and mu_y: 0.10177877895428128\n",
      "1922, loss is 0.0019740921355289004 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20027432358391845 and mu_y: 0.10167506487617345\n",
      "1923, loss is 0.0019739238365837474 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20019624742536243 and mu_y: 0.10157142782916206\n",
      "1924, loss is 0.0019737558025623284 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20011823894638522 and mu_y: 0.10146786772327529\n",
      "1925, loss is 0.001973588032931249 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.20004029805855483 and mu_y: 0.10136438446870345\n",
      "1926, loss is 0.0019734205271584697 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19996242467360079 and mu_y: 0.10126097797579867\n",
      "1927, loss is 0.001973253284713311 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19988461870341379 and mu_y: 0.10115764815507443\n",
      "1928, loss is 0.0019730863050664376 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1998068800600454 and mu_y: 0.10105439491720529\n",
      "1929, loss is 0.0019729195876898634 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19972920865570756 and mu_y: 0.10095121817302642\n",
      "1930, loss is 0.0019727531320569407 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19965160440277233 and mu_y: 0.10084811783353327\n",
      "1931, loss is 0.00197258693764236 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19957406721377138 and mu_y: 0.1007450938098812\n",
      "1932, loss is 0.001972421003922146 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19949659700139583 and mu_y: 0.10064214601338506\n",
      "1933, loss is 0.001972255330373649 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19941919367849564 and mu_y: 0.10053927435551888\n",
      "1934, loss is 0.0019720899164755493 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19934185715807945 and mu_y: 0.10043647874791545\n",
      "1935, loss is 0.001971924761707844 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19926458735331407 and mu_y: 0.10033375910236597\n",
      "1936, loss is 0.001971759865551848 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19918738417752418 and mu_y: 0.10023111533081969\n",
      "1937, loss is 0.0019715952274901908 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19911024754419201 and mu_y: 0.1001285473453835\n",
      "1938, loss is 0.001971430847006807 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19903317736695691 and mu_y: 0.10002605505832163\n",
      "1939, loss is 0.001971266723586939 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19895617355961498 and mu_y: 0.0999236383820552\n",
      "1940, loss is 0.001971102856717129 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19887923603611876 and mu_y: 0.09982129722916194\n",
      "1941, loss is 0.001970939245885217 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19880236471057683 and mu_y: 0.09971903151237575\n",
      "1942, loss is 0.001970775890580332 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19872555949725348 and mu_y: 0.0996168411445864\n",
      "1943, loss is 0.001970612790292897 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19864882031056838 and mu_y: 0.09951472603883911\n",
      "1944, loss is 0.001970449944514617 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19857214706509613 and mu_y: 0.09941268610833423\n",
      "1945, loss is 0.0019702873527384797 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19849553967556596 and mu_y: 0.09931072126642687\n",
      "1946, loss is 0.0019701250144587472 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19841899805686145 and mu_y: 0.09920883142662654\n",
      "1947, loss is 0.0019699629291709568 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19834252212402 and mu_y: 0.09910701650259675\n",
      "1948, loss is 0.0019698010963719145 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1982661117922327 and mu_y: 0.09900527640815474\n",
      "1949, loss is 0.0019696395155596935 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1981897669768437 and mu_y: 0.09890361105727104\n",
      "1950, loss is 0.0019694781862336264 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1981134875933502 and mu_y: 0.09880202036406917\n",
      "1951, loss is 0.0019693171078943054 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1980372735574018 and mu_y: 0.09870050424282524\n",
      "1952, loss is 0.001969156280043575 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1979611247848003 and mu_y: 0.09859906260796765\n",
      "1953, loss is 0.001968995702184529 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19788504119149933 and mu_y: 0.09849769537407667\n",
      "1954, loss is 0.0019688353738215136 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.197809022693604 and mu_y: 0.09839640245588414\n",
      "1955, loss is 0.001968675294460109 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19773306920737055 and mu_y: 0.09829518376827312\n",
      "1956, loss is 0.0019685154636071398 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.197657180649206 and mu_y: 0.09819403922627751\n",
      "1957, loss is 0.001968355880770666 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19758135693566783 and mu_y: 0.09809296874508171\n",
      "1958, loss is 0.001968196545459975 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19750559798346357 and mu_y: 0.09799197224002028\n",
      "1959, loss is 0.0019680374571855847 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19742990370945054 and mu_y: 0.0978910496265776\n",
      "1960, loss is 0.0019678786154592384 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19735427403063552 and mu_y: 0.09779020082038752\n",
      "1961, loss is 0.0019677200197938953 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19727870886417428 and mu_y: 0.09768942573723298\n",
      "1962, loss is 0.0019675616697037344 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1972032081273714 and mu_y: 0.09758872429304574\n",
      "1963, loss is 0.0019674035647041454 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19712777173767984 and mu_y: 0.09748809640390596\n",
      "1964, loss is 0.001967245704311729 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1970523996127006 and mu_y: 0.0973875419860419\n",
      "1965, loss is 0.0019670880880442907 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1969770916701824 and mu_y: 0.09728706095582955\n",
      "1966, loss is 0.0019669307154208376 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1969018478280214 and mu_y: 0.09718665322979235\n",
      "1967, loss is 0.0019667735859615755 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19682666800426077 and mu_y: 0.09708631872460079\n",
      "1968, loss is 0.001966616699187904 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19675155211709042 and mu_y: 0.09698605735707207\n",
      "1969, loss is 0.0019664600546224153 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19667650008484663 and mu_y: 0.0968858690441698\n",
      "1970, loss is 0.0019663036517888876 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19660151182601177 and mu_y: 0.09678575370300369\n",
      "1971, loss is 0.0019661474902122828 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1965265872592139 and mu_y: 0.09668571125082909\n",
      "1972, loss is 0.0019659915694187455 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19645172630322652 and mu_y: 0.0965857416050468\n",
      "1973, loss is 0.0019658358889355944 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19637692887696817 and mu_y: 0.09648584468320263\n",
      "1974, loss is 0.001965680448291323 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1963021948995021 and mu_y: 0.09638602040298716\n",
      "1975, loss is 0.001965525247015593 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.196227524290036 and mu_y: 0.0962862686822353\n",
      "1976, loss is 0.001965370284639233 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1961529169679217 and mu_y: 0.09618658943892608\n",
      "1977, loss is 0.0019652155606942365 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19607837285265467 and mu_y: 0.09608698259118219\n",
      "1978, loss is 0.0019650610747137523 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1960038918638739 and mu_y: 0.09598744805726978\n",
      "1979, loss is 0.001964906826232089 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19592947392136148 and mu_y: 0.09588798575559801\n",
      "1980, loss is 0.0019647528147847025 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19585511894504226 and mu_y: 0.09578859560471883\n",
      "1981, loss is 0.001964599039908202 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19578082685498358 and mu_y: 0.0956892775233266\n",
      "1982, loss is 0.0019644455011403415 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19570659757139489 and mu_y: 0.09559003143025774\n",
      "1983, loss is 0.0019642921980200143 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19563243101462752 and mu_y: 0.09549085724449045\n",
      "1984, loss is 0.001964139130087254 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19555832710517426 and mu_y: 0.09539175488514438\n",
      "1985, loss is 0.00196398629688323 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19548428576366908 and mu_y: 0.09529272427148029\n",
      "1986, loss is 0.001963833697950242 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19541030691088687 and mu_y: 0.09519376532289973\n",
      "1987, loss is 0.001963681332831719 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.195336390467743 and mu_y: 0.09509487795894474\n",
      "1988, loss is 0.0019635292010722147 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19526253635529314 and mu_y: 0.09499606209929748\n",
      "1989, loss is 0.001963377302217404 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19518874449473284 and mu_y: 0.09489731766377998\n",
      "1990, loss is 0.0019632256358140814 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19511501480739726 and mu_y: 0.09479864457235378\n",
      "1991, loss is 0.0019630742014101555 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19504134721476085 and mu_y: 0.09470004274511959\n",
      "1992, loss is 0.001962922998554646 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19496774163843705 and mu_y: 0.09460151210231704\n",
      "1993, loss is 0.0019627720267976806 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.194894198000178 and mu_y: 0.0945030525643243\n",
      "1994, loss is 0.001962621285690494 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19482071622187408 and mu_y: 0.09440466405165779\n",
      "1995, loss is 0.0019624707747854225 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19474729622555384 and mu_y: 0.09430634648497187\n",
      "1996, loss is 0.0019623204936358983 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19467393793338353 and mu_y: 0.09420809978505852\n",
      "1997, loss is 0.001962170441796452 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1946006412676668 and mu_y: 0.09410992387284704\n",
      "1998, loss is 0.0019620206188227032 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1945274061508444 and mu_y: 0.09401181866940371\n",
      "1999, loss is 0.0019618710242713623 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19445423250549398 and mu_y: 0.09391378409593149\n",
      "2000, loss is 0.001961721657700223 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19438112025432963 and mu_y: 0.09381582007376973\n",
      "2001, loss is 0.001961572518668165 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19430806932020167 and mu_y: 0.09371792652439387\n",
      "2002, loss is 0.001961423606735144 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1942350796260963 and mu_y: 0.09362010336941505\n",
      "2003, loss is 0.001961274921462191 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1941621510951353 and mu_y: 0.0935223505305799\n",
      "2004, loss is 0.001961126462411414 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19408928365057576 and mu_y: 0.0934246679297702\n",
      "2005, loss is 0.001960978229145984 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19401647721580978 and mu_y: 0.09332705548900253\n",
      "2006, loss is 0.0019608302212301442 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1939437317143641 and mu_y: 0.09322951313042803\n",
      "2007, loss is 0.001960682438229198 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1938710470698999 and mu_y: 0.09313204077633208\n",
      "2008, loss is 0.0019605348797095096 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19379842320621243 and mu_y: 0.09303463834913395\n",
      "2009, loss is 0.0019603875452384994 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1937258600472307 and mu_y: 0.09293730577138655\n",
      "2010, loss is 0.001960240434384643 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1936533575170172 and mu_y: 0.09284004296577611\n",
      "2011, loss is 0.0019600935467174656 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19358091553976772 and mu_y: 0.09274284985512188\n",
      "2012, loss is 0.0019599468818075386 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19350853403981083 and mu_y: 0.09264572636237582\n",
      "2013, loss is 0.0019598004392264827 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19343621294160773 and mu_y: 0.09254867241062233\n",
      "2014, loss is 0.0019596542185469534 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19336395216975197 and mu_y: 0.09245168792307788\n",
      "2015, loss is 0.00195950821934265 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19329175164896906 and mu_y: 0.09235477282309083\n",
      "2016, loss is 0.0019593624411883047 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19321961130411627 and mu_y: 0.09225792703414101\n",
      "2017, loss is 0.001959216883659681 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1931475310601823 and mu_y: 0.09216115047983951\n",
      "2018, loss is 0.001959071546333575 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1930755108422869 and mu_y: 0.09206444308392835\n",
      "2019, loss is 0.001958926428787804 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19300355057568083 and mu_y: 0.09196780477028016\n",
      "2020, loss is 0.0019587815306012133 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19293165018574523 and mu_y: 0.09187123546289797\n",
      "2021, loss is 0.0019586368513536657 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19285980959799162 and mu_y: 0.0917747350859148\n",
      "2022, loss is 0.0019584923906260424 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19278802873806145 and mu_y: 0.09167830356359348\n",
      "2023, loss is 0.001958348148000237 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19271630753172586 and mu_y: 0.09158194082032628\n",
      "2024, loss is 0.001958204123059156 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1926446459048854 and mu_y: 0.09148564678063464\n",
      "2025, loss is 0.001958060315386712 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1925730437835697 and mu_y: 0.09138942136916893\n",
      "2026, loss is 0.0019579167245678273 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19250150109393732 and mu_y: 0.09129326451070807\n",
      "2027, loss is 0.0019577733501884224 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19243001776227525 and mu_y: 0.09119717613015932\n",
      "2028, loss is 0.0019576301918354166 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1923585937149988 and mu_y: 0.09110115615255794\n",
      "2029, loss is 0.00195748724909673 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19228722887865127 and mu_y: 0.09100520450306694\n",
      "2030, loss is 0.0019573445215612735 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1922159231799036 and mu_y: 0.09090932110697679\n",
      "2031, loss is 0.0019572020088189476 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1921446765455542 and mu_y: 0.09081350588970509\n",
      "2032, loss is 0.0019570597104606427 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19207348890252857 and mu_y: 0.09071775877679635\n",
      "2033, loss is 0.0019569176260782334 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19200236017787908 and mu_y: 0.09062207969392165\n",
      "2034, loss is 0.001956775755264576 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19193129029878467 and mu_y: 0.09052646856687842\n",
      "2035, loss is 0.0019566340976135068 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19186027919255058 and mu_y: 0.09043092532159008\n",
      "2036, loss is 0.0019564926527198354 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19178932678660807 and mu_y: 0.09033544988410581\n",
      "2037, loss is 0.00195635142017935 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1917184330085141 and mu_y: 0.09024004218060028\n",
      "2038, loss is 0.001956210399588804 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19164759778595114 and mu_y: 0.09014470213737331\n",
      "2039, loss is 0.001956069590545923 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19157682104672683 and mu_y: 0.09004942968084967\n",
      "2040, loss is 0.001955928992649395 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19150610271877372 and mu_y: 0.0899542247375787\n",
      "2041, loss is 0.0019557886054988706 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19143544273014895 and mu_y: 0.08985908723423416\n",
      "2042, loss is 0.0019556484286949605 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19136484100903411 and mu_y: 0.08976401709761385\n",
      "2043, loss is 0.0019555084618392317 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1912942974837348 and mu_y: 0.08966901425463936\n",
      "2044, loss is 0.0019553687045342034 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1912238120826805 and mu_y: 0.08957407863235582\n",
      "2045, loss is 0.001955229156383348 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19115338473442417 and mu_y: 0.0894792101579316\n",
      "2046, loss is 0.001955089816991085 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1910830153676421 and mu_y: 0.08938440875865804\n",
      "2047, loss is 0.0019549506859627805 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19101270391113356 and mu_y: 0.08928967436194919\n",
      "2048, loss is 0.0019548117629047414 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19094245029382054 and mu_y: 0.08919500689534152\n",
      "2049, loss is 0.001954673047424216 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19087225444474754 and mu_y: 0.08910040628649366\n",
      "2050, loss is 0.001954534539129391 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1908021162930812 and mu_y: 0.08900587246318611\n",
      "2051, loss is 0.0019543962376293855 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19073203576811013 and mu_y: 0.08891140535332101\n",
      "2052, loss is 0.001954258142534251 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1906620127992446 and mu_y: 0.08881700488492182\n",
      "2053, loss is 0.001954120253454969 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1905920473160163 and mu_y: 0.08872267098613308\n",
      "2054, loss is 0.001953982570003447 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.190522139248078 and mu_y: 0.08862840358522014\n",
      "2055, loss is 0.0019538450917925172 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19045228852520338 and mu_y: 0.0885342026105689\n",
      "2056, loss is 0.001953707818435932 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1903824950772867 and mu_y: 0.08844006799068549\n",
      "2057, loss is 0.001953570749548361 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19031275883434254 and mu_y: 0.0883459996541961\n",
      "2058, loss is 0.0019534338847453938 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19024307972650562 and mu_y: 0.08825199752984661\n",
      "2059, loss is 0.001953297223643528 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19017345768403043 and mu_y: 0.08815806154650242\n",
      "2060, loss is 0.001953160765860176 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19010389263729105 and mu_y: 0.0880641916331481\n",
      "2061, loss is 0.001953024511013656 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.19003438451678084 and mu_y: 0.0879703877188872\n",
      "2062, loss is 0.001952888458723192 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18996493325311217 and mu_y: 0.08787664973294192\n",
      "2063, loss is 0.0019527526086089118 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18989553877701623 and mu_y: 0.08778297760465291\n",
      "2064, loss is 0.001952616960291842 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1898262010193427 and mu_y: 0.08768937126347898\n",
      "2065, loss is 0.0019524815133939058 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18975691991105953 and mu_y: 0.08759583063899681\n",
      "2066, loss is 0.0019523462675379245 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18968769538325267 and mu_y: 0.08750235566090075\n",
      "2067, loss is 0.001952211222347609 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18961852736712584 and mu_y: 0.08740894625900253\n",
      "2068, loss is 0.0019520763774475611 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1895494157940002 and mu_y: 0.08731560236323098\n",
      "2069, loss is 0.0019519417324632702 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18948036059531417 and mu_y: 0.08722232390363181\n",
      "2070, loss is 0.0019518072870211107 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1894113617026232 and mu_y: 0.08712911081036732\n",
      "2071, loss is 0.0019516730407483363 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1893424190475994 and mu_y: 0.08703596301371619\n",
      "2072, loss is 0.0019515389932730858 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1892735325620314 and mu_y: 0.08694288044407317\n",
      "2073, loss is 0.0019514051442243694 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.189204702177824 and mu_y: 0.08684986303194885\n",
      "2074, loss is 0.0019512714932320753 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18913592782699803 and mu_y: 0.0867569107079694\n",
      "2075, loss is 0.0019511380399269646 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18906720944169003 and mu_y: 0.08666402340287634\n",
      "2076, loss is 0.0019510047839406647 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18899854695415197 and mu_y: 0.08657120104752625\n",
      "2077, loss is 0.0019508717249056733 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1889299402967511 and mu_y: 0.08647844357289053\n",
      "2078, loss is 0.0019507388624553507 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18886138940196956 and mu_y: 0.08638575091005517\n",
      "2079, loss is 0.001950606196223921 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18879289420240428 and mu_y: 0.08629312299022046\n",
      "2080, loss is 0.0019504737258464657 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18872445463076665 and mu_y: 0.08620055974470078\n",
      "2081, loss is 0.0019503414509589264 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18865607061988227 and mu_y: 0.08610806110492432\n",
      "2082, loss is 0.001950209371198098 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18858774210269075 and mu_y: 0.08601562700243283\n",
      "2083, loss is 0.001950077486201629 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1885194690122454 and mu_y: 0.08592325736888139\n",
      "2084, loss is 0.0019499457956080155 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18845125128171303 and mu_y: 0.08583095213603817\n",
      "2085, loss is 0.0019498142990566028 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18838308884437371 and mu_y: 0.08573871123578414\n",
      "2086, loss is 0.0019496829961875828 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1883149816336205 and mu_y: 0.08564653460011286\n",
      "2087, loss is 0.0019495518866419878 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18824692958295922 and mu_y: 0.08555442216113024\n",
      "2088, loss is 0.0019494209700616906 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18817893262600818 and mu_y: 0.08546237385105425\n",
      "2089, loss is 0.001949290246089403 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.188110990696498 and mu_y: 0.08537038960221473\n",
      "2090, loss is 0.0019491597143686725 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18804310372827132 and mu_y: 0.08527846934705309\n",
      "2091, loss is 0.0019490293745438778 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18797527165528255 and mu_y: 0.08518661301812212\n",
      "2092, loss is 0.001948899226260231 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18790749441159765 and mu_y: 0.08509482054808572\n",
      "2093, loss is 0.001948769269163772 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18783977193139392 and mu_y: 0.08500309186971863\n",
      "2094, loss is 0.0019486395029013658 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18777210414895973 and mu_y: 0.08491142691590627\n",
      "2095, loss is 0.0019485099271207018 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18770449099869424 and mu_y: 0.08481982561964439\n",
      "2096, loss is 0.00194838054147029 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18763693241510726 and mu_y: 0.08472828791403894\n",
      "2097, loss is 0.0019482513455994627 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1875694283328189 and mu_y: 0.08463681373230575\n",
      "2098, loss is 0.0019481223391583646 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18750197868655943 and mu_y: 0.08454540300777032\n",
      "2099, loss is 0.001947993521797958 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.187434583411169 and mu_y: 0.08445405567386759\n",
      "2100, loss is 0.0019478648931700155 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18736724244159741 and mu_y: 0.08436277166414166\n",
      "2101, loss is 0.0019477364529271218 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18729995571290387 and mu_y: 0.08427155091224564\n",
      "2102, loss is 0.001947608200722667 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18723272316025674 and mu_y: 0.0841803933519413\n",
      "2103, loss is 0.001947480136210848 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18716554471893337 and mu_y: 0.08408929891709895\n",
      "2104, loss is 0.0019473522590466642 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18709842032431984 and mu_y: 0.08399826754169708\n",
      "2105, loss is 0.0019472245688859162 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18703134991191064 and mu_y: 0.08390729915982224\n",
      "2106, loss is 0.0019470970653852006 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1869643334173086 and mu_y: 0.08381639370566875\n",
      "2107, loss is 0.001946969748201915 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18689737077622445 and mu_y: 0.08372555111353845\n",
      "2108, loss is 0.0019468426169942468 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18683046192447686 and mu_y: 0.08363477131784051\n",
      "2109, loss is 0.0019467156714211772 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18676360679799192 and mu_y: 0.0835440542530912\n",
      "2110, loss is 0.001946588911142477 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18669680533280314 and mu_y: 0.08345339985391356\n",
      "2111, loss is 0.0019464623358187044 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18663005746505107 and mu_y: 0.08336280805503735\n",
      "2112, loss is 0.0019463359451112013 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18656336313098315 and mu_y: 0.08327227879129863\n",
      "2113, loss is 0.001946209738682093 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1864967222669535 and mu_y: 0.08318181199763965\n",
      "2114, loss is 0.001946083716194289 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1864301348094226 and mu_y: 0.08309140760910858\n",
      "2115, loss is 0.0019459578773114712 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1863636006949572 and mu_y: 0.08300106556085929\n",
      "2116, loss is 0.0019458322216981024 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1862971198602299 and mu_y: 0.0829107857881511\n",
      "2117, loss is 0.0019457067490194196 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18623069224201913 and mu_y: 0.0828205682263486\n",
      "2118, loss is 0.0019455814589414279 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1861643177772088 and mu_y: 0.08273041281092137\n",
      "2119, loss is 0.0019454563511309062 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18609799640278812 and mu_y: 0.08264031947744378\n",
      "2120, loss is 0.0019453314252554001 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18603172805585136 and mu_y: 0.08255028816159478\n",
      "2121, loss is 0.0019452066809832191 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18596551267359765 and mu_y: 0.08246031879915762\n",
      "2122, loss is 0.0019450821179834384 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1858993501933307 and mu_y: 0.08237041132601967\n",
      "2123, loss is 0.0019449577359258925 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18583324055245867 and mu_y: 0.08228056567817223\n",
      "2124, loss is 0.0019448335344811767 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18576718368849388 and mu_y: 0.0821907817917102\n",
      "2125, loss is 0.0019447095133206416 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18570117953905257 and mu_y: 0.08210105960283196\n",
      "2126, loss is 0.0019445856721163946 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18563522804185478 and mu_y: 0.08201139904783909\n",
      "2127, loss is 0.0019444620105412943 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18556932913472401 and mu_y: 0.08192180006313618\n",
      "2128, loss is 0.0019443385282689506 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18550348275558712 and mu_y: 0.08183226258523058\n",
      "2129, loss is 0.001944215224973722 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18543768884247397 and mu_y: 0.0817427865507322\n",
      "2130, loss is 0.0019440921003307137 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18537194733351733 and mu_y: 0.08165337189635326\n",
      "2131, loss is 0.0019439691540157743 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18530625816695265 and mu_y: 0.08156401855890814\n",
      "2132, loss is 0.0019438463857054972 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1852406212811177 and mu_y: 0.08147472647531309\n",
      "2133, loss is 0.0019437237950772114 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1851750366144526 and mu_y: 0.08138549558258602\n",
      "2134, loss is 0.0019436013818089895 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1851095041054993 and mu_y: 0.08129632581784633\n",
      "2135, loss is 0.0019434791455796377 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1850440236929017 and mu_y: 0.08120721711831463\n",
      "2136, loss is 0.0019433570860686957 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18497859531540517 and mu_y: 0.08111816942131257\n",
      "2137, loss is 0.0019432352029564368 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18491321891185641 and mu_y: 0.08102918266426261\n",
      "2138, loss is 0.001943113495923863 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18484789442120333 and mu_y: 0.0809402567846878\n",
      "2139, loss is 0.0019429919646527039 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18478262178249472 and mu_y: 0.08085139172021157\n",
      "2140, loss is 0.0019428706088254187 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18471740093488007 and mu_y: 0.08076258740855748\n",
      "2141, loss is 0.0019427494281251865 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1846522318176094 and mu_y: 0.08067384378754908\n",
      "2142, loss is 0.00194262842223591 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.184587114370033 and mu_y: 0.08058516079510965\n",
      "2143, loss is 0.0019425075908422117 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18452204853160126 and mu_y: 0.08049653836926196\n",
      "2144, loss is 0.0019423869336294315 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18445703424186438 and mu_y: 0.08040797644812812\n",
      "2145, loss is 0.0019422664502836261 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1843920714404723 and mu_y: 0.08031947496992933\n",
      "2146, loss is 0.0019421461404915683 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18432716006717434 and mu_y: 0.08023103387298568\n",
      "2147, loss is 0.0019420260039407378 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1842623000618191 and mu_y: 0.0801426530957159\n",
      "2148, loss is 0.001941906040319328 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18419749136435418 and mu_y: 0.08005433257663724\n",
      "2149, loss is 0.0019417862493162402 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.184132733914826 and mu_y: 0.07996607225436517\n",
      "2150, loss is 0.0019416666306210806 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18406802765337965 and mu_y: 0.07987787206761321\n",
      "2151, loss is 0.00194154718392416 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18400337252025858 and mu_y: 0.07978973195519272\n",
      "2152, loss is 0.0019414279089164932 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18393876845580445 and mu_y: 0.07970165185601269\n",
      "2153, loss is 0.0019413088052897915 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1838742154004569 and mu_y: 0.07961363170907954\n",
      "2154, loss is 0.0019411898727364689 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1838097132947534 and mu_y: 0.07952567145349687\n",
      "2155, loss is 0.0019410711109496333 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18374526207932898 and mu_y: 0.07943777102846535\n",
      "2156, loss is 0.0019409525196230886 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18368086169491604 and mu_y: 0.07934993037328239\n",
      "2157, loss is 0.001940834098451328 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18361651208234422 and mu_y: 0.07926214942734203\n",
      "2158, loss is 0.001940715847129539 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18355221318254009 and mu_y: 0.07917442813013469\n",
      "2159, loss is 0.001940597765353597 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18348796493652697 and mu_y: 0.07908676642124697\n",
      "2160, loss is 0.0019404798528200656 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18342376728542478 and mu_y: 0.07899916424036149\n",
      "2161, loss is 0.0019403621092261886 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18335962017044985 and mu_y: 0.0789116215272566\n",
      "2162, loss is 0.001940244534269899 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18329552353291462 and mu_y: 0.07882413822180626\n",
      "2163, loss is 0.0019401271276498066 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1832314773142275 and mu_y: 0.07873671426397978\n",
      "2164, loss is 0.0019400098890652033 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1831674814558927 and mu_y: 0.07864934959384166\n",
      "2165, loss is 0.0019398928182160578 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18310353589950998 and mu_y: 0.07856204415155138\n",
      "2166, loss is 0.0019397759148030139 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18303964058677447 and mu_y: 0.07847479787736315\n",
      "2167, loss is 0.00193965917852739 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18297579545947648 and mu_y: 0.0783876107116258\n",
      "2168, loss is 0.0019395426090911753 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1829120004595013 and mu_y: 0.07830048259478249\n",
      "2169, loss is 0.0019394262061970312 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18284825552882894 and mu_y: 0.07821341346737058\n",
      "2170, loss is 0.0019393099695482854 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18278456060953407 and mu_y: 0.07812640327002138\n",
      "2171, loss is 0.0019391938988489337 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18272091564378568 and mu_y: 0.07803945194345997\n",
      "2172, loss is 0.0019390779938036331 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18265732057384698 and mu_y: 0.07795255942850503\n",
      "2173, loss is 0.0019389622541177093 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18259377534207513 and mu_y: 0.07786572566606859\n",
      "2174, loss is 0.0019388466794971445 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18253027989092113 and mu_y: 0.07777895059715588\n",
      "2175, loss is 0.0019387312696485816 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18246683416292958 and mu_y: 0.07769223416286511\n",
      "2176, loss is 0.0019386160242793203 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18240343810073842 and mu_y: 0.07760557630438727\n",
      "2177, loss is 0.0019385009430973174 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18234009164707887 and mu_y: 0.07751897696300598\n",
      "2178, loss is 0.0019383860258111812 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18227679474477515 and mu_y: 0.07743243608009721\n",
      "2179, loss is 0.0019382712721301753 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1822135473367443 and mu_y: 0.07734595359712916\n",
      "2180, loss is 0.00193815668176421 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.182150349365996 and mu_y: 0.07725952945566203\n",
      "2181, loss is 0.001938042254423848 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18208720077563237 and mu_y: 0.07717316359734784\n",
      "2182, loss is 0.0019379279898202937 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18202410150884776 and mu_y: 0.07708685596393024\n",
      "2183, loss is 0.0019378138876654017 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18196105150892863 and mu_y: 0.0770006064972443\n",
      "2184, loss is 0.001937699947671667 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18189805071925327 and mu_y: 0.07691441513921635\n",
      "2185, loss is 0.0019375861695522254 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18183509908329165 and mu_y: 0.07682828183186374\n",
      "2186, loss is 0.0019374725530208565 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18177219654460525 and mu_y: 0.07674220651729471\n",
      "2187, loss is 0.0019373590977919727 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18170934304684683 and mu_y: 0.07665618913770815\n",
      "2188, loss is 0.001937245803580625 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18164653853376025 and mu_y: 0.07657022963539342\n",
      "2189, loss is 0.001937132670102501 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18158378294918037 and mu_y: 0.07648432795273018\n",
      "2190, loss is 0.001937019697073918 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1815210762370327 and mu_y: 0.07639848403218817\n",
      "2191, loss is 0.0019369068842118248 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18145841834133333 and mu_y: 0.07631269781632706\n",
      "2192, loss is 0.0019367942312338024 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18139580920618875 and mu_y: 0.07622696924779622\n",
      "2193, loss is 0.0019366817378580568 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1813332487757956 and mu_y: 0.07614129826933456\n",
      "2194, loss is 0.0019365694038034204 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18127073699444046 and mu_y: 0.07605568482377037\n",
      "2195, loss is 0.0019364572287893494 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18120827380649981 and mu_y: 0.07597012885402105\n",
      "2196, loss is 0.0019363452125359247 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18114585915643971 and mu_y: 0.07588463030309299\n",
      "2197, loss is 0.001936233354763847 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18108349298881565 and mu_y: 0.07579918911408139\n",
      "2198, loss is 0.0019361216551944348 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18102117524827235 and mu_y: 0.07571380523017002\n",
      "2199, loss is 0.0019360101135496265 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18095890587954366 and mu_y: 0.07562847859463108\n",
      "2200, loss is 0.001935898729551977 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1808966848274523 and mu_y: 0.07554320915082502\n",
      "2201, loss is 0.0019357875029246512 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18083451203690967 and mu_y: 0.07545799684220031\n",
      "2202, loss is 0.0019356764333914298 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18077238745291568 and mu_y: 0.07537284161229331\n",
      "2203, loss is 0.0019355655206767064 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18071031102055865 and mu_y: 0.07528774340472803\n",
      "2204, loss is 0.0019354547645054785 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18064828268501498 and mu_y: 0.07520270216321603\n",
      "2205, loss is 0.0019353441646033569 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18058630239154913 and mu_y: 0.07511771783155614\n",
      "2206, loss is 0.0019352337206965538 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18052437008551328 and mu_y: 0.07503279035363435\n",
      "2207, loss is 0.0019351234325118893 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1804624857123473 and mu_y: 0.0749479196734236\n",
      "2208, loss is 0.0019350132997767832 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18040064921757842 and mu_y: 0.07486310573498359\n",
      "2209, loss is 0.001934903322219259 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18033886054682122 and mu_y: 0.07477834848246065\n",
      "2210, loss is 0.0019347934995679397 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1802771196457773 and mu_y: 0.07469364786008749\n",
      "2211, loss is 0.0019346838315520433 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1802154264602352 and mu_y: 0.07460900381218306\n",
      "2212, loss is 0.0019345743179013876 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18015378093607015 and mu_y: 0.07452441628315239\n",
      "2213, loss is 0.0019344649583463826 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.18009218301924396 and mu_y: 0.07443988521748633\n",
      "2214, loss is 0.001934355752618033 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1800306326558048 and mu_y: 0.0743554105597615\n",
      "2215, loss is 0.0019342467004479355 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17996912979188706 and mu_y: 0.07427099225464\n",
      "2216, loss is 0.0019341378015682734 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17990767437371114 and mu_y: 0.07418663024686928\n",
      "2217, loss is 0.0019340290557118228 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17984626634758324 and mu_y: 0.07410232448128196\n",
      "2218, loss is 0.0019339204626119427 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1797849056598953 and mu_y: 0.07401807490279565\n",
      "2219, loss is 0.0019338120220025816 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1797235922571247 and mu_y: 0.07393388145641276\n",
      "2220, loss is 0.0019337037336182666 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17966232608583418 and mu_y: 0.07384974408722038\n",
      "2221, loss is 0.0019335955971941112 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17960110709267163 and mu_y: 0.07376566274039002\n",
      "2222, loss is 0.0019334876124658075 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1795399352243699 and mu_y: 0.07368163736117751\n",
      "2223, loss is 0.0019333797791696258 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1794788104277466 and mu_y: 0.07359766789492278\n",
      "2224, loss is 0.001933272097042416 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17941773264970406 and mu_y: 0.07351375428704969\n",
      "2225, loss is 0.0019331645658216027 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.179356701837229 and mu_y: 0.0734298964830659\n",
      "2226, loss is 0.001933057185245185 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1792957179373924 and mu_y: 0.07334609442856266\n",
      "2227, loss is 0.0019329499550517334 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17923478089734945 and mu_y: 0.07326234806921461\n",
      "2228, loss is 0.001932842874980393 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17917389066433922 and mu_y: 0.07317865735077968\n",
      "2229, loss is 0.001932735944770875 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17911304718568458 and mu_y: 0.07309502221909886\n",
      "2230, loss is 0.0019326291641634625 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17905225040879194 and mu_y: 0.07301144262009605\n",
      "2231, loss is 0.0019325225328990024 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17899150028115124 and mu_y: 0.07292791849977791\n",
      "2232, loss is 0.0019324160507189078 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1789307967503356 and mu_y: 0.07284444980423362\n",
      "2233, loss is 0.0019323097173651568 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17887013976400132 and mu_y: 0.0727610364796348\n",
      "2234, loss is 0.0019322035325802871 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17880952926988755 and mu_y: 0.07267767847223529\n",
      "2235, loss is 0.0019320974961074006 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17874896521581624 and mu_y: 0.07259437572837098\n",
      "2236, loss is 0.0019319916076901552 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1786884475496919 and mu_y: 0.07251112819445964\n",
      "2237, loss is 0.001931885867072769 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1786279762195015 and mu_y: 0.07242793581700079\n",
      "2238, loss is 0.0019317802740000142 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17856755117331427 and mu_y: 0.07234479854257547\n",
      "2239, loss is 0.001931674828217219 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1785071723592815 and mu_y: 0.07226171631784616\n",
      "2240, loss is 0.0019315695294702668 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17844683972563646 and mu_y: 0.07217868908955649\n",
      "2241, loss is 0.0019314643775055883 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1783865532206941 and mu_y: 0.0720957168045312\n",
      "2242, loss is 0.0019313593720701704 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17832631279285105 and mu_y: 0.07201279940967588\n",
      "2243, loss is 0.0019312545129115428 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1782661183905853 and mu_y: 0.07192993685197688\n",
      "2244, loss is 0.0019311497997777885 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17820596996245613 and mu_y: 0.07184712907850106\n",
      "2245, loss is 0.0019310452324175326 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17814586745710398 and mu_y: 0.07176437603639571\n",
      "2246, loss is 0.0019309408105799468 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17808581082325017 and mu_y: 0.07168167767288833\n",
      "2247, loss is 0.0019308365340147443 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1780258000096968 and mu_y: 0.07159903393528648\n",
      "2248, loss is 0.0019307324024721824 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1779658349653266 and mu_y: 0.07151644477097761\n",
      "2249, loss is 0.0019306284157030566 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17790591563910274 and mu_y: 0.07143391012742893\n",
      "2250, loss is 0.0019305245734587023 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17784604198006868 and mu_y: 0.07135142995218721\n",
      "2251, loss is 0.0019304208754909937 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17778621393734803 and mu_y: 0.07126900419287863\n",
      "2252, loss is 0.0019303173215523364 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17772643146014433 and mu_y: 0.07118663279720859\n",
      "2253, loss is 0.0019302139113956764 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17766669449774097 and mu_y: 0.07110431571296162\n",
      "2254, loss is 0.0019301106447744893 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17760700299950094 and mu_y: 0.07102205288800115\n",
      "2255, loss is 0.0019300075214427836 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17754735691486676 and mu_y: 0.07093984427026938\n",
      "2256, loss is 0.0019299045411550985 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17748775619336024 and mu_y: 0.0708576898077871\n",
      "2257, loss is 0.0019298017036665028 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17742820078458238 and mu_y: 0.07077558944865357\n",
      "2258, loss is 0.0019296990087325906 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17736869063821317 and mu_y: 0.07069354314104631\n",
      "2259, loss is 0.0019295964561094842 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1773092257040115 and mu_y: 0.07061155083322097\n",
      "2260, loss is 0.0019294940455538297 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17724980593181489 and mu_y: 0.07052961247351117\n",
      "2261, loss is 0.0019293917768227991 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1771904312715394 and mu_y: 0.07044772801032831\n",
      "2262, loss is 0.0019292896496740837 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17713110167317953 and mu_y: 0.07036589739216147\n",
      "2263, loss is 0.0019291876638658973 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17707181708680791 and mu_y: 0.0702841205675772\n",
      "2264, loss is 0.0019290858191569724 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1770125774625753 and mu_y: 0.07020239748521939\n",
      "2265, loss is 0.0019289841153065572 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17695338275071035 and mu_y: 0.0701207280938091\n",
      "2266, loss is 0.0019288825520744214 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17689423290151945 and mu_y: 0.07003911234214442\n",
      "2267, loss is 0.0019287811292208472 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1768351278653866 and mu_y: 0.0699575501791003\n",
      "2268, loss is 0.0019286798465066313 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17677606759277326 and mu_y: 0.06987604155362837\n",
      "2269, loss is 0.0019285787036930826 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17671705203421814 and mu_y: 0.06979458641475683\n",
      "2270, loss is 0.0019284777005420207 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1766580811403371 and mu_y: 0.06971318471159028\n",
      "2271, loss is 0.0019283768368157767 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17659915486182298 and mu_y: 0.06963183639330957\n",
      "2272, loss is 0.0019282761122771889 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17654027314944543 and mu_y: 0.0695505414091716\n",
      "2273, loss is 0.0019281755266896054 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1764814359540508 and mu_y: 0.06946929970850924\n",
      "2274, loss is 0.0019280750798168762 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17642264322656193 and mu_y: 0.0693881112407311\n",
      "2275, loss is 0.0019279747714233604 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17636389491797805 and mu_y: 0.06930697595532145\n",
      "2276, loss is 0.0019278746012739172 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1763051909793746 and mu_y: 0.06922589380184002\n",
      "2277, loss is 0.0019277745691339068 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17624653136190307 and mu_y: 0.06914486472992185\n",
      "2278, loss is 0.0019276746747691961 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17618791601679087 and mu_y: 0.06906388868927715\n",
      "2279, loss is 0.0019275749179461447 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17612934489534118 and mu_y: 0.06898296562969117\n",
      "2280, loss is 0.0019274752984316142 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17607081794893278 and mu_y: 0.06890209550102398\n",
      "2281, loss is 0.0019273758159929616 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17601233512901993 and mu_y: 0.0688212782532104\n",
      "2282, loss is 0.0019272764703980394 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17595389638713216 and mu_y: 0.06874051383625979\n",
      "2283, loss is 0.001927177261415195 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17589550167487417 and mu_y: 0.06865980220025593\n",
      "2284, loss is 0.001927078188813268 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1758371509439257 and mu_y: 0.06857914329535686\n",
      "2285, loss is 0.00192697925236159 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17577884414604136 and mu_y: 0.06849853707179475\n",
      "2286, loss is 0.0019268804518299838 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17572058123305043 and mu_y: 0.0684179834798757\n",
      "2287, loss is 0.0019267817869887598 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17566236215685677 and mu_y: 0.06833748246997964\n",
      "2288, loss is 0.0019266832576087173 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17560418686943866 and mu_y: 0.06825703399256018\n",
      "2289, loss is 0.0019265848634611405 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17554605532284867 and mu_y: 0.06817663799814441\n",
      "2290, loss is 0.001926486604317803 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17548796746921347 and mu_y: 0.06809629443733282\n",
      "2291, loss is 0.0019263884799509568 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17542992326073373 and mu_y: 0.06801600326079912\n",
      "2292, loss is 0.0019262904901333423 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17537192264968393 and mu_y: 0.06793576441929008\n",
      "2293, loss is 0.001926192634638177 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17531396558841225 and mu_y: 0.06785557786362541\n",
      "2294, loss is 0.0019260949132391602 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1752560520293404 and mu_y: 0.06777544354469758\n",
      "2295, loss is 0.0019259973257104725 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17519818192496345 and mu_y: 0.06769536141347174\n",
      "2296, loss is 0.0019258998718267681 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1751403552278498 and mu_y: 0.06761533142098547\n",
      "2297, loss is 0.0019258025513631827 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1750825718906409 and mu_y: 0.06753535351834875\n",
      "2298, loss is 0.0019257053640953225 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17502483186605114 and mu_y: 0.06745542765674371\n",
      "2299, loss is 0.0019256083097992703 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1749671351068678 and mu_y: 0.06737555378742459\n",
      "2300, loss is 0.0019255113882515828 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17490948156595074 and mu_y: 0.06729573186171749\n",
      "2301, loss is 0.0019254145992292876 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1748518711962324 and mu_y: 0.06721596183102028\n",
      "2302, loss is 0.0019253179425098813 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17479430395071763 and mu_y: 0.06713624364680248\n",
      "2303, loss is 0.00192522141787133 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17473677978248348 and mu_y: 0.06705657726060509\n",
      "2304, loss is 0.0019251250250920705 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1746792986446791 and mu_y: 0.0669769626240404\n",
      "2305, loss is 0.0019250287639510039 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17462186049052564 and mu_y: 0.06689739968879196\n",
      "2306, loss is 0.0019249326342274974 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17456446527331604 and mu_y: 0.06681788840661432\n",
      "2307, loss is 0.0019248366357013838 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1745071129464149 and mu_y: 0.06673842872933296\n",
      "2308, loss is 0.0019247407681529586 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17444980346325842 and mu_y: 0.06665902060884411\n",
      "2309, loss is 0.0019246450313629778 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17439253677735408 and mu_y: 0.06657966399711467\n",
      "2310, loss is 0.0019245494251126601 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17433531284228074 and mu_y: 0.06650035884618197\n",
      "2311, loss is 0.001924453949183684 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17427813161168831 and mu_y: 0.06642110510815372\n",
      "2312, loss is 0.0019243586033581858 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17422099303929767 and mu_y: 0.06634190273520782\n",
      "2313, loss is 0.0019242633874187588 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17416389707890056 and mu_y: 0.06626275167959225\n",
      "2314, loss is 0.0019241683011484523 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1741068436843594 and mu_y: 0.06618365189362492\n",
      "2315, loss is 0.001924073344330773 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17404983280960723 and mu_y: 0.06610460332969349\n",
      "2316, loss is 0.0019239785167496787 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1739928644086474 and mu_y: 0.0660256059402553\n",
      "2317, loss is 0.0019238838181895807 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1739359384355536 and mu_y: 0.0659466596778372\n",
      "2318, loss is 0.001923789248435343 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1738790548444697 and mu_y: 0.06586776449503536\n",
      "2319, loss is 0.0019236948072722773 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1738222135896095 and mu_y: 0.06578892034451525\n",
      "2320, loss is 0.0019236004944861475 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17376541462525677 and mu_y: 0.06571012717901141\n",
      "2321, loss is 0.0019235063098631622 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1737086579057649 and mu_y: 0.06563138495132732\n",
      "2322, loss is 0.0019234122531899816 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17365194338555698 and mu_y: 0.06555269361433531\n",
      "2323, loss is 0.001923318324253708 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17359527101912547 and mu_y: 0.06547405312097637\n",
      "2324, loss is 0.0019232245228418888 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17353864076103226 and mu_y: 0.06539546342426004\n",
      "2325, loss is 0.001923130848742516 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17348205256590832 and mu_y: 0.0653169244772643\n",
      "2326, loss is 0.001923037301744022 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17342550638845375 and mu_y: 0.06523843623313537\n",
      "2327, loss is 0.001922943881635284 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17336900218343756 and mu_y: 0.06515999864508763\n",
      "2328, loss is 0.001922850588205617 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17331253990569753 and mu_y: 0.06508161166640347\n",
      "2329, loss is 0.0019227574212447728 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17325611951014008 and mu_y: 0.06500327525043313\n",
      "2330, loss is 0.0019226643805429445 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17319974095174018 and mu_y: 0.06492498935059461\n",
      "2331, loss is 0.0019225714658907623 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17314340418554117 and mu_y: 0.06484675392037349\n",
      "2332, loss is 0.0019224786770792898 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17308710916665465 and mu_y: 0.06476856891332286\n",
      "2333, loss is 0.001922386013900025 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17303085585026032 and mu_y: 0.06469043428306309\n",
      "2334, loss is 0.0019222934761449016 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17297464419160588 and mu_y: 0.0646123499832818\n",
      "2335, loss is 0.001922201063606284 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1729184741460069 and mu_y: 0.06453431596773367\n",
      "2336, loss is 0.0019221087760769686 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17286234566884662 and mu_y: 0.06445633219024029\n",
      "2337, loss is 0.0019220166133501805 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17280625871557592 and mu_y: 0.06437839860469008\n",
      "2338, loss is 0.0019219245752195757 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17275021324171316 and mu_y: 0.06430051516503814\n",
      "2339, loss is 0.0019218326614792369 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17269420920284395 and mu_y: 0.06422268182530609\n",
      "2340, loss is 0.0019217408719236747 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17263824655462115 and mu_y: 0.06414489853958198\n",
      "2341, loss is 0.0019216492063478248 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1725823252527647 and mu_y: 0.06406716526202014\n",
      "2342, loss is 0.001921557664547048 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17252644525306143 and mu_y: 0.06398948194684104\n",
      "2343, loss is 0.0019214662463171283 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17247060651136503 and mu_y: 0.06391184854833117\n",
      "2344, loss is 0.0019213749514542715 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17241480898359582 and mu_y: 0.0638342650208429\n",
      "2345, loss is 0.0019212837797551085 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1723590526257407 and mu_y: 0.06375673131879438\n",
      "2346, loss is 0.0019211927310166853 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17230333739385298 and mu_y: 0.06367924739666939\n",
      "2347, loss is 0.001921101805036473 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17224766324405225 and mu_y: 0.06360181320901719\n",
      "2348, loss is 0.0019210110016123546 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1721920301325243 and mu_y: 0.06352442871045243\n",
      "2349, loss is 0.0019209203205426354 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1721364380155209 and mu_y: 0.063447093855655\n",
      "2350, loss is 0.0019208297616260374 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17208088684935977 and mu_y: 0.06336980859936991\n",
      "2351, loss is 0.0019207393246616924 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1720253765904244 and mu_y: 0.06329257289640715\n",
      "2352, loss is 0.001920649009449151 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17196990719516395 and mu_y: 0.06321538670164158\n",
      "2353, loss is 0.0019205588157883756 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17191447862009307 and mu_y: 0.06313824997001279\n",
      "2354, loss is 0.0019204687434797411 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17185909082179182 and mu_y: 0.06306116265652496\n",
      "2355, loss is 0.001920378792324032 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17180374375690555 and mu_y: 0.06298412471624679\n",
      "2356, loss is 0.0019202889621224434 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17174843738214474 and mu_y: 0.0629071361043113\n",
      "2357, loss is 0.0019201992526765804 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1716931716542849 and mu_y: 0.06283019677591574\n",
      "2358, loss is 0.001920109663788454 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17163794653016648 and mu_y: 0.06275330668632148\n",
      "2359, loss is 0.001920020195260483 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1715827619666946 and mu_y: 0.06267646579085386\n",
      "2360, loss is 0.0019199308468954939 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17152761792083912 and mu_y: 0.06259967404490205\n",
      "2361, loss is 0.0019198416184967146 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17147251434963437 and mu_y: 0.06252293140391897\n",
      "2362, loss is 0.0019197525098677793 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1714174512101791 and mu_y: 0.062446237823421145\n",
      "2363, loss is 0.0019196635208127244 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17136242845963634 and mu_y: 0.06236959325898856\n",
      "2364, loss is 0.0019195746511359868 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17130744605523326 and mu_y: 0.06229299766626457\n",
      "2365, loss is 0.0019194859006424077 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17125250395426106 and mu_y: 0.06221645100095574\n",
      "2366, loss is 0.0019193972691372227 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17119760211407484 and mu_y: 0.06213995321883177\n",
      "2367, loss is 0.0019193087564260726 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1711427404920935 and mu_y: 0.06206350427572532\n",
      "2368, loss is 0.0019192203623149887 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17108791904579956 and mu_y: 0.061987104127531924\n",
      "2369, loss is 0.001919132086610405 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17103313773273915 and mu_y: 0.06191075273020984\n",
      "2370, loss is 0.0019190439291191506 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17097839651052174 and mu_y: 0.06183445003977997\n",
      "2371, loss is 0.0019189558896484454 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17092369533682011 and mu_y: 0.061758196012325677\n",
      "2372, loss is 0.0019188679680059073 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17086903416937024 and mu_y: 0.06168199060399271\n",
      "2373, loss is 0.0019187801639995446 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17081441296597116 and mu_y: 0.06160583377098908\n",
      "2374, loss is 0.0019186924774377589 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1707598316844848 and mu_y: 0.06152972546958491\n",
      "2375, loss is 0.001918604908129342 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1707052902828359 and mu_y: 0.06145366565611235\n",
      "2376, loss is 0.0019185174558834757 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17065078871901193 and mu_y: 0.06137765428696543\n",
      "2377, loss is 0.0019184301205097307 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17059632695106292 and mu_y: 0.06130169131859994\n",
      "2378, loss is 0.0019183429018180644 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1705419049371013 and mu_y: 0.061225776707533326\n",
      "2379, loss is 0.001918255799618825 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1704875226353019 and mu_y: 0.06114991041034457\n",
      "2380, loss is 0.0019181688137227418 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17043318000390173 and mu_y: 0.06107409238367406\n",
      "2381, loss is 0.001918081943940933 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17037887700119989 and mu_y: 0.06099832258422346\n",
      "2382, loss is 0.0019179951900848992 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17032461358555745 and mu_y: 0.060922600968755625\n",
      "2383, loss is 0.0019179085519665233 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17027038971539735 and mu_y: 0.06084692749409445\n",
      "2384, loss is 0.0019178220293980725 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17021620534920426 and mu_y: 0.060771302117124774\n",
      "2385, loss is 0.001917735622192194 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17016206044552445 and mu_y: 0.060695724794792245\n",
      "2386, loss is 0.0019176493301619152 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17010795496296577 and mu_y: 0.06062019548410321\n",
      "2387, loss is 0.001917563153120644 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.17005388886019737 and mu_y: 0.06054471414212461\n",
      "2388, loss is 0.0019174770908821652 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1699998620959497 and mu_y: 0.06046928072598383\n",
      "2389, loss is 0.0019173911432606406 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16994587462901437 and mu_y: 0.06039389519286861\n",
      "2390, loss is 0.0019173053100706122 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16989192641824402 and mu_y: 0.06031855750002694\n",
      "2391, loss is 0.0019172195911269937 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1698380174225522 and mu_y: 0.060243267604766886\n",
      "2392, loss is 0.0019171339862450744 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1697841476009133 and mu_y: 0.06016802546445655\n",
      "2393, loss is 0.0019170484952405185 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16973031691236232 and mu_y: 0.06009283103652389\n",
      "2394, loss is 0.001916963117929362 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16967652531599492 and mu_y: 0.06001768427845664\n",
      "2395, loss is 0.0019168778541280135 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16962277277096718 and mu_y: 0.059942585147802194\n",
      "2396, loss is 0.001916792703653252 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1695690592364955 and mu_y: 0.05986753360216747\n",
      "2397, loss is 0.001916707666322226 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1695153846718566 and mu_y: 0.059792529599218804\n",
      "2398, loss is 0.0019166227419524545 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16946174903638717 and mu_y: 0.05971757309668185\n",
      "2399, loss is 0.0019165379303618252 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.169408152289484 and mu_y: 0.05964266405234146\n",
      "2400, loss is 0.0019164532313685908 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16935459439060374 and mu_y: 0.059567802424041555\n",
      "2401, loss is 0.0019163686447913714 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16930107529926283 and mu_y: 0.05949298816968501\n",
      "2402, loss is 0.001916284170449153 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16924759497503736 and mu_y: 0.05941822124723358\n",
      "2403, loss is 0.0019161998081612876 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16919415337756297 and mu_y: 0.05934350161470773\n",
      "2404, loss is 0.0019161155577474887 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1691407504665347 and mu_y: 0.059268829230186566\n",
      "2405, loss is 0.0019160314190278312 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16908738620170696 and mu_y: 0.05919420405180771\n",
      "2406, loss is 0.0019159473918227562 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16903406054289336 and mu_y: 0.05911962603776718\n",
      "2407, loss is 0.0019158634759530628 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16898077344996654 and mu_y: 0.059045095146319275\n",
      "2408, loss is 0.0019157796712399133 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16892752488285823 and mu_y: 0.058970611335776475\n",
      "2409, loss is 0.0019156959775048239 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16887431480155896 and mu_y: 0.05889617456450933\n",
      "2410, loss is 0.001915612394569674 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16882114316611807 and mu_y: 0.05882178479094634\n",
      "2411, loss is 0.0019155289222566978 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1687680099366435 and mu_y: 0.058747441973573844\n",
      "2412, loss is 0.0019154455603884886 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1687149150733018 and mu_y: 0.058673146070935926\n",
      "2413, loss is 0.0019153623087879925 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16866185853631788 and mu_y: 0.05859889704163427\n",
      "2414, loss is 0.0019152791672785137 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.168608840285975 and mu_y: 0.05852469484432809\n",
      "2415, loss is 0.0019151961356837083 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16855586028261466 and mu_y: 0.058450539437733984\n",
      "2416, loss is 0.0019151132138275836 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1685029184866364 and mu_y: 0.058376430780625856\n",
      "2417, loss is 0.0019150304015345039 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1684500148584978 and mu_y: 0.05830236883183478\n",
      "2418, loss is 0.0019149476986291814 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16839714935871433 and mu_y: 0.05822835355024891\n",
      "2419, loss is 0.00191486510493668 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1683443219478592 and mu_y: 0.05815438489481336\n",
      "2420, loss is 0.0019147826202824138 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1682915325865633 and mu_y: 0.05808046282453009\n",
      "2421, loss is 0.0019147002444921434 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16823878123551503 and mu_y: 0.05800658729845781\n",
      "2422, loss is 0.0019146179773919813 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16818606785546034 and mu_y: 0.057932758275711885\n",
      "2423, loss is 0.0019145358188083835 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16813339240720243 and mu_y: 0.057858975715464174\n",
      "2424, loss is 0.001914453768568154 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16808075485160176 and mu_y: 0.05778523957694299\n",
      "2425, loss is 0.0019143718264984415 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16802815514957592 and mu_y: 0.05771154981943293\n",
      "2426, loss is 0.0019142899924267393 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16797559326209954 and mu_y: 0.05763790640227483\n",
      "2427, loss is 0.0019142082661808872 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1679230691502041 and mu_y: 0.0575643092848656\n",
      "2428, loss is 0.0019141266475890622 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16787058277497796 and mu_y: 0.05749075842665814\n",
      "2429, loss is 0.001914045136479789 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1678181340975661 and mu_y: 0.05741725378716127\n",
      "2430, loss is 0.0019139637326819302 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16776572307917015 and mu_y: 0.05734379532593954\n",
      "2431, loss is 0.001913882436024689 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1677133496810482 and mu_y: 0.057270383002613216\n",
      "2432, loss is 0.001913801246337611 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16766101386451474 and mu_y: 0.0571970167768581\n",
      "2433, loss is 0.0019137201634505771 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16760871559094048 and mu_y: 0.05712369660840548\n",
      "2434, loss is 0.0019136391871938082 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16755645482175235 and mu_y: 0.057050422457041984\n",
      "2435, loss is 0.001913558317397861 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16750423151843336 and mu_y: 0.05697719428260949\n",
      "2436, loss is 0.00191347755389363 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16745204564252242 and mu_y: 0.056904012045005045\n",
      "2437, loss is 0.001913396896512343 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16739989715561432 and mu_y: 0.05683087570418071\n",
      "2438, loss is 0.0019133163450855651 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1673477860193596 and mu_y: 0.05675778522014349\n",
      "2439, loss is 0.0019132358994451927 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16729571219546446 and mu_y: 0.05668474055295524\n",
      "2440, loss is 0.0019131555594234574 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16724367564569062 and mu_y: 0.05661174166273253\n",
      "2441, loss is 0.0019130753248529214 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16719167633185525 and mu_y: 0.056538788509646554\n",
      "2442, loss is 0.0019129951955664795 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16713971421583085 and mu_y: 0.05646588105392303\n",
      "2443, loss is 0.0019129151713973558 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16708778925954515 and mu_y: 0.0563930192558421\n",
      "2444, loss is 0.0019128352521791052 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16703590142498104 and mu_y: 0.056320203075738214\n",
      "2445, loss is 0.0019127554377456114 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16698405067417638 and mu_y: 0.05624743247400004\n",
      "2446, loss is 0.001912675727931086 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16693223696922396 and mu_y: 0.056174707411070356\n",
      "2447, loss is 0.0019125961225700677 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16688046027227146 and mu_y: 0.056102027847445946\n",
      "2448, loss is 0.0019125166214974247 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1668287205455212 and mu_y: 0.0560293937436775\n",
      "2449, loss is 0.0019124372245483473 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16677701775123013 and mu_y: 0.05595680506036951\n",
      "2450, loss is 0.0019123579315583515 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16672535185170978 and mu_y: 0.05588426175818018\n",
      "2451, loss is 0.0019122787423632786 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.166673722809326 and mu_y: 0.05581176379782131\n",
      "2452, loss is 0.0019121996567992943 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.166622130586499 and mu_y: 0.05573931114005819\n",
      "2453, loss is 0.001912120674702885 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16657057514570323 and mu_y: 0.05566690374570952\n",
      "2454, loss is 0.00191204179591086 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1665190564494672 and mu_y: 0.055594541575647305\n",
      "2455, loss is 0.0019119630202603499 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1664675744603735 and mu_y: 0.05552222459079673\n",
      "2456, loss is 0.0019118843475888045 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16641612914105852 and mu_y: 0.0554499527521361\n",
      "2457, loss is 0.0019118057777339956 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16636472045421255 and mu_y: 0.055377726020696696\n",
      "2458, loss is 0.0019117273105340104 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16631334836257958 and mu_y: 0.05530554435756271\n",
      "2459, loss is 0.0019116489458272574 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16626201282895717 and mu_y: 0.05523340772387112\n",
      "2460, loss is 0.0019115706834524604 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16621071381619643 and mu_y: 0.05516131608081163\n",
      "2461, loss is 0.00191149252324866 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16615945128720186 and mu_y: 0.055089269389626515\n",
      "2462, loss is 0.001911414465055214 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1661082252049313 and mu_y: 0.05501726761161056\n",
      "2463, loss is 0.0019113365087117943 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16605703553239579 and mu_y: 0.05494531070811096\n",
      "2464, loss is 0.0019112586540583863 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16600588223265947 and mu_y: 0.05487339864052721\n",
      "2465, loss is 0.0019111809009352894 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16595476526883954 and mu_y: 0.05480153137031101\n",
      "2466, loss is 0.0019111032491831153 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1659036846041061 and mu_y: 0.05472970885896617\n",
      "2467, loss is 0.0019110256986427897 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16585264020168203 and mu_y: 0.054657931068048504\n",
      "2468, loss is 0.0019109482491555477 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16580163202484302 and mu_y: 0.05458619795916575\n",
      "2469, loss is 0.0019108709005629348 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16575066003691732 and mu_y: 0.05451450949397745\n",
      "2470, loss is 0.001910793652706807 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16569972420128573 and mu_y: 0.05444286563419488\n",
      "2471, loss is 0.0019107165054293297 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1656488244813815 and mu_y: 0.05437126634158091\n",
      "2472, loss is 0.001910639458572974 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16559796084069017 and mu_y: 0.054299711577949966\n",
      "2473, loss is 0.0019105625119805235 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16554713324274958 and mu_y: 0.05422820130516788\n",
      "2474, loss is 0.0019104856654950633 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16549634165114968 and mu_y: 0.05415673548515183\n",
      "2475, loss is 0.0019104089189599888 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1654455860295325 and mu_y: 0.05408531407987023\n",
      "2476, loss is 0.0019103322722189963 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16539486634159195 and mu_y: 0.05401393705134262\n",
      "2477, loss is 0.0019102557251160915 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1653441825510739 and mu_y: 0.0539426043616396\n",
      "2478, loss is 0.0019101792774955818 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16529353462177587 and mu_y: 0.05387131597288271\n",
      "2479, loss is 0.0019101029292020754 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16524292251754716 and mu_y: 0.05380007184724434\n",
      "2480, loss is 0.0019100266800804885 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16519234620228856 and mu_y: 0.053728871946947664\n",
      "2481, loss is 0.0019099505299760326 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16514180563995237 and mu_y: 0.053657716234266496\n",
      "2482, loss is 0.001909874478734225 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16509130079454223 and mu_y: 0.053586604671525234\n",
      "2483, loss is 0.001909798526200881 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16504083163011313 and mu_y: 0.05351553722109874\n",
      "2484, loss is 0.001909722672222117 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1649903981107712 and mu_y: 0.05344451384541227\n",
      "2485, loss is 0.0019096469166443465 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1649400002006737 and mu_y: 0.05337353450694136\n",
      "2486, loss is 0.0019095712593142828 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16488963786402888 and mu_y: 0.05330259916821174\n",
      "2487, loss is 0.0019094957000789338 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16483931106509592 and mu_y: 0.053231707791799254\n",
      "2488, loss is 0.0019094202387856083 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1647890197681848 and mu_y: 0.053160860340329734\n",
      "2489, loss is 0.0019093448752819083 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16473876393765624 and mu_y: 0.05309005677647895\n",
      "2490, loss is 0.0019092696094157315 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16468854353792156 and mu_y: 0.05301929706297246\n",
      "2491, loss is 0.0019091944410352703 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16463835853344266 and mu_y: 0.05294858116258559\n",
      "2492, loss is 0.0019091193699890111 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16458820888873188 and mu_y: 0.05287790903814328\n",
      "2493, loss is 0.0019090443961257346 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16453809456835186 and mu_y: 0.05280728065252002\n",
      "2494, loss is 0.0019089695192945112 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1644880155369156 and mu_y: 0.05273669596863976\n",
      "2495, loss is 0.0019088947393447063 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1644379717590862 and mu_y: 0.05266615494947579\n",
      "2496, loss is 0.0019088200561259744 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16438796319957685 and mu_y: 0.05259565755805069\n",
      "2497, loss is 0.0019087454694882624 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16433798982315073 and mu_y: 0.05252520375743622\n",
      "2498, loss is 0.0019086709792818044 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16428805159462095 and mu_y: 0.052454793510753196\n",
      "2499, loss is 0.001908596585357124 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16423814847885038 and mu_y: 0.05238442678117147\n",
      "2500, loss is 0.0019085222875650362 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1641882804407516 and mu_y: 0.05231410353190978\n",
      "2501, loss is 0.0019084480857566397 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16413844744528686 and mu_y: 0.052243823726235684\n",
      "2502, loss is 0.0019083739797833236 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1640886494574679 and mu_y: 0.05217358732746545\n",
      "2503, loss is 0.0019082999694967598 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16403888644235595 and mu_y: 0.052103394298964004\n",
      "2504, loss is 0.0019082260547489088 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16398915836506153 and mu_y: 0.052033244604144796\n",
      "2505, loss is 0.0019081522353920162 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16393946519074448 and mu_y: 0.051963138206469736\n",
      "2506, loss is 0.0019080785112786094 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16388980688461377 and mu_y: 0.0518930750694491\n",
      "2507, loss is 0.0019080048822615013 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1638401834119275 and mu_y: 0.05182305515664146\n",
      "2508, loss is 0.0019079313481937877 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16379059473799268 and mu_y: 0.051753078431653526\n",
      "2509, loss is 0.0019078579089288465 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16374104082816532 and mu_y: 0.051683144858140156\n",
      "2510, loss is 0.0019077845643203362 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16369152164785022 and mu_y: 0.05161325439980419\n",
      "2511, loss is 0.0019077113142221993 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16364203716250086 and mu_y: 0.05154340702039639\n",
      "2512, loss is 0.0019076381584886542 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16359258733761942 and mu_y: 0.05147360268371536\n",
      "2513, loss is 0.0019075650969742025 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16354317213875658 and mu_y: 0.05140384135360745\n",
      "2514, loss is 0.0019074921295336238 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16349379153151153 and mu_y: 0.05133412299396664\n",
      "2515, loss is 0.0019074192560219764 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1634444454815318 and mu_y: 0.05126444756873451\n",
      "2516, loss is 0.0019073464762945941 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16339513395451322 and mu_y: 0.0511948150419001\n",
      "2517, loss is 0.0019072737902070904 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1633458569161998 and mu_y: 0.051125225377499854\n",
      "2518, loss is 0.001907201197615355 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16329661433238368 and mu_y: 0.05105567853961752\n",
      "2519, loss is 0.0019071286983755504 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16324740616890507 and mu_y: 0.05098617449238405\n",
      "2520, loss is 0.0019070562923441195 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16319823239165202 and mu_y: 0.050916713199977565\n",
      "2521, loss is 0.001906983979377774 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1631490929665605 and mu_y: 0.05084729462662319\n",
      "2522, loss is 0.0019069117593335035 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1630999878596142 and mu_y: 0.050777918736593035\n",
      "2523, loss is 0.0019068396320685685 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16305091703684452 and mu_y: 0.05070858549420607\n",
      "2524, loss is 0.0019067675974405024 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16300188046433045 and mu_y: 0.050639294863828066\n",
      "2525, loss is 0.0019066956553071119 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1629528781081985 and mu_y: 0.05057004680987148\n",
      "2526, loss is 0.001906623805526473 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16290390993462256 and mu_y: 0.0505008412967954\n",
      "2527, loss is 0.0019065520479569342 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16285497590982387 and mu_y: 0.05043167828910542\n",
      "2528, loss is 0.0019064803824571123 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1628060760000709 and mu_y: 0.050362557751353614\n",
      "2529, loss is 0.001906408808885894 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16275721017167935 and mu_y: 0.050293479648138385\n",
      "2530, loss is 0.0019063373271024351 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1627083783910119 and mu_y: 0.05022444394410443\n",
      "2531, loss is 0.001906265936966159 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16265958062447833 and mu_y: 0.050155450603942615\n",
      "2532, loss is 0.0019061946383367584 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16261081683853523 and mu_y: 0.05008649959238994\n",
      "2533, loss is 0.0019061234310741903 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16256208699968605 and mu_y: 0.05001759087422941\n",
      "2534, loss is 0.001906052315038678 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.162513391074481 and mu_y: 0.04994872441428996\n",
      "2535, loss is 0.0019059812900907125 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16246472902951695 and mu_y: 0.0498799001774464\n",
      "2536, loss is 0.0019059103560910484 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1624161008314373 and mu_y: 0.04981111812861929\n",
      "2537, loss is 0.001905839512900706 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16236750644693193 and mu_y: 0.049742378232774886\n",
      "2538, loss is 0.0019057687603809667 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1623189458427372 and mu_y: 0.04967368045492505\n",
      "2539, loss is 0.0019056980983933772 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1622704189856357 and mu_y: 0.049605024760127146\n",
      "2540, loss is 0.0019056275267997466 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16222192584245634 and mu_y: 0.049536411113483995\n",
      "2541, loss is 0.0019055570454621445 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16217346638007413 and mu_y: 0.04946783948014376\n",
      "2542, loss is 0.0019054866542429034 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16212504056541013 and mu_y: 0.04939930982529987\n",
      "2543, loss is 0.0019054163530046171 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16207664836543145 and mu_y: 0.049330822114190966\n",
      "2544, loss is 0.0019053461416101366 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16202828974715106 and mu_y: 0.04926237631210077\n",
      "2545, loss is 0.0019052760199225734 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16197996467762776 and mu_y: 0.04919397238435804\n",
      "2546, loss is 0.0019052059878053016 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16193167312396614 and mu_y: 0.049125610296336476\n",
      "2547, loss is 0.001905136045121948 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16188341505331638 and mu_y: 0.04905729001345463\n",
      "2548, loss is 0.0019050661917364002 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16183519043287425 and mu_y: 0.04898901150117584\n",
      "2549, loss is 0.0019049964275128027 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16178699922988107 and mu_y: 0.04892077472500815\n",
      "2550, loss is 0.0019049267523155566 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1617388414116235 and mu_y: 0.048852579650504206\n",
      "2551, loss is 0.001904857166009318 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16169071694543358 and mu_y: 0.04878442624326119\n",
      "2552, loss is 0.001904787668458999 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16164262579868857 and mu_y: 0.04871631446892074\n",
      "2553, loss is 0.0019047182595297652 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16159456793881094 and mu_y: 0.04864824429316888\n",
      "2554, loss is 0.001904648939087038 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1615465433332682 and mu_y: 0.04858021568173591\n",
      "2555, loss is 0.001904579706996493 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16149855194957294 and mu_y: 0.04851222860039635\n",
      "2556, loss is 0.0019045105631240562 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1614505937552826 and mu_y: 0.04844428301496886\n",
      "2557, loss is 0.0019044415073359063 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1614026687179995 and mu_y: 0.04837637889131614\n",
      "2558, loss is 0.0019043725394984766 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16135477680537072 and mu_y: 0.04830851619534487\n",
      "2559, loss is 0.0019043036594784493 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16130691798508806 and mu_y: 0.048240694893005615\n",
      "2560, loss is 0.0019042348671427563 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1612590922248879 and mu_y: 0.04817291495029277\n",
      "2561, loss is 0.0019041661623585828 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16121129949255114 and mu_y: 0.04810517633324446\n",
      "2562, loss is 0.0019040975449933603 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16116353975590317 and mu_y: 0.048037479007942446\n",
      "2563, loss is 0.001904029014914771 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1611158129828137 and mu_y: 0.047969822940512094\n",
      "2564, loss is 0.0019039605719907446 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16106811914119676 and mu_y: 0.04790220809712225\n",
      "2565, loss is 0.0019038922160894594 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1610204581990106 and mu_y: 0.04783463444398518\n",
      "2566, loss is 0.00190382394707934 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16097283012425756 and mu_y: 0.047767101947356505\n",
      "2567, loss is 0.0019037557648290584 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1609252348849841 and mu_y: 0.04769961057353509\n",
      "2568, loss is 0.0019036876692075323 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16087767244928058 and mu_y: 0.047632160288862996\n",
      "2569, loss is 0.0019036196600839238 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16083014278528132 and mu_y: 0.04756475105972539\n",
      "2570, loss is 0.0019035517373276422 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16078264586116445 and mu_y: 0.04749738285255046\n",
      "2571, loss is 0.00190348390080834 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1607351816451518 and mu_y: 0.04743005563380935\n",
      "2572, loss is 0.0019034161503959119 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16068775010550893 and mu_y: 0.047362769370016086\n",
      "2573, loss is 0.0019033484859604993 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1606403512105449 and mu_y: 0.047295524027727485\n",
      "2574, loss is 0.001903280907372483 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16059298492861238 and mu_y: 0.04722831957354308\n",
      "2575, loss is 0.001903213414502488 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1605456512281074 and mu_y: 0.04716115597410505\n",
      "2576, loss is 0.0019031460072213794 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16049835007746938 and mu_y: 0.047094033196098145\n",
      "2577, loss is 0.0019030786854002644 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16045108144518097 and mu_y: 0.0470269512062496\n",
      "2578, loss is 0.0019030114489104915 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1604038452997681 and mu_y: 0.04695990997132905\n",
      "2579, loss is 0.0019029442976236457 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16035664160979976 and mu_y: 0.046892909458148495\n",
      "2580, loss is 0.0019028772314115565 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.160309470343888 and mu_y: 0.046825949633562174\n",
      "2581, loss is 0.0019028102501462856 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16026233147068789 and mu_y: 0.04675903046446652\n",
      "2582, loss is 0.0019027433537001398 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1602152249588973 and mu_y: 0.04669215191780008\n",
      "2583, loss is 0.0019026765419456605 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16016815077725705 and mu_y: 0.046625313960543424\n",
      "2584, loss is 0.001902609814755624 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16012110889455056 and mu_y: 0.046558516559719085\n",
      "2585, loss is 0.0019025431720030468 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.16007409927960403 and mu_y: 0.04649175968239148\n",
      "2586, loss is 0.0019024766135611808 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1600271219012862 and mu_y: 0.04642504329566683\n",
      "2587, loss is 0.001902410139303513 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15998017672850837 and mu_y: 0.046358367366693104\n",
      "2588, loss is 0.0019023437491037646 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15993326373022423 and mu_y: 0.04629173186265992\n",
      "2589, loss is 0.0019022774428358927 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15988638287542986 and mu_y: 0.046225136750798465\n",
      "2590, loss is 0.0019022112203740864 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15983953413316365 and mu_y: 0.046158581998381465\n",
      "2591, loss is 0.0019021450815927717 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1597927174725062 and mu_y: 0.04609206757272306\n",
      "2592, loss is 0.001902079026366603 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15974593286258024 and mu_y: 0.04602559344117875\n",
      "2593, loss is 0.0019020130545704711 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15969918027255056 and mu_y: 0.045959159571145346\n",
      "2594, loss is 0.0019019471660794958 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15965245967162398 and mu_y: 0.04589276593006085\n",
      "2595, loss is 0.0019018813607690308 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15960577102904921 and mu_y: 0.04582641248540441\n",
      "2596, loss is 0.0019018156385146572 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15955911431411687 and mu_y: 0.04576009920469624\n",
      "2597, loss is 0.001901749999192191 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15951248949615926 and mu_y: 0.04569382605549755\n",
      "2598, loss is 0.001901684442677672 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15946589654455046 and mu_y: 0.04562759300541048\n",
      "2599, loss is 0.0019016189688473753 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15941933542870612 and mu_y: 0.045561400022077994\n",
      "2600, loss is 0.0019015535775777997 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15937280611808347 and mu_y: 0.04549524707318385\n",
      "2601, loss is 0.0019014882687456748 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15932630858218122 and mu_y: 0.0454291341264525\n",
      "2602, loss is 0.0019014230422279579 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1592798427905395 and mu_y: 0.04536306114964902\n",
      "2603, loss is 0.0019013578979018328 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15923340871273975 and mu_y: 0.04529702811057905\n",
      "2604, loss is 0.0019012928356447103 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1591870063184047 and mu_y: 0.04523103497708872\n",
      "2605, loss is 0.0019012278553342263 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15914063557719826 and mu_y: 0.04516508171706456\n",
      "2606, loss is 0.001901162956848243 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15909429645882542 and mu_y: 0.04509916829843346\n",
      "2607, loss is 0.0019010981400648488 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15904798893303226 and mu_y: 0.04503329468916256\n",
      "2608, loss is 0.0019010334048623545 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15900171296960586 and mu_y: 0.04496746085725921\n",
      "2609, loss is 0.0019009687511192966 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1589554685383741 and mu_y: 0.04490166677077087\n",
      "2610, loss is 0.001900904178714434 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15890925560920582 and mu_y: 0.044835912397785074\n",
      "2611, loss is 0.0019008396875267511 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1588630741520105 and mu_y: 0.04477019770642933\n",
      "2612, loss is 0.0019007752774354506 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1588169241367384 and mu_y: 0.04470452266487106\n",
      "2613, loss is 0.0019007109483199624 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1587708055333803 and mu_y: 0.044638887241317524\n",
      "2614, loss is 0.0019006467000599332 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15872471831196763 and mu_y: 0.044573291404015766\n",
      "2615, loss is 0.001900582532535233 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15867866244257223 and mu_y: 0.04450773512125252\n",
      "2616, loss is 0.0019005184456259542 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15863263789530635 and mu_y: 0.04444221836135416\n",
      "2617, loss is 0.001900454439212405 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1585866446403226 and mu_y: 0.04437674109268661\n",
      "2618, loss is 0.0019003905131751157 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15854068264781382 and mu_y: 0.0443113032836553\n",
      "2619, loss is 0.0019003266673948377 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15849475188801304 and mu_y: 0.044245904902705045\n",
      "2620, loss is 0.001900262901752536 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15844885233119346 and mu_y: 0.04418054591832006\n",
      "2621, loss is 0.0019001992161293971 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15840298394766827 and mu_y: 0.044115226299023806\n",
      "2622, loss is 0.0019001356104068256 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15835714670779066 and mu_y: 0.04404994601337897\n",
      "2623, loss is 0.0019000720844664395 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15831134058195376 and mu_y: 0.04398470502998738\n",
      "2624, loss is 0.0019000086381900792 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1582655655405905 and mu_y: 0.043919503317489936\n",
      "2625, loss is 0.0018999452714597953 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15821982155417366 and mu_y: 0.04385434084456654\n",
      "2626, loss is 0.0018998819841578576 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15817410859321562 and mu_y: 0.043789217579936035\n",
      "2627, loss is 0.0018998187761667506 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15812842662826845 and mu_y: 0.043724133492356126\n",
      "2628, loss is 0.001899755647369172 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1580827756299238 and mu_y: 0.04365908855062332\n",
      "2629, loss is 0.0018996925976480358 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15803715556881276 and mu_y: 0.04359408272357286\n",
      "2630, loss is 0.0018996296268864676 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1579915664156059 and mu_y: 0.043529115980078636\n",
      "2631, loss is 0.001899566734967807 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15794600814101314 and mu_y: 0.04346418828905314\n",
      "2632, loss is 0.0018995039217756088 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1579004807157837 and mu_y: 0.04339929961944739\n",
      "2633, loss is 0.001899441187193637 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15785498411070595 and mu_y: 0.04333444994025086\n",
      "2634, loss is 0.0018993785311058667 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15780951829660753 and mu_y: 0.043269639220491415\n",
      "2635, loss is 0.001899315953396487 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15776408324435506 and mu_y: 0.043204867429235246\n",
      "2636, loss is 0.0018992534539498986 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15771867892485425 and mu_y: 0.043140134535586794\n",
      "2637, loss is 0.0018991910326507083 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15767330530904972 and mu_y: 0.043075440508688695\n",
      "2638, loss is 0.0018991286893837367 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15762796236792498 and mu_y: 0.0430107853177217\n",
      "2639, loss is 0.0018990664240340121 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15758265007250238 and mu_y: 0.04294616893190461\n",
      "2640, loss is 0.0018990042364867728 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15753736839384302 and mu_y: 0.042881591320494225\n",
      "2641, loss is 0.001898942126627464 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15749211730304663 and mu_y: 0.04281705245278526\n",
      "2642, loss is 0.0018988800943417405 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1574468967712516 and mu_y: 0.042752552298110286\n",
      "2643, loss is 0.0018988181395154648 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15740170676963486 and mu_y: 0.04268809082583965\n",
      "2644, loss is 0.0018987562620347055 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1573565472694118 and mu_y: 0.042623668005381435\n",
      "2645, loss is 0.001898694461785737 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15731141824183625 and mu_y: 0.042559283806181375\n",
      "2646, loss is 0.0018986327386550433 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15726631965820037 and mu_y: 0.04249493819772279\n",
      "2647, loss is 0.0018985710925293118 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15722125148983462 and mu_y: 0.04243063114952654\n",
      "2648, loss is 0.001898509523295434 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15717621370810766 and mu_y: 0.042366362631150914\n",
      "2649, loss is 0.0018984480308405086 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15713120628442628 and mu_y: 0.042302132612191616\n",
      "2650, loss is 0.0018983866150518375 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1570862291902354 and mu_y: 0.042237941062281674\n",
      "2651, loss is 0.001898325275816927 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15704128239701792 and mu_y: 0.04217378795109137\n",
      "2652, loss is 0.0018982640130234861 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1569963658762947 and mu_y: 0.042109673248328185\n",
      "2653, loss is 0.0018982028265594293 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15695147959962452 and mu_y: 0.04204559692373673\n",
      "2654, loss is 0.0018981417163128683 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1569066235386039 and mu_y: 0.0419815589470987\n",
      "2655, loss is 0.001898080682172124 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15686179766486721 and mu_y: 0.04191755928823277\n",
      "2656, loss is 0.0018980197240257128 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15681700195008647 and mu_y: 0.04185359791699456\n",
      "2657, loss is 0.0018979588417623557 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1567722363659713 and mu_y: 0.04178967480327657\n",
      "2658, loss is 0.0018978980352709735 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1567275008842689 and mu_y: 0.0417257899170081\n",
      "2659, loss is 0.0018978373044406878 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15668279547676398 and mu_y: 0.0416619432281552\n",
      "2660, loss is 0.0018977766491608203 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15663812011527867 and mu_y: 0.0415981347067206\n",
      "2661, loss is 0.0018977160693208902 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15659347477167246 and mu_y: 0.04153436432274364\n",
      "2662, loss is 0.0018976555648106187 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15654885941784216 and mu_y: 0.04147063204630023\n",
      "2663, loss is 0.0018975951355199227 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1565042740257218 and mu_y: 0.04140693784750275\n",
      "2664, loss is 0.001897534781338919 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15645971856728264 and mu_y: 0.04134328169650003\n",
      "2665, loss is 0.0018974745021579224 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15641519301453294 and mu_y: 0.041279663563477224\n",
      "2666, loss is 0.001897414297867443 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15637069733951808 and mu_y: 0.041216083418655826\n",
      "2667, loss is 0.001897354168358188 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15632623151432046 and mu_y: 0.041152541232293546\n",
      "2668, loss is 0.0018972941135210648 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15628179551105933 and mu_y: 0.04108903697468427\n",
      "2669, loss is 0.001897234133247172 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15623738930189082 and mu_y: 0.041025570616158004\n",
      "2670, loss is 0.001897174227427806 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15619301285900786 and mu_y: 0.04096214212708079\n",
      "2671, loss is 0.0018971143959544568 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1561486661546401 and mu_y: 0.040898751477854656\n",
      "2672, loss is 0.0018970546387188122 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15610434916105387 and mu_y: 0.04083539863891756\n",
      "2673, loss is 0.00189699495561275 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1560600618505521 and mu_y: 0.04077208358074332\n",
      "2674, loss is 0.001896935346528345 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15601580419547426 and mu_y: 0.04070880627384155\n",
      "2675, loss is 0.0018968758113578638 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1559715761681963 and mu_y: 0.040645566688757594\n",
      "2676, loss is 0.001896816349993767 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15592737774113058 and mu_y: 0.04058236479607249\n",
      "2677, loss is 0.0018967569623287066 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15588320888672583 and mu_y: 0.04051920056640287\n",
      "2678, loss is 0.0018966976482555284 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15583906957746704 and mu_y: 0.04045607397040093\n",
      "2679, loss is 0.0018966384076672673 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1557949597858755 and mu_y: 0.04039298497875435\n",
      "2680, loss is 0.001896579240457152 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15575087948450855 and mu_y: 0.04032993356218623\n",
      "2681, loss is 0.0018965201465186011 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15570682864595978 and mu_y: 0.040266919691455065\n",
      "2682, loss is 0.0018964611257452234 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15566280724285872 and mu_y: 0.04020394333735462\n",
      "2683, loss is 0.0018964021780308155 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1556188152478709 and mu_y: 0.040141004470713934\n",
      "2684, loss is 0.0018963433032693695 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15557485263369783 and mu_y: 0.040078103062397216\n",
      "2685, loss is 0.0018962845013550612 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1555309193730768 and mu_y: 0.04001523908330381\n",
      "2686, loss is 0.0018962257721822566 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15548701543878096 and mu_y: 0.03995241250436811\n",
      "2687, loss is 0.0018961671156455108 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15544314080361918 and mu_y: 0.03988962329655952\n",
      "2688, loss is 0.001896108531639567 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15539929544043599 and mu_y: 0.039826871430882385\n",
      "2689, loss is 0.0018960500200593563 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15535547932211155 and mu_y: 0.03976415687837593\n",
      "2690, loss is 0.0018959915807999935 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1553116924215616 and mu_y: 0.03970147961011421\n",
      "2691, loss is 0.0018959332137567849 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15526793471173733 and mu_y: 0.03963883959720603\n",
      "2692, loss is 0.0018958749188252193 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1552242061656254 and mu_y: 0.03957623681079491\n",
      "2693, loss is 0.0018958166959009738 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15518050675624784 and mu_y: 0.03951367122205901\n",
      "2694, loss is 0.0018957585448799098 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15513683645666196 and mu_y: 0.03945114280221106\n",
      "2695, loss is 0.0018957004656580743 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15509319523996037 and mu_y: 0.03938865152249834\n",
      "2696, loss is 0.0018956424581316976 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1550495830792709 and mu_y: 0.03932619735420256\n",
      "2697, loss is 0.0018955845221971977 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15500599994775638 and mu_y: 0.039263780268639865\n",
      "2698, loss is 0.0018955266577511717 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15496244581861487 and mu_y: 0.039201400237160726\n",
      "2699, loss is 0.0018954688646904043 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1549189206650794 and mu_y: 0.03913905723114992\n",
      "2700, loss is 0.00189541114291186 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15487542446041788 and mu_y: 0.039076751222026425\n",
      "2701, loss is 0.0018953534923126902 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15483195717793322 and mu_y: 0.03901448218124342\n",
      "2702, loss is 0.0018952959127902236 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15478851879096311 and mu_y: 0.03895225008028817\n",
      "2703, loss is 0.001895238404241974 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15474510927288004 and mu_y: 0.038890054890682015\n",
      "2704, loss is 0.001895180966565636 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15470172859709122 and mu_y: 0.03882789658398027\n",
      "2705, loss is 0.001895123599659083 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1546583767370385 and mu_y: 0.038765775131772186\n",
      "2706, loss is 0.0018950663034203743 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15461505366619835 and mu_y: 0.038703690505680906\n",
      "2707, loss is 0.0018950090777477453 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1545717593580818 and mu_y: 0.038641642677363384\n",
      "2708, loss is 0.001894951922539612 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15452849378623432 and mu_y: 0.038579631618510336\n",
      "2709, loss is 0.0018948948376945702 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15448525692423584 and mu_y: 0.038517657300846185\n",
      "2710, loss is 0.0018948378231113943 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15444204874570067 and mu_y: 0.038455719696129\n",
      "2711, loss is 0.0018947808786890397 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1543988692242774 and mu_y: 0.038393818776150446\n",
      "2712, loss is 0.0018947240043266373 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15435571833364886 and mu_y: 0.0383319545127357\n",
      "2713, loss is 0.0018946671999234973 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15431259604753214 and mu_y: 0.038270126877743435\n",
      "2714, loss is 0.001894610465379108 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1542695023396784 and mu_y: 0.03820833584306573\n",
      "2715, loss is 0.0018945538005931332 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1542264371838729 and mu_y: 0.03814658138062803\n",
      "2716, loss is 0.0018944972054654157 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15418340055393498 and mu_y: 0.038084863462389075\n",
      "2717, loss is 0.0018944406798959731 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15414039242371785 and mu_y: 0.03802318206034086\n",
      "2718, loss is 0.001894384223784999 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15409741276710867 and mu_y: 0.037961537146508566\n",
      "2719, loss is 0.0018943278370328644 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15405446155802846 and mu_y: 0.037899928692950516\n",
      "2720, loss is 0.0018942715195401137 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15401153877043203 and mu_y: 0.0378383566717581\n",
      "2721, loss is 0.0018942152712074656 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1539686443783079 and mu_y: 0.037776821055055726\n",
      "2722, loss is 0.001894159091935817 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1539257783556783 and mu_y: 0.037715321815000785\n",
      "2723, loss is 0.001894102981626235 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15388294067659908 and mu_y: 0.03765385892378356\n",
      "2724, loss is 0.0018940469401799622 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1538401313151596 and mu_y: 0.03759243235362719\n",
      "2725, loss is 0.0018939909674984153 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15379735024548286 and mu_y: 0.03753104207678762\n",
      "2726, loss is 0.0018939350634831825 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15375459744172515 and mu_y: 0.037469688065553515\n",
      "2727, loss is 0.0018938792280360243 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15371187287807628 and mu_y: 0.03740837029224625\n",
      "2728, loss is 0.0018938234610588775 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15366917652875936 and mu_y: 0.03734708872921982\n",
      "2729, loss is 0.0018937677624538448 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15362650836803077 and mu_y: 0.03728584334886078\n",
      "2730, loss is 0.0018937121321232057 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15358386837018012 and mu_y: 0.037224634123588236\n",
      "2731, loss is 0.001893656569969407 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15354125650953024 and mu_y: 0.03716346102585373\n",
      "2732, loss is 0.0018936010758950684 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.153498672760437 and mu_y: 0.03710232402814123\n",
      "2733, loss is 0.0018935456498029803 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1534561170972894 and mu_y: 0.03704122310296705\n",
      "2734, loss is 0.0018934902915961017 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15341358949450942 and mu_y: 0.036980158222879804\n",
      "2735, loss is 0.0018934350011775626 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.153371089926552 and mu_y: 0.03691912936046036\n",
      "2736, loss is 0.0018933797784506604 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15332861836790493 and mu_y: 0.03685813648832176\n",
      "2737, loss is 0.0018933246233188666 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15328617479308893 and mu_y: 0.0367971795791092\n",
      "2738, loss is 0.001893269535685813 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15324375917665742 and mu_y: 0.03673625860549994\n",
      "2739, loss is 0.0018932145154553063 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1532013714931966 and mu_y: 0.03667537354020329\n",
      "2740, loss is 0.0018931595625313207 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15315901171732532 and mu_y: 0.0366145243559605\n",
      "2741, loss is 0.0018931046768179934 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1531166798236951 and mu_y: 0.03655371102554477\n",
      "2742, loss is 0.001893049858219633 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15307437578698993 and mu_y: 0.03649293352176115\n",
      "2743, loss is 0.0018929951066407145 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15303209958192643 and mu_y: 0.03643219181744651\n",
      "2744, loss is 0.0018929404219858773 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1529898511832536 and mu_y: 0.036371485885469464\n",
      "2745, loss is 0.0018928858041599276 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15294763056575283 and mu_y: 0.03631081569873035\n",
      "2746, loss is 0.0018928312530678395 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15290543770423795 and mu_y: 0.03625018123016114\n",
      "2747, loss is 0.0018927767686147498 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.152863272573555 and mu_y: 0.03618958245272541\n",
      "2748, loss is 0.0018927223507059611 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1528211351485823 and mu_y: 0.03612901933941828\n",
      "2749, loss is 0.001892667999246941 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15277902540423038 and mu_y: 0.036068491863266355\n",
      "2750, loss is 0.001892613714143322 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15273694331544183 and mu_y: 0.03600799999732769\n",
      "2751, loss is 0.0018925594953008997 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15269488885719137 and mu_y: 0.03594754371469172\n",
      "2752, loss is 0.0018925053426256336 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1526528620044858 and mu_y: 0.03588712298847921\n",
      "2753, loss is 0.0018924512560236464 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1526108627323638 and mu_y: 0.0358267377918422\n",
      "2754, loss is 0.0018923972354012233 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.152568891015896 and mu_y: 0.035766388097963966\n",
      "2755, loss is 0.0018923432806648138 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1525269468301849 and mu_y: 0.03570607388005896\n",
      "2756, loss is 0.001892289391721027 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15248503015036485 and mu_y: 0.03564579511137275\n",
      "2757, loss is 0.0018922355684766366 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15244314095160194 and mu_y: 0.03558555176518198\n",
      "2758, loss is 0.0018921818108385763 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15240127920909394 and mu_y: 0.0355253438147943\n",
      "2759, loss is 0.0018921281187139418 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1523594448980703 and mu_y: 0.03546517123354834\n",
      "2760, loss is 0.0018920744920099878 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15231763799379208 and mu_y: 0.03540503399481363\n",
      "2761, loss is 0.001892020930634131 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15227585847155187 and mu_y: 0.035344932071990576\n",
      "2762, loss is 0.0018919674344939517 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15223410630667378 and mu_y: 0.03528486543851039\n",
      "2763, loss is 0.0018919140034971817 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1521923814745134 and mu_y: 0.03522483406783505\n",
      "2764, loss is 0.0018918606375517197 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1521506839504576 and mu_y: 0.03516483793345721\n",
      "2765, loss is 0.0018918073365656208 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15210901370992475 and mu_y: 0.03510487700890022\n",
      "2766, loss is 0.0018917541004471001 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15206737072836435 and mu_y: 0.03504495126771801\n",
      "2767, loss is 0.0018917009291045282 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15202575498125726 and mu_y: 0.03498506068349507\n",
      "2768, loss is 0.0018916478224464371 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15198416644411544 and mu_y: 0.0349252052298464\n",
      "2769, loss is 0.0018915947803815158 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15194260509248206 and mu_y: 0.03486538488041743\n",
      "2770, loss is 0.0018915418028186105 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15190107090193133 and mu_y: 0.03480559960888402\n",
      "2771, loss is 0.001891488889666723 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1518595638480685 and mu_y: 0.03474584938895235\n",
      "2772, loss is 0.0018914360408350147 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15181808390652984 and mu_y: 0.034686134194358925\n",
      "2773, loss is 0.0018913832562328023 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15177663105298247 and mu_y: 0.03462645399887049\n",
      "2774, loss is 0.0018913305357695582 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15173520526312442 and mu_y: 0.03456680877628397\n",
      "2775, loss is 0.0018912778793549103 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15169380651268458 and mu_y: 0.03450719850042647\n",
      "2776, loss is 0.0018912252868986447 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1516524347774226 and mu_y: 0.034447623145155155\n",
      "2777, loss is 0.0018911727583106987 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15161109003312884 and mu_y: 0.03438808268435727\n",
      "2778, loss is 0.0018911202935011668 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15156977225562432 and mu_y: 0.03432857709195005\n",
      "2779, loss is 0.001891067892380298 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15152848142076072 and mu_y: 0.03426910634188066\n",
      "2780, loss is 0.001891015554858495 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15148721750442032 and mu_y: 0.03420967040812618\n",
      "2781, loss is 0.001890963280846315 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15144598048251584 and mu_y: 0.034150269264693535\n",
      "2782, loss is 0.0018909110702544677 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1514047703309905 and mu_y: 0.03409090288561944\n",
      "2783, loss is 0.0018908589229938164 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.151363587025818 and mu_y: 0.03403157124497036\n",
      "2784, loss is 0.0018908068389753788 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15132243054300237 and mu_y: 0.03397227431684247\n",
      "2785, loss is 0.0018907548181103222 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15128130085857794 and mu_y: 0.03391301207536159\n",
      "2786, loss is 0.0018907028603099682 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15124019794860935 and mu_y: 0.03385378449468313\n",
      "2787, loss is 0.0018906509654857892 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15119912178919143 and mu_y: 0.033794591548992066\n",
      "2788, loss is 0.0018905991335494113 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1511580723564492 and mu_y: 0.03373543321250287\n",
      "2789, loss is 0.0018905473644126108 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15111704962653785 and mu_y: 0.033676309459459465\n",
      "2790, loss is 0.001890495657987313 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15107605357564255 and mu_y: 0.03361722026413518\n",
      "2791, loss is 0.001890444014185597 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15103508417997855 and mu_y: 0.033558165600832704\n",
      "2792, loss is 0.00189039243291969 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15099414141579107 and mu_y: 0.03349914544388403\n",
      "2793, loss is 0.00189034091410197 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15095322525935526 and mu_y: 0.033440159767650406\n",
      "2794, loss is 0.0018902894576449652 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15091233568697612 and mu_y: 0.0333812085465223\n",
      "2795, loss is 0.0018902380634613523 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15087147267498852 and mu_y: 0.03332229175491934\n",
      "2796, loss is 0.0018901867314639574 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15083063619975706 and mu_y: 0.033263409367290254\n",
      "2797, loss is 0.001890135461565756 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15078982623767612 and mu_y: 0.03320456135811285\n",
      "2798, loss is 0.0018900842536798716 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1507490427651697 and mu_y: 0.033145747701893956\n",
      "2799, loss is 0.0018900331077195754 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1507082857586915 and mu_y: 0.03308696837316936\n",
      "2800, loss is 0.001889982023598288 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15066755519472474 and mu_y: 0.033028223346503766\n",
      "2801, loss is 0.0018899310012295738 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15062685104978224 and mu_y: 0.032969512596490766\n",
      "2802, loss is 0.0018898800405271494 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15058617330040625 and mu_y: 0.03291083609775278\n",
      "2803, loss is 0.0018898291414048748 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15054552192316847 and mu_y: 0.032852193824940985\n",
      "2804, loss is 0.001889778303776758 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15050489689467003 and mu_y: 0.03279358575273532\n",
      "2805, loss is 0.0018897275275569529 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15046429819154136 and mu_y: 0.03273501185584438\n",
      "2806, loss is 0.0018896768126597597 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1504237257904422 and mu_y: 0.03267647210900542\n",
      "2807, loss is 0.001889626158999623 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1503831796680615 and mu_y: 0.03261796648698427\n",
      "2808, loss is 0.0018895755664911367 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15034265980111747 and mu_y: 0.0325594949645753\n",
      "2809, loss is 0.001889525035049034 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15030216616635744 and mu_y: 0.032501057516601393\n",
      "2810, loss is 0.0018894745645881967 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15026169874055784 and mu_y: 0.03244265411791386\n",
      "2811, loss is 0.0018894241550236515 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15022125750052415 and mu_y: 0.03238428474339242\n",
      "2812, loss is 0.0018893738062705668 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15018084242309088 and mu_y: 0.03232594936794516\n",
      "2813, loss is 0.0018893235182442564 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1501404534851215 and mu_y: 0.03226764796650846\n",
      "2814, loss is 0.0018892732908601766 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15010009066350838 and mu_y: 0.03220938051404697\n",
      "2815, loss is 0.0018892231240339283 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15005975393517273 and mu_y: 0.03215114698555355\n",
      "2816, loss is 0.0018891730176812554 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.15001944327706465 and mu_y: 0.032092947356049235\n",
      "2817, loss is 0.0018891229717180437 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14997915866616296 and mu_y: 0.032034781600583186\n",
      "2818, loss is 0.0018890729860603214 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14993890007947522 and mu_y: 0.031976649694232626\n",
      "2819, loss is 0.0018890230606242585 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14989866749403766 and mu_y: 0.03191855161210282\n",
      "2820, loss is 0.0018889731953261684 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14985846088691512 and mu_y: 0.03186048732932703\n",
      "2821, loss is 0.001888923390082504 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1498182802352011 and mu_y: 0.03180245682106643\n",
      "2822, loss is 0.00188887364480986 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14977812551601757 and mu_y: 0.0317444600625101\n",
      "2823, loss is 0.0018888239594249726 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14973799670651503 and mu_y: 0.03168649702887498\n",
      "2824, loss is 0.0018887743338447192 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14969789378387238 and mu_y: 0.03162856769540579\n",
      "2825, loss is 0.0018887247679861166 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.149657816725297 and mu_y: 0.03157067203737503\n",
      "2826, loss is 0.0018886752617663202 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14961776550802453 and mu_y: 0.03151281003008289\n",
      "2827, loss is 0.0018886258151026274 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14957774010931899 and mu_y: 0.03145498164885724\n",
      "2828, loss is 0.0018885764279124755 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14953774050647262 and mu_y: 0.03139718686905356\n",
      "2829, loss is 0.0018885271001134387 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1494977666768059 and mu_y: 0.03133942566605491\n",
      "2830, loss is 0.0018884778316232303 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14945781859766746 and mu_y: 0.031281698015271885\n",
      "2831, loss is 0.0018884286223597047 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14941789624643412 and mu_y: 0.031224003892142565\n",
      "2832, loss is 0.0018883794722408527 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14937799960051068 and mu_y: 0.03116634327213247\n",
      "2833, loss is 0.0018883303811848028 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14933812863733 and mu_y: 0.031108716130734508\n",
      "2834, loss is 0.001888281349109822 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.149298283334353 and mu_y: 0.03105112244346895\n",
      "2835, loss is 0.0018882323759343155 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14925846366906845 and mu_y: 0.030993562185883367\n",
      "2836, loss is 0.001888183461576823 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14921866961899308 and mu_y: 0.030936035333552592\n",
      "2837, loss is 0.0018881346059560248 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14917890116167143 and mu_y: 0.03087854186207868\n",
      "2838, loss is 0.0018880858089907347 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1491391582746759 and mu_y: 0.03082108174709086\n",
      "2839, loss is 0.0018880370705999035 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1490994409356066 and mu_y: 0.030763654964245487\n",
      "2840, loss is 0.0018879883907026215 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14905974912209138 and mu_y: 0.030706261489226002\n",
      "2841, loss is 0.0018879397692181089 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14902008281178578 and mu_y: 0.03064890129774289\n",
      "2842, loss is 0.001887891206065724 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1489804419823729 and mu_y: 0.030591574365533628\n",
      "2843, loss is 0.0018878427011649631 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14894082661156352 and mu_y: 0.03053428066836265\n",
      "2844, loss is 0.001887794254435452 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1489012366770959 and mu_y: 0.0304770201820213\n",
      "2845, loss is 0.0018877458657969575 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1488616721567358 and mu_y: 0.030419792882327792\n",
      "2846, loss is 0.0018876975351693752 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1488221330282764 and mu_y: 0.030362598745127152\n",
      "2847, loss is 0.001887649262472736 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14878261926953837 and mu_y: 0.030305437746291193\n",
      "2848, loss is 0.0018876010476272086 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14874313085836968 and mu_y: 0.03024830986171846\n",
      "2849, loss is 0.00188755289055309 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14870366777264563 and mu_y: 0.030191215067334198\n",
      "2850, loss is 0.0018875047911708128 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1486642299902688 and mu_y: 0.030134153339090287\n",
      "2851, loss is 0.0018874567494009437 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14862481748916898 and mu_y: 0.030077124652965224\n",
      "2852, loss is 0.0018874087651641793 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14858543024730317 and mu_y: 0.030020128984964062\n",
      "2853, loss is 0.001887360838381352 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14854606824265548 and mu_y: 0.029963166311118377\n",
      "2854, loss is 0.001887312968973424 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14850673145323717 and mu_y: 0.029906236607486224\n",
      "2855, loss is 0.0018872651568614901 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1484674198570865 and mu_y: 0.029849339850152087\n",
      "2856, loss is 0.0018872174019667765 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1484281334322688 and mu_y: 0.029792476015226842\n",
      "2857, loss is 0.0018871697042106407 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1483888721568763 and mu_y: 0.029735645078847718\n",
      "2858, loss is 0.0018871220635145727 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14834963600902817 and mu_y: 0.029678847017178246\n",
      "2859, loss is 0.0018870744798001912 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14831042496687052 and mu_y: 0.029622081806408223\n",
      "2860, loss is 0.001887026952989247 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14827123900857625 and mu_y: 0.029565349422753663\n",
      "2861, loss is 0.0018869794830036204 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14823207811234504 and mu_y: 0.029508649842456762\n",
      "2862, loss is 0.0018869320697653229 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14819294225640336 and mu_y: 0.029451983041785854\n",
      "2863, loss is 0.0018868847131964937 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14815383141900437 and mu_y: 0.029395348997035362\n",
      "2864, loss is 0.0018868374132194037 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1481147455784279 and mu_y: 0.02933874768452577\n",
      "2865, loss is 0.0018867901697564521 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1480756847129804 and mu_y: 0.029282179080603567\n",
      "2866, loss is 0.0018867429827301658 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14803664880099493 and mu_y: 0.029225643161641206\n",
      "2867, loss is 0.0018866958520632041 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14799763782083103 and mu_y: 0.029169139904037078\n",
      "2868, loss is 0.0018866487776783496 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14795865175087478 and mu_y: 0.029112669284215447\n",
      "2869, loss is 0.0018866017594985165 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1479196905695387 and mu_y: 0.02905623127862643\n",
      "2870, loss is 0.0018865547974467474 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14788075425526168 and mu_y: 0.028999825863745943\n",
      "2871, loss is 0.0018865078914462115 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14784184278650908 and mu_y: 0.02894345301607566\n",
      "2872, loss is 0.0018864610414202037 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1478029561417725 and mu_y: 0.028887112712142973\n",
      "2873, loss is 0.0018864142472921489 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14776409429956985 and mu_y: 0.028830804928500958\n",
      "2874, loss is 0.0018863675089855968 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1477252572384453 and mu_y: 0.028774529641728323\n",
      "2875, loss is 0.0018863208264242259 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14768644493696917 and mu_y: 0.02871828682842937\n",
      "2876, loss is 0.0018862741995318384 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.147647657373738 and mu_y: 0.028662076465233957\n",
      "2877, loss is 0.0018862276282323653 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14760889452737444 and mu_y: 0.02860589852879746\n",
      "2878, loss is 0.0018861811124498602 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14757015637652715 and mu_y: 0.028549752995800717\n",
      "2879, loss is 0.0018861346521085063 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1475314428998709 and mu_y: 0.028493639842950006\n",
      "2880, loss is 0.0018860882471326086 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14749275407610643 and mu_y: 0.028437559046976993\n",
      "2881, loss is 0.0018860418974466012 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1474540898839604 and mu_y: 0.028381510584638697\n",
      "2882, loss is 0.0018859956029750374 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1474154503021854 and mu_y: 0.02832549443271744\n",
      "2883, loss is 0.0018859493636425992 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1473768353095599 and mu_y: 0.02826951056802082\n",
      "2884, loss is 0.0018859031793740932 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14733824488488814 and mu_y: 0.028213558967381657\n",
      "2885, loss is 0.0018858570500944476 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14729967900700025 and mu_y: 0.028157639607657967\n",
      "2886, loss is 0.0018858109757287174 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14726113765475204 and mu_y: 0.02810175246573291\n",
      "2887, loss is 0.0018857649562020779 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.147222620807025 and mu_y: 0.028045897518514756\n",
      "2888, loss is 0.0018857189914398289 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14718412844272635 and mu_y: 0.027990074742936834\n",
      "2889, loss is 0.001885673081367395 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14714566054078887 and mu_y: 0.02793428411595751\n",
      "2890, loss is 0.0018856272259103227 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14710721708017094 and mu_y: 0.027878525614560144\n",
      "2891, loss is 0.0018855814249942788 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1470687980398565 and mu_y: 0.027822799215753025\n",
      "2892, loss is 0.001885535678545057 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14703040339885498 and mu_y: 0.027767104896569368\n",
      "2893, loss is 0.001885489986488568 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14699203313620127 and mu_y: 0.027711442634067246\n",
      "2894, loss is 0.0018854443487508487 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14695368723095564 and mu_y: 0.027655812405329567\n",
      "2895, loss is 0.0018853987652580552 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1469153656622038 and mu_y: 0.027600214187464025\n",
      "2896, loss is 0.0018853532359364654 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1468770684090568 and mu_y: 0.027544647957603065\n",
      "2897, loss is 0.0018853077607124775 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1468387954506509 and mu_y: 0.02748911369290384\n",
      "2898, loss is 0.0018852623395126129 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14680054676614773 and mu_y: 0.02743361137054818\n",
      "2899, loss is 0.0018852169722635124 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14676232233473407 and mu_y: 0.02737814096774254\n",
      "2900, loss is 0.001885171658891936 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1467241221356219 and mu_y: 0.027322702461717977\n",
      "2901, loss is 0.001885126399324765 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1466859461480483 and mu_y: 0.02726729582973009\n",
      "2902, loss is 0.0018850811934890007 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14664779435127553 and mu_y: 0.027211921049059003\n",
      "2903, loss is 0.0018850360413117633 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14660966672459086 and mu_y: 0.02715657809700931\n",
      "2904, loss is 0.0018849909427202944 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14657156324730655 and mu_y: 0.027101266950910047\n",
      "2905, loss is 0.001884945897641952 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1465334838987599 and mu_y: 0.027045987588114644\n",
      "2906, loss is 0.001884900906004215 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1464954286583131 and mu_y: 0.026990739986000892\n",
      "2907, loss is 0.0018848559677346792 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14645739750535328 and mu_y: 0.0269355241219709\n",
      "2908, loss is 0.0018848110827610616 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1464193904192924 and mu_y: 0.026880339973451066\n",
      "2909, loss is 0.0018847662510111944 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14638140737956726 and mu_y: 0.026825187517892025\n",
      "2910, loss is 0.00188472147241303 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14634344836563942 and mu_y: 0.026770066732768622\n",
      "2911, loss is 0.0018846767468946373 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14630551335699524 and mu_y: 0.026714977595579868\n",
      "2912, loss is 0.0018846320743842048 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14626760233314573 and mu_y: 0.026659920083848904\n",
      "2913, loss is 0.0018845874548100348 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14622971527362658 and mu_y: 0.026604894175122958\n",
      "2914, loss is 0.0018845428881005487 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1461918521579981 and mu_y: 0.026549899846973316\n",
      "2915, loss is 0.001884498374184285 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1461540129658452 and mu_y: 0.026494937076995274\n",
      "2916, loss is 0.0018844539129898984 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14611619767677736 and mu_y: 0.02644000584280811\n",
      "2917, loss is 0.0018844095044461598 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1460784062704285 and mu_y: 0.026385106122055038\n",
      "2918, loss is 0.0018843651484819568 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14604063872645712 and mu_y: 0.02633023789240317\n",
      "2919, loss is 0.001884320845026291 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14600289502454605 and mu_y: 0.026275401131543488\n",
      "2920, loss is 0.0018842765940082816 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14596517514440258 and mu_y: 0.026220595817190794\n",
      "2921, loss is 0.0018842323953571622 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14592747906575831 and mu_y: 0.026165821927083683\n",
      "2922, loss is 0.0018841882490022834 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1458898067683692 and mu_y: 0.026111079438984497\n",
      "2923, loss is 0.0018841441548731082 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1458521582320155 and mu_y: 0.026056368330679293\n",
      "2924, loss is 0.001884100112899216 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14581453343650164 and mu_y: 0.026001688579977804\n",
      "2925, loss is 0.0018840561230103001 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1457769323616563 and mu_y: 0.0259470401647134\n",
      "2926, loss is 0.0018840121851361666 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1457393549873323 and mu_y: 0.02589242306274306\n",
      "2927, loss is 0.0018839682992067397 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1457018012934066 and mu_y: 0.025837837251947313\n",
      "2928, loss is 0.001883924465152054 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1456642712597803 and mu_y: 0.02578328271023023\n",
      "2929, loss is 0.0018838806829022576 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14562676486637846 and mu_y: 0.025728759415519362\n",
      "2930, loss is 0.001883836952387613 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14558928209315022 and mu_y: 0.025674267345765722\n",
      "2931, loss is 0.0018837932735384978 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14555182292006869 and mu_y: 0.025619806478943734\n",
      "2932, loss is 0.0018837496462853977 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1455143873271309 and mu_y: 0.025565376793051202\n",
      "2933, loss is 0.0018837060705589167 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14547697529435777 and mu_y: 0.025510978266109274\n",
      "2934, loss is 0.0018836625462897664 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1454395868017941 and mu_y: 0.025456610876162404\n",
      "2935, loss is 0.0018836190734087736 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14540222182950857 and mu_y: 0.02540227460127832\n",
      "2936, loss is 0.0018835756518468761 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14536488035759357 and mu_y: 0.02534796941954798\n",
      "2937, loss is 0.0018835322815351227 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14532756236616526 and mu_y: 0.025293695309085536\n",
      "2938, loss is 0.0018834889624046764 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14529026783536353 and mu_y: 0.02523945224802831\n",
      "2939, loss is 0.0018834456943868086 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14525299674535197 and mu_y: 0.025185240214536733\n",
      "2940, loss is 0.001883402477412904 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14521574907631776 and mu_y: 0.025131059186794345\n",
      "2941, loss is 0.001883359311414456 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14517852480847174 and mu_y: 0.025076909143007718\n",
      "2942, loss is 0.0018833161963230708 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14514132392204826 and mu_y: 0.025022790061406456\n",
      "2943, loss is 0.0018832731320704641 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14510414639730523 and mu_y: 0.024968701920243135\n",
      "2944, loss is 0.0018832301185884625 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1450669922145241 and mu_y: 0.024914644697793274\n",
      "2945, loss is 0.001883187155809001 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1450298613540097 and mu_y: 0.024860618372355307\n",
      "2946, loss is 0.0018831442436641266 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14499275379609028 and mu_y: 0.024806622922250537\n",
      "2947, loss is 0.001883101382085994 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14495566952111755 and mu_y: 0.0247526583258231\n",
      "2948, loss is 0.0018830585710068685 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1449186085094665 and mu_y: 0.02469872456143994\n",
      "2949, loss is 0.0018830158103591253 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1448815707415355 and mu_y: 0.024644821607490763\n",
      "2950, loss is 0.0018829731000752456 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14484455619774608 and mu_y: 0.024590949442388006\n",
      "2951, loss is 0.0018829304400878226 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14480756485854313 and mu_y: 0.0245371080445668\n",
      "2952, loss is 0.0018828878303295566 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14477059670439466 and mu_y: 0.024483297392484938\n",
      "2953, loss is 0.001882845270733255 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1447336517157919 and mu_y: 0.024429517464622835\n",
      "2954, loss is 0.0018828027612318356 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14469672987324916 and mu_y: 0.024375768239483495\n",
      "2955, loss is 0.001882760301758323 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14465983115730394 and mu_y: 0.024322049695592478\n",
      "2956, loss is 0.0018827178922458478 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14462295554851665 and mu_y: 0.02426836181149786\n",
      "2957, loss is 0.0018826755326276524 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14458610302747085 and mu_y: 0.0242147045657702\n",
      "2958, loss is 0.0018826332228370824 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14454927357477304 and mu_y: 0.024161077937002513\n",
      "2959, loss is 0.001882590962807592 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14451246717105265 and mu_y: 0.024107481903810218\n",
      "2960, loss is 0.0018825487524727418 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14447568379696205 and mu_y: 0.024053916444831118\n",
      "2961, loss is 0.0018825065917661991 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1444389234331765 and mu_y: 0.02400038153872536\n",
      "2962, loss is 0.0018824644806217387 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14440218606039407 and mu_y: 0.0239468771641754\n",
      "2963, loss is 0.0018824224189732406 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14436547165933566 and mu_y: 0.02389340329988597\n",
      "2964, loss is 0.00188238040675469 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.144328780210745 and mu_y: 0.023839959924584046\n",
      "2965, loss is 0.0018823384439001789 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14429211169538844 and mu_y: 0.0237865470170188\n",
      "2966, loss is 0.0018822965303439054 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14425546609405512 and mu_y: 0.023733164555961587\n",
      "2967, loss is 0.0018822546660201707 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1442188433875568 and mu_y: 0.02367981252020589\n",
      "2968, loss is 0.0018822128508633848 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14418224355672793 and mu_y: 0.0236264908885673\n",
      "2969, loss is 0.0018821710848080594 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1441456665824255 and mu_y: 0.023573199639883476\n",
      "2970, loss is 0.0018821293677888126 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1441091124455291 and mu_y: 0.023519938753014114\n",
      "2971, loss is 0.0018820876997403656 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14407258112694082 and mu_y: 0.023466708206840905\n",
      "2972, loss is 0.0018820460805975465 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14403607260758527 and mu_y: 0.02341350798026751\n",
      "2973, loss is 0.0018820045102952848 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1439995868684095 and mu_y: 0.023360338052219525\n",
      "2974, loss is 0.001881962988768615 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14396312389038296 and mu_y: 0.02330719840164444\n",
      "2975, loss is 0.0018819215159526764 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14392668365449757 and mu_y: 0.023254089007511615\n",
      "2976, loss is 0.00188188009178271 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1438902661417675 and mu_y: 0.023201009848812234\n",
      "2977, loss is 0.0018818387161940611 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14385387133322933 and mu_y: 0.023147960904559284\n",
      "2978, loss is 0.0018817973891221773 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14381749920994188 and mu_y: 0.023094942153787514\n",
      "2979, loss is 0.0018817561105026112 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14378114975298623 and mu_y: 0.023041953575553407\n",
      "2980, loss is 0.0018817148802710152 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14374482294346566 and mu_y: 0.02298899514893514\n",
      "2981, loss is 0.0018816736983631465 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14370851876250565 and mu_y: 0.022936066853032552\n",
      "2982, loss is 0.001881632564714865 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14367223719125383 and mu_y: 0.022883168666967112\n",
      "2983, loss is 0.0018815914792621293 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14363597821087992 and mu_y: 0.02283030056988189\n",
      "2984, loss is 0.0018815504419410034 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14359974180257576 and mu_y: 0.022777462540941516\n",
      "2985, loss is 0.0018815094526876514 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14356352794755523 and mu_y: 0.02272465455933215\n",
      "2986, loss is 0.0018814685114383395 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14352733662705416 and mu_y: 0.02267187660426145\n",
      "2987, loss is 0.0018814276181294354 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14349116782233046 and mu_y: 0.02261912865495854\n",
      "2988, loss is 0.0018813867726974066 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14345502151466388 and mu_y: 0.022566410690673975\n",
      "2989, loss is 0.0018813459750788234 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14341889768535615 and mu_y: 0.022513722690679708\n",
      "2990, loss is 0.001881305225210354 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14338279631573084 and mu_y: 0.022461064634269053\n",
      "2991, loss is 0.001881264523028772 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1433467173871334 and mu_y: 0.022408436500756666\n",
      "2992, loss is 0.001881223868470947 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14331066088093106 and mu_y: 0.02235583826947849\n",
      "2993, loss is 0.0018811832614738493 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14327462677851283 and mu_y: 0.02230326991979175\n",
      "2994, loss is 0.0018811427019745511 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1432386150612895 and mu_y: 0.022250731431074897\n",
      "2995, loss is 0.0018811021899102223 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14320262571069348 and mu_y: 0.022198222782727588\n",
      "2996, loss is 0.0018810617252181339 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14316665870817896 and mu_y: 0.022145743954170644\n",
      "2997, loss is 0.0018810213078356561 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1431307140352217 and mu_y: 0.02209329492484603\n",
      "2998, loss is 0.0018809809377002577 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14309479167331912 and mu_y: 0.02204087567421681\n",
      "2999, loss is 0.001880940614749506 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14305889160399016 and mu_y: 0.021988486181767124\n",
      "3000, loss is 0.0018809003389210677 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14302301380877533 and mu_y: 0.021936126427002156\n",
      "3001, loss is 0.0018808601101527082 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1429871582692367 and mu_y: 0.021883796389448092\n",
      "3002, loss is 0.0018808199283822916 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14295132496695773 and mu_y: 0.0218314960486521\n",
      "3003, loss is 0.0018807797935477804 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14291551388354337 and mu_y: 0.021779225384182286\n",
      "3004, loss is 0.0018807397055872332 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14287972500062002 and mu_y: 0.021726984375627673\n",
      "3005, loss is 0.0018806996644388095 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14284395829983537 and mu_y: 0.021674773002598163\n",
      "3006, loss is 0.001880659670040763 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14280821376285852 and mu_y: 0.021622591244724505\n",
      "3007, loss is 0.0018806197223314486 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14277249137137987 and mu_y: 0.021570439081658264\n",
      "3008, loss is 0.001880579821249315 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1427367911071111 and mu_y: 0.021518316493071794\n",
      "3009, loss is 0.0018805399667329095 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14270111295178514 and mu_y: 0.0214662234586582\n",
      "3010, loss is 0.0018805001587208782 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14266545688715612 and mu_y: 0.02141415995813131\n",
      "3011, loss is 0.0018804603971519596 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14262982289499937 and mu_y: 0.021362125971225637\n",
      "3012, loss is 0.001880420681964993 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14259421095711136 and mu_y: 0.02131012147769636\n",
      "3013, loss is 0.0018803810130989104 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1425586210553097 and mu_y: 0.02125814645731928\n",
      "3014, loss is 0.0018803413904927436 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14252305317143307 and mu_y: 0.021206200889890794\n",
      "3015, loss is 0.001880301814085618 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14248750728734122 and mu_y: 0.02115428475522787\n",
      "3016, loss is 0.0018802622838167552 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14245198338491488 and mu_y: 0.021102398033167998\n",
      "3017, loss is 0.001880222799625472 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14241648144605584 and mu_y: 0.021050540703569178\n",
      "3018, loss is 0.0018801833614511814 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14238100145268678 and mu_y: 0.02099871274630988\n",
      "3019, loss is 0.001880143969233392 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14234554338675134 and mu_y: 0.020946914141289016\n",
      "3020, loss is 0.0018801046229117067 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14231010723021406 and mu_y: 0.020895144868425898\n",
      "3021, loss is 0.001880065322425822 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14227469296506032 and mu_y: 0.020843404907660228\n",
      "3022, loss is 0.0018800260677155315 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14223930057329634 and mu_y: 0.02079169423895204\n",
      "3023, loss is 0.0018799868587207232 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14220393003694917 and mu_y: 0.020740012842281705\n",
      "3024, loss is 0.0018799476953813763 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1421685813380666 and mu_y: 0.020688360697649857\n",
      "3025, loss is 0.0018799085776375693 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1421332544587171 and mu_y: 0.0206367377850774\n",
      "3026, loss is 0.001879869505429468 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14209794938098996 and mu_y: 0.020585144084605458\n",
      "3027, loss is 0.0018798304786973399 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14206266608699508 and mu_y: 0.020533579576295344\n",
      "3028, loss is 0.001879791497381539 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.142027404558863 and mu_y: 0.020482044240228543\n",
      "3029, loss is 0.001879752561422515 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14199216477874488 and mu_y: 0.020430538056506662\n",
      "3030, loss is 0.0018797136707608142 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14195694672881246 and mu_y: 0.020379061005251418\n",
      "3031, loss is 0.0018796748253370717 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.141921750391258 and mu_y: 0.020327613066604595\n",
      "3032, loss is 0.0018796360250920158 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14188657574829436 and mu_y: 0.02027619422072802\n",
      "3033, loss is 0.0018795972699664713 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14185142278215476 and mu_y: 0.020224804447803533\n",
      "3034, loss is 0.0018795585599013505 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.141816291475093 and mu_y: 0.02017344372803295\n",
      "3035, loss is 0.001879519894837662 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1417811818093832 and mu_y: 0.020122112041638038\n",
      "3036, loss is 0.0018794812747165047 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14174609376731995 and mu_y: 0.020070809368860493\n",
      "3037, loss is 0.00187944269947907 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14171102733121815 and mu_y: 0.02001953568996189\n",
      "3038, loss is 0.0018794041690666401 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1416759824834131 and mu_y: 0.019968290985223677\n",
      "3039, loss is 0.0018793656834205903 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1416409592062603 and mu_y: 0.019917075234947124\n",
      "3040, loss is 0.0018793272424823884 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14160595748213559 and mu_y: 0.0198658884194533\n",
      "3041, loss is 0.001879288846193589 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14157097729343504 and mu_y: 0.019814730519083053\n",
      "3042, loss is 0.0018792504944958421 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1415360186225749 and mu_y: 0.01976360151419697\n",
      "3043, loss is 0.001879212187330888 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14150108145199164 and mu_y: 0.019712501385175343\n",
      "3044, loss is 0.0018791739246405564 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14146616576414184 and mu_y: 0.019661430112418155\n",
      "3045, loss is 0.0018791357063667683 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1414312715415022 and mu_y: 0.01961038767634504\n",
      "3046, loss is 0.0018790975324515344 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14139639876656956 and mu_y: 0.019559374057395246\n",
      "3047, loss is 0.0018790594028369576 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14136154742186074 and mu_y: 0.019508389236027626\n",
      "3048, loss is 0.0018790213174652293 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14132671748991263 and mu_y: 0.019457433192720593\n",
      "3049, loss is 0.0018789832762786305 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1412919089532821 and mu_y: 0.019406505907972094\n",
      "3050, loss is 0.0018789452792195337 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14125712179454603 and mu_y: 0.01935560736229958\n",
      "3051, loss is 0.001878907326230399 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14122235599630115 and mu_y: 0.01930473753623998\n",
      "3052, loss is 0.0018788694172537776 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14118761154116416 and mu_y: 0.01925389641034967\n",
      "3053, loss is 0.0018788315522323081 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1411528884117716 and mu_y: 0.019203083965204443\n",
      "3054, loss is 0.0018787937311087201 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1411181865907799 and mu_y: 0.019152300181399486\n",
      "3055, loss is 0.001878755953825831 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14108350606086528 and mu_y: 0.019101545039549337\n",
      "3056, loss is 0.0018787182203265464 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14104884680472374 and mu_y: 0.019050818520287872\n",
      "3057, loss is 0.0018786805305538623 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.141014208805071 and mu_y: 0.019000120604268266\n",
      "3058, loss is 0.0018786428844508624 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1409795920446426 and mu_y: 0.01894945127216297\n",
      "3059, loss is 0.0018786052819607167 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14094499650619371 and mu_y: 0.01889881050466367\n",
      "3060, loss is 0.0018785677230266848 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1409104221724992 and mu_y: 0.01884819828248128\n",
      "3061, loss is 0.0018785302075921152 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14087586902635352 and mu_y: 0.018797614586345896\n",
      "3062, loss is 0.001878492735600443 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14084133705057078 and mu_y: 0.018747059397006768\n",
      "3063, loss is 0.0018784553069951906 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14080682622798468 and mu_y: 0.018696532695232283\n",
      "3064, loss is 0.0018784179217199676 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1407723365414484 and mu_y: 0.018646034461809926\n",
      "3065, loss is 0.0018783805797184736 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14073786797383475 and mu_y: 0.01859556467754625\n",
      "3066, loss is 0.0018783432809344898 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14070342050803591 and mu_y: 0.01854512332326686\n",
      "3067, loss is 0.0018783060253118908 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1406689941269636 and mu_y: 0.018494710379816374\n",
      "3068, loss is 0.001878268812794632 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14063458881354893 and mu_y: 0.018444325828058397\n",
      "3069, loss is 0.0018782316433267592 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14060020455074246 and mu_y: 0.01839396964887549\n",
      "3070, loss is 0.0018781945168524043 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1405658413215141 and mu_y: 0.018343641823169155\n",
      "3071, loss is 0.0018781574333157824 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14053149910885307 and mu_y: 0.018293342331859783\n",
      "3072, loss is 0.0018781203926611992 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14049717789576796 and mu_y: 0.018243071155886654\n",
      "3073, loss is 0.0018780833948330421 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14046287766528662 and mu_y: 0.018192828276207884\n",
      "3074, loss is 0.0018780464397757878 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14042859840045613 and mu_y: 0.018142613673800417\n",
      "3075, loss is 0.0018780095274339964 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14039434008434287 and mu_y: 0.018092427329659978\n",
      "3076, loss is 0.0018779726577523137 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14036010270003238 and mu_y: 0.018042269224801063\n",
      "3077, loss is 0.0018779358306754712 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14032588623062936 and mu_y: 0.0179921393402569\n",
      "3078, loss is 0.0018778990461482848 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14029169065925767 and mu_y: 0.017942037657079423\n",
      "3079, loss is 0.0018778623041156568 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1402575159690603 and mu_y: 0.01789196415633925\n",
      "3080, loss is 0.001877825604522574 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1402233621431993 and mu_y: 0.017841918819125648\n",
      "3081, loss is 0.001877788947314106 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1401892291648558 and mu_y: 0.017791901626546508\n",
      "3082, loss is 0.001877752332435408 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1401551170172299 and mu_y: 0.01774191255972832\n",
      "3083, loss is 0.0018777157598317213 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1401210256835408 and mu_y: 0.017691951599816142\n",
      "3084, loss is 0.001877679229448368 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14008695514702657 and mu_y: 0.017642018727973573\n",
      "3085, loss is 0.0018776427412307568 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1400529053909443 and mu_y: 0.017592113925382725\n",
      "3086, loss is 0.0018776062951243787 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.14001887639857 and mu_y: 0.017542237173244202\n",
      "3087, loss is 0.001877569891074811 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1399848681531985 and mu_y: 0.017492388452777063\n",
      "3088, loss is 0.0018775335290277101 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13995088063814354 and mu_y: 0.017442567745218802\n",
      "3089, loss is 0.0018774972089288192 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13991691383673766 and mu_y: 0.017392775031825316\n",
      "3090, loss is 0.0018774609307239645 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13988296773233225 and mu_y: 0.017343010293870885\n",
      "3091, loss is 0.0018774246943590533 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13984904230829742 and mu_y: 0.017293273512648134\n",
      "3092, loss is 0.0018773884997800782 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13981513754802208 and mu_y: 0.01724356466946801\n",
      "3093, loss is 0.0018773523469331121 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13978125343491382 and mu_y: 0.01719388374565977\n",
      "3094, loss is 0.0018773162357643134 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13974738995239896 and mu_y: 0.017144230722570927\n",
      "3095, loss is 0.0018772801662199205 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13971354708392245 and mu_y: 0.01709460558156724\n",
      "3096, loss is 0.001877244138246254 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13967972481294788 and mu_y: 0.017045008304032692\n",
      "3097, loss is 0.0018772081517897197 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13964592312295745 and mu_y: 0.016995438871369443\n",
      "3098, loss is 0.001877172206796801 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13961214199745198 and mu_y: 0.016945897264997827\n",
      "3099, loss is 0.0018771363032140673 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1395783814199508 and mu_y: 0.016896383466356305\n",
      "3100, loss is 0.0018771004409881653 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13954464137399175 and mu_y: 0.016846897456901454\n",
      "3101, loss is 0.0018770646200658284 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13951092184313124 and mu_y: 0.01679743921810793\n",
      "3102, loss is 0.0018770288403938678 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13947722281094407 and mu_y: 0.016748008731468443\n",
      "3103, loss is 0.001876993101919175 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13944354426102354 and mu_y: 0.016698605978493736\n",
      "3104, loss is 0.0018769574045887265 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13940988617698136 and mu_y: 0.016649230940712557\n",
      "3105, loss is 0.0018769217483495762 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1393762485424476 and mu_y: 0.016599883599671624\n",
      "3106, loss is 0.0018768861331488608 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1393426313410707 and mu_y: 0.016550563936935613\n",
      "3107, loss is 0.0018768505589337964 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13930903455651744 and mu_y: 0.016501271934087115\n",
      "3108, loss is 0.0018768150256516804 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13927545817247294 and mu_y: 0.016452007572726628\n",
      "3109, loss is 0.0018767795332498903 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13924190217264057 and mu_y: 0.016402770834472512\n",
      "3110, loss is 0.0018767440816758831 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13920836654074192 and mu_y: 0.016353561700960983\n",
      "3111, loss is 0.0018767086708771975 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13917485126051687 and mu_y: 0.016304380153846068\n",
      "3112, loss is 0.0018766733008014492 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13914135631572347 and mu_y: 0.01625522617479959\n",
      "3113, loss is 0.0018766379713963364 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13910788169013794 and mu_y: 0.016206099745511137\n",
      "3114, loss is 0.0018766026826096361 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13907442736755463 and mu_y: 0.01615700084768804\n",
      "3115, loss is 0.0018765674343892036 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13904099333178604 and mu_y: 0.016107929463055344\n",
      "3116, loss is 0.0018765322266829753 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1390075795666628 and mu_y: 0.01605888557335579\n",
      "3117, loss is 0.0018764970594389659 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13897418605603348 and mu_y: 0.016009869160349768\n",
      "3118, loss is 0.0018764619326052676 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13894081278376483 and mu_y: 0.01596088020581532\n",
      "3119, loss is 0.0018764268461300539 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1389074597337415 and mu_y: 0.015911918691548094\n",
      "3120, loss is 0.0018763917999615745 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1388741268898662 and mu_y: 0.015862984599361325\n",
      "3121, loss is 0.0018763567940481606 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13884081423605957 and mu_y: 0.015814077911085807\n",
      "3122, loss is 0.001876321828338219 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13880752175626018 and mu_y: 0.01576519860856987\n",
      "3123, loss is 0.0018762869027802375 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1387742494344245 and mu_y: 0.01571634667367935\n",
      "3124, loss is 0.001876252017322779 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13874099725452693 and mu_y: 0.01566752208829758\n",
      "3125, loss is 0.001876217171914486 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13870776520055964 and mu_y: 0.015618724834325337\n",
      "3126, loss is 0.0018761823665040791 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1386745532565327 and mu_y: 0.015569954893680835\n",
      "3127, loss is 0.001876147601040357 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13864136140647393 and mu_y: 0.015521212248299698\n",
      "3128, loss is 0.0018761128754721935 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13860818963442897 and mu_y: 0.015472496880134932\n",
      "3129, loss is 0.0018760781897485413 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1385750379244612 and mu_y: 0.015423808771156901\n",
      "3130, loss is 0.0018760435438184325 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13854190626065166 and mu_y: 0.0153751479033533\n",
      "3131, loss is 0.001876008937630972 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1385087946270992 and mu_y: 0.015326514258729131\n",
      "3132, loss is 0.001875974371135344 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13847570300792025 and mu_y: 0.015277907819306677\n",
      "3133, loss is 0.0018759398442808114 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1384426313872489 and mu_y: 0.015229328567125475\n",
      "3134, loss is 0.001875905357016709 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1384095797492369 and mu_y: 0.015180776484242302\n",
      "3135, loss is 0.0018758709092924534 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13837654807805355 and mu_y: 0.015132251552731135\n",
      "3136, loss is 0.0018758365010575345 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13834353635788574 and mu_y: 0.015083753754683132\n",
      "3137, loss is 0.0018758021322615177 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13831054457293787 and mu_y: 0.015035283072206612\n",
      "3138, loss is 0.0018757678028540467 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1382775727074319 and mu_y: 0.014986839487427024\n",
      "3139, loss is 0.0018757335127848412 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13824462074560728 and mu_y: 0.014938422982486923\n",
      "3140, loss is 0.0018756992620036946 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13821168867172087 and mu_y: 0.014890033539545948\n",
      "3141, loss is 0.0018756650504604792 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13817877647004703 and mu_y: 0.014841671140780796\n",
      "3142, loss is 0.0018756308781051377 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1381458841248775 and mu_y: 0.014793335768385197\n",
      "3143, loss is 0.0018755967448876936 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1381130116205214 and mu_y: 0.014745027404569887\n",
      "3144, loss is 0.0018755626507582445 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13808015894130524 and mu_y: 0.01469674603156259\n",
      "3145, loss is 0.0018755285956669613 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13804732607157283 and mu_y: 0.014648491631607984\n",
      "3146, loss is 0.0018754945795640895 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13801451299568535 and mu_y: 0.014600264186967688\n",
      "3147, loss is 0.0018754606023999522 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13798171969802123 and mu_y: 0.014552063679920228\n",
      "3148, loss is 0.001875426664124946 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13794894616297615 and mu_y: 0.014503890092761016\n",
      "3149, loss is 0.0018753927646895398 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13791619237496303 and mu_y: 0.014455743407802327\n",
      "3150, loss is 0.0018753589040442812 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13788345831841203 and mu_y: 0.014407623607373271\n",
      "3151, loss is 0.0018753250821397901 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13785074397777047 and mu_y: 0.014359530673819773\n",
      "3152, loss is 0.001875291298926759 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13781804933750283 and mu_y: 0.014311464589504549\n",
      "3153, loss is 0.0018752575543559567 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13778537438209074 and mu_y: 0.014263425336807075\n",
      "3154, loss is 0.0018752238483782243 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13775271909603293 and mu_y: 0.014215412898123572\n",
      "3155, loss is 0.001875190180944479 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1377200834638452 and mu_y: 0.014167427255866975\n",
      "3156, loss is 0.0018751565520057087 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13768746747006047 and mu_y: 0.014119468392466913\n",
      "3157, loss is 0.001875122961512977 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13765487109922864 and mu_y: 0.014071536290369682\n",
      "3158, loss is 0.0018750894094174196 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1376222943359166 and mu_y: 0.014023630932038225\n",
      "3159, loss is 0.0018750558956702468 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13758973716470832 and mu_y: 0.013975752299952104\n",
      "3160, loss is 0.0018750224202227397 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13755719957020462 and mu_y: 0.013927900376607478\n",
      "3161, loss is 0.0018749889830262554 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13752468153702335 and mu_y: 0.01388007514451708\n",
      "3162, loss is 0.001874955584032222 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1374921830497992 and mu_y: 0.01383227658621019\n",
      "3163, loss is 0.001874922223192139 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1374597040931838 and mu_y: 0.013784504684232618\n",
      "3164, loss is 0.0018748889004575825 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13742724465184564 and mu_y: 0.01373675942114667\n",
      "3165, loss is 0.001874855615780196 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13739480471047 and mu_y: 0.013689040779531137\n",
      "3166, loss is 0.0018748223691116997 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13736238425375902 and mu_y: 0.013641348741981259\n",
      "3167, loss is 0.001874789160403883 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13732998326643162 and mu_y: 0.013593683291108709\n",
      "3168, loss is 0.00187475598960861 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13729760173322347 and mu_y: 0.013546044409541567\n",
      "3169, loss is 0.0018747228566778143 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.137265239638887 and mu_y: 0.013498432079924301\n",
      "3170, loss is 0.0018746897615635023 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13723289696819135 and mu_y: 0.013450846284917734\n",
      "3171, loss is 0.001874656704217752 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13720057370592234 and mu_y: 0.013403287007199031\n",
      "3172, loss is 0.0018746236845927123 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1371682698368825 and mu_y: 0.013355754229461668\n",
      "3173, loss is 0.001874590702640605 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13713598534589092 and mu_y: 0.013308247934415412\n",
      "3174, loss is 0.001874557758313722 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1371037202177834 and mu_y: 0.0132607681047863\n",
      "3175, loss is 0.001874524851564426 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13707147443741227 and mu_y: 0.013213314723316612\n",
      "3176, loss is 0.0018744919823451523 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1370392479896465 and mu_y: 0.013165887772764846\n",
      "3177, loss is 0.0018744591506084055 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13700704085937157 and mu_y: 0.013118487235905703\n",
      "3178, loss is 0.0018744263563067601 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13697485303148946 and mu_y: 0.013071113095530055\n",
      "3179, loss is 0.0018743935993928667 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13694268449091868 and mu_y: 0.013023765334444928\n",
      "3180, loss is 0.001874360879819438 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1369105352225942 and mu_y: 0.012976443935473477\n",
      "3181, loss is 0.0018743281975392638 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13687840521146744 and mu_y: 0.012929148881454963\n",
      "3182, loss is 0.0018742955525052004 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1368462944425063 and mu_y: 0.012881880155244727\n",
      "3183, loss is 0.0018742629446701765 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.136814202900695 and mu_y: 0.012834637739714173\n",
      "3184, loss is 0.00187423037398719 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1367821305710342 and mu_y: 0.012787421617750741\n",
      "3185, loss is 0.001874197840409307 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13675007743854092 and mu_y: 0.012740231772257887\n",
      "3186, loss is 0.0018741653438896669 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13671804348824848 and mu_y: 0.012693068186155058\n",
      "3187, loss is 0.0018741328843814747 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13668602870520655 and mu_y: 0.01264593084237767\n",
      "3188, loss is 0.0018741004618380076 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13665403307448104 and mu_y: 0.012598819723877086\n",
      "3189, loss is 0.0018740680762126117 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13662205658115414 and mu_y: 0.01255173481362059\n",
      "3190, loss is 0.0018740357274587016 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1365900992103243 and mu_y: 0.01250467609459137\n",
      "3191, loss is 0.0018740034155297607 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13655816094710618 and mu_y: 0.012457643549788493\n",
      "3192, loss is 0.001873971140379344 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1365262417766306 and mu_y: 0.012410637162226882\n",
      "3193, loss is 0.0018739389019610715 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1364943416840446 and mu_y: 0.01236365691493729\n",
      "3194, loss is 0.0018739067002286345 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13646246065451131 and mu_y: 0.012316702790966286\n",
      "3195, loss is 0.0018738745351357926 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13643059867321006 and mu_y: 0.012269774773376227\n",
      "3196, loss is 0.0018738424066363727 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1363987557253362 and mu_y: 0.012222872845245234\n",
      "3197, loss is 0.001873810314684271 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13636693179610118 and mu_y: 0.012175996989667174\n",
      "3198, loss is 0.0018737782592334524 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13633512687073254 and mu_y: 0.012129147189751638\n",
      "3199, loss is 0.0018737462402379492 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13630334093447383 and mu_y: 0.012082323428623913\n",
      "3200, loss is 0.0018737142576518608 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13627157397258458 and mu_y: 0.012035525689424965\n",
      "3201, loss is 0.0018736823114293571 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13623982597034034 and mu_y: 0.011988753955311418\n",
      "3202, loss is 0.0018736504015246737 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1362080969130326 and mu_y: 0.011942008209455526\n",
      "3203, loss is 0.0018736185278921138 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1361763867859688 and mu_y: 0.011895288435045157\n",
      "3204, loss is 0.0018735866904860481 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1361446955744723 and mu_y: 0.011848594615283765\n",
      "3205, loss is 0.001873554889260916 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13611302326388236 and mu_y: 0.011801926733390375\n",
      "3206, loss is 0.0018735231241712232 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13608136983955404 and mu_y: 0.011755284772599557\n",
      "3207, loss is 0.0018734913951715412 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13604973528685835 and mu_y: 0.011708668716161401\n",
      "3208, loss is 0.001873459702216513 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13601811959118207 and mu_y: 0.011662078547341503\n",
      "3209, loss is 0.0018734280452608427 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13598652273792777 and mu_y: 0.011615514249420937\n",
      "3210, loss is 0.0018733964242593044 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13595494471251385 and mu_y: 0.011568975805696236\n",
      "3211, loss is 0.0018733648391667391 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13592338550037442 and mu_y: 0.011522463199479367\n",
      "3212, loss is 0.0018733332899380545 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13589184508695934 and mu_y: 0.011475976414097717\n",
      "3213, loss is 0.0018733017765282215 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1358603234577342 and mu_y: 0.011429515432894059\n",
      "3214, loss is 0.0018732702988922812 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13582882059818022 and mu_y: 0.011383080239226542\n",
      "3215, loss is 0.001873238856985338 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13579733649379433 and mu_y: 0.011336670816468664\n",
      "3216, loss is 0.0018732074507625655 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13576587113008912 and mu_y: 0.01129028714800925\n",
      "3217, loss is 0.0018731760801792008 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1357344244925928 and mu_y: 0.011243929217252435\n",
      "3218, loss is 0.001873144745190548 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13570299656684912 and mu_y: 0.011197597007617636\n",
      "3219, loss is 0.001873113445751974 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13567158733841747 and mu_y: 0.011151290502539535\n",
      "3220, loss is 0.0018730821818189163 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13564019679287279 and mu_y: 0.011105009685468058\n",
      "3221, loss is 0.0018730509533468743 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1356088249158055 and mu_y: 0.01105875453986835\n",
      "3222, loss is 0.0018730197602914134 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1355774716928216 and mu_y: 0.011012525049220758\n",
      "3223, loss is 0.0018729886026081653 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13554613710954255 and mu_y: 0.010966321197020805\n",
      "3224, loss is 0.0018729574802528255 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13551482115160524 and mu_y: 0.010920142966779175\n",
      "3225, loss is 0.0018729263931811552 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13548352380466205 and mu_y: 0.010873990342021684\n",
      "3226, loss is 0.0018728953413489802 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13545224505438078 and mu_y: 0.010827863306289267\n",
      "3227, loss is 0.001872864324712191 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1354209848864446 and mu_y: 0.01078176184313795\n",
      "3228, loss is 0.0018728333432267439 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1353897432865521 and mu_y: 0.010735685936138833\n",
      "3229, loss is 0.0018728023968486588 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1353585202404172 and mu_y: 0.010689635568878069\n",
      "3230, loss is 0.0018727714855340193 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13532731573376913 and mu_y: 0.01064361072495684\n",
      "3231, loss is 0.0018727406092389754 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1352961297523525 and mu_y: 0.01059761138799134\n",
      "3232, loss is 0.0018727097679197386 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13526496228192716 and mu_y: 0.01055163754161275\n",
      "3233, loss is 0.001872678961532586 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13523381330826825 and mu_y: 0.01050568916946722\n",
      "3234, loss is 0.00187264819003386 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13520268281716613 and mu_y: 0.010459766255215846\n",
      "3235, loss is 0.001872617453379964 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1351715707944264 and mu_y: 0.010413868782534651\n",
      "3236, loss is 0.001872586751527368 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1351404772258699 and mu_y: 0.010367996735114566\n",
      "3237, loss is 0.0018725560844326029 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13510940209733258 and mu_y: 0.010322150096661403\n",
      "3238, loss is 0.0018725254520522657 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13507834539466562 and mu_y: 0.010276328850895843\n",
      "3239, loss is 0.0018724948543430136 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13504730710373533 and mu_y: 0.010230532981553405\n",
      "3240, loss is 0.0018724642912615712 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13501628721042308 and mu_y: 0.010184762472384434\n",
      "3241, loss is 0.001872433762764723 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1349852857006254 and mu_y: 0.010139017307154077\n",
      "3242, loss is 0.0018724032688093191 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13495430256025387 and mu_y: 0.010093297469642264\n",
      "3243, loss is 0.0018723728093522683 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13492333777523513 and mu_y: 0.010047602943643683\n",
      "3244, loss is 0.0018723423843505483 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13489239133151085 and mu_y: 0.010001933712967767\n",
      "3245, loss is 0.0018723119937611946 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1348614632150377 and mu_y: 0.009956289761438667\n",
      "3246, loss is 0.001872281637541308 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13483055341178735 and mu_y: 0.009910671072895233\n",
      "3247, loss is 0.00187225131564805 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13479966190774642 and mu_y: 0.009865077631190995\n",
      "3248, loss is 0.0018722210280386468 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13476878868891654 and mu_y: 0.009819509420194146\n",
      "3249, loss is 0.001872190774670383 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13473793374131418 and mu_y: 0.009773966423787512\n",
      "3250, loss is 0.0018721605555006113 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13470709705097078 and mu_y: 0.009728448625868542\n",
      "3251, loss is 0.0018721303704867407 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1346762786039326 and mu_y: 0.009682956010349282\n",
      "3252, loss is 0.0018721002195862453 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13464547838626087 and mu_y: 0.009637488561156355\n",
      "3253, loss is 0.0018720701027566604 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13461469638403153 and mu_y: 0.009592046262230947\n",
      "3254, loss is 0.001872040019955582 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13458393258333545 and mu_y: 0.009546629097528776\n",
      "3255, loss is 0.0018720099711406714 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13455318697027824 and mu_y: 0.009501237051020081\n",
      "3256, loss is 0.0018719799562696455 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13452245953098033 and mu_y: 0.0094558701066896\n",
      "3257, loss is 0.0018719499753002873 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13449175025157684 and mu_y: 0.009410528248536545\n",
      "3258, loss is 0.00187192002819044 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1344610591182177 and mu_y: 0.00936521146057459\n",
      "3259, loss is 0.001871890114898007 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13443038611706754 and mu_y: 0.009319919726831848\n",
      "3260, loss is 0.0018718602353809538 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13439973123430565 and mu_y: 0.009274653031350843\n",
      "3261, loss is 0.0018718303895973063 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13436909445612602 and mu_y: 0.009229411358188505\n",
      "3262, loss is 0.001871800577505153 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1343384757687373 and mu_y: 0.009184194691416138\n",
      "3263, loss is 0.0018717707990626394 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1343078751583628 and mu_y: 0.009139003015119405\n",
      "3264, loss is 0.0018717410542279757 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13427729261124033 and mu_y: 0.009093836313398312\n",
      "3265, loss is 0.0018717113429594294 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13424672811362243 and mu_y: 0.009048694570367178\n",
      "3266, loss is 0.001871681665215332 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13421618165177615 and mu_y: 0.009003577770154626\n",
      "3267, loss is 0.0018716520209540722 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1341856532119831 and mu_y: 0.008958485896903557\n",
      "3268, loss is 0.0018716224101341 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13415514278053944 and mu_y: 0.008913418934771133\n",
      "3269, loss is 0.0018715928327139256 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13412465034375579 and mu_y: 0.008868376867928756\n",
      "3270, loss is 0.0018715632886521201 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13409417588795727 and mu_y: 0.008823359680562049\n",
      "3271, loss is 0.0018715337779073135 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1340637193994835 and mu_y: 0.008778367356870837\n",
      "3272, loss is 0.0018715043004381953 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13403328086468855 and mu_y: 0.008733399881069127\n",
      "3273, loss is 0.001871474856203515 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1340028602699409 and mu_y: 0.00868845723738509\n",
      "3274, loss is 0.0018714454451620828 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13397245760162346 and mu_y: 0.008643539410061036\n",
      "3275, loss is 0.0018714160672727675 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13394207284613352 and mu_y: 0.008598646383353406\n",
      "3276, loss is 0.0018713867224944961 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13391170598988272 and mu_y: 0.008553778141532738\n",
      "3277, loss is 0.0018713574107862587 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13388135701929707 and mu_y: 0.008508934668883661\n",
      "3278, loss is 0.0018713281321070991 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13385102592081688 and mu_y: 0.008464115949704868\n",
      "3279, loss is 0.0018712988864161247 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13382071268089682 and mu_y: 0.008419321968309097\n",
      "3280, loss is 0.0018712696736725009 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1337904172860058 and mu_y: 0.008374552709023115\n",
      "3281, loss is 0.0018712404938354499 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13376013972262701 and mu_y: 0.0083298081561877\n",
      "3282, loss is 0.0018712113468642556 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1337298799772579 and mu_y: 0.008285088294157613\n",
      "3283, loss is 0.0018711822327182595 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13369963803641016 and mu_y: 0.008240393107301592\n",
      "3284, loss is 0.0018711531513568597 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13366941388660963 and mu_y: 0.008195722580002321\n",
      "3285, loss is 0.0018711241027395155 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13363920751439642 and mu_y: 0.00815107669665642\n",
      "3286, loss is 0.0018710950868257431 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13360901890632473 and mu_y: 0.00810645544167442\n",
      "3287, loss is 0.001871066103575118 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13357884804896297 and mu_y: 0.008061858799480745\n",
      "3288, loss is 0.001871037152947273 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13354869492889365 and mu_y: 0.008017286754513698\n",
      "3289, loss is 0.001871008234901899 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13351855953271338 and mu_y: 0.007972739291225434\n",
      "3290, loss is 0.0018709793493987457 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13348844184703287 and mu_y: 0.007928216394081948\n",
      "3291, loss is 0.0018709504963976195 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1334583418584769 and mu_y: 0.007883718047563052\n",
      "3292, loss is 0.0018709216758583853 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13342825955368434 and mu_y: 0.00783924423616236\n",
      "3293, loss is 0.0018708928877409655 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13339819491930802 and mu_y: 0.0077947949443872636\n",
      "3294, loss is 0.0018708641320053395 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13336814794201482 and mu_y: 0.007750370156758921\n",
      "3295, loss is 0.0018708354086115462 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1333381186084856 and mu_y: 0.007705969857812233\n",
      "3296, loss is 0.00187080671751968 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1333081069054152 and mu_y: 0.0076615940320958215\n",
      "3297, loss is 0.0018707780586898915 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1332781128195124 and mu_y: 0.00761724266417202\n",
      "3298, loss is 0.001870749432082392 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13324813633749993 and mu_y: 0.007572915738616847\n",
      "3299, loss is 0.0018707208376574464 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13321817744611444 and mu_y: 0.00752861324001999\n",
      "3300, loss is 0.001870692275375378 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13318823613210645 and mu_y: 0.007484335152984788\n",
      "3301, loss is 0.0018706637451965677 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13315831238224035 and mu_y: 0.007440081462128212\n",
      "3302, loss is 0.001870635247081452 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1331284061832944 and mu_y: 0.007395852152080847\n",
      "3303, loss is 0.0018706067809905248 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13309851752206073 and mu_y: 0.007351647207486872\n",
      "3304, loss is 0.0018705783468843358 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1330686463853452 and mu_y: 0.0073074666130040445\n",
      "3305, loss is 0.001870549944723492 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13303879275996758 and mu_y: 0.00726331035330368\n",
      "3306, loss is 0.0018705215744686558 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1330089566327613 and mu_y: 0.007219178413070634\n",
      "3307, loss is 0.0018704932360805475 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13297913799057362 and mu_y: 0.007175070777003284\n",
      "3308, loss is 0.0018704649295199418 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13294933682026555 and mu_y: 0.007130987429813511\n",
      "3309, loss is 0.0018704366547476704 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13291955310871179 and mu_y: 0.007086928356226682\n",
      "3310, loss is 0.0018704084117246217 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13288978684280076 and mu_y: 0.00704289354098163\n",
      "3311, loss is 0.001870380200411738 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13286003800943452 and mu_y: 0.006998882968830637\n",
      "3312, loss is 0.001870352020770019 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13283030659552886 and mu_y: 0.006954896624539417\n",
      "3313, loss is 0.0018703238727605191 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13280059258801316 and mu_y: 0.006910934492887097\n",
      "3314, loss is 0.0018702957563443501 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1327708959738305 and mu_y: 0.006866996558666198\n",
      "3315, loss is 0.0018702676714826777 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13274121673993744 and mu_y: 0.006823082806682616\n",
      "3316, loss is 0.0018702396181367222 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13271155487330424 and mu_y: 0.006779193221755609\n",
      "3317, loss is 0.0018702115962677618 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1326819103609147 and mu_y: 0.006735327788717773\n",
      "3318, loss is 0.001870183605837127 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13265228318976616 and mu_y: 0.006691486492415027\n",
      "3319, loss is 0.0018701556468062063 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1326226733468695 and mu_y: 0.006647669317706596\n",
      "3320, loss is 0.0018701277191364419 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13259308081924912 and mu_y: 0.006603876249464992\n",
      "3321, loss is 0.0018700998227893291 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13256350559394287 and mu_y: 0.006560107272575994\n",
      "3322, loss is 0.0018700719577264219 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13253394765800214 and mu_y: 0.006516362371938633\n",
      "3323, loss is 0.0018700441239093257 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13250440699849172 and mu_y: 0.006472641532465176\n",
      "3324, loss is 0.001870016321299703 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1324748836024899 and mu_y: 0.006428944739081102\n",
      "3325, loss is 0.0018699885498592672 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13244537745708834 and mu_y: 0.006385271976725089\n",
      "3326, loss is 0.001869960809549792 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1324158885493921 and mu_y: 0.006341623230348998\n",
      "3327, loss is 0.0018699331003330995 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13238641686651964 and mu_y: 0.006297998484917848\n",
      "3328, loss is 0.0018699054221710707 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13235696239560282 and mu_y: 0.006254397725409807\n",
      "3329, loss is 0.001869877775025637 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1323275251237868 and mu_y: 0.006210820936816168\n",
      "3330, loss is 0.001869850158858786 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13229810503823003 and mu_y: 0.006167268104141334\n",
      "3331, loss is 0.0018698225736325602 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13226870212610436 and mu_y: 0.006123739212402801\n",
      "3332, loss is 0.001869795019309054 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1322393163745949 and mu_y: 0.006080234246631139\n",
      "3333, loss is 0.0018697674958504161 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1322099477709 and mu_y: 0.006036753191869975\n",
      "3334, loss is 0.001869740003218849 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13218059630223128 and mu_y: 0.005993296033175978\n",
      "3335, loss is 0.00186971254137661 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1321512619558136 and mu_y: 0.005949862755618837\n",
      "3336, loss is 0.0018696851102860072 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13212194471888503 and mu_y: 0.005906453344281246\n",
      "3337, loss is 0.0018696577099094065 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13209264457869688 and mu_y: 0.0058630677842588875\n",
      "3338, loss is 0.0018696303402092216 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13206336152251358 and mu_y: 0.005819706060660414\n",
      "3339, loss is 0.0018696030011479258 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13203409553761275 and mu_y: 0.005776368158607432\n",
      "3340, loss is 0.0018695756926880387 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13200484661128517 and mu_y: 0.005733054063234482\n",
      "3341, loss is 0.0018695484147921394 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13197561473083474 and mu_y: 0.005689763759689024\n",
      "3342, loss is 0.0018695211674228556 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13194639988357845 and mu_y: 0.005646497233131418\n",
      "3343, loss is 0.0018694939505428678 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1319172020568464 and mu_y: 0.0056032544687349105\n",
      "3344, loss is 0.0018694667641149139 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13188802123798174 and mu_y: 0.005560035451685612\n",
      "3345, loss is 0.0018694396081017808 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13185885741434072 and mu_y: 0.005516840167182486\n",
      "3346, loss is 0.001869412482466307 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13182971057329257 and mu_y: 0.005473668600437326\n",
      "3347, loss is 0.0018693853871713866 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1318005807022196 and mu_y: 0.005430520736674742\n",
      "3348, loss is 0.001869358322179964 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13177146778851703 and mu_y: 0.005387396561132145\n",
      "3349, loss is 0.0018693312874550369 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1317423718195932 and mu_y: 0.005344296059059723\n",
      "3350, loss is 0.0018693042829596564 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13171329278286928 and mu_y: 0.005301219215720434\n",
      "3351, loss is 0.0018692773086569226 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13168423066577947 and mu_y: 0.005258166016389979\n",
      "3352, loss is 0.0018692503645099904 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13165518545577085 and mu_y: 0.005215136446356792\n",
      "3353, loss is 0.001869223450482067 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13162615714030346 and mu_y: 0.005172130490922022\n",
      "3354, loss is 0.0018691965665364081 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1315971457068502 and mu_y: 0.005129148135399514\n",
      "3355, loss is 0.001869169712636325 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13156815114289686 and mu_y: 0.005086189365115791\n",
      "3356, loss is 0.0018691428887451793 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1315391734359421 and mu_y: 0.005043254165410045\n",
      "3357, loss is 0.0018691160948263834 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1315102125734974 and mu_y: 0.005000342521634109\n",
      "3358, loss is 0.0018690893308434034 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1314812685430871 and mu_y: 0.00495745441915245\n",
      "3359, loss is 0.001869062596759753 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13145234133224826 and mu_y: 0.004914589843342147\n",
      "3360, loss is 0.001869035892539003 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13142343092853084 and mu_y: 0.004871748779592875\n",
      "3361, loss is 0.0018690092181447699 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1313945373194975 and mu_y: 0.004828931213306889\n",
      "3362, loss is 0.0018689825735407248 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13136566049272366 and mu_y: 0.004786137129899009\n",
      "3363, loss is 0.0018689559586905896 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13133680043579754 and mu_y: 0.004743366514796601\n",
      "3364, loss is 0.0018689293735581346 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13130795713631999 and mu_y: 0.004700619353439559\n",
      "3365, loss is 0.0018689028181071853 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1312791305819046 and mu_y: 0.004657895631280294\n",
      "3366, loss is 0.0018688762923016141 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13125032076017767 and mu_y: 0.004615195333783712\n",
      "3367, loss is 0.001868849796105346 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13122152765877815 and mu_y: 0.004572518446427202\n",
      "3368, loss is 0.0018688233294823586 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13119275126535762 and mu_y: 0.004529864954700614\n",
      "3369, loss is 0.0018687968923966755 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1311639915675803 and mu_y: 0.004487234844106249\n",
      "3370, loss is 0.001868770484812374 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13113524855312303 and mu_y: 0.004444628100158838\n",
      "3371, loss is 0.0018687441066935827 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13110652220967528 and mu_y: 0.004402044708385526\n",
      "3372, loss is 0.001868717758004477 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13107781252493905 and mu_y: 0.00435948465432586\n",
      "3373, loss is 0.0018686914387092864 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13104911948662892 and mu_y: 0.0043169479235317665\n",
      "3374, loss is 0.0018686651487722877 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13102044308247204 and mu_y: 0.00427443450156754\n",
      "3375, loss is 0.0018686388881578096 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13099178330020808 and mu_y: 0.004231944374009823\n",
      "3376, loss is 0.0018686126568302288 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1309631401275892 and mu_y: 0.0041894775264475935\n",
      "3377, loss is 0.0018685864547539758 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13093451355238006 and mu_y: 0.0041470339444821475\n",
      "3378, loss is 0.001868560281893526 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13090590356235782 and mu_y: 0.004104613613727081\n",
      "3379, loss is 0.0018685341382134076 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1308773101453121 and mu_y: 0.004062216519808276\n",
      "3380, loss is 0.0018685080236781975 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13084873328904492 and mu_y: 0.004019842648363883\n",
      "3381, loss is 0.0018684819382525247 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1308201729813708 and mu_y: 0.003977491985044306\n",
      "3382, loss is 0.001868455881901062 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13079162921011664 and mu_y: 0.003935164515512187\n",
      "3383, loss is 0.0018684298545885384 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13076310196312171 and mu_y: 0.003892860225442388\n",
      "3384, loss is 0.0018684038562797253 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1307345912282377 and mu_y: 0.0038505791005219755\n",
      "3385, loss is 0.0018683778869394508 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1307060969933286 and mu_y: 0.0038083211264502066\n",
      "3386, loss is 0.001868351946532587 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13067761924627083 and mu_y: 0.0037660862889385104\n",
      "3387, loss is 0.0018683260350240553 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13064915797495305 and mu_y: 0.003723874573710473\n",
      "3388, loss is 0.0018683001523788277 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13062071316727628 and mu_y: 0.003681685966501823\n",
      "3389, loss is 0.001868274298561927 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1305922848111538 and mu_y: 0.003639520453060414\n",
      "3390, loss is 0.0018682484735384189 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13056387289451124 and mu_y: 0.003597378019146209\n",
      "3391, loss is 0.0018682226772734243 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13053547740528637 and mu_y: 0.003555258650531265\n",
      "3392, loss is 0.0018681969097321092 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13050709833142932 and mu_y: 0.003513162332999717\n",
      "3393, loss is 0.001868171170879688 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13047873566090237 and mu_y: 0.0034710890523477625\n",
      "3394, loss is 0.0018681454606814263 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13045038938168008 and mu_y: 0.003429038794383646\n",
      "3395, loss is 0.001868119779102635 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13042205948174912 and mu_y: 0.0033870115449276417\n",
      "3396, loss is 0.0018680941261086745 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1303937459491084 and mu_y: 0.003345007289812041\n",
      "3397, loss is 0.0018680685016649549 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.130365448771769 and mu_y: 0.0033030260148811325\n",
      "3398, loss is 0.0018680429057369335 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1303371679377541 and mu_y: 0.003261067705991191\n",
      "3399, loss is 0.0018680173382901145 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13030890343509902 and mu_y: 0.003219132349010459\n",
      "3400, loss is 0.0018679917992900517 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13028065525185117 and mu_y: 0.003177219929819131\n",
      "3401, loss is 0.0018679662887023467 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13025242337607013 and mu_y: 0.0031353304343093406\n",
      "3402, loss is 0.0018679408064926476 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13022420779582747 and mu_y: 0.0030934638483851415\n",
      "3403, loss is 0.0018679153526266524 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1301960084992069 and mu_y: 0.0030516201579624948\n",
      "3404, loss is 0.0018678899270701036 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1301678254743041 and mu_y: 0.0030097993489692524\n",
      "3405, loss is 0.001867864529788797 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1301396587092269 and mu_y: 0.0029680014073451416\n",
      "3406, loss is 0.0018678391607485688 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13011150819209497 and mu_y: 0.0029262263190417493\n",
      "3407, loss is 0.0018678138199153074 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13008337391104013 and mu_y: 0.002884474070022508\n",
      "3408, loss is 0.0018677885072549481 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13005525585420613 and mu_y: 0.002842744646262679\n",
      "3409, loss is 0.0018677632227334718 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.13002715400974865 and mu_y: 0.0028010380337493384\n",
      "3410, loss is 0.0018677379663169088 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12999906836583536 and mu_y: 0.0027593542184813605\n",
      "3411, loss is 0.0018677127379713343 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12997099891064587 and mu_y: 0.002717693186469403\n",
      "3412, loss is 0.0018676875376628728 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12994294563237166 and mu_y: 0.0026760549237358922\n",
      "3413, loss is 0.0018676623653576933 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12991490851921617 and mu_y: 0.0026344394163150073\n",
      "3414, loss is 0.001867637221022013 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12988688755939468 and mu_y: 0.0025928466502526653\n",
      "3415, loss is 0.0018676121046220981 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12985888274113436 and mu_y: 0.002551276611606506\n",
      "3416, loss is 0.0018675870161242573 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12983089405267426 and mu_y: 0.002509729286445878\n",
      "3417, loss is 0.0018675619554948484 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1298029214822652 and mu_y: 0.0024682046608518198\n",
      "3418, loss is 0.0018675369227002774 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12977496501816985 and mu_y: 0.0024267027209170498\n",
      "3419, loss is 0.001867511917706992 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12974702464866272 and mu_y: 0.002385223452745947\n",
      "3420, loss is 0.0018674869404814913 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1297191003620301 and mu_y: 0.0023437668424545395\n",
      "3421, loss is 0.001867461990990319 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12969119214657002 and mu_y: 0.0023023328761704854\n",
      "3422, loss is 0.0018674370692000639 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12966329999059226 and mu_y: 0.002260921540033062\n",
      "3423, loss is 0.001867412175077362 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1296354238824184 and mu_y: 0.002219532820193149\n",
      "3424, loss is 0.0018673873085888965 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1296075638103817 and mu_y: 0.0021781667028132118\n",
      "3425, loss is 0.001867362469701395 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12957971976282714 and mu_y: 0.00213682317406729\n",
      "3426, loss is 0.001867337658381631 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1295518917281114 and mu_y: 0.002095502220140981\n",
      "3427, loss is 0.0018673128745964258 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12952407969460286 and mu_y: 0.0020542038272314237\n",
      "3428, loss is 0.0018672881183126441 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12949628365068153 and mu_y: 0.002012927981547286\n",
      "3429, loss is 0.001867263389497198 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12946850358473908 and mu_y: 0.0019716746693087487\n",
      "3430, loss is 0.0018672386881170453 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1294407394851788 and mu_y: 0.0019304438767474908\n",
      "3431, loss is 0.001867214014139189 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12941299134041567 and mu_y: 0.0018892355901066755\n",
      "3432, loss is 0.001867189367530677 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12938525913887616 and mu_y: 0.0018480497956409347\n",
      "3433, loss is 0.0018671647482586032 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1293575428689984 and mu_y: 0.0018068864796163546\n",
      "3434, loss is 0.0018671401562901078 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12932984251923205 and mu_y: 0.001765745628310461\n",
      "3435, loss is 0.0018671155915923746 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12930215807803835 and mu_y: 0.0017246272280122044\n",
      "3436, loss is 0.0018670910541326341 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1292744895338901 and mu_y: 0.0016835312650219463\n",
      "3437, loss is 0.0018670665438781607 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12924683687527158 and mu_y: 0.001642457725651443\n",
      "3438, loss is 0.0018670420607962744 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12921920009067858 and mu_y: 0.0016014065962238323\n",
      "3439, loss is 0.0018670176048543414 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12919157916861843 and mu_y: 0.001560377863073619\n",
      "3440, loss is 0.0018669931760197705 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12916397409760988 and mu_y: 0.0015193715125466595\n",
      "3441, loss is 0.001866968774260018 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1291363848661832 and mu_y: 0.0014783875310001478\n",
      "3442, loss is 0.0018669443995425821 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12910881146288006 and mu_y: 0.001437425904802601\n",
      "3443, loss is 0.0018669200518350074 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12908125387625358 and mu_y: 0.0013964866203338454\n",
      "3444, loss is 0.0018668957311048832 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1290537120948683 and mu_y: 0.0013555696639850007\n",
      "3445, loss is 0.0018668714373198437 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12902618610730016 and mu_y: 0.001314675022158467\n",
      "3446, loss is 0.0018668471704475665 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12899867590213648 and mu_y: 0.0012738026812679096\n",
      "3447, loss is 0.0018668229304557734 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12897118146797598 and mu_y: 0.0012329526277382447\n",
      "3448, loss is 0.0018667987173122329 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1289437027934287 and mu_y: 0.0011921248480056257\n",
      "3449, loss is 0.001866774530984754 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12891623986711603 and mu_y: 0.0011513193285174284\n",
      "3450, loss is 0.0018667503714411928 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1288887926776707 and mu_y: 0.0011105360557322364\n",
      "3451, loss is 0.001866726238649449 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12886136121373673 and mu_y: 0.0010697750161198277\n",
      "3452, loss is 0.0018667021325774657 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12883394546396945 and mu_y: 0.0010290361961611597\n",
      "3453, loss is 0.0018666780531932312 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12880654541703546 and mu_y: 0.0009883195823483554\n",
      "3454, loss is 0.0018666540004647755 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12877916106161263 and mu_y: 0.0009476251611846891\n",
      "3455, loss is 0.0018666299743601744 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12875179238639012 and mu_y: 0.0009069529191845722\n",
      "3456, loss is 0.0018666059748475461 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12872443938006825 and mu_y: 0.0008663028428735394\n",
      "3457, loss is 0.0018665820018950554 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12869710203135862 and mu_y: 0.0008256749187882338\n",
      "3458, loss is 0.0018665580554709058 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12866978032898402 and mu_y: 0.000785069133476394\n",
      "3459, loss is 0.0018665341355433487 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12864247426167844 and mu_y: 0.0007444854734968388\n",
      "3460, loss is 0.0018665102420806767 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.128615183818187 and mu_y: 0.0007039239254194538\n",
      "3461, loss is 0.0018664863750512267 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12858790898726605 and mu_y: 0.0006633844758251777\n",
      "3462, loss is 0.0018664625344233785 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12856064975768303 and mu_y: 0.0006228671113059876\n",
      "3463, loss is 0.0018664387201655552 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12853340611821654 and mu_y: 0.0005823718184648854\n",
      "3464, loss is 0.0018664149322462232 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12850617805765632 and mu_y: 0.000541898583915884\n",
      "3465, loss is 0.001866391170633893 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12847896556480315 and mu_y: 0.0005014473942839931\n",
      "3466, loss is 0.001866367435297116 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12845176862846897 and mu_y: 0.00046101823620520513\n",
      "3467, loss is 0.0018663437262044884 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1284245872374767 and mu_y: 0.00042061109632648215\n",
      "3468, loss is 0.0018663200433246471 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12839742138066046 and mu_y: 0.0003802259613057412\n",
      "3469, loss is 0.0018662963866262758 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12837027104686524 and mu_y: 0.0003398628178118409\n",
      "3470, loss is 0.0018662727560780975 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1283431362249472 and mu_y: 0.00029952165252456744\n",
      "3471, loss is 0.0018662491516488779 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12831601690377345 and mu_y: 0.00025920245213462086\n",
      "3472, loss is 0.001866225573307428 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12828891307222212 and mu_y: 0.0002189052033436015\n",
      "3473, loss is 0.0018662020210225983 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12826182471918232 and mu_y: 0.00017862989286399595\n",
      "3474, loss is 0.0018661784947632842 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12823475183355412 and mu_y: 0.00013837650741916355\n",
      "3475, loss is 0.0018661549944984227 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12820769440424856 and mu_y: 9.814503374332269e-05\n",
      "3476, loss is 0.0018661315201969923 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1281806524201876 and mu_y: 5.7935458581537015e-05\n",
      "3477, loss is 0.0018661080718280145 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12815362587030418 and mu_y: 1.774776868970191e-05\n",
      "3478, loss is 0.0018660846493605537 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1281266147435421 and mu_y: -2.2418049165469162e-05\n",
      "3479, loss is 0.001866061252763714 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12809961902885605 and mu_y: -6.256200820645819e-05\n",
      "3480, loss is 0.0018660378820066453 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12807263871521168 and mu_y: -0.00010268412164495634\n",
      "3481, loss is 0.0018660145370585366 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12804567379158546 and mu_y: -0.00014278440268187726\n",
      "3482, loss is 0.0018659912178886193 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1280187242469647 and mu_y: -0.00018286286450737088\n",
      "3483, loss is 0.0018659679244661673 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12799179007034756 and mu_y: -0.00022291952030083667\n",
      "3484, loss is 0.0018659446567604958 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12796487125074305 and mu_y: -0.0002629543832309373\n",
      "3485, loss is 0.0018659214147409627 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12793796777717098 and mu_y: -0.000302967466455612\n",
      "3486, loss is 0.0018658981983769671 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12791107963866197 and mu_y: -0.00034295878312208994\n",
      "3487, loss is 0.0018658750076379486 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12788420682425738 and mu_y: -0.0003829283463669038\n",
      "3488, loss is 0.0018658518424933893 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1278573493230094 and mu_y: -0.000422876169315903\n",
      "3489, loss is 0.0018658287029128123 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12783050712398095 and mu_y: -0.0004628022650842673\n",
      "3490, loss is 0.0018658055888657829 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1278036802162457 and mu_y: -0.0005027066467765197\n",
      "3491, loss is 0.0018657825003219072 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.127776868588888 and mu_y: -0.0005425893274865403\n",
      "3492, loss is 0.0018657594372508335 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.127750072231003 and mu_y: -0.0005824503202975791\n",
      "3493, loss is 0.001865736399622249 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12772329113169645 and mu_y: -0.0006222896382822697\n",
      "3494, loss is 0.0018657133874058836 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12769652528008488 and mu_y: -0.0006621072945026424\n",
      "3495, loss is 0.0018656904005715097 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12766977466529544 and mu_y: -0.0007019033020101371\n",
      "3496, loss is 0.0018656674390889368 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12764303927646595 and mu_y: -0.000741677673845617\n",
      "3497, loss is 0.001865644502928018 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12761631910274487 and mu_y: -0.0007814304230393818\n",
      "3498, loss is 0.0018656215920586474 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12758961413329128 and mu_y: -0.0008211615626111802\n",
      "3499, loss is 0.0018655987064507603 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12756292435727493 and mu_y: -0.0008608711055702239\n",
      "3500, loss is 0.00186557584607433 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12753624976387606 and mu_y: -0.0009005590649152001\n",
      "3501, loss is 0.0018655530108993728 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12750959034228562 and mu_y: -0.0009402254536342847\n",
      "3502, loss is 0.0018655302008959455 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12748294608170507 and mu_y: -0.0009798702847051558\n",
      "3503, loss is 0.0018655074160341446 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12745631697134643 and mu_y: -0.0010194935710950061\n",
      "3504, loss is 0.0018654846562841075 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12742970300043227 and mu_y: -0.0010590953257605567\n",
      "3505, loss is 0.001865461921616012 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12740310415819572 and mu_y: -0.0010986755616480693\n",
      "3506, loss is 0.0018654392120000748 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1273765204338804 and mu_y: -0.00113823429169336\n",
      "3507, loss is 0.0018654165274065559 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12734995181674044 and mu_y: -0.001177771528821811\n",
      "3508, loss is 0.0018653938678057527 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12732339829604047 and mu_y: -0.0012172872859483853\n",
      "3509, loss is 0.0018653712331680036 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1272968598610556 and mu_y: -0.0012567815759776382\n",
      "3510, loss is 0.0018653486234636888 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1272703365010714 and mu_y: -0.001296254411803731\n",
      "3511, loss is 0.0018653260386632254 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12724382820538385 and mu_y: -0.0013357058063104435\n",
      "3512, loss is 0.001865303478737073 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12721733496329943 and mu_y: -0.0013751357723711867\n",
      "3513, loss is 0.00186528094365573 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12719085676413502 and mu_y: -0.0014145443228490162\n",
      "3514, loss is 0.0018652584333897339 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1271643935972179 and mu_y: -0.0014539314705966444\n",
      "3515, loss is 0.0018652359479096633 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12713794545188575 and mu_y: -0.0014932972284564538\n",
      "3516, loss is 0.001865213487186136 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12711151231748663 and mu_y: -0.0015326416092605096\n",
      "3517, loss is 0.0018651910511898093 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.127085094183379 and mu_y: -0.0015719646258305722\n",
      "3518, loss is 0.0018651686398913796 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12705869103893158 and mu_y: -0.0016112662909781104\n",
      "3519, loss is 0.0018651462532615847 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12703230287352357 and mu_y: -0.0016505466175043137\n",
      "3520, loss is 0.0018651238912711988 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1270059296765444 and mu_y: -0.0016898056182001052\n",
      "3521, loss is 0.0018651015538910382 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12697957143739383 and mu_y: -0.0017290433058461542\n",
      "3522, loss is 0.001865079241091956 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12695322814548196 and mu_y: -0.0017682596932128887\n",
      "3523, loss is 0.0018650569528448485 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12692689979022914 and mu_y: -0.0018074547930605083\n",
      "3524, loss is 0.0018650346891206462 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.126900586361066 and mu_y: -0.0018466286181389967\n",
      "3525, loss is 0.001865012449890322 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12687428784743343 and mu_y: -0.0018857811811881344\n",
      "3526, loss is 0.0018649902351248865 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1268480042387826 and mu_y: -0.0019249124949375107\n",
      "3527, loss is 0.0018649680447953905 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12682173552457485 and mu_y: -0.0019640225721065372\n",
      "3528, loss is 0.0018649458788729222 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12679548169428181 and mu_y: -0.002003111425404459\n",
      "3529, loss is 0.0018649237373286106 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1267692427373853 and mu_y: -0.002042179067530369\n",
      "3530, loss is 0.0018649016201336217 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12674301864337728 and mu_y: -0.002081225511173219\n",
      "3531, loss is 0.0018648795272591602 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12671680940175997 and mu_y: -0.002120250769011832\n",
      "3532, loss is 0.0018648574586764706 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1266906150020457 and mu_y: -0.002159254853714915\n",
      "3533, loss is 0.0018648354143568358 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.126664435433757 and mu_y: -0.0021982377779410727\n",
      "3534, loss is 0.0018648133942715775 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12663827068642647 and mu_y: -0.002237199554338818\n",
      "3535, loss is 0.001864791398392054 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12661212074959693 and mu_y: -0.002276140195546585\n",
      "3536, loss is 0.0018647694266896646 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12658598561282128 and mu_y: -0.0023150597141927414\n",
      "3537, loss is 0.0018647474791358457 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12655986526566249 and mu_y: -0.002353958122895602\n",
      "3538, loss is 0.0018647255557020718 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12653375969769365 and mu_y: -0.0023928354342634384\n",
      "3539, loss is 0.001864703656359855 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12650766889849793 and mu_y: -0.002431691660894494\n",
      "3540, loss is 0.001864681781080749 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12648159285766855 and mu_y: -0.0024705268153769945\n",
      "3541, loss is 0.0018646599298363402 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12645553156480877 and mu_y: -0.002509340910289161\n",
      "3542, loss is 0.001864638102598258 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1264294850095319 and mu_y: -0.0025481339581992215\n",
      "3543, loss is 0.0018646162993381677 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12640345318146132 and mu_y: -0.002586905971665424\n",
      "3544, loss is 0.0018645945200277709 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1263774360702303 and mu_y: -0.0026256569632360483\n",
      "3545, loss is 0.0018645727646388116 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12635143366548224 and mu_y: -0.002664386945449418\n",
      "3546, loss is 0.001864551033143066 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12632544595687045 and mu_y: -0.002703095930833913\n",
      "3547, loss is 0.0018645293255123527 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12629947293405824 and mu_y: -0.0027417839319079807\n",
      "3548, loss is 0.0018645076417185265 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12627351458671887 and mu_y: -0.0027804509611801496\n",
      "3549, loss is 0.0018644859817334774 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12624757090453556 and mu_y: -0.002819097031149041\n",
      "3550, loss is 0.0018644643455291365 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12622164187720142 and mu_y: -0.0028577221543033787\n",
      "3551, loss is 0.0018644427330774716 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12619572749441954 and mu_y: -0.0028963263431220055\n",
      "3552, loss is 0.0018644211443504862 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12616982774590288 and mu_y: -0.002934909610073891\n",
      "3553, loss is 0.0018643995793202223 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12614394262137432 and mu_y: -0.0029734719676181463\n",
      "3554, loss is 0.001864378037958761 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12611807211056658 and mu_y: -0.0030120134282040347\n",
      "3555, loss is 0.0018643565202382177 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1260922162032223 and mu_y: -0.003050534004270984\n",
      "3556, loss is 0.0018643350261307455 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12606637488909397 and mu_y: -0.0030890337082485984\n",
      "3557, loss is 0.0018643135556085375 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12604054815794388 and mu_y: -0.003127512552556671\n",
      "3558, loss is 0.0018642921086438199 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1260147359995442 and mu_y: -0.0031659705496051944\n",
      "3559, loss is 0.0018642706852088594 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12598893840367686 and mu_y: -0.003204407711794374\n",
      "3560, loss is 0.001864249285275957 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1259631553601337 and mu_y: -0.0032428240515146394\n",
      "3561, loss is 0.0018642279088174523 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12593738685871625 and mu_y: -0.0032812195811466557\n",
      "3562, loss is 0.0018642065558057215 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12591163288923587 and mu_y: -0.003319594313061336\n",
      "3563, loss is 0.0018641852262131775 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1258858934415137 and mu_y: -0.0033579482596198524\n",
      "3564, loss is 0.00186416392001227 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12586016850538062 and mu_y: -0.0033962814331736494\n",
      "3565, loss is 0.0018641426371754837 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12583445807067722 and mu_y: -0.003434593846064454\n",
      "3566, loss is 0.0018641213776753427 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12580876212725386 and mu_y: -0.0034728855106242874\n",
      "3567, loss is 0.0018641001414844065 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12578308066497063 and mu_y: -0.003511156439175479\n",
      "3568, loss is 0.0018640789285752708 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12575741367369728 and mu_y: -0.0035494066440306758\n",
      "3569, loss is 0.0018640577389205683 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1257317611433133 and mu_y: -0.0035876361374928543\n",
      "3570, loss is 0.001864036572492967 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12570612306370785 and mu_y: -0.0036258449318553334\n",
      "3571, loss is 0.0018640154292651726 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1256804994247797 and mu_y: -0.003664033039401785\n",
      "3572, loss is 0.0018639943092099262 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1256548902164374 and mu_y: -0.003702200472406246\n",
      "3573, loss is 0.0018639732123000065 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.125629295428599 and mu_y: -0.0037403472431331306\n",
      "3574, loss is 0.001863952138508226 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12560371505119228 and mu_y: -0.00377847336383724\n",
      "3575, loss is 0.0018639310878074355 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12557814907415463 and mu_y: -0.003816578846763776\n",
      "3576, loss is 0.0018639100601705201 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.125552597487433 and mu_y: -0.003854663704148352\n",
      "3577, loss is 0.001863889055570403 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12552706028098395 and mu_y: -0.0038927279482170035\n",
      "3578, loss is 0.0018638680739800414 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1255015374447737 and mu_y: -0.003930771591186201\n",
      "3579, loss is 0.0018638471153724287 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12547602896877788 and mu_y: -0.003968794645262861\n",
      "3580, loss is 0.001863826179720596 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12545053484298185 and mu_y: -0.004006797122644356\n",
      "3581, loss is 0.001863805266997607 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1254250550573804 and mu_y: -0.00404477903551853\n",
      "3582, loss is 0.0018637843771765641 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12539958960197792 and mu_y: -0.004082740396063705\n",
      "3583, loss is 0.0018637635102306035 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12537413846678824 and mu_y: -0.004120681216448696\n",
      "3584, loss is 0.0018637426661328967 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1253487016418348 and mu_y: -0.00415860150883282\n",
      "3585, loss is 0.0018637218448566539 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12532327911715044 and mu_y: -0.004196501285365911\n",
      "3586, loss is 0.0018637010463751166 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12529787088277758 and mu_y: -0.004234380558188326\n",
      "3587, loss is 0.001863680270661566 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12527247692876806 and mu_y: -0.0042722393394309605\n",
      "3588, loss is 0.0018636595176893124 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12524709724518315 and mu_y: -0.004310077641215259\n",
      "3589, loss is 0.001863638787431709 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12522173182209365 and mu_y: -0.004347895475653225\n",
      "3590, loss is 0.0018636180798621395 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12519638064957972 and mu_y: -0.004385692854847435\n",
      "3591, loss is 0.0018635973949540233 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12517104371773097 and mu_y: -0.004423469790891046\n",
      "3592, loss is 0.0018635767326808162 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12514572101664645 and mu_y: -0.004461226295867811\n",
      "3593, loss is 0.001863556093016009 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12512041253643458 and mu_y: -0.004498962381852084\n",
      "3594, loss is 0.0018635354759331257 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12509511826721317 and mu_y: -0.00453667806090884\n",
      "3595, loss is 0.0018635148814057274 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1250698381991094 and mu_y: -0.004574373345093679\n",
      "3596, loss is 0.0018634943094074101 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12504457232225985 and mu_y: -0.004612048246452839\n",
      "3597, loss is 0.001863473759911803 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12501932062681043 and mu_y: -0.004649702777023209\n",
      "3598, loss is 0.0018634532328925713 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12499408310291636 and mu_y: -0.004687336948832339\n",
      "3599, loss is 0.001863432728323415 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12496885974074223 and mu_y: -0.004724950773898451\n",
      "3600, loss is 0.0018634122461780684 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12494365053046194 and mu_y: -0.00476254426423045\n",
      "3601, loss is 0.001863391786430301 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12491845546225869 and mu_y: -0.004800117431827934\n",
      "3602, loss is 0.001863371349053916 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12489327452632497 and mu_y: -0.004837670288681209\n",
      "3603, loss is 0.0018633509340227527 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12486810771286255 and mu_y: -0.004875202846771295\n",
      "3604, loss is 0.0018633305413106825 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1248429550120825 and mu_y: -0.004912715118069941\n",
      "3605, loss is 0.0018633101708916131 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12481781641420508 and mu_y: -0.004950207114539634\n",
      "3606, loss is 0.0018632898227394874 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12479269190945987 and mu_y: -0.00498767884813361\n",
      "3607, loss is 0.0018632694968282798 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12476758148808563 and mu_y: -0.005025130330795867\n",
      "3608, loss is 0.0018632491931320008 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12474248514033037 and mu_y: -0.005062561574461173\n",
      "3609, loss is 0.0018632289116246965 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12471740285645132 and mu_y: -0.0050999725910550785\n",
      "3610, loss is 0.0018632086522804435 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12469233462671488 and mu_y: -0.005137363392493928\n",
      "3611, loss is 0.0018631884150733563 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12466728044139665 and mu_y: -0.005174733990684869\n",
      "3612, loss is 0.0018631681999775806 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12464224029078141 and mu_y: -0.005212084397525867\n",
      "3613, loss is 0.0018631480069672976 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12461721416516311 and mu_y: -0.00524941462490571\n",
      "3614, loss is 0.001863127836016722 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12459220205484484 and mu_y: -0.005286724684704025\n",
      "3615, loss is 0.0018631076871001037 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12456720395013882 and mu_y: -0.005324014588791287\n",
      "3616, loss is 0.0018630875601917236 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12454221984136643 and mu_y: -0.0053612843490288276\n",
      "3617, loss is 0.0018630674552659004 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12451724971885815 and mu_y: -0.00539853397726885\n",
      "3618, loss is 0.0018630473722969821 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12449229357295356 and mu_y: -0.005435763485354436\n",
      "3619, loss is 0.0018630273112593535 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12446735139400136 and mu_y: -0.00547297288511956\n",
      "3620, loss is 0.0018630072721274316 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12444242317235932 and mu_y: -0.005510162188389095\n",
      "3621, loss is 0.001862987254875669 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12441750889839426 and mu_y: -0.00554733140697883\n",
      "3622, loss is 0.0018629672594785496 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12439260856248208 and mu_y: -0.0055844805526954755\n",
      "3623, loss is 0.0018629472859105906 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12436772215500773 and mu_y: -0.005621609637336676\n",
      "3624, loss is 0.0018629273341463455 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1243428496663652 and mu_y: -0.005658718672691021\n",
      "3625, loss is 0.0018629074041603974 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12431799108695751 and mu_y: -0.005695807670538054\n",
      "3626, loss is 0.0018628874959273646 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12429314640719669 and mu_y: -0.005732876642648285\n",
      "3627, loss is 0.0018628676094219012 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12426831561750375 and mu_y: -0.005769925600783201\n",
      "3628, loss is 0.00186284774461869 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12424349870830871 and mu_y: -0.005806954556695277\n",
      "3629, loss is 0.0018628279014924504 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12421869567005059 and mu_y: -0.005843963522127984\n",
      "3630, loss is 0.0018628080800179316 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12419390649317735 and mu_y: -0.005880952508815801\n",
      "3631, loss is 0.0018627882801699192 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12416913116814593 and mu_y: -0.005917921528484228\n",
      "3632, loss is 0.0018627685019232294 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1241443696854222 and mu_y: -0.005954870592849793\n",
      "3633, loss is 0.0018627487452527146 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12411962203548096 and mu_y: -0.005991799713620063\n",
      "3634, loss is 0.0018627290101332562 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12409488820880596 and mu_y: -0.006028708902493658\n",
      "3635, loss is 0.0018627092965397705 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12407016819588984 and mu_y: -0.006065598171160256\n",
      "3636, loss is 0.0018626896044472068 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12404546198723415 and mu_y: -0.006102467531300611\n",
      "3637, loss is 0.0018626699338305465 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12402076957334934 and mu_y: -0.006139316994586553\n",
      "3638, loss is 0.001862650284664803 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12399609094475474 and mu_y: -0.006176146572681009\n",
      "3639, loss is 0.0018626306569250245 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1239714260919785 and mu_y: -0.006212956277238007\n",
      "3640, loss is 0.0018626110505862905 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1239467750055577 and mu_y: -0.006249746119902688\n",
      "3641, loss is 0.0018625914656237134 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12392213767603821 and mu_y: -0.006286516112311318\n",
      "3642, loss is 0.0018625719020124375 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12389751409397477 and mu_y: -0.006323266266091295\n",
      "3643, loss is 0.0018625523597276396 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12387290424993093 and mu_y: -0.006359996592861163\n",
      "3644, loss is 0.0018625328387445307 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12384830813447904 and mu_y: -0.0063967071042306195\n",
      "3645, loss is 0.0018625133390383507 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12382372573820027 and mu_y: -0.006433397811800528\n",
      "3646, loss is 0.0018624938605843761 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12379915705168458 and mu_y: -0.006470068727162927\n",
      "3647, loss is 0.001862474403357912 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1237746020655307 and mu_y: -0.00650671986190104\n",
      "3648, loss is 0.001862454967334297 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12375006077034613 and mu_y: -0.006543351227589288\n",
      "3649, loss is 0.0018624355524889031 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12372553315674713 and mu_y: -0.0065799628357932965\n",
      "3650, loss is 0.0018624161587971321 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1237010192153587 and mu_y: -0.0066165546980699085\n",
      "3651, loss is 0.001862396786234421 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12367651893681458 and mu_y: -0.006653126825967193\n",
      "3652, loss is 0.001862377434776235 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12365203231175725 and mu_y: -0.006689679231024456\n",
      "3653, loss is 0.0018623581043980745 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12362755933083788 and mu_y: -0.006726211924772251\n",
      "3654, loss is 0.0018623387950754701 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12360309998471636 and mu_y: -0.006762724918732388\n",
      "3655, loss is 0.0018623195067839842 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12357865426406126 and mu_y: -0.006799218224417945\n",
      "3656, loss is 0.0018623002394992125 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12355422215954982 and mu_y: -0.006835691853333278\n",
      "3657, loss is 0.0018622809931967807 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12352980366186798 and mu_y: -0.006872145816974029\n",
      "3658, loss is 0.001862261767852347 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12350539876171032 and mu_y: -0.00690858012682714\n",
      "3659, loss is 0.0018622425634416022 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12348100744978008 and mu_y: -0.006944994794370859\n",
      "3660, loss is 0.0018622233799402677 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12345662971678913 and mu_y: -0.0069813898310747535\n",
      "3661, loss is 0.0018622042173240946 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12343226555345795 and mu_y: -0.007017765248399718\n",
      "3662, loss is 0.0018621850755688703 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12340791495051566 and mu_y: -0.007054121057797985\n",
      "3663, loss is 0.0018621659546504082 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1233835778987 and mu_y: -0.007090457270713136\n",
      "3664, loss is 0.001862146854544559 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12335925438875726 and mu_y: -0.007126773898580109\n",
      "3665, loss is 0.0018621277752271994 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12333494441144234 and mu_y: -0.007163070952825213\n",
      "3666, loss is 0.0018621087166742398 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12331064795751871 and mu_y: -0.007199348444866134\n",
      "3667, loss is 0.001862089678861622 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12328636501775841 and mu_y: -0.007235606386111943\n",
      "3668, loss is 0.0018620706617653192 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12326209558294203 and mu_y: -0.0072718447879631136\n",
      "3669, loss is 0.0018620516653613352 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12323783964385868 and mu_y: -0.007308063661811525\n",
      "3670, loss is 0.0018620326896257046 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.123213597191306 and mu_y: -0.007344263019040475\n",
      "3671, loss is 0.001862013734534494 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12318936821609021 and mu_y: -0.007380442871024689\n",
      "3672, loss is 0.0018619948000638017 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12316515270902596 and mu_y: -0.00741660322913033\n",
      "3673, loss is 0.001861975886189754 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12314095066093644 and mu_y: -0.007452744104715008\n",
      "3674, loss is 0.0018619569928885107 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12311676206265333 and mu_y: -0.007488865509127792\n",
      "3675, loss is 0.0018619381201362632 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12309258690501677 and mu_y: -0.007524967453709217\n",
      "3676, loss is 0.0018619192679092305 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12306842517887538 and mu_y: -0.007561049949791296\n",
      "3677, loss is 0.0018619004361836668 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12304427687508623 and mu_y: -0.007597113008697528\n",
      "3678, loss is 0.0018618816249358523 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12302014198451484 and mu_y: -0.007633156641742909\n",
      "3679, loss is 0.0018618628341421012 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12299602049803517 and mu_y: -0.0076691808602339425\n",
      "3680, loss is 0.0018618440637787582 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12297191240652958 and mu_y: -0.007705185675468647\n",
      "3681, loss is 0.0018618253138221969 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12294781770088888 and mu_y: -0.007741171098736567\n",
      "3682, loss is 0.0018618065842488218 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12292373637201226 and mu_y: -0.007777137141318784\n",
      "3683, loss is 0.0018617878750350706 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12289966841080731 and mu_y: -0.007813083814487923\n",
      "3684, loss is 0.001861769186157408 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12287561380819 and mu_y: -0.007849011129508168\n",
      "3685, loss is 0.0018617505175923307 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12285157255508468 and mu_y: -0.007884919097635262\n",
      "3686, loss is 0.0018617318693163664 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12282754464242406 and mu_y: -0.007920807730116526\n",
      "3687, loss is 0.001861713241306072 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12280353006114919 and mu_y: -0.007956677038190866\n",
      "3688, loss is 0.0018616946335380344 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12277952880220949 and mu_y: -0.007992527033088781\n",
      "3689, loss is 0.0018616760459888725 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12275554085656268 and mu_y: -0.008028357726032371\n",
      "3690, loss is 0.0018616574786352335 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12273156621517482 and mu_y: -0.008064169128235354\n",
      "3691, loss is 0.0018616389314537961 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12270760486902027 and mu_y: -0.008099961250903065\n",
      "3692, loss is 0.0018616204044212693 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1226836568090817 and mu_y: -0.008135734105232476\n",
      "3693, loss is 0.0018616018975143906 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12265972202635007 and mu_y: -0.008171487702412198\n",
      "3694, loss is 0.0018615834107099287 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12263580051182461 and mu_y: -0.008207222053622492\n",
      "3695, loss is 0.0018615649439846817 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12261189225651282 and mu_y: -0.008242937170035285\n",
      "3696, loss is 0.001861546497315479 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12258799725143048 and mu_y: -0.00827863306281417\n",
      "3697, loss is 0.0018615280706791777 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12256411548760159 and mu_y: -0.00831430974311442\n",
      "3698, loss is 0.0018615096640526652 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12254024695605839 and mu_y: -0.008349967222083\n",
      "3699, loss is 0.001861491277412862 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12251639164784138 and mu_y: -0.008385605510858572\n",
      "3700, loss is 0.0018614729107367133 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12249254955399926 and mu_y: -0.008421224620571507\n",
      "3701, loss is 0.0018614545640011973 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12246872066558893 and mu_y: -0.008456824562343894\n",
      "3702, loss is 0.0018614362371833211 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12244490497367551 and mu_y: -0.008492405347289546\n",
      "3703, loss is 0.001861417930260121 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12242110246933229 and mu_y: -0.008527966986514016\n",
      "3704, loss is 0.0018613996432086627 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12239731314364073 and mu_y: -0.008563509491114603\n",
      "3705, loss is 0.0018613813760060428 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12237353698769049 and mu_y: -0.008599032872180359\n",
      "3706, loss is 0.0018613631286293856 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12234977399257936 and mu_y: -0.008634537140792103\n",
      "3707, loss is 0.0018613449010558465 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12232602414941329 and mu_y: -0.008670022308022426\n",
      "3708, loss is 0.0018613266932626092 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12230228744930637 and mu_y: -0.008705488384935706\n",
      "3709, loss is 0.001861308505226886 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1222785638833808 and mu_y: -0.008740935382588109\n",
      "3710, loss is 0.0018612903369259206 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12225485344276693 and mu_y: -0.008776363312027606\n",
      "3711, loss is 0.0018612721883369855 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12223115611860318 and mu_y: -0.008811772184293978\n",
      "3712, loss is 0.00186125405943738 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1222074719020361 and mu_y: -0.008847162010418828\n",
      "3713, loss is 0.0018612359502044355 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1221838007842203 and mu_y: -0.008882532801425588\n",
      "3714, loss is 0.0018612178606155114 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1221601427563185 and mu_y: -0.008917884568329528\n",
      "3715, loss is 0.0018611997906479963 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12213649780950145 and mu_y: -0.008953217322137769\n",
      "3716, loss is 0.0018611817402793066 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.122112865934948 and mu_y: -0.008988531073849287\n",
      "3717, loss is 0.00186116370948689 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.122089247123845 and mu_y: -0.009023825834454926\n",
      "3718, loss is 0.0018611456982482208 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1220656413673874 and mu_y: -0.009059101614937407\n",
      "3719, loss is 0.001861127706540804 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12204204865677812 and mu_y: -0.009094358426271331\n",
      "3720, loss is 0.0018611097343421731 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12201846898322813 and mu_y: -0.009129596279423202\n",
      "3721, loss is 0.0018610917816298887 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1219949023379564 and mu_y: -0.00916481518535142\n",
      "3722, loss is 0.001861073848381543 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12197134871218991 and mu_y: -0.0092000151550063\n",
      "3723, loss is 0.0018610559345747563 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1219478080971636 and mu_y: -0.00923519619933008\n",
      "3724, loss is 0.001861038040187174 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12192428048412042 and mu_y: -0.009270358329256927\n",
      "3725, loss is 0.0018610201651964751 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12190076586431128 and mu_y: -0.009305501555712947\n",
      "3726, loss is 0.0018610023095803644 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12187726422899504 and mu_y: -0.009340625889616198\n",
      "3727, loss is 0.0018609844733165756 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12185377556943854 and mu_y: -0.009375731341876695\n",
      "3728, loss is 0.0018609666563828727 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1218302998769165 and mu_y: -0.00941081792339642\n",
      "3729, loss is 0.0018609488587570436 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12180683714271164 and mu_y: -0.009445885645069329\n",
      "3730, loss is 0.0018609310804169115 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12178338735811454 and mu_y: -0.009480934517781365\n",
      "3731, loss is 0.0018609133213403216 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12175995051442376 and mu_y: -0.009515964552410465\n",
      "3732, loss is 0.0018608955815051494 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12173652660294569 and mu_y: -0.009550975759826568\n",
      "3733, loss is 0.0018608778608893018 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12171311561499466 and mu_y: -0.009585968150891628\n",
      "3734, loss is 0.0018608601594707103 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12168971754189287 and mu_y: -0.009620941736459616\n",
      "3735, loss is 0.0018608424772273355 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12166633237497036 and mu_y: -0.009655896527376537\n",
      "3736, loss is 0.0018608248141371675 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12164296010556509 and mu_y: -0.00969083253448043\n",
      "3737, loss is 0.0018608071701782221 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12161960072502284 and mu_y: -0.009725749768601388\n",
      "3738, loss is 0.0018607895453285452 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12159625422469723 and mu_y: -0.009760648240561555\n",
      "3739, loss is 0.0018607719395662104 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12157292059594973 and mu_y: -0.009795527961175143\n",
      "3740, loss is 0.0018607543528693193 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12154959983014964 and mu_y: -0.00983038894124844\n",
      "3741, loss is 0.0018607367852160003 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12152629191867403 and mu_y: -0.009865231191579813\n",
      "3742, loss is 0.0018607192365844103 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12150299685290784 and mu_y: -0.009900054722959727\n",
      "3743, loss is 0.0018607017069527363 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12147971462424376 and mu_y: -0.009934859546170745\n",
      "3744, loss is 0.0018606841962991892 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12145644522408228 and mu_y: -0.009969645671987538\n",
      "3745, loss is 0.0018606667046020113 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12143318864383165 and mu_y: -0.010004413111176898\n",
      "3746, loss is 0.0018606492318394702 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12140994487490793 and mu_y: -0.010039161874497745\n",
      "3747, loss is 0.001860631777989862 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1213867139087349 and mu_y: -0.010073891972701133\n",
      "3748, loss is 0.0018606143430315103 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12136349573674411 and mu_y: -0.010108603416530264\n",
      "3749, loss is 0.0018605969269427682 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12134029035037484 and mu_y: -0.010143296216720492\n",
      "3750, loss is 0.0018605795297020136 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1213170977410741 and mu_y: -0.010177970383999332\n",
      "3751, loss is 0.0018605621512876526 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12129391790029662 and mu_y: -0.010212625929086472\n",
      "3752, loss is 0.0018605447916781198 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12127075081950482 and mu_y: -0.01024726286269378\n",
      "3753, loss is 0.0018605274508518772 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12124759649016888 and mu_y: -0.010281881195525311\n",
      "3754, loss is 0.001860510128787413 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1212244549037666 and mu_y: -0.01031648093827732\n",
      "3755, loss is 0.0018604928254632451 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12120132605178352 and mu_y: -0.010351062101638265\n",
      "3756, loss is 0.001860475540857915 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12117820992571282 and mu_y: -0.010385624696288821\n",
      "3757, loss is 0.001860458274949996 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12115510651705537 and mu_y: -0.010420168732901885\n",
      "3758, loss is 0.0018604410277180835 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12113201581731967 and mu_y: -0.010454694222142588\n",
      "3759, loss is 0.0018604237991408066 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12110893781802187 and mu_y: -0.010489201174668297\n",
      "3760, loss is 0.001860406589196815 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12108587251068578 and mu_y: -0.010523689601128632\n",
      "3761, loss is 0.001860389397864791 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12106281988684281 and mu_y: -0.010558159512165469\n",
      "3762, loss is 0.0018603722251234387 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.121039779938032 and mu_y: -0.01059261091841295\n",
      "3763, loss is 0.0018603550709514944 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12101675265579999 and mu_y: -0.010627043830497495\n",
      "3764, loss is 0.0018603379353277173 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12099373803170103 and mu_y: -0.010661458259037802\n",
      "3765, loss is 0.001860320818230897 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12097073605729697 and mu_y: -0.010695854214644866\n",
      "3766, loss is 0.001860303719639847 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1209477467241572 and mu_y: -0.01073023170792198\n",
      "3767, loss is 0.00186028663953341 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12092477002385872 and mu_y: -0.010764590749464745\n",
      "3768, loss is 0.0018602695778904548 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12090180594798608 and mu_y: -0.01079893134986108\n",
      "3769, loss is 0.0018602525346898767 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12087885448813139 and mu_y: -0.010833253519691234\n",
      "3770, loss is 0.0018602355099105968 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12085591563589429 and mu_y: -0.010867557269527784\n",
      "3771, loss is 0.0018602185035315648 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12083298938288196 and mu_y: -0.010901842609935652\n",
      "3772, loss is 0.001860201515531757 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12081007572070912 and mu_y: -0.010936109551472114\n",
      "3773, loss is 0.0018601845458901744 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12078717464099799 and mu_y: -0.010970358104686802\n",
      "3774, loss is 0.0018601675945858478 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1207642861353783 and mu_y: -0.01100458828012172\n",
      "3775, loss is 0.001860150661597831 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1207414101954873 and mu_y: -0.011038800088311245\n",
      "3776, loss is 0.001860133746905207 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1207185468129697 and mu_y: -0.011072993539782139\n",
      "3777, loss is 0.001860116850487083 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12069569597947771 and mu_y: -0.01110716864505356\n",
      "3778, loss is 0.0018600999723225957 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.120672857686671 and mu_y: -0.011141325414637065\n",
      "3779, loss is 0.0018600831123909054 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12065003192621672 and mu_y: -0.011175463859036623\n",
      "3780, loss is 0.0018600662706712017 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12062721868978946 and mu_y: -0.01120958398874862\n",
      "3781, loss is 0.0018600494471426956 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12060441796907125 and mu_y: -0.01124368581426187\n",
      "3782, loss is 0.0018600326417846295 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12058162975575155 and mu_y: -0.011277769346057618\n",
      "3783, loss is 0.0018600158545762702 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12055885404152727 and mu_y: -0.01131183459460956\n",
      "3784, loss is 0.0018599990854969108 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12053609081810274 and mu_y: -0.011345881570383834\n",
      "3785, loss is 0.0018599823345258686 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12051334007718967 and mu_y: -0.011379910283839044\n",
      "3786, loss is 0.0018599656016424914 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12049060181050719 and mu_y: -0.011413920745426262\n",
      "3787, loss is 0.001859948886826149 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12046787600978182 and mu_y: -0.011447912965589033\n",
      "3788, loss is 0.0018599321900562382 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12044516266674744 and mu_y: -0.01148188695476339\n",
      "3789, loss is 0.0018599155113121846 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12042246177314535 and mu_y: -0.011515842723377858\n",
      "3790, loss is 0.0018598988505734357 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12039977332072417 and mu_y: -0.01154978028185346\n",
      "3791, loss is 0.0018598822078194682 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1203770973012399 and mu_y: -0.011583699640603731\n",
      "3792, loss is 0.0018598655830297827 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12035443370645586 and mu_y: -0.011617600810034724\n",
      "3793, loss is 0.001859848976183906 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12033178252814275 and mu_y: -0.011651483800545015\n",
      "3794, loss is 0.0018598323872613925 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12030914375807857 and mu_y: -0.011685348622525715\n",
      "3795, loss is 0.00185981581624182 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12028651738804863 and mu_y: -0.011719195286360479\n",
      "3796, loss is 0.0018597992631047937 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12026390340984558 and mu_y: -0.011753023802425506\n",
      "3797, loss is 0.0018597827278299436 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12024130181526935 and mu_y: -0.01178683418108956\n",
      "3798, loss is 0.0018597662103969248 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12021871259612718 and mu_y: -0.011820626432713966\n",
      "3799, loss is 0.0018597497107854205 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12019613574423359 and mu_y: -0.011854400567652626\n",
      "3800, loss is 0.0018597332289751385 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12017357125141037 and mu_y: -0.011888156596252022\n",
      "3801, loss is 0.001859716764945808 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1201510191094866 and mu_y: -0.01192189452885123\n",
      "3802, loss is 0.0018597003186771918 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12012847931029857 and mu_y: -0.011955614375781923\n",
      "3803, loss is 0.0018596838901490714 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12010595184568988 and mu_y: -0.011989316147368378\n",
      "3804, loss is 0.001859667479341256 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12008343670751134 and mu_y: -0.012022999853927489\n",
      "3805, loss is 0.0018596510862335818 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12006093388762099 and mu_y: -0.012056665505768773\n",
      "3806, loss is 0.001859634710805908 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1200384433778841 and mu_y: -0.012090313113194378\n",
      "3807, loss is 0.0018596183530381202 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.12001596517017316 and mu_y: -0.012123942686499085\n",
      "3808, loss is 0.0018596020129101282 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11999349925636785 and mu_y: -0.01215755423597033\n",
      "3809, loss is 0.0018595856904018702 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11997104562835507 and mu_y: -0.012191147771888195\n",
      "3810, loss is 0.0018595693854933054 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11994860427802892 and mu_y: -0.012224723304525432\n",
      "3811, loss is 0.0018595530981644222 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11992617519729064 and mu_y: -0.01225828084414746\n",
      "3812, loss is 0.001859536828395231 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11990375837804867 and mu_y: -0.012291820401012376\n",
      "3813, loss is 0.001859520576165769 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11988135381221862 and mu_y: -0.012325341985370965\n",
      "3814, loss is 0.0018595043414560983 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11985896149172323 and mu_y: -0.012358845607466704\n",
      "3815, loss is 0.0018594881242463054 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1198365814084924 and mu_y: -0.012392331277535773\n",
      "3816, loss is 0.0018594719245165021 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11981421355446319 and mu_y: -0.012425799005807063\n",
      "3817, loss is 0.0018594557422468257 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11979185792157974 and mu_y: -0.01245924880250218\n",
      "3818, loss is 0.0018594395774174381 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11976951450179336 and mu_y: -0.012492680677835459\n",
      "3819, loss is 0.001859423430008527 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11974718328706246 and mu_y: -0.012526094642013966\n",
      "3820, loss is 0.0018594073000003024 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11972486426935254 and mu_y: -0.01255949070523751\n",
      "3821, loss is 0.0018593911873730018 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1197025574406362 and mu_y: -0.01259286887769865\n",
      "3822, loss is 0.0018593750921068858 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11968026279289314 and mu_y: -0.0126262291695827\n",
      "3823, loss is 0.0018593590141822408 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11965798031811012 and mu_y: -0.012659571591067738\n",
      "3824, loss is 0.001859342953579378 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11963571000828098 and mu_y: -0.012692896152324619\n",
      "3825, loss is 0.0018593269102786317 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11961345185540663 and mu_y: -0.012726202863516972\n",
      "3826, loss is 0.0018593108842603623 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11959120585149503 and mu_y: -0.012759491734801221\n",
      "3827, loss is 0.0018592948755049561 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11956897198856119 and mu_y: -0.01279276277632658\n",
      "3828, loss is 0.0018592788839928208 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11954675025862713 and mu_y: -0.01282601599823507\n",
      "3829, loss is 0.0018592629097043908 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11952454065372192 and mu_y: -0.012859251410661524\n",
      "3830, loss is 0.001859246952620124 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11950234316588165 and mu_y: -0.012892469023733592\n",
      "3831, loss is 0.0018592310127205035 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11948015778714943 and mu_y: -0.012925668847571748\n",
      "3832, loss is 0.0018592150899860366 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11945798450957536 and mu_y: -0.012958850892289308\n",
      "3833, loss is 0.0018591991843972544 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11943582332521653 and mu_y: -0.012992015167992423\n",
      "3834, loss is 0.0018591832959347146 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11941367422613704 and mu_y: -0.0130251616847801\n",
      "3835, loss is 0.0018591674245789953 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11939153720440794 and mu_y: -0.013058290452744196\n",
      "3836, loss is 0.0018591515703107022 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11936941225210727 and mu_y: -0.01309140148196944\n",
      "3837, loss is 0.001859135733110464 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11934729936132003 and mu_y: -0.013124494782533433\n",
      "3838, loss is 0.0018591199129589344 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11932519852413817 and mu_y: -0.01315757036450665\n",
      "3839, loss is 0.0018591041098367906 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11930310973266058 and mu_y: -0.01319062823795246\n",
      "3840, loss is 0.001859088323724733 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11928103297899309 and mu_y: -0.013223668412927126\n",
      "3841, loss is 0.0018590725546034884 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11925896825524848 and mu_y: -0.013256690899479815\n",
      "3842, loss is 0.0018590568024538052 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11923691555354643 and mu_y: -0.013289695707652604\n",
      "3843, loss is 0.0018590410672564585 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11921487486601352 and mu_y: -0.013322682847480487\n",
      "3844, loss is 0.0018590253489922447 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11919284618478326 and mu_y: -0.013355652328991387\n",
      "3845, loss is 0.0018590096476419871 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11917082950199606 and mu_y: -0.013388604162206157\n",
      "3846, loss is 0.0018589939631865303 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11914882480979919 and mu_y: -0.013421538357138591\n",
      "3847, loss is 0.0018589782956067434 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11912683210034682 and mu_y: -0.013454454923795435\n",
      "3848, loss is 0.0018589626448835194 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11910485136579997 and mu_y: -0.013487353872176387\n",
      "3849, loss is 0.0018589470109977781 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11908288259832657 and mu_y: -0.013520235212274112\n",
      "3850, loss is 0.0018589313939304571 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11906092579010136 and mu_y: -0.013553098954074241\n",
      "3851, loss is 0.0018589157936625244 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11903898093330595 and mu_y: -0.01358594510755539\n",
      "3852, loss is 0.0018589002101749668 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11901704802012879 and mu_y: -0.013618773682689156\n",
      "3853, loss is 0.0018588846434487967 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11899512704276514 and mu_y: -0.01365158468944013\n",
      "3854, loss is 0.00185886909346505 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11897321799341712 and mu_y: -0.013684378137765903\n",
      "3855, loss is 0.0018588535602047868 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11895132086429362 and mu_y: -0.013717154037617078\n",
      "3856, loss is 0.0018588380436490894 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11892943564761037 and mu_y: -0.013749912398937272\n",
      "3857, loss is 0.0018588225437790656 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1189075623355899 and mu_y: -0.013782653231663122\n",
      "3858, loss is 0.0018588070605758446 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11888570092046151 and mu_y: -0.013815376545724296\n",
      "3859, loss is 0.00185879159402058 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1188638513944613 and mu_y: -0.013848082351043504\n",
      "3860, loss is 0.0018587761440944507 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11884201374983214 and mu_y: -0.013880770657536498\n",
      "3861, loss is 0.0018587607107786552 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11882018797882365 and mu_y: -0.01391344147511208\n",
      "3862, loss is 0.0018587452940544184 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11879837407369226 and mu_y: -0.013946094813672118\n",
      "3863, loss is 0.0018587298939029878 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1187765720267011 and mu_y: -0.013978730683111543\n",
      "3864, loss is 0.0018587145103056346 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11875478183012006 and mu_y: -0.01401134909331836\n",
      "3865, loss is 0.001858699143243651 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11873300347622577 and mu_y: -0.014043950054173656\n",
      "3866, loss is 0.0018586837926983565 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11871123695730158 and mu_y: -0.014076533575551612\n",
      "3867, loss is 0.0018586684586510897 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11868948226563757 and mu_y: -0.014109099667319498\n",
      "3868, loss is 0.0018586531410832142 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11866773939353051 and mu_y: -0.014141648339337693\n",
      "3869, loss is 0.0018586378399761188 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11864600833328391 and mu_y: -0.014174179601459684\n",
      "3870, loss is 0.0018586225553112123 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11862428907720794 and mu_y: -0.014206693463532078\n",
      "3871, loss is 0.0018586072870699264 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11860258161761948 and mu_y: -0.014239189935394607\n",
      "3872, loss is 0.0018585920352337192 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11858088594684209 and mu_y: -0.014271669026880134\n",
      "3873, loss is 0.001858576799784069 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11855920205720598 and mu_y: -0.014304130747814666\n",
      "3874, loss is 0.001858561580702477 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11853752994104805 and mu_y: -0.014336575108017353\n",
      "3875, loss is 0.0018585463779704702 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11851586959071184 and mu_y: -0.014369002117300501\n",
      "3876, loss is 0.0018585311915695942 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11849422099854755 and mu_y: -0.014401411785469578\n",
      "3877, loss is 0.0018585160214814214 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11847258415691202 and mu_y: -0.014433804122323219\n",
      "3878, loss is 0.0018585008676875459 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11845095905816871 and mu_y: -0.014466179137653237\n",
      "3879, loss is 0.0018584857301695828 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11842934569468773 and mu_y: -0.014498536841244625\n",
      "3880, loss is 0.0018584706089091732 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11840774405884578 and mu_y: -0.014530877242875571\n",
      "3881, loss is 0.0018584555038879767 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1183861541430262 and mu_y: -0.014563200352317457\n",
      "3882, loss is 0.0018584404150876796 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1183645759396189 and mu_y: -0.014595506179334868\n",
      "3883, loss is 0.0018584253424899898 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1183430094410204 and mu_y: -0.014627794733685601\n",
      "3884, loss is 0.0018584102860766374 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11832145463963381 and mu_y: -0.014660066025120677\n",
      "3885, loss is 0.0018583952458293737 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11829991152786881 and mu_y: -0.014692320063384338\n",
      "3886, loss is 0.0018583802217299766 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11827838009814168 and mu_y: -0.014724556858214059\n",
      "3887, loss is 0.0018583652137602413 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11825686034287522 and mu_y: -0.014756776419340555\n",
      "3888, loss is 0.0018583502219019898 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11823535225449881 and mu_y: -0.01478897875648779\n",
      "3889, loss is 0.001858335246137065 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11821385582544838 and mu_y: -0.01482116387937298\n",
      "3890, loss is 0.0018583202864473323 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11819237104816639 and mu_y: -0.014853331797706603\n",
      "3891, loss is 0.0018583053428146794 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11817089791510185 and mu_y: -0.014885482521192405\n",
      "3892, loss is 0.0018582904152210171 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11814943641871029 and mu_y: -0.014917616059527407\n",
      "3893, loss is 0.001858275503648277 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11812798655145373 and mu_y: -0.014949732422401912\n",
      "3894, loss is 0.0018582606080784153 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11810654830580074 and mu_y: -0.014981831619499512\n",
      "3895, loss is 0.0018582457284934085 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11808512167422637 and mu_y: -0.015013913660497095\n",
      "3896, loss is 0.0018582308648752567 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11806370664921217 and mu_y: -0.015045978555064853\n",
      "3897, loss is 0.0018582160172059801 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11804230322324619 and mu_y: -0.015078026312866288\n",
      "3898, loss is 0.0018582011854676253 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11802091138882292 and mu_y: -0.015110056943558218\n",
      "3899, loss is 0.0018581863696422562 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11799953113844339 and mu_y: -0.015142070456790786\n",
      "3900, loss is 0.001858171569711963 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11797816246461502 and mu_y: -0.015174066862207467\n",
      "3901, loss is 0.0018581567856588552 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11795680535985174 and mu_y: -0.01520604616944507\n",
      "3902, loss is 0.0018581420174650651 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11793545981667392 and mu_y: -0.015238008388133752\n",
      "3903, loss is 0.0018581272651127475 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11791412582760835 and mu_y: -0.01526995352789702\n",
      "3904, loss is 0.0018581125285840787 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11789280338518827 and mu_y: -0.015301881598351741\n",
      "3905, loss is 0.0018580978078612579 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11787149248195336 and mu_y: -0.015333792609108146\n",
      "3906, loss is 0.0018580831029265058 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1178501931104497 and mu_y: -0.01536568656976984\n",
      "3907, loss is 0.001858068413762064 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11782890526322978 and mu_y: -0.015397563489933807\n",
      "3908, loss is 0.001858053740350198 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11780762893285253 and mu_y: -0.015429423379190415\n",
      "3909, loss is 0.001858039082673194 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11778636411188323 and mu_y: -0.015461266247123425\n",
      "3910, loss is 0.0018580244407133584 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11776511079289358 and mu_y: -0.015493092103310001\n",
      "3911, loss is 0.001858009814453022 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11774386896846165 and mu_y: -0.01552490095732071\n",
      "3912, loss is 0.0018579952038745374 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11772263863117188 and mu_y: -0.015556692818719534\n",
      "3913, loss is 0.0018579806089602763 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1177014197736151 and mu_y: -0.015588467697063875\n",
      "3914, loss is 0.0018579660296926357 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1176802123883885 and mu_y: -0.015620225601904562\n",
      "3915, loss is 0.0018579514660540303 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11765901646809558 and mu_y: -0.015651966542785858\n",
      "3916, loss is 0.0018579369180269005 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11763783200534625 and mu_y: -0.015683690529245464\n",
      "3917, loss is 0.0018579223855937045 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1176166589927567 and mu_y: -0.01571539757081453\n",
      "3918, loss is 0.001857907868736925 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11759549742294949 and mu_y: -0.015747087677017664\n",
      "3919, loss is 0.0018578933674390655 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11757434728855348 and mu_y: -0.01577876085737293\n",
      "3920, loss is 0.0018578788816826495 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11755320858220386 and mu_y: -0.015810417121391855\n",
      "3921, loss is 0.0018578644114502236 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11753208129654213 and mu_y: -0.01584205647857945\n",
      "3922, loss is 0.0018578499567243555 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11751096542421609 and mu_y: -0.015873678938434204\n",
      "3923, loss is 0.0018578355174876345 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11748986095787982 and mu_y: -0.01590528451044809\n",
      "3924, loss is 0.0018578210937226704 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1174687678901937 and mu_y: -0.015936873204106576\n",
      "3925, loss is 0.001857806685412096 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11744768621382438 and mu_y: -0.015968445028888636\n",
      "3926, loss is 0.0018577922925385635 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11742661592144481 and mu_y: -0.015999999994266746\n",
      "3927, loss is 0.0018577779150847486 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11740555700573417 and mu_y: -0.016031538109706898\n",
      "3928, loss is 0.0018577635530333454 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11738450945937794 and mu_y: -0.016063059384668604\n",
      "3929, loss is 0.0018577492063670724 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1173634732750678 and mu_y: -0.016094563828604906\n",
      "3930, loss is 0.0018577348750686666 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11734244844550171 and mu_y: -0.01612605145096238\n",
      "3931, loss is 0.0018577205591208882 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11732143496338385 and mu_y: -0.016157522261181143\n",
      "3932, loss is 0.001857706258506518 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11730043282142463 and mu_y: -0.01618897626869486\n",
      "3933, loss is 0.0018576919732083569 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1172794420123407 and mu_y: -0.01622041348293074\n",
      "3934, loss is 0.0018576777032092285 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1172584625288549 and mu_y: -0.01625183391330957\n",
      "3935, loss is 0.0018576634484919754 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11723749436369629 and mu_y: -0.01628323756924569\n",
      "3936, loss is 0.0018576492090394644 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11721653750960014 and mu_y: -0.016314624460147024\n",
      "3937, loss is 0.001857634984834579 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11719559195930788 and mu_y: -0.016345994595415067\n",
      "3938, loss is 0.0018576207758602282 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11717465770556719 and mu_y: -0.016377347984444908\n",
      "3939, loss is 0.001857606582099339 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11715373474113186 and mu_y: -0.016408684636625228\n",
      "3940, loss is 0.0018575924035348608 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11713282305876188 and mu_y: -0.016440004561338303\n",
      "3941, loss is 0.001857578240149762 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11711192265122342 and mu_y: -0.016471307767960023\n",
      "3942, loss is 0.001857564091927034 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11709103351128879 and mu_y: -0.01650259426585989\n",
      "3943, loss is 0.0018575499588496872 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11707015563173645 and mu_y: -0.016533864064401015\n",
      "3944, loss is 0.0018575358409007548 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11704928900535101 and mu_y: -0.01656511717294015\n",
      "3945, loss is 0.0018575217380632904 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11702843362492321 and mu_y: -0.01659635360082767\n",
      "3946, loss is 0.0018575076503203653 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11700758948324994 and mu_y: -0.016627573357407593\n",
      "3947, loss is 0.0018574935776550752 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11698675657313418 and mu_y: -0.01665877645201758\n",
      "3948, loss is 0.0018574795200505352 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11696593488738505 and mu_y: -0.016689962893988945\n",
      "3949, loss is 0.0018574654774898818 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11694512441881777 and mu_y: -0.01672113269264666\n",
      "3950, loss is 0.0018574514499562693 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11692432516025367 and mu_y: -0.01675228585730936\n",
      "3951, loss is 0.0018574374374328766 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11690353710452016 and mu_y: -0.01678342239728936\n",
      "3952, loss is 0.0018574234399028997 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11688276024445074 and mu_y: -0.016814542321892643\n",
      "3953, loss is 0.0018574094573495575 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.116861994572885 and mu_y: -0.016845645640418877\n",
      "3954, loss is 0.001857395489756089 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1168412400826686 and mu_y: -0.016876732362161424\n",
      "3955, loss is 0.0018573815371057518 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11682049676665325 and mu_y: -0.016907802496407342\n",
      "3956, loss is 0.0018573675993818262 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11679976461769676 and mu_y: -0.01693885605243739\n",
      "3957, loss is 0.0018573536765676118 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11677904362866295 and mu_y: -0.016969893039526042\n",
      "3958, loss is 0.0018573397686464303 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11675833379242172 and mu_y: -0.01700091346694148\n",
      "3959, loss is 0.0018573258756016194 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11673763510184897 and mu_y: -0.017031917343945616\n",
      "3960, loss is 0.001857311997416543 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11671694754982666 and mu_y: -0.017062904679794082\n",
      "3961, loss is 0.001857298134074581 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11669627112924277 and mu_y: -0.017093875483736257\n",
      "3962, loss is 0.0018572842855591348 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11667560583299132 and mu_y: -0.01712482976501525\n",
      "3963, loss is 0.0018572704518536275 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11665495165397229 and mu_y: -0.017155767532867922\n",
      "3964, loss is 0.0018572566329414998 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11663430858509169 and mu_y: -0.01718668879652489\n",
      "3965, loss is 0.0018572428288062151 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11661367661926154 and mu_y: -0.017217593565210527\n",
      "3966, loss is 0.0018572290394312542 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11659305574939985 and mu_y: -0.01724848184814298\n",
      "3967, loss is 0.0018572152648001208 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1165724459684306 and mu_y: -0.017279353654534157\n",
      "3968, loss is 0.0018572015048963371 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11655184726928373 and mu_y: -0.017310208993589753\n",
      "3969, loss is 0.001857187759703447 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1165312596448952 and mu_y: -0.017341047874509248\n",
      "3970, loss is 0.001857174029205012 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11651068308820689 and mu_y: -0.017371870306485914\n",
      "3971, loss is 0.0018571603133846156 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11649011759216665 and mu_y: -0.01740267629870682\n",
      "3972, loss is 0.00185714661222586 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11646956314972828 and mu_y: -0.017433465860352833\n",
      "3973, loss is 0.001857132925712368 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11644901975385154 and mu_y: -0.01746423900059864\n",
      "3974, loss is 0.0018571192538277832 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11642848739750208 and mu_y: -0.017494995728612735\n",
      "3975, loss is 0.0018571055965557678 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11640796607365154 and mu_y: -0.017525736053557447\n",
      "3976, loss is 0.0018570919538800034 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11638745577527744 and mu_y: -0.01755645998458892\n",
      "3977, loss is 0.001857078325784194 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11636695649536322 and mu_y: -0.017587167530857144\n",
      "3978, loss is 0.0018570647122520597 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11634646822689824 and mu_y: -0.017617858701505944\n",
      "3979, loss is 0.0018570511132673451 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11632599096287777 and mu_y: -0.017648533505672994\n",
      "3980, loss is 0.0018570375288138102 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11630552469630295 and mu_y: -0.01767919195248982\n",
      "3981, loss is 0.0018570239588752368 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11628506942018084 and mu_y: -0.017709834051081813\n",
      "3982, loss is 0.0018570104034354264 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11626462512752435 and mu_y: -0.017740459810568224\n",
      "3983, loss is 0.0018569968624781996 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11624419181135229 and mu_y: -0.017771069240062175\n",
      "3984, loss is 0.0018569833359873983 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11622376946468933 and mu_y: -0.017801662348670675\n",
      "3985, loss is 0.0018569698239468808 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.116203358080566 and mu_y: -0.01783223914549461\n",
      "3986, loss is 0.0018569563263405278 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1161829576520187 and mu_y: -0.017862799639628755\n",
      "3987, loss is 0.0018569428431522384 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11616256817208967 and mu_y: -0.017893343840161786\n",
      "3988, loss is 0.0018569293743659326 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11614218963382697 and mu_y: -0.017923871756176282\n",
      "3989, loss is 0.001856915919965547 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11612182203028452 and mu_y: -0.01795438339674873\n",
      "3990, loss is 0.0018569024799350428 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11610146535452208 and mu_y: -0.017984878770949522\n",
      "3991, loss is 0.0018568890542583938 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1160811195996052 and mu_y: -0.018015357887842982\n",
      "3992, loss is 0.0018568756429195987 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11606078475860526 and mu_y: -0.01804582075648736\n",
      "3993, loss is 0.0018568622459026742 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11604046082459947 and mu_y: -0.018076267385934833\n",
      "3994, loss is 0.0018568488631916559 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11602014779067081 and mu_y: -0.01810669778523152\n",
      "3995, loss is 0.001856835494770598 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11599984564990808 and mu_y: -0.01813711196341749\n",
      "3996, loss is 0.0018568221406235746 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11597955439540585 and mu_y: -0.01816750992952675\n",
      "3997, loss is 0.001856808800734681 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11595927402026449 and mu_y: -0.018197891692587276\n",
      "3998, loss is 0.0018567954750880287 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11593900451759014 and mu_y: -0.018228257261621004\n",
      "3999, loss is 0.0018567821636677516 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1159187458804947 and mu_y: -0.018258606645643834\n",
      "4000, loss is 0.001856768866458 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11589849810209585 and mu_y: -0.018288939853665642\n",
      "4001, loss is 0.0018567555834429449 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11587826117551701 and mu_y: -0.01831925689469029\n",
      "4002, loss is 0.001856742314606775 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11585803509388738 and mu_y: -0.018349557777715624\n",
      "4003, loss is 0.0018567290599337022 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11583781985034187 and mu_y: -0.01837984251173348\n",
      "4004, loss is 0.001856715819407952 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11581761543802115 and mu_y: -0.018410111105729696\n",
      "4005, loss is 0.0018567025930137726 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1157974218500716 and mu_y: -0.018440363568684115\n",
      "4006, loss is 0.0018566893807354305 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11577723907964532 and mu_y: -0.018470599909570586\n",
      "4007, loss is 0.0018566761825572098 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11575706711990018 and mu_y: -0.01850082013735698\n",
      "4008, loss is 0.001856662998463417 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1157369059639997 and mu_y: -0.01853102426100519\n",
      "4009, loss is 0.0018566498284383738 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11571675560511314 and mu_y: -0.018561212289471128\n",
      "4010, loss is 0.0018566366724664229 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11569661603641546 and mu_y: -0.018591384231704755\n",
      "4011, loss is 0.001856623530531926 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11567648725108727 and mu_y: -0.01862154009665006\n",
      "4012, loss is 0.0018566104026192622 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11565636924231491 and mu_y: -0.01865167989324508\n",
      "4013, loss is 0.0018565972887128316 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1156362620032904 and mu_y: -0.01868180363042191\n",
      "4014, loss is 0.0018565841887970523 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1156161655272114 and mu_y: -0.0187119113171067\n",
      "4015, loss is 0.00185657110285636 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11559607980728127 and mu_y: -0.01874200296221966\n",
      "4016, loss is 0.0018565580308752098 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.115576004836709 and mu_y: -0.01877207857467507\n",
      "4017, loss is 0.0018565449728380776 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11555594060870926 and mu_y: -0.018802138163381287\n",
      "4018, loss is 0.0018565319287294556 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11553588711650235 and mu_y: -0.01883218173724075\n",
      "4019, loss is 0.001856518898533856 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11551584435331423 and mu_y: -0.018862209305149986\n",
      "4020, loss is 0.001856505882235809 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11549581231237646 and mu_y: -0.018892220875999607\n",
      "4021, loss is 0.0018564928798198634 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11547579098692627 and mu_y: -0.018922216458674333\n",
      "4022, loss is 0.0018564798912705876 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11545578037020648 and mu_y: -0.018952196062052982\n",
      "4023, loss is 0.001856466916572568 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11543578045546554 and mu_y: -0.01898215969500848\n",
      "4024, loss is 0.0018564539557104098 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11541579123595751 and mu_y: -0.019012107366407877\n",
      "4025, loss is 0.0018564410086687358 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11539581270494204 and mu_y: -0.019042039085112338\n",
      "4026, loss is 0.001856428075432189 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11537584485568439 and mu_y: -0.019071954859977158\n",
      "4027, loss is 0.0018564151559854296 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11535588768145542 and mu_y: -0.019101854699851765\n",
      "4028, loss is 0.0018564022503131375 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11533594117553156 and mu_y: -0.019131738613579724\n",
      "4029, loss is 0.0018563893584000095 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1153160053311948 and mu_y: -0.019161606609998744\n",
      "4030, loss is 0.0018563764802307615 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11529608014173275 and mu_y: -0.01919145869794069\n",
      "4031, loss is 0.001856363615790129 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11527616560043853 and mu_y: -0.019221294886231574\n",
      "4032, loss is 0.001856350765062864 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11525626170061086 and mu_y: -0.01925111518369158\n",
      "4033, loss is 0.0018563379280337386 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.115236368435554 and mu_y: -0.019280919599135048\n",
      "4034, loss is 0.0018563251046875423 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11521648579857775 and mu_y: -0.019310708141370498\n",
      "4035, loss is 0.0018563122950090816 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11519661378299746 and mu_y: -0.01934048081920063\n",
      "4036, loss is 0.0018562994989831843 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.115176752382134 and mu_y: -0.019370237641422327\n",
      "4037, loss is 0.0018562867165946948 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11515690158931378 and mu_y: -0.019399978616826657\n",
      "4038, loss is 0.001856273947828476 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11513706139786875 and mu_y: -0.019429703754198894\n",
      "4039, loss is 0.0018562611926694077 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11511723180113634 and mu_y: -0.019459413062318503\n",
      "4040, loss is 0.0018562484511023894 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1150974127924595 and mu_y: -0.01948910654995916\n",
      "4041, loss is 0.001856235723112339 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1150776043651867 and mu_y: -0.019518784225888756\n",
      "4042, loss is 0.0018562230086841905 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11505780651267189 and mu_y: -0.019548446098869396\n",
      "4043, loss is 0.0018562103078029004 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11503801922827452 and mu_y: -0.01957809217765741\n",
      "4044, loss is 0.0018561976204534377 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11501824250535952 and mu_y: -0.019607722471003362\n",
      "4045, loss is 0.0018561849466207931 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11499847633729732 and mu_y: -0.01963733698765205\n",
      "4046, loss is 0.0018561722862899732 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11497872071746378 and mu_y: -0.019666935736342504\n",
      "4047, loss is 0.0018561596394460068 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11495897563924025 and mu_y: -0.01969651872580801\n",
      "4048, loss is 0.0018561470060739342 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11493924109601356 and mu_y: -0.019726085964776104\n",
      "4049, loss is 0.0018561343861588188 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11491951708117595 and mu_y: -0.019755637461968577\n",
      "4050, loss is 0.0018561217796857403 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11489980358812515 and mu_y: -0.019785173226101484\n",
      "4051, loss is 0.0018561091866397957 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11488010061026432 and mu_y: -0.01981469326588515\n",
      "4052, loss is 0.0018560966070061014 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11486040814100205 and mu_y: -0.01984419759002417\n",
      "4053, loss is 0.001856084040769791 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11484072617375236 and mu_y: -0.019873686207217425\n",
      "4054, loss is 0.0018560714879160144 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1148210547019347 and mu_y: -0.019903159126158077\n",
      "4055, loss is 0.0018560589484299412 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11480139371897392 and mu_y: -0.01993261635553358\n",
      "4056, loss is 0.0018560464222967578 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11478174321830031 and mu_y: -0.01996205790402568\n",
      "4057, loss is 0.0018560339095016693 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11476210319334956 and mu_y: -0.01999148378031043\n",
      "4058, loss is 0.0018560214100298985 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11474247363756275 and mu_y: -0.020020893993058193\n",
      "4059, loss is 0.001856008923866685 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11472285454438634 and mu_y: -0.020050288550933635\n",
      "4060, loss is 0.0018559964509972855 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11470324590727221 and mu_y: -0.02007966746259575\n",
      "4061, loss is 0.0018559839914069776 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1146836477196776 and mu_y: -0.020109030736697845\n",
      "4062, loss is 0.0018559715450810533 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11466405997506512 and mu_y: -0.02013837838188757\n",
      "4063, loss is 0.0018559591120048218 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11464448266690279 and mu_y: -0.020167710406806896\n",
      "4064, loss is 0.0018559466921636142 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11462491578866395 and mu_y: -0.020197026820092143\n",
      "4065, loss is 0.001855934285542775 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11460535933382732 and mu_y: -0.020226327630373974\n",
      "4066, loss is 0.0018559218921276675 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11458581329587697 and mu_y: -0.020255612846277398\n",
      "4067, loss is 0.001855909511903672 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11456627766830231 and mu_y: -0.020284882476421788\n",
      "4068, loss is 0.0018558971448561887 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1145467524445981 and mu_y: -0.020314136529420875\n",
      "4069, loss is 0.0018558847909706324 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1145272376182644 and mu_y: -0.02034337501388276\n",
      "4070, loss is 0.0018558724502324374 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11450773318280666 and mu_y: -0.02037259793840991\n",
      "4071, loss is 0.0018558601226270535 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1144882391317356 and mu_y: -0.020401805311599183\n",
      "4072, loss is 0.00185584780813995 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11446875545856729 and mu_y: -0.0204309971420418\n",
      "4073, loss is 0.0018558355067566112 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11444928215682308 and mu_y: -0.020460173438323393\n",
      "4074, loss is 0.0018558232184625416 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11442981922002965 and mu_y: -0.02048933420902397\n",
      "4075, loss is 0.00185581094324326 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11441036664171897 and mu_y: -0.02051847946271795\n",
      "4076, loss is 0.0018557986810843054 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1143909244154283 and mu_y: -0.020547609207974153\n",
      "4077, loss is 0.0018557864319712325 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11437149253470018 and mu_y: -0.020576723453355806\n",
      "4078, loss is 0.0018557741958896141 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11435207099308246 and mu_y: -0.02060582220742056\n",
      "4079, loss is 0.0018557619728250371 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11433265978412825 and mu_y: -0.02063490547872048\n",
      "4080, loss is 0.0018557497627631108 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11431325890139592 and mu_y: -0.020663973275802053\n",
      "4081, loss is 0.0018557375656894578 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1142938683384491 and mu_y: -0.020693025607206213\n",
      "4082, loss is 0.00185572538158972 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1142744880888567 and mu_y: -0.020722062481468316\n",
      "4083, loss is 0.0018557132104495553 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11425511814619287 and mu_y: -0.020751083907118165\n",
      "4084, loss is 0.0018557010522546385 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.114235758504037 and mu_y: -0.02078008989268001\n",
      "4085, loss is 0.0018556889069906626 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11421640915597374 and mu_y: -0.02080908044667256\n",
      "4086, loss is 0.0018556767746433374 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11419707009559296 and mu_y: -0.020838055577608972\n",
      "4087, loss is 0.0018556646551983885 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11417774131648976 and mu_y: -0.020867015293996875\n",
      "4088, loss is 0.0018556525486415605 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11415842281226447 and mu_y: -0.02089595960433836\n",
      "4089, loss is 0.0018556404549586133 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11413911457652264 and mu_y: -0.020924888517129994\n",
      "4090, loss is 0.0018556283741353247 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.114119816602875 and mu_y: -0.020953802040862824\n",
      "4091, loss is 0.00185561630615749 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11410052888493753 and mu_y: -0.02098270018402238\n",
      "4092, loss is 0.0018556042510109196 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1140812514163314 and mu_y: -0.021011582955088686\n",
      "4093, loss is 0.0018555922086814422 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11406198419068295 and mu_y: -0.021040450362536253\n",
      "4094, loss is 0.001855580179154903 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11404272720162373 and mu_y: -0.0210693024148341\n",
      "4095, loss is 0.0018555681624171658 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11402348044279047 and mu_y: -0.021098139120445742\n",
      "4096, loss is 0.0018555561584541079 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11400424390782508 and mu_y: -0.021126960487829215\n",
      "4097, loss is 0.0018555441672516253 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11398501759037463 and mu_y: -0.021155766525437065\n",
      "4098, loss is 0.0018555321887956315 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11396580148409137 and mu_y: -0.02118455724171636\n",
      "4099, loss is 0.001855520223072055 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1139465955826327 and mu_y: -0.02121333264510869\n",
      "4100, loss is 0.0018555082700668427 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11392739987966119 and mu_y: -0.021242092744050183\n",
      "4101, loss is 0.0018554963297659577 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11390821436884453 and mu_y: -0.0212708375469715\n",
      "4102, loss is 0.0018554844021553797 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11388903904385558 and mu_y: -0.021299567062297842\n",
      "4103, loss is 0.0018554724872211035 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11386987389837233 and mu_y: -0.02132828129844896\n",
      "4104, loss is 0.001855460584949144 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11385071892607791 and mu_y: -0.021356980263839156\n",
      "4105, loss is 0.0018554486953255307 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11383157412066056 and mu_y: -0.021385663966877286\n",
      "4106, loss is 0.0018554368183363087 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11381243947581364 and mu_y: -0.021414332415966773\n",
      "4107, loss is 0.0018554249539675424 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11379331498523565 and mu_y: -0.0214429856195056\n",
      "4108, loss is 0.001855413102205309 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11377420064263016 and mu_y: -0.02147162358588633\n",
      "4109, loss is 0.0018554012630357074 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1137550964417059 and mu_y: -0.021500246323496102\n",
      "4110, loss is 0.001855389436444849 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11373600237617663 and mu_y: -0.021528853840716636\n",
      "4111, loss is 0.0018553776224188617 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11371691843976127 and mu_y: -0.021557446145924235\n",
      "4112, loss is 0.0018553658209438922 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11369784462618378 and mu_y: -0.021586023247489806\n",
      "4113, loss is 0.0018553540320061022 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11367878092917322 and mu_y: -0.021614585153778842\n",
      "4114, loss is 0.0018553422555916705 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11365972734246373 and mu_y: -0.021643131873151446\n",
      "4115, loss is 0.0018553304916867925 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1136406838597945 and mu_y: -0.02167166341396233\n",
      "4116, loss is 0.0018553187402776778 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11362165047490982 and mu_y: -0.021700179784560816\n",
      "4117, loss is 0.0018553070013505551 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11360262718155902 and mu_y: -0.021728680993290842\n",
      "4118, loss is 0.0018552952748916688 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11358361397349646 and mu_y: -0.021757167048490973\n",
      "4119, loss is 0.0018552835608872786 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11356461084448159 and mu_y: -0.021785637958494402\n",
      "4120, loss is 0.0018552718593236608 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11354561778827887 and mu_y: -0.021814093731628955\n",
      "4121, loss is 0.0018552601701871097 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11352663479865784 and mu_y: -0.021842534376217092\n",
      "4122, loss is 0.0018552484934639332 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11350766186939301 and mu_y: -0.021870959900575925\n",
      "4123, loss is 0.0018552368291404585 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11348869899426396 and mu_y: -0.021899370313017207\n",
      "4124, loss is 0.0018552251772030242 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11346974616705528 and mu_y: -0.021927765621847346\n",
      "4125, loss is 0.001855213537637992 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1134508033815566 and mu_y: -0.02195614583536741\n",
      "4126, loss is 0.0018552019104317325 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1134318706315625 and mu_y: -0.02198451096187313\n",
      "4127, loss is 0.0018551902955706383 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11341294791087263 and mu_y: -0.0220128610096549\n",
      "4128, loss is 0.0018551786930411152 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11339403521329158 and mu_y: -0.0220411959869978\n",
      "4129, loss is 0.0018551671028295856 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11337513253262899 and mu_y: -0.022069515902181574\n",
      "4130, loss is 0.0018551555249224868 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11335623986269945 and mu_y: -0.022097820763480658\n",
      "4131, loss is 0.0018551439593062751 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11333735719732255 and mu_y: -0.022126110579164172\n",
      "4132, loss is 0.0018551324059674196 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11331848453032284 and mu_y: -0.022154385357495934\n",
      "4133, loss is 0.0018551208648924095 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11329962185552986 and mu_y: -0.022182645106734455\n",
      "4134, loss is 0.0018551093360677454 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11328076916677811 and mu_y: -0.022210889835132953\n",
      "4135, loss is 0.001855097819479947 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11326192645790704 and mu_y: -0.022239119550939348\n",
      "4136, loss is 0.0018550863151155482 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11324309372276109 and mu_y: -0.022267334262396278\n",
      "4137, loss is 0.0018550748229611007 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11322427095518961 and mu_y: -0.0222955339777411\n",
      "4138, loss is 0.001855063343003169 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11320545814904691 and mu_y: -0.02232371870520589\n",
      "4139, loss is 0.0018550518752283383 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11318665529819225 and mu_y: -0.02235188845301745\n",
      "4140, loss is 0.0018550404196232052 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11316786239648981 and mu_y: -0.022380043229397323\n",
      "4141, loss is 0.0018550289761743834 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11314907943780869 and mu_y: -0.02240818304256178\n",
      "4142, loss is 0.0018550175448685045 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11313030641602295 and mu_y: -0.022436307900721836\n",
      "4143, loss is 0.001855006125692213 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11311154332501154 and mu_y: -0.02246441781208326\n",
      "4144, loss is 0.0018549947186321713 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11309279015865832 and mu_y: -0.022492512784846565\n",
      "4145, loss is 0.0018549833236750563 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11307404691085207 and mu_y: -0.022520592827207028\n",
      "4146, loss is 0.0018549719408075612 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11305531357548647 and mu_y: -0.02254865794735468\n",
      "4147, loss is 0.0018549605700163953 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11303659014646007 and mu_y: -0.022576708153474324\n",
      "4148, loss is 0.0018549492112882823 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11301787661767637 and mu_y: -0.02260474345374553\n",
      "4149, loss is 0.0018549378646099636 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1129991729830437 and mu_y: -0.022632763856342653\n",
      "4150, loss is 0.0018549265299681935 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11298047923647529 and mu_y: -0.022660769369434817\n",
      "4151, loss is 0.0018549152073497445 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11296179537188926 and mu_y: -0.022688760001185942\n",
      "4152, loss is 0.001854903896741405 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11294312138320858 and mu_y: -0.022716735759754733\n",
      "4153, loss is 0.0018548925981299758 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11292445726436111 and mu_y: -0.02274469665329469\n",
      "4154, loss is 0.0018548813115022759 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11290580300927952 and mu_y: -0.02277264268995412\n",
      "4155, loss is 0.001854870036845139 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11288715861190139 and mu_y: -0.02280057387787613\n",
      "4156, loss is 0.0018548587741454153 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11286852406616912 and mu_y: -0.022828490225198637\n",
      "4157, loss is 0.0018548475233899693 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11284989936602997 and mu_y: -0.022856391740054376\n",
      "4158, loss is 0.0018548362845656821 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11283128450543602 and mu_y: -0.022884278430570892\n",
      "4159, loss is 0.0018548250576594489 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11281267947834418 and mu_y: -0.02291215030487057\n",
      "4160, loss is 0.0018548138426581812 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11279408427871622 and mu_y: -0.022940007371070607\n",
      "4161, loss is 0.001854802639548806 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1127754989005187 and mu_y: -0.022967849637283048\n",
      "4162, loss is 0.001854791448318266 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11275692333772303 and mu_y: -0.022995677111614765\n",
      "4163, loss is 0.0018547802689535186 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1127383575843054 and mu_y: -0.023023489802167483\n",
      "4164, loss is 0.0018547691014415358 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11271980163424682 and mu_y: -0.02305128771703777\n",
      "4165, loss is 0.0018547579457693071 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1127012554815331 and mu_y: -0.023079070864317045\n",
      "4166, loss is 0.001854746801923837 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11268271912015487 and mu_y: -0.023106839252091588\n",
      "4167, loss is 0.0018547356698921439 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11266419254410752 and mu_y: -0.02313459288844254\n",
      "4168, loss is 0.0018547245496612606 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11264567574739123 and mu_y: -0.02316233178144591\n",
      "4169, loss is 0.001854713441218239 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11262716872401099 and mu_y: -0.023190055939172574\n",
      "4170, loss is 0.001854702344550142 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11260867146797653 and mu_y: -0.02321776536968829\n",
      "4171, loss is 0.001854691259644051 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11259018397330238 and mu_y: -0.023245460081053698\n",
      "4172, loss is 0.0018546801864870613 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11257170623400782 and mu_y: -0.023273140081324313\n",
      "4173, loss is 0.001854669125066283 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1125532382441169 and mu_y: -0.02330080537855055\n",
      "4174, loss is 0.0018546580753688413 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1125347799976584 and mu_y: -0.023328455980777717\n",
      "4175, loss is 0.0018546470373818778 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11251633148866591 and mu_y: -0.02335609189604602\n",
      "4176, loss is 0.001854636011092548 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1124978927111777 and mu_y: -0.023383713132390575\n",
      "4177, loss is 0.001854624996488024 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11247946365923682 and mu_y: -0.023411319697841396\n",
      "4178, loss is 0.0018546139935554904 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11246104432689104 and mu_y: -0.02343891160042342\n",
      "4179, loss is 0.0018546030022821498 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11244263470819287 and mu_y: -0.023466488848156497\n",
      "4180, loss is 0.001854592022655217 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11242423479719953 and mu_y: -0.023494051449055402\n",
      "4181, loss is 0.0018545810546619253 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11240584458797297 and mu_y: -0.02352159941112984\n",
      "4182, loss is 0.001854570098289519 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11238746407457985 and mu_y: -0.023549132742384443\n",
      "4183, loss is 0.0018545591535252604 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11236909325109155 and mu_y: -0.023576651450818782\n",
      "4184, loss is 0.0018545482203564264 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11235073211158417 and mu_y: -0.023604155544427373\n",
      "4185, loss is 0.001854537298770307 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11233238065013847 and mu_y: -0.02363164503119967\n",
      "4186, loss is 0.0018545263887542079 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11231403886083992 and mu_y: -0.02365911991912009\n",
      "4187, loss is 0.0018545154902954526 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1122957067377787 and mu_y: -0.023686580216167985\n",
      "4188, loss is 0.0018545046033813751 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11227738427504963 and mu_y: -0.023714025930317687\n",
      "4189, loss is 0.0018544937279993269 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11225907146675226 and mu_y: -0.02374145706953848\n",
      "4190, loss is 0.001854482864136673 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11224076830699081 and mu_y: -0.023768873641794624\n",
      "4191, loss is 0.0018544720117807951 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11222247478987413 and mu_y: -0.023796275655045347\n",
      "4192, loss is 0.001854461170919088 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11220419090951576 and mu_y: -0.023823663117244858\n",
      "4193, loss is 0.0018544503415389615 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11218591666003391 and mu_y: -0.02385103603634235\n",
      "4194, loss is 0.001854439523627841 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11216765203555143 and mu_y: -0.023878394420281994\n",
      "4195, loss is 0.0018544287171731657 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11214939703019582 and mu_y: -0.023905738277002965\n",
      "4196, loss is 0.0018544179221623904 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11213115163809922 and mu_y: -0.023933067614439425\n",
      "4197, loss is 0.0018544071385829838 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11211291585339843 and mu_y: -0.023960382440520542\n",
      "4198, loss is 0.0018543963664224299 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11209468967023486 and mu_y: -0.02398768276317049\n",
      "4199, loss is 0.0018543856056682272 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11207647308275458 and mu_y: -0.024014968590308442\n",
      "4200, loss is 0.0018543748563078892 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11205826608510824 and mu_y: -0.024042239929848597\n",
      "4201, loss is 0.0018543641183289433 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11204006867145117 and mu_y: -0.02406949678970017\n",
      "4202, loss is 0.001854353391718932 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11202188083594326 and mu_y: -0.024096739177767394\n",
      "4203, loss is 0.0018543426764654116 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11200370257274905 and mu_y: -0.024123967101949535\n",
      "4204, loss is 0.001854331972555955 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11198553387603766 and mu_y: -0.02415118057014089\n",
      "4205, loss is 0.001854321279978147 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1119673747399828 and mu_y: -0.024178379590230795\n",
      "4206, loss is 0.0018543105987195885 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11194922515876284 and mu_y: -0.024205564170103618\n",
      "4207, loss is 0.0018542999287678955 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11193108512656065 and mu_y: -0.024232734317638782\n",
      "4208, loss is 0.001854289270110698 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11191295463756375 and mu_y: -0.024259890040710757\n",
      "4209, loss is 0.0018542786227356382 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11189483368596422 and mu_y: -0.024287031347189066\n",
      "4210, loss is 0.0018542679866303772 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11187672226595871 and mu_y: -0.02431415824493829\n",
      "4211, loss is 0.001854257361782586 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11185862037174847 and mu_y: -0.02434127074181808\n",
      "4212, loss is 0.0018542467481799533 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11184052799753927 and mu_y: -0.024368368845683146\n",
      "4213, loss is 0.00185423614581018 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11182244513754147 and mu_y: -0.024395452564383278\n",
      "4214, loss is 0.0018542255546609844 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11180437178597 and mu_y: -0.024422521905763335\n",
      "4215, loss is 0.001854214974720096 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1117863079370443 and mu_y: -0.024449576877663262\n",
      "4216, loss is 0.001854204405975258 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1117682535849884 and mu_y: -0.024476617487918087\n",
      "4217, loss is 0.0018541938484142328 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11175020872403084 and mu_y: -0.02450364374435793\n",
      "4218, loss is 0.0018541833020247925 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11173217334840471 and mu_y: -0.02453065565480801\n",
      "4219, loss is 0.0018541727667947254 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11171414745234765 and mu_y: -0.024557653227088628\n",
      "4220, loss is 0.001854162242711833 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11169613103010179 and mu_y: -0.024584636469015205\n",
      "4221, loss is 0.0018541517297639334 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1116781240759138 and mu_y: -0.024611605388398263\n",
      "4222, loss is 0.0018541412279388554 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11166012658403489 and mu_y: -0.024638559993043437\n",
      "4223, loss is 0.0018541307372244454 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11164213854872075 and mu_y: -0.024665500290751475\n",
      "4224, loss is 0.0018541202576085618 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1116241599642316 and mu_y: -0.02469242628931825\n",
      "4225, loss is 0.0018541097890790786 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11160619082483214 and mu_y: -0.024719337996534755\n",
      "4226, loss is 0.0018540993316238823 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11158823112479159 and mu_y: -0.024746235420187116\n",
      "4227, loss is 0.0018540888852308758 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11157028085838366 and mu_y: -0.02477311856805659\n",
      "4228, loss is 0.001854078449887974 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11155234001988655 and mu_y: -0.024799987447919575\n",
      "4229, loss is 0.0018540680255831063 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11153440860358294 and mu_y: -0.024826842067547608\n",
      "4230, loss is 0.0018540576123042187 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11151648660375997 and mu_y: -0.024853682434707373\n",
      "4231, loss is 0.0018540472100392672 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1114985740147093 and mu_y: -0.024880508557160706\n",
      "4232, loss is 0.0018540368187762238 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11148067083072703 and mu_y: -0.024907320442664596\n",
      "4233, loss is 0.0018540264385030765 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11146277704611374 and mu_y: -0.024934118098971197\n",
      "4234, loss is 0.001854016069207824 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11144489265517445 and mu_y: -0.024960901533827823\n",
      "4235, loss is 0.00185400571087848 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11142701765221864 and mu_y: -0.024987670754976953\n",
      "4236, loss is 0.001853995363503073 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11140915203156028 and mu_y: -0.02501442577015624\n",
      "4237, loss is 0.0018539850270696463 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11139129578751773 and mu_y: -0.02504116658709852\n",
      "4238, loss is 0.0018539747015662545 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11137344891441382 and mu_y: -0.0250678932135318\n",
      "4239, loss is 0.001853964386980968 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11135561140657584 and mu_y: -0.025094605657179282\n",
      "4240, loss is 0.0018539540833018711 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11133778325833545 and mu_y: -0.02512130392575935\n",
      "4241, loss is 0.0018539437905170596 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1113199644640288 and mu_y: -0.02514798802698558\n",
      "4242, loss is 0.0018539335086146472 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11130215501799644 and mu_y: -0.025174657968566758\n",
      "4243, loss is 0.0018539232375827587 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11128435491458333 and mu_y: -0.025201313758206858\n",
      "4244, loss is 0.0018539129774095332 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11126656414813885 and mu_y: -0.02522795540360507\n",
      "4245, loss is 0.0018539027280831241 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11124878271301679 and mu_y: -0.025254582912455793\n",
      "4246, loss is 0.0018538924895916977 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11123101060357535 and mu_y: -0.025281196292448637\n",
      "4247, loss is 0.0018538822619234348 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11121324781417713 and mu_y: -0.025307795551268435\n",
      "4248, loss is 0.0018538720450665314 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11119549433918911 and mu_y: -0.02533438069659524\n",
      "4249, loss is 0.0018538618390091923 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11117775017298268 and mu_y: -0.025360951736104337\n",
      "4250, loss is 0.0018538516437396411 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1111600153099336 and mu_y: -0.02538750867746624\n",
      "4251, loss is 0.001853841459246115 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.111142289744422 and mu_y: -0.0254140515283467\n",
      "4252, loss is 0.001853831285516861 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11112457347083245 and mu_y: -0.025440580296406706\n",
      "4253, loss is 0.001853821122540143 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1111068664835538 and mu_y: -0.025467094989302497\n",
      "4254, loss is 0.0018538109703042371 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11108916877697936 and mu_y: -0.025493595614685553\n",
      "4255, loss is 0.0018538008287974342 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11107148034550672 and mu_y: -0.025520082180202613\n",
      "4256, loss is 0.001853790698008038 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11105380118353787 and mu_y: -0.025546554693495666\n",
      "4257, loss is 0.0018537805779243652 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11103613128547918 and mu_y: -0.025573013162201973\n",
      "4258, loss is 0.0018537704685347477 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1110184706457413 and mu_y: -0.025599457593954048\n",
      "4259, loss is 0.0018537603698275298 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1110008192587393 and mu_y: -0.025625887996379687\n",
      "4260, loss is 0.001853750281791069 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11098317711889252 and mu_y: -0.025652304377101948\n",
      "4261, loss is 0.0018537402044137374 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1109655442206247 and mu_y: -0.025678706743739173\n",
      "4262, loss is 0.0018537301376839214 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11094792055836386 and mu_y: -0.025705095103904986\n",
      "4263, loss is 0.0018537200815900172 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11093030612654237 and mu_y: -0.025731469465208292\n",
      "4264, loss is 0.0018537100361204388 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11091270091959692 and mu_y: -0.025757829835253293\n",
      "4265, loss is 0.0018537000012636123 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11089510493196851 and mu_y: -0.025784176221639483\n",
      "4266, loss is 0.0018536899770079732 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11087751815810247 and mu_y: -0.025810508631961653\n",
      "4267, loss is 0.0018536799633419785 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11085994059244843 and mu_y: -0.025836827073809895\n",
      "4268, loss is 0.0018536699602540911 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1108423722294603 and mu_y: -0.02586313155476961\n",
      "4269, loss is 0.001853659967732791 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11082481306359634 and mu_y: -0.02588942208242151\n",
      "4270, loss is 0.0018536499857665706 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11080726308931906 and mu_y: -0.02591569866434162\n",
      "4271, loss is 0.0018536400143439368 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11078972230109527 and mu_y: -0.02594196130810129\n",
      "4272, loss is 0.001853630053453408 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11077219069339607 and mu_y: -0.025968210021267184\n",
      "4273, loss is 0.001853620103083517 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11075466826069685 and mu_y: -0.025994444811401302\n",
      "4274, loss is 0.0018536101632228104 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11073715499747727 and mu_y: -0.026020665686060967\n",
      "4275, loss is 0.0018536002338598468 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11071965089822126 and mu_y: -0.02604687265279884\n",
      "4276, loss is 0.0018535903149831984 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11070215595741703 and mu_y: -0.026073065719162927\n",
      "4277, loss is 0.0018535804065814507 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11068467016955703 and mu_y: -0.026099244892696567\n",
      "4278, loss is 0.0018535705086432032 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11066719352913798 and mu_y: -0.026125410180938453\n",
      "4279, loss is 0.0018535606211570678 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11064972603066087 and mu_y: -0.02615156159142263\n",
      "4280, loss is 0.0018535507441116712 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11063226766863091 and mu_y: -0.026177699131678497\n",
      "4281, loss is 0.0018535408774956494 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11061481843755758 and mu_y: -0.026203822809230812\n",
      "4282, loss is 0.0018535310212976564 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11059737833195459 and mu_y: -0.026229932631599697\n",
      "4283, loss is 0.0018535211755063559 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1105799473463399 and mu_y: -0.026256028606300642\n",
      "4284, loss is 0.0018535113401104257 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11056252547523568 and mu_y: -0.02628211074084451\n",
      "4285, loss is 0.0018535015150985576 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11054511271316836 and mu_y: -0.02630817904273754\n",
      "4286, loss is 0.0018534917004594553 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11052770905466855 and mu_y: -0.026334233519481345\n",
      "4287, loss is 0.0018534818961818363 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11051031449427112 and mu_y: -0.026360274178572927\n",
      "4288, loss is 0.0018534721022544316 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11049292902651514 and mu_y: -0.026386301027504673\n",
      "4289, loss is 0.0018534623186659827 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11047555264594387 and mu_y: -0.026412314073764365\n",
      "4290, loss is 0.0018534525454052483 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11045818534710482 and mu_y: -0.026438313324835178\n",
      "4291, loss is 0.0018534427824609952 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11044082712454965 and mu_y: -0.026464298788195686\n",
      "4292, loss is 0.001853433029822009 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11042347797283426 and mu_y: -0.02649027047131987\n",
      "4293, loss is 0.0018534232874770822 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11040613788651872 and mu_y: -0.026516228381677113\n",
      "4294, loss is 0.0018534135554150238 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1103888068601673 and mu_y: -0.02654217252673222\n",
      "4295, loss is 0.0018534038336246567 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11037148488834846 and mu_y: -0.026568102913945398\n",
      "4296, loss is 0.0018533941220948132 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1103541719656348 and mu_y: -0.026594019550772285\n",
      "4297, loss is 0.0018533844208143415 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11033686808660313 and mu_y: -0.026619922444663935\n",
      "4298, loss is 0.0018533747297721007 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11031957324583444 and mu_y: -0.026645811603066834\n",
      "4299, loss is 0.0018533650489569644 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11030228743791387 and mu_y: -0.0266716870334229\n",
      "4300, loss is 0.0018533553783578176 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11028501065743072 and mu_y: -0.02669754874316948\n",
      "4301, loss is 0.00185334571796356 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11026774289897845 and mu_y: -0.026723396739739363\n",
      "4302, loss is 0.0018533360677631032 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11025048415715467 and mu_y: -0.026749231030560785\n",
      "4303, loss is 0.0018533264277453695 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11023323442656117 and mu_y: -0.026775051623057426\n",
      "4304, loss is 0.0018533167978992974 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11021599370180385 and mu_y: -0.02680085852464842\n",
      "4305, loss is 0.0018533071782138363 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11019876197749275 and mu_y: -0.026826651742748345\n",
      "4306, loss is 0.0018532975686779488 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11018153924824206 and mu_y: -0.026852431284767254\n",
      "4307, loss is 0.0018532879692806108 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11016432550867011 and mu_y: -0.026878197158110656\n",
      "4308, loss is 0.0018532783800108087 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11014712075339936 and mu_y: -0.026903949370179522\n",
      "4309, loss is 0.0018532688008575451 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11012992497705636 and mu_y: -0.026929687928370298\n",
      "4310, loss is 0.001853259231809833 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11011273817427181 and mu_y: -0.026955412840074904\n",
      "4311, loss is 0.001853249672856697 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11009556033968053 and mu_y: -0.026981124112680735\n",
      "4312, loss is 0.0018532401239871777 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11007839146792142 and mu_y: -0.027006821753570675\n",
      "4313, loss is 0.0018532305851903252 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11006123155363752 and mu_y: -0.027032505770123085\n",
      "4314, loss is 0.0018532210564552046 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11004408059147595 and mu_y: -0.027058176169711828\n",
      "4315, loss is 0.001853211537770892 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11002693857608795 and mu_y: -0.027083832959706247\n",
      "4316, loss is 0.001853202029126477 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.11000980550212881 and mu_y: -0.027109476147471195\n",
      "4317, loss is 0.0018531925305110611 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10999268136425797 and mu_y: -0.027135105740367017\n",
      "4318, loss is 0.0018531830419137576 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1099755661571389 and mu_y: -0.02716072174574957\n",
      "4319, loss is 0.0018531735633236957 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10995845987543919 and mu_y: -0.02718632417097021\n",
      "4320, loss is 0.0018531640947300138 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10994136251383049 and mu_y: -0.027211913023375826\n",
      "4321, loss is 0.0018531546361218638 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10992427406698853 and mu_y: -0.027237488310308804\n",
      "4322, loss is 0.0018531451874884103 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1099071945295931 and mu_y: -0.027263050039107055\n",
      "4323, loss is 0.0018531357488188298 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10989012389632807 and mu_y: -0.027288598217104023\n",
      "4324, loss is 0.001853126320102312 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10987306216188135 and mu_y: -0.027314132851628672\n",
      "4325, loss is 0.0018531169013280599 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10985600932094491 and mu_y: -0.0273396539500055\n",
      "4326, loss is 0.0018531074924852864 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1098389653682148 and mu_y: -0.027365161519554544\n",
      "4327, loss is 0.0018530980935632193 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10982193029839109 and mu_y: -0.027390655567591377\n",
      "4328, loss is 0.0018530887045510966 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10980490410617788 and mu_y: -0.027416136101427117\n",
      "4329, loss is 0.0018530793254381707 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10978788678628335 and mu_y: -0.02744160312836843\n",
      "4330, loss is 0.0018530699562137058 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10977087833341968 and mu_y: -0.02746705665571753\n",
      "4331, loss is 0.0018530605968669768 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10975387874230311 and mu_y: -0.027492496690772188\n",
      "4332, loss is 0.0018530512473872729 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10973688800765387 and mu_y: -0.027517923240825738\n",
      "4333, loss is 0.0018530419077638968 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10971990612419626 and mu_y: -0.02754333631316707\n",
      "4334, loss is 0.0018530325779861595 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10970293308665856 and mu_y: -0.027568735915080644\n",
      "4335, loss is 0.0018530232580433867 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10968596888977307 and mu_y: -0.027594122053846485\n",
      "4336, loss is 0.001853013947924918 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10966901352827613 and mu_y: -0.027619494736740198\n",
      "4337, loss is 0.001853004647620101 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10965206699690805 and mu_y: -0.027644853971032963\n",
      "4338, loss is 0.0018529953571183005 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10963512929041316 and mu_y: -0.02767019976399154\n",
      "4339, loss is 0.0018529860764088888 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1096182004035398 and mu_y: -0.027695532122878272\n",
      "4340, loss is 0.0018529768054812547 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10960128033104026 and mu_y: -0.027720851054951097\n",
      "4341, loss is 0.001852967544324796 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10958436906767087 and mu_y: -0.02774615656746354\n",
      "4342, loss is 0.0018529582929289236 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10956746660819192 and mu_y: -0.027771448667664723\n",
      "4343, loss is 0.001852949051283061 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10955057294736768 and mu_y: -0.02779672736279937\n",
      "4344, loss is 0.001852939819376645 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10953368807996641 and mu_y: -0.027821992660107812\n",
      "4345, loss is 0.001852930597199121 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10951681200076034 and mu_y: -0.02784724456682598\n",
      "4346, loss is 0.00185292138473995 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10949994470452568 and mu_y: -0.027872483090185415\n",
      "4347, loss is 0.0018529121819886038 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10948308618604256 and mu_y: -0.02789770823741328\n",
      "4348, loss is 0.0018529029889345662 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10946623644009514 and mu_y: -0.027922920015732353\n",
      "4349, loss is 0.0018528938055673337 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10944939546147146 and mu_y: -0.027948118432361033\n",
      "4350, loss is 0.0018528846318764138 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10943256324496359 and mu_y: -0.027973303494513345\n",
      "4351, loss is 0.0018528754678513266 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1094157397853675 and mu_y: -0.027998475209398948\n",
      "4352, loss is 0.0018528663134816038 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10939892507748313 and mu_y: -0.028023633584223127\n",
      "4353, loss is 0.0018528571687567905 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10938211911611433 and mu_y: -0.028048778626186807\n",
      "4354, loss is 0.0018528480336664423 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10936532189606891 and mu_y: -0.028073910342486557\n",
      "4355, loss is 0.0018528389082001263 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10934853341215862 and mu_y: -0.028099028740314586\n",
      "4356, loss is 0.0018528297923474254 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10933175365919913 and mu_y: -0.028124133826858747\n",
      "4357, loss is 0.0018528206860979283 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10931498263201003 and mu_y: -0.028149225609302556\n",
      "4358, loss is 0.0018528115894412417 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10929822032541484 and mu_y: -0.028174304094825176\n",
      "4359, loss is 0.0018528025023669804 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10928146673424097 and mu_y: -0.028199369290601427\n",
      "4360, loss is 0.0018527934248647716 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10926472185331979 and mu_y: -0.028224421203801798\n",
      "4361, loss is 0.001852784356924255 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10924798567748653 and mu_y: -0.02824945984159244\n",
      "4362, loss is 0.0018527752985350839 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10923125820158038 and mu_y: -0.028274485211135174\n",
      "4363, loss is 0.00185276624968692 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10921453942044437 and mu_y: -0.028299497319587495\n",
      "4364, loss is 0.001852757210369439 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10919782932892548 and mu_y: -0.028324496174102574\n",
      "4365, loss is 0.0018527481805723275 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10918112792187455 and mu_y: -0.028349481781829264\n",
      "4366, loss is 0.0018527391602852859 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10916443519414633 and mu_y: -0.0283744541499121\n",
      "4367, loss is 0.0018527301494980237 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10914775114059942 and mu_y: -0.02839941328549131\n",
      "4368, loss is 0.001852721148200264 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10913107575609635 and mu_y: -0.028424359195702804\n",
      "4369, loss is 0.0018527121563817405 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10911440903550348 and mu_y: -0.028449291887678196\n",
      "4370, loss is 0.0018527031740322001 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1090977509736911 and mu_y: -0.028474211368544795\n",
      "4371, loss is 0.0018526942011413989 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1090811015655333 and mu_y: -0.028499117645425613\n",
      "4372, loss is 0.0018526852376991075 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10906446080590809 and mu_y: -0.028524010725439367\n",
      "4373, loss is 0.0018526762836951084 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10904782868969731 and mu_y: -0.028548890615700484\n",
      "4374, loss is 0.0018526673391191925 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10903120521178668 and mu_y: -0.028573757323319102\n",
      "4375, loss is 0.0018526584039611645 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10901459036706576 and mu_y: -0.028598610855401076\n",
      "4376, loss is 0.001852649478210842 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10899798415042797 and mu_y: -0.028623451219047986\n",
      "4377, loss is 0.0018526405618580519 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10898138655677056 and mu_y: -0.028648278421357126\n",
      "4378, loss is 0.0018526316548926345 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10896479758099463 and mu_y: -0.028673092469421527\n",
      "4379, loss is 0.001852622757304439 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10894821721800513 and mu_y: -0.028697893370329946\n",
      "4380, loss is 0.00185261386908333 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10893164546271082 and mu_y: -0.028722681131166872\n",
      "4381, loss is 0.0018526049902191826 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10891508231002431 and mu_y: -0.02874745575901254\n",
      "4382, loss is 0.0018525961207018803 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10889852775486203 and mu_y: -0.028772217260942912\n",
      "4383, loss is 0.0018525872605213223 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10888198179214423 and mu_y: -0.028796965644029712\n",
      "4384, loss is 0.0018525784096674167 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10886544441679498 and mu_y: -0.028821700915340403\n",
      "4385, loss is 0.0018525695681300852 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10884891562374216 and mu_y: -0.0288464230819382\n",
      "4386, loss is 0.001852560735899259 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10883239540791748 and mu_y: -0.02887113215088207\n",
      "4387, loss is 0.0018525519129648815 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10881588376425642 and mu_y: -0.028895828129226753\n",
      "4388, loss is 0.0018525430993169088 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10879938068769832 and mu_y: -0.028920511024022738\n",
      "4389, loss is 0.0018525342949453068 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10878288617318625 and mu_y: -0.028945180842316284\n",
      "4390, loss is 0.001852525499840053 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10876640021566714 and mu_y: -0.02896983759114942\n",
      "4391, loss is 0.001852516713991138 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10874992281009166 and mu_y: -0.028994481277559946\n",
      "4392, loss is 0.001852507937388562 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1087334539514143 and mu_y: -0.029019111908581443\n",
      "4393, loss is 0.0018524991700223368 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10871699363459333 and mu_y: -0.02904372949124327\n",
      "4394, loss is 0.0018524904118824876 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1087005418545908 and mu_y: -0.029068334032570566\n",
      "4395, loss is 0.0018524816629590483 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10868409860637251 and mu_y: -0.02909292553958426\n",
      "4396, loss is 0.0018524729232420665 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10866766388490808 and mu_y: -0.029117504019301074\n",
      "4397, loss is 0.0018524641927215985 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10865123768517083 and mu_y: -0.029142069478733518\n",
      "4398, loss is 0.0018524554713877138 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10863482000213792 and mu_y: -0.029166621924889904\n",
      "4399, loss is 0.001852446759230494 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10861841083079023 and mu_y: -0.029191161364774346\n",
      "4400, loss is 0.0018524380562400307 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10860201016611239 and mu_y: -0.029215687805386758\n",
      "4401, loss is 0.001852429362406426 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10858561800309281 and mu_y: -0.029240201253722863\n",
      "4402, loss is 0.0018524206777197952 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10856923433672365 and mu_y: -0.029264701716774196\n",
      "4403, loss is 0.0018524120021702639 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10855285916200079 and mu_y: -0.029289189201528107\n",
      "4404, loss is 0.0018524033357479688 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10853649247392386 and mu_y: -0.029313663714967762\n",
      "4405, loss is 0.001852394678443058 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10852013426749624 and mu_y: -0.029338125264072153\n",
      "4406, loss is 0.0018523860302456909 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10850378453772504 and mu_y: -0.02936257385581609\n",
      "4407, loss is 0.0018523773911460384 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10848744327962109 and mu_y: -0.029387009497170217\n",
      "4408, loss is 0.0018523687611342828 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10847111048819898 and mu_y: -0.02941143219510101\n",
      "4409, loss is 0.0018523601402006154 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10845478615847698 and mu_y: -0.029435841956570778\n",
      "4410, loss is 0.0018523515283352427 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1084384702854771 and mu_y: -0.02946023878853767\n",
      "4411, loss is 0.0018523429255283782 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10842216286422507 and mu_y: -0.02948462269795567\n",
      "4412, loss is 0.0018523343317702508 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10840586388975032 and mu_y: -0.029508993691774624\n",
      "4413, loss is 0.0018523257470510943 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.108389573357086 and mu_y: -0.02953335177694021\n",
      "4414, loss is 0.0018523171713611607 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10837329126126896 and mu_y: -0.029557696960393967\n",
      "4415, loss is 0.0018523086046907092 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10835701759733976 and mu_y: -0.02958202924907329\n",
      "4416, loss is 0.0018523000470300102 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10834075236034264 and mu_y: -0.029606348649911424\n",
      "4417, loss is 0.0018522914983693456 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10832449554532554 and mu_y: -0.02963065516983749\n",
      "4418, loss is 0.0018522829586990097 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1083082471473401 and mu_y: -0.029654948815776464\n",
      "4419, loss is 0.0018522744280093048 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1082920071614416 and mu_y: -0.0296792295946492\n",
      "4420, loss is 0.0018522659062905475 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1082757755826891 and mu_y: -0.029703497513372416\n",
      "4421, loss is 0.0018522573935330633 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10825955240614522 and mu_y: -0.02972775257885871\n",
      "4422, loss is 0.0018522488897271894 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10824333762687635 and mu_y: -0.02975199479801656\n",
      "4423, loss is 0.0018522403948632747 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1082271312399525 and mu_y: -0.029776224177750325\n",
      "4424, loss is 0.0018522319089316769 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10821093324044738 and mu_y: -0.029800440724960253\n",
      "4425, loss is 0.001852223431922768 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10819474362343832 and mu_y: -0.029824644446542477\n",
      "4426, loss is 0.0018522149638269282 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10817856238400636 and mu_y: -0.02984883534938903\n",
      "4427, loss is 0.0018522065046345493 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10816238951723615 and mu_y: -0.029873013440387827\n",
      "4428, loss is 0.0018521980543360346 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10814622501821602 and mu_y: -0.0298971787264227\n",
      "4429, loss is 0.0018521896129217968 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10813006888203795 and mu_y: -0.029921331214373372\n",
      "4430, loss is 0.001852181180382263 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10811392110379757 and mu_y: -0.029945470911115477\n",
      "4431, loss is 0.0018521727567078678 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10809778167859413 and mu_y: -0.029969597823520554\n",
      "4432, loss is 0.0018521643418890565 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10808165060153052 and mu_y: -0.02999371195845606\n",
      "4433, loss is 0.0018521559359162875 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1080655278677133 and mu_y: -0.030017813322785365\n",
      "4434, loss is 0.0018521475387800288 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10804941347225262 and mu_y: -0.030041901923367757\n",
      "4435, loss is 0.0018521391504707592 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10803330741026228 and mu_y: -0.03006597776705845\n",
      "4436, loss is 0.001852130770978969 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10801720967685968 and mu_y: -0.030090040860708583\n",
      "4437, loss is 0.0018521224002951589 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10800112026716588 and mu_y: -0.030114091211165223\n",
      "4438, loss is 0.0018521140384098402 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10798503917630553 and mu_y: -0.030138128825271372\n",
      "4439, loss is 0.0018521056853135346 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1079689663994069 and mu_y: -0.030162153709865965\n",
      "4440, loss is 0.0018520973409967751 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10795290193160184 and mu_y: -0.03018616587178388\n",
      "4441, loss is 0.0018520890054501066 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10793684576802585 and mu_y: -0.03021016531785593\n",
      "4442, loss is 0.0018520806786640827 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10792079790381803 and mu_y: -0.030234152054908883\n",
      "4443, loss is 0.0018520723606292684 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10790475833412104 and mu_y: -0.030258126089765452\n",
      "4444, loss is 0.001852064051336239 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10788872705408116 and mu_y: -0.0302820874292443\n",
      "4445, loss is 0.0018520557507755821 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10787270405884827 and mu_y: -0.030306036080160047\n",
      "4446, loss is 0.0018520474589378954 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10785668934357583 and mu_y: -0.030329972049323275\n",
      "4447, loss is 0.0018520391758137854 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10784068290342086 and mu_y: -0.030353895343540525\n",
      "4448, loss is 0.0018520309013938716 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.107824684733544 and mu_y: -0.030377805969614303\n",
      "4449, loss is 0.0018520226356687822 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10780869482910943 and mu_y: -0.030401703934343084\n",
      "4450, loss is 0.0018520143786291583 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10779271318528494 and mu_y: -0.030425589244521316\n",
      "4451, loss is 0.0018520061302656498 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10777673979724185 and mu_y: -0.030449461906939417\n",
      "4452, loss is 0.0018519978905689174 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1077607746601551 and mu_y: -0.03047332192838379\n",
      "4453, loss is 0.0018519896595296328 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10774481776920314 and mu_y: -0.03049716931563682\n",
      "4454, loss is 0.0018519814371384786 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.107728869119568 and mu_y: -0.030521004075476872\n",
      "4455, loss is 0.0018519732233861477 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10771292870643527 and mu_y: -0.0305448262146783\n",
      "4456, loss is 0.0018519650182633432 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10769699652499409 and mu_y: -0.03056863574001145\n",
      "4457, loss is 0.0018519568217607782 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10768107257043716 and mu_y: -0.030592432658242668\n",
      "4458, loss is 0.0018519486338691776 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10766515683796068 and mu_y: -0.030616216976134286\n",
      "4459, loss is 0.0018519404545792762 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10764924932276446 and mu_y: -0.030639988700444643\n",
      "4460, loss is 0.0018519322838818203 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10763335002005178 and mu_y: -0.030663747837928083\n",
      "4461, loss is 0.0018519241217675644 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10761745892502951 and mu_y: -0.03068749439533496\n",
      "4462, loss is 0.0018519159682272757 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10760157603290803 and mu_y: -0.030711228379411627\n",
      "4463, loss is 0.0018519078232517294 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10758570133890123 and mu_y: -0.030734949796900467\n",
      "4464, loss is 0.0018518996868317145 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10756983483822655 and mu_y: -0.030758658654539868\n",
      "4465, loss is 0.0018518915589580286 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10755397652610493 and mu_y: -0.030782354959064243\n",
      "4466, loss is 0.0018518834396214778 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10753812639776085 and mu_y: -0.030806038717204026\n",
      "4467, loss is 0.0018518753288128827 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10752228444842228 and mu_y: -0.03082970993568568\n",
      "4468, loss is 0.0018518672265230717 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10750645067332072 and mu_y: -0.03085336862123169\n",
      "4469, loss is 0.0018518591327428835 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10749062506769116 and mu_y: -0.030877014780560586\n",
      "4470, loss is 0.001851851047463167 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10747480762677211 and mu_y: -0.030900648420386922\n",
      "4471, loss is 0.0018518429706747843 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10745899834580558 and mu_y: -0.030924269547421303\n",
      "4472, loss is 0.0018518349023686034 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10744319722003705 and mu_y: -0.030947878168370364\n",
      "4473, loss is 0.0018518268425355055 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10742740424471552 and mu_y: -0.030971474289936796\n",
      "4474, loss is 0.0018518187911663823 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10741161941509346 and mu_y: -0.030995057918819333\n",
      "4475, loss is 0.0018518107482521343 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10739584272642684 and mu_y: -0.03101862906171276\n",
      "4476, loss is 0.0018518027137836733 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10738007417397512 and mu_y: -0.031042187725307917\n",
      "4477, loss is 0.0018517946877519209 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1073643137530012 and mu_y: -0.031065733916291707\n",
      "4478, loss is 0.0018517866701478099 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10734856145877152 and mu_y: -0.03108926764134709\n",
      "4479, loss is 0.0018517786609622805 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10733281728655593 and mu_y: -0.03111278890715309\n",
      "4480, loss is 0.0018517706601862876 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10731708123162778 and mu_y: -0.0311362977203848\n",
      "4481, loss is 0.0018517626678107924 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10730135328926388 and mu_y: -0.031159794087713386\n",
      "4482, loss is 0.001851754683826769 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1072856334547445 and mu_y: -0.03118327801580608\n",
      "4483, loss is 0.0018517467082251988 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10726992172335337 and mu_y: -0.031206749511326196\n",
      "4484, loss is 0.0018517387409970776 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10725421809037768 and mu_y: -0.031230208580933127\n",
      "4485, loss is 0.001851730782133406 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10723852255110805 and mu_y: -0.03125365523128235\n",
      "4486, loss is 0.0018517228316252 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10722283510083859 and mu_y: -0.03127708946902543\n",
      "4487, loss is 0.0018517148894634829 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10720715573486682 and mu_y: -0.03130051130081002\n",
      "4488, loss is 0.0018517069556392878 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1071914844484937 and mu_y: -0.03132392073327986\n",
      "4489, loss is 0.0018516990301436589 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10717582123702366 and mu_y: -0.031347317773074784\n",
      "4490, loss is 0.0018516911129676512 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10716016609576452 and mu_y: -0.03137070242683074\n",
      "4491, loss is 0.0018516832041023286 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10714451902002758 and mu_y: -0.03139407470117976\n",
      "4492, loss is 0.001851675303538765 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10712888000512753 and mu_y: -0.03141743460275\n",
      "4493, loss is 0.0018516674112680454 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1071132490463825 and mu_y: -0.031440782138165695\n",
      "4494, loss is 0.001851659527281264 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10709762613911404 and mu_y: -0.03146411731404721\n",
      "4495, loss is 0.0018516516515695257 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10708201127864712 and mu_y: -0.03148744013701103\n",
      "4496, loss is 0.0018516437841239435 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10706640446031013 and mu_y: -0.03151075061366975\n",
      "4497, loss is 0.0018516359249356445 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10705080567943484 and mu_y: -0.03153404875063208\n",
      "4498, loss is 0.001851628073995761 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10703521493135647 and mu_y: -0.03155733455450285\n",
      "4499, loss is 0.00185162023129544 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10701963221141363 and mu_y: -0.031580608031883034\n",
      "4500, loss is 0.0018516123968258342 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1070040575149483 and mu_y: -0.031603869189369714\n",
      "4501, loss is 0.0018516045705781075 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10698849083730592 and mu_y: -0.03162711803355612\n",
      "4502, loss is 0.0018515967525434365 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10697293217383527 and mu_y: -0.0316503545710316\n",
      "4503, loss is 0.0018515889427130046 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10695738151988854 and mu_y: -0.03167357880838167\n",
      "4504, loss is 0.001851581141078006 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1069418388708213 and mu_y: -0.03169679075218795\n",
      "4505, loss is 0.0018515733476296456 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10692630422199254 and mu_y: -0.031719990409028245\n",
      "4506, loss is 0.0018515655623591368 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10691077756876458 and mu_y: -0.03174317778547647\n",
      "4507, loss is 0.0018515577852577048 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10689525890650314 and mu_y: -0.031766352888102714\n",
      "4508, loss is 0.0018515500163165826 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10687974823057733 and mu_y: -0.03178951572347321\n",
      "4509, loss is 0.001851542255527014 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10686424553635962 and mu_y: -0.03181266629815035\n",
      "4510, loss is 0.0018515345028802537 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10684875081922583 and mu_y: -0.031835804618692676\n",
      "4511, loss is 0.001851526758367565 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10683326407455516 and mu_y: -0.031858930691654914\n",
      "4512, loss is 0.0018515190219802208 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1068177852977302 and mu_y: -0.031882044523587935\n",
      "4513, loss is 0.0018515112937095043 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10680231448413684 and mu_y: -0.03190514612103879\n",
      "4514, loss is 0.0018515035735467101 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10678685162916436 and mu_y: -0.031928235490550703\n",
      "4515, loss is 0.0018514958614831386 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10677139672820539 and mu_y: -0.031951312638663056\n",
      "4516, loss is 0.0018514881575101049 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10675594977665591 and mu_y: -0.031974377571911426\n",
      "4517, loss is 0.00185148046161893 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10674051076991523 and mu_y: -0.03199743029682757\n",
      "4518, loss is 0.001851472773800946 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10672507970338602 and mu_y: -0.03202047081993942\n",
      "4519, loss is 0.001851465094047496 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10670965657247426 and mu_y: -0.03204349914777109\n",
      "4520, loss is 0.0018514574223499297 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10669424137258932 and mu_y: -0.0320665152868429\n",
      "4521, loss is 0.0018514497586996103 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10667883409914383 and mu_y: -0.03208951924367135\n",
      "4522, loss is 0.0018514421030879093 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10666343474755381 and mu_y: -0.03211251102476914\n",
      "4523, loss is 0.001851434455506205 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10664804331323857 and mu_y: -0.03213549063664517\n",
      "4524, loss is 0.0018514268159458911 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10663265979162076 and mu_y: -0.03215845808580454\n",
      "4525, loss is 0.001851419184398365 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10661728417812633 and mu_y: -0.032181413378748545\n",
      "4526, loss is 0.0018514115608550385 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10660191646818457 and mu_y: -0.0322043565219747\n",
      "4527, loss is 0.0018514039453073304 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10658655665722806 and mu_y: -0.03222728752197673\n",
      "4528, loss is 0.0018513963377466698 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1065712047406927 and mu_y: -0.03225020638524457\n",
      "4529, loss is 0.0018513887381644961 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10655586071401771 and mu_y: -0.032273113118264356\n",
      "4530, loss is 0.001851381146552257 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10654052457264558 and mu_y: -0.03229600772751847\n",
      "4531, loss is 0.0018513735629014103 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10652519631202213 and mu_y: -0.0323188902194855\n",
      "4532, loss is 0.0018513659872034251 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10650987592759648 and mu_y: -0.032341760600640264\n",
      "4533, loss is 0.0018513584194497779 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.106494563414821 and mu_y: -0.0323646188774538\n",
      "4534, loss is 0.001851350859631955 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10647925876915139 and mu_y: -0.03238746505639339\n",
      "4535, loss is 0.0018513433077414526 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10646396198604662 and mu_y: -0.03241029914392254\n",
      "4536, loss is 0.0018513357637697774 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10644867306096895 and mu_y: -0.03243312114650099\n",
      "4537, loss is 0.0018513282277084445 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10643339198938391 and mu_y: -0.032455931070584726\n",
      "4538, loss is 0.0018513206995489783 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10641811876676034 and mu_y: -0.03247872892262598\n",
      "4539, loss is 0.0018513131792829154 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10640285338857032 and mu_y: -0.032501514709073226\n",
      "4540, loss is 0.0018513056669017972 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1063875958502892 and mu_y: -0.03252428843637118\n",
      "4541, loss is 0.0018512981623971783 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10637234614739562 and mu_y: -0.03254705011096082\n",
      "4542, loss is 0.0018512906657606218 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10635710427537147 and mu_y: -0.03256979973927937\n",
      "4543, loss is 0.0018512831769837003 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1063418702297019 and mu_y: -0.03259253732776031\n",
      "4544, loss is 0.0018512756960579956 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10632664400587533 and mu_y: -0.03261526288283339\n",
      "4545, loss is 0.0018512682229750981 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10631142559938342 and mu_y: -0.032637976410924606\n",
      "4546, loss is 0.00185126075772661 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1062962150057211 and mu_y: -0.03266067791845624\n",
      "4547, loss is 0.001851253300304141 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10628101222038654 and mu_y: -0.03268336741184683\n",
      "4548, loss is 0.0018512458506993099 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10626581723888114 and mu_y: -0.03270604489751119\n",
      "4549, loss is 0.0018512384089037462 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10625063005670957 and mu_y: -0.0327287103818604\n",
      "4550, loss is 0.0018512309749090896 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10623545066937971 and mu_y: -0.03275136387130182\n",
      "4551, loss is 0.0018512235487069856 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10622027907240272 and mu_y: -0.03277400537223911\n",
      "4552, loss is 0.0018512161302890922 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10620511526129295 and mu_y: -0.03279663489107218\n",
      "4553, loss is 0.0018512087196470772 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10618995923156799 and mu_y: -0.03281925243419725\n",
      "4554, loss is 0.0018512013167726145 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10617481097874866 and mu_y: -0.03284185800800682\n",
      "4555, loss is 0.0018511939216573903 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10615967049835902 and mu_y: -0.032864451618889685\n",
      "4556, loss is 0.0018511865342930984 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10614453778592632 and mu_y: -0.03288703327323093\n",
      "4557, loss is 0.0018511791546714442 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10612941283698106 and mu_y: -0.03290960297741193\n",
      "4558, loss is 0.001851171782784139 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10611429564705693 and mu_y: -0.032932160737810384\n",
      "4559, loss is 0.0018511644186229056 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10609918621169086 and mu_y: -0.032954706560800275\n",
      "4560, loss is 0.0018511570621794755 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10608408452642294 and mu_y: -0.03297724045275189\n",
      "4561, loss is 0.0018511497134455909 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1060689905867965 and mu_y: -0.03299976242003184\n",
      "4562, loss is 0.0018511423724130002 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10605390438835807 and mu_y: -0.03302227246900303\n",
      "4563, loss is 0.001851135039073463 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10603882592665738 and mu_y: -0.03304477060602469\n",
      "4564, loss is 0.00185112771341875 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10602375519724734 and mu_y: -0.03306725683745236\n",
      "4565, loss is 0.0018511203954406368 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10600869219568407 and mu_y: -0.03308973116963791\n",
      "4566, loss is 0.001851113085130911 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10599363691752686 and mu_y: -0.03311219360892953\n",
      "4567, loss is 0.0018511057824813692 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1059785893583382 and mu_y: -0.03313464416167172\n",
      "4568, loss is 0.0018510984874838161 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10596354951368378 and mu_y: -0.033157082834205334\n",
      "4569, loss is 0.0018510912001300675 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10594851737913244 and mu_y: -0.03317950963286754\n",
      "4570, loss is 0.0018510839204119453 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10593349295025621 and mu_y: -0.03320192456399184\n",
      "4571, loss is 0.0018510766483212844 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1059184762226303 and mu_y: -0.033224327633908084\n",
      "4572, loss is 0.0018510693838499257 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10590346719183308 and mu_y: -0.033246718848942446\n",
      "4573, loss is 0.0018510621269897214 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10588846585344609 and mu_y: -0.03326909821541746\n",
      "4574, loss is 0.0018510548777325297 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10587347220305406 and mu_y: -0.033291465739651985\n",
      "4575, loss is 0.0018510476360702216 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10585848623624483 and mu_y: -0.03331382142796124\n",
      "4576, loss is 0.0018510404019946745 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10584350794860946 and mu_y: -0.03333616528665681\n",
      "4577, loss is 0.0018510331754977784 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10582853733574211 and mu_y: -0.0333584973220466\n",
      "4578, loss is 0.0018510259565714272 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10581357439324014 and mu_y: -0.03338081754043489\n",
      "4579, loss is 0.001851018745207527 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10579861911670405 and mu_y: -0.03340312594812233\n",
      "4580, loss is 0.0018510115413979931 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10578367150173744 and mu_y: -0.0334254225514059\n",
      "4581, loss is 0.0018510043451347494 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10576873154394711 and mu_y: -0.03344770735657898\n",
      "4582, loss is 0.0018509971564097294 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.105753799238943 and mu_y: -0.0334699803699313\n",
      "4583, loss is 0.0018509899752148738 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10573887458233815 and mu_y: -0.03349224159774895\n",
      "4584, loss is 0.0018509828015421332 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10572395756974876 and mu_y: -0.03351449104631441\n",
      "4585, loss is 0.0018509756353834678 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10570904819679415 and mu_y: -0.033536728721906536\n",
      "4586, loss is 0.0018509684767308468 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10569414645909678 and mu_y: -0.03355895463080055\n",
      "4587, loss is 0.0018509613255762469 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10567925235228223 and mu_y: -0.03358116877926807\n",
      "4588, loss is 0.001850954181911656 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10566436587197921 and mu_y: -0.033603371173577076\n",
      "4589, loss is 0.00185094704572907 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10564948701381954 and mu_y: -0.033625561819991955\n",
      "4590, loss is 0.0018509399170204925 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10563461577343816 and mu_y: -0.03364774072477348\n",
      "4591, loss is 0.001850932795777937 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10561975214647314 and mu_y: -0.033669907894178806\n",
      "4592, loss is 0.0018509256819934262 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10560489612856562 and mu_y: -0.033692063334461494\n",
      "4593, loss is 0.0018509185756589923 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10559004771535989 and mu_y: -0.033714207051871496\n",
      "4594, loss is 0.001850911476766675 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10557520690250333 and mu_y: -0.03373633905265517\n",
      "4595, loss is 0.0018509043853085225 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10556037368564643 and mu_y: -0.03375845934305527\n",
      "4596, loss is 0.0018508973012765942 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10554554806044275 and mu_y: -0.03378056792931096\n",
      "4597, loss is 0.001850890224662956 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10553073002254898 and mu_y: -0.03380266481765781\n",
      "4598, loss is 0.0018508831554596848 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10551591956762489 and mu_y: -0.03382475001432781\n",
      "4599, loss is 0.0018508760936588636 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10550111669133334 and mu_y: -0.033846823525549345\n",
      "4600, loss is 0.001850869039252587 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10548632138934029 and mu_y: -0.033868885357547236\n",
      "4601, loss is 0.0018508619922329571 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10547153365731475 and mu_y: -0.033890935516542715\n",
      "4602, loss is 0.0018508549525920852 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10545675349092884 and mu_y: -0.03391297400875344\n",
      "4603, loss is 0.00185084792032209 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10544198088585775 and mu_y: -0.033935000840393484\n",
      "4604, loss is 0.0018508408954151009 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10542721583777977 and mu_y: -0.03395701601767336\n",
      "4605, loss is 0.0018508338778632557 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10541245834237621 and mu_y: -0.03397901954680001\n",
      "4606, loss is 0.0018508268676586995 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1053977083953315 and mu_y: -0.03400101143397678\n",
      "4607, loss is 0.0018508198647935884 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10538296599233311 and mu_y: -0.0340229916854035\n",
      "4608, loss is 0.001850812869260085 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1053682311290716 and mu_y: -0.034044960307276405\n",
      "4609, loss is 0.0018508058810503623 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10535350380124053 and mu_y: -0.03406691730578818\n",
      "4610, loss is 0.0018507989001566012 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1053387840045366 and mu_y: -0.034088862687127956\n",
      "4611, loss is 0.0018507919265709919 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1053240717346595 and mu_y: -0.0341107964574813\n",
      "4612, loss is 0.0018507849602857334 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10530936698731201 and mu_y: -0.03413271862303024\n",
      "4613, loss is 0.0018507780012930314 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10529466975819994 and mu_y: -0.034154629189953246\n",
      "4614, loss is 0.0018507710495851027 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10527998004303216 and mu_y: -0.03417652816442525\n",
      "4615, loss is 0.0018507641051541722 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10526529783752056 and mu_y: -0.034198415552617635\n",
      "4616, loss is 0.0018507571679924734 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10525062313738011 and mu_y: -0.03422029136069825\n",
      "4617, loss is 0.0018507502380922464 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10523595593832878 and mu_y: -0.0342421555948314\n",
      "4618, loss is 0.0018507433154457444 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1052212962360876 and mu_y: -0.03426400826117786\n",
      "4619, loss is 0.0018507364000452241 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10520664402638061 and mu_y: -0.03428584936589487\n",
      "4620, loss is 0.0018507294918829545 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10519199930493489 and mu_y: -0.03430767891513613\n",
      "4621, loss is 0.0018507225909512126 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10517736206748056 and mu_y: -0.03432949691505183\n",
      "4622, loss is 0.0018507156972422827 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10516273230975075 and mu_y: -0.03435130337178862\n",
      "4623, loss is 0.0018507088107484581 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1051481100274816 and mu_y: -0.03437309829148965\n",
      "4624, loss is 0.0018507019314620416 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10513349521641228 and mu_y: -0.034394881680294524\n",
      "4625, loss is 0.0018506950593753428 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10511888787228499 and mu_y: -0.03441665354433935\n",
      "4626, loss is 0.0018506881944806827 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1051042879908449 and mu_y: -0.03443841388975671\n",
      "4627, loss is 0.0018506813367703881 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10508969556784023 and mu_y: -0.03446016272267567\n",
      "4628, loss is 0.0018506744862367946 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10507511059902219 and mu_y: -0.03448190004922181\n",
      "4629, loss is 0.0018506676428722488 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10506053308014499 and mu_y: -0.03450362587551718\n",
      "4630, loss is 0.0018506608066691044 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10504596300696584 and mu_y: -0.03452534020768035\n",
      "4631, loss is 0.0018506539776197207 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10503140037524496 and mu_y: -0.034547043051826355\n",
      "4632, loss is 0.0018506471557164707 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10501684518074555 and mu_y: -0.03456873441406676\n",
      "4633, loss is 0.001850640340951731 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10500229741923382 and mu_y: -0.034590414300509624\n",
      "4634, loss is 0.0018506335333178918 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10498775708647895 and mu_y: -0.03461208271725952\n",
      "4635, loss is 0.001850626732807347 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10497322417825312 and mu_y: -0.03463373967041751\n",
      "4636, loss is 0.001850619939412501 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10495869869033149 and mu_y: -0.034655385166081194\n",
      "4637, loss is 0.0018506131531257671 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10494418061849219 and mu_y: -0.034677019210344676\n",
      "4638, loss is 0.001850606373939566 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10492966995851634 and mu_y: -0.034698641809298575\n",
      "4639, loss is 0.0018505996018463276 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10491516670618803 and mu_y: -0.03472025296903003\n",
      "4640, loss is 0.0018505928368384903 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10490067085729432 and mu_y: -0.0347418526956227\n",
      "4641, loss is 0.0018505860789085 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10488618240762526 and mu_y: -0.03476344099515678\n",
      "4642, loss is 0.001850579328048811 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10487170135297384 and mu_y: -0.03478501787370898\n",
      "4643, loss is 0.0018505725842518875 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10485722768913602 and mu_y: -0.03480658333735255\n",
      "4644, loss is 0.0018505658475102005 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10484276141191073 and mu_y: -0.03482813739215727\n",
      "4645, loss is 0.0018505591178162306 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10482830251709986 and mu_y: -0.03484968004418944\n",
      "4646, loss is 0.001850552395162465 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10481385100050823 and mu_y: -0.03487121129951192\n",
      "4647, loss is 0.0018505456795414007 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10479940685794366 and mu_y: -0.0348927311641841\n",
      "4648, loss is 0.001850538970945543 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10478497008521687 and mu_y: -0.034914239644261914\n",
      "4649, loss is 0.001850532269367405 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10477054067814155 and mu_y: -0.03493573674579784\n",
      "4650, loss is 0.0018505255747995075 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10475611863253434 and mu_y: -0.03495722247484092\n",
      "4651, loss is 0.001850518887234383 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10474170394421481 and mu_y: -0.034978696837436714\n",
      "4652, loss is 0.0018505122066645669 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10472729660900548 and mu_y: -0.035000159839627364\n",
      "4653, loss is 0.0018505055330826064 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10471289662273181 and mu_y: -0.03502161148745155\n",
      "4654, loss is 0.0018504988664810563 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10469850398122217 and mu_y: -0.03504305178694453\n",
      "4655, loss is 0.00185049220685248 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10468411868030787 and mu_y: -0.0350644807441381\n",
      "4656, loss is 0.001850485554189449 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10466974071582316 and mu_y: -0.03508589836506063\n",
      "4657, loss is 0.0018504789084845407 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1046553700836052 and mu_y: -0.03510730465573706\n",
      "4658, loss is 0.0018504722697303458 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10464100677949409 and mu_y: -0.03512869962218889\n",
      "4659, loss is 0.0018504656379194585 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10462665079933282 and mu_y: -0.0351500832704342\n",
      "4660, loss is 0.0018504590130444833 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10461230213896734 and mu_y: -0.035171455606487635\n",
      "4661, loss is 0.001850452395098033 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10459796079424648 and mu_y: -0.03519281663636042\n",
      "4662, loss is 0.001850445784072727 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10458362676102198 and mu_y: -0.035214166366060354\n",
      "4663, loss is 0.001850439179961195 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10456930003514851 and mu_y: -0.03523550480159183\n",
      "4664, loss is 0.0018504325827560734 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10455498061248364 and mu_y: -0.035256831948955805\n",
      "4665, loss is 0.0018504259924500075 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10454066848888784 and mu_y: -0.03527814781414984\n",
      "4666, loss is 0.001850419409035652 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10452636366022447 and mu_y: -0.03529945240316808\n",
      "4667, loss is 0.001850412832505666 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1045120661223598 and mu_y: -0.03532074572200125\n",
      "4668, loss is 0.0018504062628527196 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10449777587116299 and mu_y: -0.035342027776636684\n",
      "4669, loss is 0.0018503997000694906 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1044834929025061 and mu_y: -0.0353632985730583\n",
      "4670, loss is 0.0018503931441486657 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10446921721226407 and mu_y: -0.03538455811724661\n",
      "4671, loss is 0.001850386595082938 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10445494879631474 and mu_y: -0.03540580641517875\n",
      "4672, loss is 0.0018503800528650082 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10444068765053882 and mu_y: -0.03542704347282844\n",
      "4673, loss is 0.0018503735174875881 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10442643377081991 and mu_y: -0.03544826929616602\n",
      "4674, loss is 0.001850366988943396 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10441218715304447 and mu_y: -0.03546948389115842\n",
      "4675, loss is 0.0018503604672251562 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10439794779310187 and mu_y: -0.035490687263769194\n",
      "4676, loss is 0.001850353952325605 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10438371568688433 and mu_y: -0.03551187941995851\n",
      "4677, loss is 0.0018503474442374832 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10436949083028695 and mu_y: -0.03553306036568314\n",
      "4678, loss is 0.001850340942953541 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10435527321920768 and mu_y: -0.0355542301068965\n",
      "4679, loss is 0.0018503344484665377 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10434106284954736 and mu_y: -0.035575388649548595\n",
      "4680, loss is 0.0018503279607692403 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10432685971720969 and mu_y: -0.03559653599958607\n",
      "4681, loss is 0.0018503214798544212 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10431266381810121 and mu_y: -0.0356176721629522\n",
      "4682, loss is 0.0018503150057148645 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10429847514813134 and mu_y: -0.03563879714558688\n",
      "4683, loss is 0.0018503085383433592 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10428429370321235 and mu_y: -0.03565991095342664\n",
      "4684, loss is 0.0018503020777327047 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10427011947925935 and mu_y: -0.03568101359240464\n",
      "4685, loss is 0.0018502956238757075 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1042559524721903 and mu_y: -0.035702105068450674\n",
      "4686, loss is 0.0018502891767651802 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10424179267792602 and mu_y: -0.03572318538749118\n",
      "4687, loss is 0.0018502827363939462 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10422764009239016 and mu_y: -0.03574425455544924\n",
      "4688, loss is 0.0018502763027548356 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10421349471150922 and mu_y: -0.03576531257824456\n",
      "4689, loss is 0.0018502698758406867 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10419935653121254 and mu_y: -0.03578635946179351\n",
      "4690, loss is 0.001850263455644345 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1041852255474323 and mu_y: -0.035807395212009104\n",
      "4691, loss is 0.0018502570421586647 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1041711017561035 and mu_y: -0.035828419834801006\n",
      "4692, loss is 0.0018502506353765072 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10415698515316398 and mu_y: -0.03584943333607553\n",
      "4693, loss is 0.001850244235290743 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1041428757345544 and mu_y: -0.03587043572173564\n",
      "4694, loss is 0.0018502378418942499 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10412877349621825 and mu_y: -0.03589142699768098\n",
      "4695, loss is 0.0018502314551799121 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10411467843410187 and mu_y: -0.03591240716980782\n",
      "4696, loss is 0.0018502250751406242 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10410059054415437 and mu_y: -0.03593337624400912\n",
      "4697, loss is 0.0018502187017692864 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10408650982232771 and mu_y: -0.0359543342261745\n",
      "4698, loss is 0.0018502123350588088 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10407243626457667 and mu_y: -0.035975281122190235\n",
      "4699, loss is 0.0018502059750021074 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10405836986685882 and mu_y: -0.03599621693793928\n",
      "4700, loss is 0.0018501996215921064 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10404431062513456 and mu_y: -0.03601714167930126\n",
      "4701, loss is 0.00185019327482174 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10403025853536707 and mu_y: -0.036038055352152466\n",
      "4702, loss is 0.0018501869346839478 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10401621359352237 and mu_y: -0.03605895796236589\n",
      "4703, loss is 0.0018501806011716783 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10400217579556925 and mu_y: -0.03607984951581118\n",
      "4704, loss is 0.0018501742742778862 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10398814513747934 and mu_y: -0.036100730018354676\n",
      "4705, loss is 0.001850167953995536 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10397412161522701 and mu_y: -0.0361215994758594\n",
      "4706, loss is 0.0018501616403175992 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10396010522478948 and mu_y: -0.03614245789418505\n",
      "4707, loss is 0.0018501553332370556 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10394609596214673 and mu_y: -0.036163305279188034\n",
      "4708, loss is 0.0018501490327468913 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10393209382328153 and mu_y: -0.036184141636721436\n",
      "4709, loss is 0.0018501427388401019 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10391809880417945 and mu_y: -0.03620496697263504\n",
      "4710, loss is 0.0018501364515096895 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10390411090082884 and mu_y: -0.03622578129277533\n",
      "4711, loss is 0.0018501301707486632 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10389013010922082 and mu_y: -0.03624658460298547\n",
      "4712, loss is 0.0018501238965500431 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10387615642534931 and mu_y: -0.03626737690910535\n",
      "4713, loss is 0.0018501176289068535 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10386218984521098 and mu_y: -0.036288158216971546\n",
      "4714, loss is 0.0018501113678121275 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1038482303648053 and mu_y: -0.03630892853241735\n",
      "4715, loss is 0.0018501051132589065 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10383427798013449 and mu_y: -0.036329687861272754\n",
      "4716, loss is 0.00185009886524024 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10382033268720355 and mu_y: -0.036350436209364456\n",
      "4717, loss is 0.001850092623749183 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10380639448202024 and mu_y: -0.03637117358251588\n",
      "4718, loss is 0.0018500863887788007 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1037924633605951 and mu_y: -0.03639189998654717\n",
      "4719, loss is 0.0018500801603221644 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1037785393189414 and mu_y: -0.03641261542727516\n",
      "4720, loss is 0.0018500739383723525 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10376462235307521 and mu_y: -0.03643331991051343\n",
      "4721, loss is 0.0018500677229224534 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1037507124590153 and mu_y: -0.03645401344207227\n",
      "4722, loss is 0.0018500615139655605 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10373680963278326 and mu_y: -0.03647469602775869\n",
      "4723, loss is 0.001850055311494778 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10372291387040337 and mu_y: -0.03649536767337645\n",
      "4724, loss is 0.0018500491155032128 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1037090251679027 and mu_y: -0.036516028384726014\n",
      "4725, loss is 0.0018500429259839853 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10369514352131104 and mu_y: -0.036536678167604586\n",
      "4726, loss is 0.0018500367429302176 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10368126892666094 and mu_y: -0.03655731702780611\n",
      "4727, loss is 0.0018500305663350452 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10366740137998767 and mu_y: -0.03657794497112126\n",
      "4728, loss is 0.001850024396191606 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10365354087732928 and mu_y: -0.03659856200333745\n",
      "4729, loss is 0.0018500182324930482 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10363968741472651 and mu_y: -0.036619168130238834\n",
      "4730, loss is 0.0018500120752325282 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10362584098822285 and mu_y: -0.03663976335760631\n",
      "4731, loss is 0.0018500059244032075 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10361200159386452 and mu_y: -0.036660347691217524\n",
      "4732, loss is 0.0018499997799982563 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10359816922770047 and mu_y: -0.036680921136846865\n",
      "4733, loss is 0.001849993642010854 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10358434388578239 and mu_y: -0.036701483700265485\n",
      "4734, loss is 0.0018499875104341851 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10357052556416466 and mu_y: -0.03672203538724127\n",
      "4735, loss is 0.0018499813852614429 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10355671425890439 and mu_y: -0.036742576203538865\n",
      "4736, loss is 0.0018499752664858265 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10354290996606144 and mu_y: -0.03676310615491969\n",
      "4737, loss is 0.001849969154100546 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10352911268169836 and mu_y: -0.03678362524714191\n",
      "4738, loss is 0.0018499630480988145 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1035153224018804 and mu_y: -0.03680413348596045\n",
      "4739, loss is 0.001849956948473856 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10350153912267554 and mu_y: -0.036824630877127\n",
      "4740, loss is 0.0018499508552189004 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10348776284015446 and mu_y: -0.036845117426390024\n",
      "4741, loss is 0.0018499447683271864 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10347399355039055 and mu_y: -0.03686559313949475\n",
      "4742, loss is 0.001849938687791959 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10346023124945991 and mu_y: -0.03688605802218318\n",
      "4743, loss is 0.0018499326136064693 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10344647593344133 and mu_y: -0.036906512080194076\n",
      "4744, loss is 0.0018499265457639798 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1034327275984163 and mu_y: -0.036926955319262995\n",
      "4745, loss is 0.0018499204842577555 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10341898624046901 and mu_y: -0.03694738774512226\n",
      "4746, loss is 0.0018499144290810721 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10340525185568633 and mu_y: -0.036967809363500984\n",
      "4747, loss is 0.0018499083802272138 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10339152444015784 and mu_y: -0.03698822018012505\n",
      "4748, loss is 0.001849902337689468 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10337780398997579 and mu_y: -0.037008620200717136\n",
      "4749, loss is 0.0018498963014611331 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10336409050123513 and mu_y: -0.037029009430996705\n",
      "4750, loss is 0.0018498902715355127 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10335038397003349 and mu_y: -0.03704938787668\n",
      "4751, loss is 0.0018498842479059193 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10333668439247118 and mu_y: -0.037069755543480076\n",
      "4752, loss is 0.001849878230565671 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10332299176465118 and mu_y: -0.03709011243710676\n",
      "4753, loss is 0.001849872219508096 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10330930608267916 and mu_y: -0.03711045856326669\n",
      "4754, loss is 0.0018498662147265273 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10329562734266344 and mu_y: -0.037130793927663296\n",
      "4755, loss is 0.0018498602162143058 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10328195554071505 and mu_y: -0.037151118535996806\n",
      "4756, loss is 0.001849854223964781 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10326829067294765 and mu_y: -0.03717143239396426\n",
      "4757, loss is 0.001849848237971308 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1032546327354776 and mu_y: -0.0371917355072595\n",
      "4758, loss is 0.0018498422582272495 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10324098172442388 and mu_y: -0.03721202788157318\n",
      "4759, loss is 0.001849836284725977 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10322733763590818 and mu_y: -0.037232309522592745\n",
      "4760, loss is 0.0018498303174608675 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10321370046605481 and mu_y: -0.03725258043600247\n",
      "4761, loss is 0.001849824356425306 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10320007021099077 and mu_y: -0.03727284062748345\n",
      "4762, loss is 0.001849818401612686 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1031864468668457 and mu_y: -0.037293090102713575\n",
      "4763, loss is 0.0018498124530164064 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10317283042975187 and mu_y: -0.037313328867367566\n",
      "4764, loss is 0.0018498065106298726 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10315922089584421 and mu_y: -0.03733355692711697\n",
      "4765, loss is 0.0018498005744465012 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10314561826126034 and mu_y: -0.03735377428763015\n",
      "4766, loss is 0.0018497946444597114 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10313202252214046 and mu_y: -0.0373739809545723\n",
      "4767, loss is 0.0018497887206629336 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10311843367462746 and mu_y: -0.03739417693360543\n",
      "4768, loss is 0.0018497828030496011 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10310485171486683 and mu_y: -0.037414362230388395\n",
      "4769, loss is 0.0018497768916131592 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10309127663900673 and mu_y: -0.03743453685057688\n",
      "4770, loss is 0.0018497709863470563 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10307770844319795 and mu_y: -0.037454700799823396\n",
      "4771, loss is 0.001849765087244751 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1030641471235939 and mu_y: -0.03747485408377729\n",
      "4772, loss is 0.0018497591942997068 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10305059267635061 and mu_y: -0.03749499670808477\n",
      "4773, loss is 0.0018497533075053974 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10303704509762678 and mu_y: -0.03751512867838885\n",
      "4774, loss is 0.0018497474268552997 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10302350438358368 and mu_y: -0.037535250000329416\n",
      "4775, loss is 0.0018497415523428995 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10300997053038524 and mu_y: -0.03755536067954319\n",
      "4776, loss is 0.0018497356839616919 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10299644353419801 and mu_y: -0.03757546072166374\n",
      "4777, loss is 0.0018497298217051762 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10298292339119114 and mu_y: -0.037595550132321486\n",
      "4778, loss is 0.0018497239655668593 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1029694100975364 and mu_y: -0.037615628917143706\n",
      "4779, loss is 0.001849718115540257 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1029559036494082 and mu_y: -0.03763569708175452\n",
      "4780, loss is 0.00184971227161889 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1029424040429835 and mu_y: -0.03765575463177492\n",
      "4781, loss is 0.001849706433796288 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10292891127444195 and mu_y: -0.037675801572822736\n",
      "4782, loss is 0.0018497006020659862 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10291542533996574 and mu_y: -0.03769583791051268\n",
      "4783, loss is 0.0018496947764215284 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10290194623573969 and mu_y: -0.03771586365045632\n",
      "4784, loss is 0.0018496889568564644 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10288847395795121 and mu_y: -0.03773587879826209\n",
      "4785, loss is 0.0018496831433643512 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10287500850279034 and mu_y: -0.03775588335953529\n",
      "4786, loss is 0.001849677335938753 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10286154986644967 and mu_y: -0.03777587733987808\n",
      "4787, loss is 0.0018496715345732414 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10284809804512443 and mu_y: -0.037795860744889526\n",
      "4788, loss is 0.001849665739261395 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10283465303501241 and mu_y: -0.03781583358016553\n",
      "4789, loss is 0.001849659949996798 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.102821214832314 and mu_y: -0.037835795851298884\n",
      "4790, loss is 0.0018496541667730446 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10280778343323219 and mu_y: -0.037855747563879265\n",
      "4791, loss is 0.001849648389583734 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10279435883397253 and mu_y: -0.03787568872349323\n",
      "4792, loss is 0.0018496426184224707 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10278094103074317 and mu_y: -0.03789561933572421\n",
      "4793, loss is 0.0018496368532828714 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10276753001975483 and mu_y: -0.03791553940615253\n",
      "4794, loss is 0.0018496310941585538 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10275412579722083 and mu_y: -0.03793544894035541\n",
      "4795, loss is 0.0018496253410431466 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10274072835935703 and mu_y: -0.037955347943906925\n",
      "4796, loss is 0.0018496195939302846 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1027273377023819 and mu_y: -0.037975236422378086\n",
      "4797, loss is 0.001849613852813609 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10271395382251645 and mu_y: -0.03799511438133677\n",
      "4798, loss is 0.0018496081176867683 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10270057671598429 and mu_y: -0.038014981826347764\n",
      "4799, loss is 0.0018496023885434174 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10268720637901156 and mu_y: -0.03803483876297274\n",
      "4800, loss is 0.0018495966653772182 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.102673842807827 and mu_y: -0.038054685196770285\n",
      "4801, loss is 0.0018495909481818422 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10266048599866189 and mu_y: -0.038074521133295874\n",
      "4802, loss is 0.0018495852369509638 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10264713594775006 and mu_y: -0.0380943465781019\n",
      "4803, loss is 0.0018495795316782675 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10263379265132792 and mu_y: -0.038114161536737655\n",
      "4804, loss is 0.0018495738323574414 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10262045610563444 and mu_y: -0.038133966014749346\n",
      "4805, loss is 0.0018495681389821834 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10260712630691111 and mu_y: -0.03815376001768008\n",
      "4806, loss is 0.0018495624515461983 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10259380325140201 and mu_y: -0.038173543551069895\n",
      "4807, loss is 0.001849556770043196 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10258048693535372 and mu_y: -0.038193316620455726\n",
      "4808, loss is 0.0018495510944668955 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1025671773550154 and mu_y: -0.03821307923137144\n",
      "4809, loss is 0.001849545424811019 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10255387450663876 and mu_y: -0.03823283138934781\n",
      "4810, loss is 0.0018495397610693001 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10254057838647802 and mu_y: -0.038252573099912555\n",
      "4811, loss is 0.0018495341032354756 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10252728899078997 and mu_y: -0.03827230436859029\n",
      "4812, loss is 0.0018495284513032919 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1025140063158339 and mu_y: -0.038292025200902566\n",
      "4813, loss is 0.0018495228052665003 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10250073035787169 and mu_y: -0.03831173560236787\n",
      "4814, loss is 0.00184951716511886 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10248746111316769 and mu_y: -0.03833143557850162\n",
      "4815, loss is 0.001849511530854136 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10247419857798881 and mu_y: -0.03835112513481615\n",
      "4816, loss is 0.0018495059024661016 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1024609427486045 and mu_y: -0.03837080427682075\n",
      "4817, loss is 0.0018495002799485357 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10244769362128671 and mu_y: -0.038390473010021624\n",
      "4818, loss is 0.0018494946632952244 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10243445119230993 and mu_y: -0.03841013133992194\n",
      "4819, loss is 0.0018494890524999611 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10242121545795115 and mu_y: -0.038429779272021784\n",
      "4820, loss is 0.001849483447556545 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1024079864144899 and mu_y: -0.0384494168118182\n",
      "4821, loss is 0.0018494778484587832 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1023947640582082 and mu_y: -0.038469043964805175\n",
      "4822, loss is 0.0018494722552004884 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10238154838539064 and mu_y: -0.03848866073647364\n",
      "4823, loss is 0.00184946666777548 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10236833939232425 and mu_y: -0.03850826713231148\n",
      "4824, loss is 0.0018494610861775863 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10235513707529861 and mu_y: -0.03852786315780352\n",
      "4825, loss is 0.0018494555104006404 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1023419414306058 and mu_y: -0.038547448818431564\n",
      "4826, loss is 0.0018494499404384823 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10232875245454041 and mu_y: -0.03856702411967434\n",
      "4827, loss is 0.0018494443762849591 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10231557014339952 and mu_y: -0.03858658906700755\n",
      "4828, loss is 0.001849438817933924 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10230239449348272 and mu_y: -0.03860614366590386\n",
      "4829, loss is 0.0018494332653792387 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10228922550109208 and mu_y: -0.0386256879218329\n",
      "4830, loss is 0.0018494277186147695 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10227606316253221 and mu_y: -0.03864522184026125\n",
      "4831, loss is 0.001849422177634391 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10226290747411015 and mu_y: -0.03866474542665247\n",
      "4832, loss is 0.0018494166424319837 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10224975843213549 and mu_y: -0.03868425868646708\n",
      "4833, loss is 0.0018494111130014327 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10223661603292028 and mu_y: -0.03870376162516257\n",
      "4834, loss is 0.0018494055893366352 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10222348027277905 and mu_y: -0.03872325424819341\n",
      "4835, loss is 0.0018494000714314907 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10221035114802884 and mu_y: -0.038742736561011036\n",
      "4836, loss is 0.0018493945592799059 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10219722865498915 and mu_y: -0.03876220856906387\n",
      "4837, loss is 0.0018493890528757959 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10218411278998196 and mu_y: -0.03878167027779731\n",
      "4838, loss is 0.00184938355221308 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10217100354933176 and mu_y: -0.03880112169265373\n",
      "4839, loss is 0.001849378057285686 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10215790092936546 and mu_y: -0.038820562819072486\n",
      "4840, loss is 0.0018493725680875474 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1021448049264125 and mu_y: -0.03883999366248993\n",
      "4841, loss is 0.0018493670846126055 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10213171553680475 and mu_y: -0.03885941422833939\n",
      "4842, loss is 0.001849361606854808 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10211863275687659 and mu_y: -0.03887882452205119\n",
      "4843, loss is 0.001849356134808107 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10210555658296482 and mu_y: -0.038898224549052646\n",
      "4844, loss is 0.0018493506684664636 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10209248701140873 and mu_y: -0.038917614314768055\n",
      "4845, loss is 0.001849345207823845 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10207942403855008 and mu_y: -0.038936993824618724\n",
      "4846, loss is 0.0018493397528742243 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10206636766073308 and mu_y: -0.03895636308402295\n",
      "4847, loss is 0.0018493343036115818 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1020533178743044 and mu_y: -0.03897572209839604\n",
      "4848, loss is 0.0018493288600299042 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10204027467561315 and mu_y: -0.03899507087315028\n",
      "4849, loss is 0.0018493234221231853 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10202723806101092 and mu_y: -0.03901440941369499\n",
      "4850, loss is 0.0018493179898854233 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10201420802685175 and mu_y: -0.03903373772543647\n",
      "4851, loss is 0.0018493125633106265 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1020011845694921 and mu_y: -0.039053055813778034\n",
      "4852, loss is 0.0018493071423928062 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10198816768529091 and mu_y: -0.039072363684120016\n",
      "4853, loss is 0.0018493017271259838 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10197515737060954 and mu_y: -0.03909166134185975\n",
      "4854, loss is 0.0018492963175041834 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10196215362181181 and mu_y: -0.03911094879239159\n",
      "4855, loss is 0.0018492909135214377 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10194915643526398 and mu_y: -0.0391302260411069\n",
      "4856, loss is 0.0018492855151717874 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10193616580733474 and mu_y: -0.03914949309339407\n",
      "4857, loss is 0.0018492801224492758 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10192318173439521 and mu_y: -0.03916874995463851\n",
      "4858, loss is 0.0018492747353479563 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10191020421281898 and mu_y: -0.03918799663022265\n",
      "4859, loss is 0.0018492693538618864 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10189723323898202 and mu_y: -0.03920723312552593\n",
      "4860, loss is 0.0018492639779851313 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10188426880926277 and mu_y: -0.039226459445924844\n",
      "4861, loss is 0.0018492586077117636 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10187131092004208 and mu_y: -0.03924567559679289\n",
      "4862, loss is 0.00184925324303586 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10185835956770323 and mu_y: -0.0392648815835006\n",
      "4863, loss is 0.001849247883951506 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10184541474863192 and mu_y: -0.03928407741141555\n",
      "4864, loss is 0.0018492425304527905 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10183247645921627 and mu_y: -0.03930326308590234\n",
      "4865, loss is 0.001849237182533812 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10181954469584684 and mu_y: -0.03932243861232261\n",
      "4866, loss is 0.0018492318401886752 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10180661945491656 and mu_y: -0.039341603996035035\n",
      "4867, loss is 0.001849226503411488 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10179370073282083 and mu_y: -0.039360759242395335\n",
      "4868, loss is 0.0018492211721963686 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10178078852595744 and mu_y: -0.03937990435675627\n",
      "4869, loss is 0.0018492158465374395 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10176788283072657 and mu_y: -0.039399039344467646\n",
      "4870, loss is 0.0018492105264288298 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10175498364353085 and mu_y: -0.03941816421087631\n",
      "4871, loss is 0.0018492052118646751 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10174209096077527 and mu_y: -0.03943727896132616\n",
      "4872, loss is 0.001849199902839119 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10172920477886725 and mu_y: -0.039456383601158135\n",
      "4873, loss is 0.0018491945993463084 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10171632509421662 and mu_y: -0.03947547813571025\n",
      "4874, loss is 0.0018491893013803983 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10170345190323558 and mu_y: -0.039494562570317554\n",
      "4875, loss is 0.001849184008935551 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10169058520233877 and mu_y: -0.03951363691031216\n",
      "4876, loss is 0.0018491787220059341 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1016777249879432 and mu_y: -0.03953270116102323\n",
      "4877, loss is 0.0018491734405857202 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10166487125646825 and mu_y: -0.03955175532777701\n",
      "4878, loss is 0.001849168164669091 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10165202400433575 and mu_y: -0.03957079941589677\n",
      "4879, loss is 0.0018491628942502334 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10163918322796986 and mu_y: -0.03958983343070288\n",
      "4880, loss is 0.0018491576293233392 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10162634892379717 and mu_y: -0.03960885737751276\n",
      "4881, loss is 0.0018491523698826082 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10161352108824663 and mu_y: -0.0396278712616409\n",
      "4882, loss is 0.0018491471159222462 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10160069971774958 and mu_y: -0.039646875088398856\n",
      "4883, loss is 0.0018491418674364654 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10158788480873976 and mu_y: -0.03966586886309526\n",
      "4884, loss is 0.0018491366244194837 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10157507635765324 and mu_y: -0.039684852591035824\n",
      "4885, loss is 0.0018491313868655263 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10156227436092852 and mu_y: -0.03970382627752333\n",
      "4886, loss is 0.0018491261547688238 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10154947881500645 and mu_y: -0.03972278992785763\n",
      "4887, loss is 0.0018491209281236121 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10153668971633024 and mu_y: -0.03974174354733568\n",
      "4888, loss is 0.0018491157069241361 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10152390706134551 and mu_y: -0.03976068714125149\n",
      "4889, loss is 0.0018491104911646456 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10151113084650021 and mu_y: -0.03977962071489618\n",
      "4890, loss is 0.0018491052808393956 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10149836106824467 and mu_y: -0.039798544273557925\n",
      "4891, loss is 0.001849100075942648 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10148559772303158 and mu_y: -0.039817457822522016\n",
      "4892, loss is 0.001849094876468673 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.101472840807316 and mu_y: -0.039836361367070826\n",
      "4893, loss is 0.0018490896824117438 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10146009031755535 and mu_y: -0.03985525491248381\n",
      "4894, loss is 0.0018490844937661417 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10144734625020939 and mu_y: -0.03987413846403753\n",
      "4895, loss is 0.0018490793105261543 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10143460860174026 and mu_y: -0.039893012027005625\n",
      "4896, loss is 0.0018490741326860737 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10142187736861245 and mu_y: -0.03991187560665886\n",
      "4897, loss is 0.0018490689602402 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10140915254729278 and mu_y: -0.03993072920826508\n",
      "4898, loss is 0.0018490637931828403 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10139643413425045 and mu_y: -0.03994957283708923\n",
      "4899, loss is 0.0018490586315083046 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10138372212595698 and mu_y: -0.03996840649839336\n",
      "4900, loss is 0.001849053475210912 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10137101651888625 and mu_y: -0.03998723019743664\n",
      "4901, loss is 0.0018490483242849867 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10135831730951447 and mu_y: -0.040006043939475336\n",
      "4902, loss is 0.001849043178724859 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10134562449432022 and mu_y: -0.040024847729762815\n",
      "4903, loss is 0.0018490380385248657 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1013329380697844 and mu_y: -0.040043641573549574\n",
      "4904, loss is 0.0018490329036793495 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10132025803239024 and mu_y: -0.040062425476083206\n",
      "4905, loss is 0.0018490277741826605 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10130758437862332 and mu_y: -0.040081199442608434\n",
      "4906, loss is 0.0018490226500291512 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10129491710497154 and mu_y: -0.04009996347836709\n",
      "4907, loss is 0.0018490175312131855 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10128225620792514 and mu_y: -0.04011871758859813\n",
      "4908, loss is 0.0018490124177291294 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10126960168397668 and mu_y: -0.04013746177853761\n",
      "4909, loss is 0.0018490073095713566 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10125695352962108 and mu_y: -0.04015619605341874\n",
      "4910, loss is 0.001849002206734247 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10124431174135554 and mu_y: -0.04017492041847184\n",
      "4911, loss is 0.0018489971092121855 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1012316763156796 and mu_y: -0.04019363487892436\n",
      "4912, loss is 0.0018489920169995654 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10121904724909513 and mu_y: -0.04021233944000087\n",
      "4913, loss is 0.0018489869300907838 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1012064245381063 and mu_y: -0.04023103410692307\n",
      "4914, loss is 0.0018489818484802446 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10119380817921962 and mu_y: -0.040249718884909816\n",
      "4915, loss is 0.001848976772162357 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1011811981689439 and mu_y: -0.04026839377917707\n",
      "4916, loss is 0.0018489717011315387 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10116859450379027 and mu_y: -0.04028705879493795\n",
      "4917, loss is 0.0018489666353822113 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10115599718027217 and mu_y: -0.0403057139374027\n",
      "4918, loss is 0.001848961574908803 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10114340619490533 and mu_y: -0.0403243592117787\n",
      "4919, loss is 0.0018489565197057484 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10113082154420781 and mu_y: -0.0403429946232705\n",
      "4920, loss is 0.0018489514697674877 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10111824322469998 and mu_y: -0.040361620177079754\n",
      "4921, loss is 0.0018489464250884674 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10110567123290448 and mu_y: -0.04038023587840529\n",
      "4922, loss is 0.001848941385663139 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10109310556534629 and mu_y: -0.04039884173244308\n",
      "4923, loss is 0.0018489363514859625 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10108054621855266 and mu_y: -0.04041743774438624\n",
      "4924, loss is 0.0018489313225514017 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10106799318905313 and mu_y: -0.04043602391942504\n",
      "4925, loss is 0.0018489262988539272 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10105544647337958 and mu_y: -0.040454600262746894\n",
      "4926, loss is 0.0018489212803880159 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10104290606806612 and mu_y: -0.04047316677953639\n",
      "4927, loss is 0.0018489162671481486 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10103037196964922 and mu_y: -0.04049172347497526\n",
      "4928, loss is 0.0018489112591288158 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10101784417466757 and mu_y: -0.0405102703542424\n",
      "4929, loss is 0.0018489062563245109 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1010053226796622 and mu_y: -0.040528807422513864\n",
      "4930, loss is 0.0018489012587297347 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1009928074811764 and mu_y: -0.040547334684962875\n",
      "4931, loss is 0.0018488962663389939 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10098029857575573 and mu_y: -0.04056585214675981\n",
      "4932, loss is 0.0018488912791468002 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10096779595994808 and mu_y: -0.04058435981307223\n",
      "4933, loss is 0.001848886297147672 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10095529963030356 and mu_y: -0.04060285768906484\n",
      "4934, loss is 0.001848881320336134 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10094280958337458 and mu_y: -0.04062134577989953\n",
      "4935, loss is 0.0018488763487067162 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10093032581571584 and mu_y: -0.04063982409073537\n",
      "4936, loss is 0.0018488713822539552 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1009178483238843 and mu_y: -0.04065829262672859\n",
      "4937, loss is 0.0018488664209723928 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10090537710443918 and mu_y: -0.04067675139303261\n",
      "4938, loss is 0.0018488614648565767 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.100892912153942 and mu_y: -0.04069520039479801\n",
      "4939, loss is 0.0018488565139010613 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10088045346895651 and mu_y: -0.04071363963717256\n",
      "4940, loss is 0.0018488515681004056 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10086800104604875 and mu_y: -0.04073206912530122\n",
      "4941, loss is 0.0018488466274491765 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.100855554881787 and mu_y: -0.04075048886432611\n",
      "4942, loss is 0.0018488416919419449 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10084311497274183 and mu_y: -0.04076889885938657\n",
      "4943, loss is 0.0018488367615732883 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10083068131548605 and mu_y: -0.04078729911561909\n",
      "4944, loss is 0.00184883183633779 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10081825390659471 and mu_y: -0.04080568963815737\n",
      "4945, loss is 0.0018488269162300391 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10080583274264517 and mu_y: -0.040824070432132306\n",
      "4946, loss is 0.001848822001244632 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10079341782021699 and mu_y: -0.040842441502671974\n",
      "4947, loss is 0.0018488170913761681 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10078100913589201 and mu_y: -0.040860802854901644\n",
      "4948, loss is 0.0018488121866192557 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1007686066862543 and mu_y: -0.040879154493943796\n",
      "4949, loss is 0.001848807286968506 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1007562104678902 and mu_y: -0.04089749642491809\n",
      "4950, loss is 0.0018488023924185387 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10074382047738827 and mu_y: -0.04091582865294141\n",
      "4951, loss is 0.0018487975029639772 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10073143671133933 and mu_y: -0.04093415118312782\n",
      "4952, loss is 0.0018487926185994528 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10071905916633643 and mu_y: -0.0409524640205886\n",
      "4953, loss is 0.001848787739319601 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10070668783897488 and mu_y: -0.04097076717043223\n",
      "4954, loss is 0.0018487828651190638 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1006943227258522 and mu_y: -0.0409890606377644\n",
      "4955, loss is 0.0018487779959924873 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10068196382356817 and mu_y: -0.041007344427688004\n",
      "4956, loss is 0.0018487731319345273 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10066961112872479 and mu_y: -0.041025618545303164\n",
      "4957, loss is 0.0018487682729398415 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10065726463792628 and mu_y: -0.0410438829957072\n",
      "4958, loss is 0.001848763419003095 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10064492434777912 and mu_y: -0.04106213778399465\n",
      "4959, loss is 0.0018487585701189595 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.100632590254892 and mu_y: -0.04108038291525727\n",
      "4960, loss is 0.001848753726282111 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10062026235587584 and mu_y: -0.041098618394584036\n",
      "4961, loss is 0.0018487488874872314 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10060794064734378 and mu_y: -0.04111684422706113\n",
      "4962, loss is 0.0018487440537290093 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10059562512591118 and mu_y: -0.04113506041777199\n",
      "4963, loss is 0.0018487392250021383 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10058331578819563 and mu_y: -0.04115326697179725\n",
      "4964, loss is 0.001848734401301318 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10057101263081693 and mu_y: -0.04117146389421477\n",
      "4965, loss is 0.0018487295826212535 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1005587156503971 and mu_y: -0.04118965119009965\n",
      "4966, loss is 0.0018487247689566572 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10054642484356038 and mu_y: -0.04120782886452422\n",
      "4967, loss is 0.001848719960302244 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1005341402069332 and mu_y: -0.041225996922558024\n",
      "4968, loss is 0.0018487151566527373 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10052186173714422 and mu_y: -0.041244155369267864\n",
      "4969, loss is 0.0018487103580028647 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10050958943082433 and mu_y: -0.04126230420971776\n",
      "4970, loss is 0.0018487055643473616 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10049732328460657 and mu_y: -0.04128044344896897\n",
      "4971, loss is 0.0018487007756809665 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10048506329512624 and mu_y: -0.04129857309208\n",
      "4972, loss is 0.0018486959919984253 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1004728094590208 and mu_y: -0.04131669314410659\n",
      "4973, loss is 0.0018486912132944875 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10046056177292995 and mu_y: -0.041334803610101715\n",
      "4974, loss is 0.0018486864395639115 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10044832023349555 and mu_y: -0.04135290449511561\n",
      "4975, loss is 0.001848681670801459 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10043608483736169 and mu_y: -0.04137099580419575\n",
      "4976, loss is 0.0018486769070018986 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10042385558117464 and mu_y: -0.041389077542386854\n",
      "4977, loss is 0.0018486721481600023 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10041163246158287 and mu_y: -0.04140714971473088\n",
      "4978, loss is 0.0018486673942705511 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10039941547523704 and mu_y: -0.041425212326267065\n",
      "4979, loss is 0.0018486626453283303 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10038720461878997 and mu_y: -0.04144326538203188\n",
      "4980, loss is 0.001848657901328129 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10037499988889673 and mu_y: -0.04146130888705905\n",
      "4981, loss is 0.0018486531622647448 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10036280128221453 and mu_y: -0.04147934284637956\n",
      "4982, loss is 0.0018486484281329783 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10035060879540278 and mu_y: -0.04149736726502166\n",
      "4983, loss is 0.0018486436989276374 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10033842242512306 and mu_y: -0.04151538214801085\n",
      "4984, loss is 0.0018486389746435363 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10032624216803913 and mu_y: -0.0415333875003699\n",
      "4985, loss is 0.0018486342552754922 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10031406802081695 and mu_y: -0.04155138332711884\n",
      "4986, loss is 0.001848629540818331 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10030189998012465 and mu_y: -0.04156936963327497\n",
      "4987, loss is 0.0018486248312668814 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10028973804263251 and mu_y: -0.041587346423852846\n",
      "4988, loss is 0.0018486201266159799 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10027758220501301 and mu_y: -0.04160531370386431\n",
      "4989, loss is 0.0018486154268604663 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10026543246394079 and mu_y: -0.041623271478318465\n",
      "4990, loss is 0.001848610731995189 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10025328881609266 and mu_y: -0.04164121975222168\n",
      "4991, loss is 0.0018486060420149992 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.1002411512581476 and mu_y: -0.04165915853057761\n",
      "4992, loss is 0.001848601356914755 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10022901978678675 and mu_y: -0.041677087818387186\n",
      "4993, loss is 0.0018485966766893188 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10021689439869341 and mu_y: -0.04169500762064861\n",
      "4994, loss is 0.0018485920013335613 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10020477509055306 and mu_y: -0.04171291794235737\n",
      "4995, loss is 0.001848587330842356 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10019266185905333 and mu_y: -0.04173081878850623\n",
      "4996, loss is 0.0018485826652105833 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10018055470088401 and mu_y: -0.04174871016408524\n",
      "4997, loss is 0.0018485780044331275 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10016845361273703 and mu_y: -0.04176659207408174\n",
      "4998, loss is 0.0018485733485048817 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10015635859130649 and mu_y: -0.04178446452348035\n",
      "4999, loss is 0.0018485686974207408 with sigma_x: 1.0 and sigma_y: 1.0 and mu_x: 0.10014426963328865 and mu_y: -0.04180232751726298\n",
      "sigma_x: 1.0 sigma_y: 1.0 mu_x: 0.10014426963328865 mu_y: -0.04180232751726298\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Gradient Descent\n",
    "num_points = 5\n",
    "\n",
    "sigma_x_target = 1\n",
    "sigma_y_target = 1\n",
    "mu_x_target = 0\n",
    "mu_y_target = 0\n",
    "\n",
    "x = np.linspace(-5, 5, num_points)\n",
    "y = np.linspace(-5, 5, num_points)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = gaussian_2D(X, Y, sigma_x_target, sigma_y_target, mu_x_target, mu_y_target)\n",
    "# Z = Z/np.amax(Z)\n",
    "Z = Z + np.random.normal(0.0001,0.01, Z.shape)\n",
    "\n",
    "#Guess parameters\n",
    "sigma_x = 1\n",
    "sigma_y = 1\n",
    "mu_x = 1\n",
    "mu_y = 1\n",
    "lr = 0.1\n",
    "\n",
    "def descend(x, y, Z, sigma_x, sigma_y, mu_x, mu_y, lr):\n",
    "    dldsigma_x = 0.0\n",
    "    dldsigma_y = 0.0\n",
    "    dldmu_x = 0.0\n",
    "    dldmu_y = 0.0\n",
    "\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Zhat = gaussian_2D(X, Y, sigma_x, sigma_y, mu_x, mu_y)\n",
    "    gaus_grad_sigma_x = get_gaussian_grad_sigma_x(X, Y, sigma_x, sigma_y, mu_x, mu_y)\n",
    "    gaus_grad_sigma_y = get_gaussian_grad_sigma_y(X, Y, sigma_x, sigma_y, mu_x, mu_y)\n",
    "    gaus_grad_mu_x = get_gaussian_grad_mu_x(X, Y, sigma_x, sigma_y, mu_x, mu_y)\n",
    "    gaus_grad_mu_y = get_gaussian_grad_mu_y(X, Y, sigma_x, sigma_y, mu_x, mu_y)\n",
    "\n",
    "    #loss = (y-yhat)^2\n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(y)):\n",
    "            # print(x[i], y[j])\n",
    "            # dldsigma_x += 2*(Z[i][j]-Zhat[i][j])*-1*gaus_grad_sigma_x[i][j]\n",
    "            # dldsigma_y += 2*(Z[i][j]-Zhat[i][j])*-1*gaus_grad_sigma_y[i][j]\n",
    "            dldmu_x += 2*(Z[i][j]-Zhat[i][j])*-1*gaus_grad_mu_x[i][j]\n",
    "            dldmu_y += 2*(Z[i][j]-Zhat[i][j])*-1*gaus_grad_mu_y[i][j]\n",
    "\n",
    "    sigma_x = sigma_x - lr*dldsigma_x\n",
    "    sigma_y = sigma_y - lr*dldsigma_y\n",
    "    mu_x = mu_x - lr*dldmu_x\n",
    "    mu_y = mu_y - lr*dldmu_y\n",
    "\n",
    "    return sigma_x, sigma_y, mu_x, mu_y\n",
    "\n",
    "loss_array = np.array([])\n",
    "mu_x_list = np.array([])\n",
    "mu_y_list = np.array([])\n",
    "loss = 1\n",
    "epoch = 0\n",
    "while 5000 > epoch:\n",
    "    sigma_x, sigma_y, mu_x, mu_y = descend(x, y, Z, sigma_x, sigma_y, mu_x, mu_y, lr)\n",
    "    mu_x_list = np.append(mu_x_list, mu_x)\n",
    "    mu_y_list = np.append(mu_y_list, mu_y)\n",
    "    Zhat = gaussian_2D(X, Y, sigma_x, sigma_y, mu_x, mu_y)\n",
    "    loss = np.sum((Z-Zhat)**2)\n",
    "    loss_array = np.append(loss_array, loss)\n",
    "    print(f'{epoch}, loss is {loss} with sigma_x: {sigma_x} and sigma_y: {sigma_y} and mu_x: {mu_x} and mu_y: {mu_y}')\n",
    "    epoch += 1\n",
    "\n",
    "loss_x = np.linspace(0,len(loss_array)-1, len(loss_array))\n",
    "plt.plot(loss_x, loss_array)\n",
    "print(\"sigma_x:\", sigma_x, \"sigma_y:\", sigma_y, \"mu_x:\", mu_x, \"mu_y:\", mu_y)\n",
    "\n",
    "##show path of mu\n",
    "\n",
    "# Define parameters\n",
    "\n",
    "# Create grid of x and y values\n",
    "x = np.linspace(-5, 5, 100)\n",
    "y = np.linspace(-5, 5, 100)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# Calculate Gaussian values\n",
    "Z = gaussian_2D(X, Y, sigma_x_target, sigma_y_target, mu_x_target, mu_y_target)\n",
    "\n",
    "# Plot the 2D Gaussian distribution and scattered points with z-values\n",
    "plt.figure()\n",
    "plt.contourf(X, Y, Z, cmap='viridis')\n",
    "plt.scatter(mu_x_list, mu_y_list, color='red', label='Scattered Points')\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('2D Gaussian Distribution with Scattered Points and Z-Values')\n",
    "plt.colorbar(label='Probability Density')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D Gradient Descent Localization 2 Emitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, loss is 0.07764841917565662 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.9930661603672664 and mu_y1: 0.9999009971427454 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.00010826182982504468 and mu_y2: -0.9930497388264949\n",
      "1, loss is 0.07669268488778246 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.9861559191247093 and mu_y1: 0.9998081320299571 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.00021034296798867156 and mu_y2: -0.9861236475311507\n",
      "2, loss is 0.07574368797739808 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.9792696242988455 and mu_y1: 0.9997213768475492 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.0003062698872623961 and mu_y2: -0.9792220909208075\n",
      "3, loss is 0.07480149857988344 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.9724076173544964 and mu_y1: 0.9996407014339727 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.00039607139384236926 and mu_y2: -0.9723454261805138\n",
      "4, loss is 0.07386618386504461 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.9655702331654996 and mu_y1: 0.9995660733129347 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.00047977859715528067 and mu_y2: -0.9654940028360917\n",
      "5, loss is 0.07293780804641045 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.9587577999892358 and mu_y1: 0.9994974577281089 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.0005574248776719557 and mu_y2: -0.9586681627230038\n",
      "6, loss is 0.07201643239288312 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.95197063944484 and mu_y1: 0.9994348176797626 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.000629045852793789 and mu_y2: -0.9518682399613327\n",
      "7, loss is 0.07110211524264833 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.9452090664949588 and mu_y1: 0.9993781139632277 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.0006946793408796272 and mu_y2: -0.9450945609366792\n",
      "8, loss is 0.07019491201925124 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.9384733894309263 and mu_y1: 0.9993273052091404 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.0007543653234829705 and mu_y2: -0.9383474442867844\n",
      "9, loss is 0.06929487524974427 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.9317639098612265 and mu_y1: 0.9992823479253702 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.0008081459058713829 and mu_y2: -0.9316272008936779\n",
      "10, loss is 0.06840205458481337 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.925080922703123 and mu_y1: 0.9992431965405608 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.0008560652759018676 and mu_y2: -0.9249341338811526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11, loss is 0.0675164968207902 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.9184247161773287 and mu_y1: 0.9992098034492007 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.0008981696613275724 and mu_y2: -0.9182685386173673\n",
      "12, loss is 0.06663824592345881 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.9117955718056032 and mu_y1: 0.9991821190581417 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.0009345072856126387 and mu_y2: -0.9116307027223769\n",
      "13, loss is 0.06576734305356659 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.9051937644111603 and mu_y1: 0.9991600918344832 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.0009651283223332264 and mu_y2: -0.9050209060803929\n",
      "14, loss is 0.06490382659394997 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.8986195621217794 and mu_y1: 0.9991436683547379 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.0009900848482437689 and mu_y2: -0.8984394208565759\n",
      "15, loss is 0.06404773217818825 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.8920732263755147 and mu_y1: 0.999132793355195 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.0010094307950883523 and mu_y2: -0.8918865115181657\n",
      "16, loss is 0.06319909272069968 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.8855550119289 and mu_y1: 0.9991274097833963 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.0010232219002377521 and mu_y2: -0.8853624348597549\n",
      "17, loss is 0.06235793844819538 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.8790651668675553 and mu_y1: 0.9991274588506404 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.001031515656233082 and mu_y2: -0.8788674400325172\n",
      "18, loss is 0.06152429693241064 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.8726039326191017 and mu_y1: 0.99913288008543 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.001034371259317305 and mu_y2: -0.8724017685772031\n",
      "19, loss is 0.06069819312403224 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.8661715439682969 and mu_y1: 0.9991436113877789 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.0010318495570359057 and mu_y2: -0.8659656544607195\n",
      "20, loss is 0.05987964938774519 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.8597682290743094 and mu_y1: 0.999159589084293 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.001024012994987943 and mu_y2: -0.8595593241161141\n",
      "21, loss is 0.059068685538323056 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.8533942094900517 and mu_y1: 0.9991807479839437 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.0010109255628084374 and mu_y2: -0.8531829964857902\n",
      "22, loss is 0.05826531887768883 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.847049700183499 and mu_y1: 0.9992070214344486 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.000992652739462595 and mu_y2: -0.8468368830677804\n",
      "23, loss is 0.057469564232874956 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.8407349095609207 and mu_y1: 0.9992383413791797 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.000969261437931828 and mu_y2: -0.8405211879649146\n",
      "24, loss is 0.05668143399481439 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.834450039491963 and mu_y1: 0.9992746384145169 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.0009408199493707327 and mu_y2: -0.8342361079367204\n",
      "25, loss is 0.055900938157895874 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.828195285336514 and mu_y1: 0.9993158418475682 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.000907397886813356 and mu_y2: -0.8279818324539004\n",
      "26, loss is 0.055128084360219626 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.8219708359732985 and mu_y1: 0.9993618797541762 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.000869066128506028 and mu_y2: -0.8217585437552362\n",
      "27, loss is 0.0543628779244916 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.8157768738301443 and mu_y1: 0.9994126790371365 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.0008258967609428971 and mu_y2: -0.8155664169067726\n",
      "28, loss is 0.05360532189949641 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.8096135749158686 and mu_y1: 0.99946816548455 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.0007779630216790375 and mu_y2: -0.8094056198631429\n",
      "29, loss is 0.052855417102092364 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.8034811088537381 and mu_y1: 0.9995282638282375 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.0007253392419945797 and mu_y2: -0.8032763135308995\n",
      "30, loss is 0.05211316215967255 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.7973796389164547 and mu_y1: 0.999592897802143 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.0006681007894818585 and mu_y2: -0.7971786518337207\n",
      "31, loss is 0.0513785535530397 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.7913093220626273 and mu_y1: 0.9996619902006559 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.0006063240106259302 and mu_y2: -0.7911127817793694\n",
      "32, loss is 0.050651585659643714 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.785270308974687 and mu_y1: 0.9997354629367842 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.0005400861734471419 and mu_y2: -0.7850788435282837\n",
      "33, loss is 0.04993225079713293 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.7792627440982125 and mu_y1: 0.9998132371001114 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.00046946541027264124 and mu_y2: -0.7790769704636872\n",
      "34, loss is 0.04922053926717232 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.7732867656826246 and mu_y1: 0.9998952330144747 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.00039454066070186174 and mu_y2: -0.7731072892631077\n",
      "35, loss is 0.048516439399483774 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.7673425058232237 and mu_y1: 0.9999813702953 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.00031539161482908314 and mu_y2: -0.7671699199712029\n",
      "36, loss is 0.04781993759606536 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.7614300905045341 and mu_y1: 1.000071567906536 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.00023209865678416424 and mu_y2: -0.761264976073792\n",
      "37, loss is 0.04713101837554836 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.7555496396449275 and mu_y1: 1.0001657442171277 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 0.00014474280865050127 and mu_y2: -0.7553925645730001\n",
      "38, loss is 0.04644966441765245 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.7497012671424976 and mu_y1: 1.0002638170569766 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: 5.34056748171418e-05 and mu_y2: -0.7495527860634249\n",
      "39, loss is 0.045775856607701136 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.7438850809221593 and mu_y1: 1.0003657037723308 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -4.1830613180150655e-05 and mu_y2: -0.7437457348092409\n",
      "40, loss is 0.04510957408116164 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.7381011829839454 and mu_y1: 1.000471321280558 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.0001408834512762824 and mu_y2: -0.7379714988221592\n",
      "41, loss is 0.044450794268173936 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.7323496694524778 and mu_y1: 1.0005805861242503 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.00024366981690228468 and mu_y2: -0.7322301599401677\n",
      "42, loss is 0.043799492938036096 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.7266306306275874 and mu_y1: 1.0006934145246158 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.000350106322370701 and mu_y2: -0.7265217939069766\n",
      "43, loss is 0.04315564424361417 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.7209441510360606 and mu_y1: 1.0008097224341137 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.00046010926757503553 and mu_y2: -0.7208464704521015\n",
      "44, loss is 0.04251922076564597 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.7152903094844882 and mu_y1: 1.0009294255882908 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.0005735946919596615 and mu_y2: -0.7152042533715183\n",
      "45, loss is 0.041890193556909726 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.709669179113194 and mu_y1: 1.0010524395567806 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.0006904784257188749 and mu_y2: -0.7095952006088267\n",
      "46, loss is 0.04126853218622978 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.70408082745122 and mu_y1: 1.001178679793429 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.000810676140186063 and mu_y2: -0.704019364336866\n",
      "47, loss is 0.040654204782292425 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.6985253164723475 and mu_y1: 1.0013080616855117 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.0009341033973762463 and mu_y2: -0.6984767910397233\n",
      "48, loss is 0.04004717807724658 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.6930027026521264 and mu_y1: 1.0014405006020122 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.0010606756986475034 and mu_y2: -0.6929675215950867\n",
      "49, loss is 0.039447417450064665 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.6875130370258957 and mu_y1: 1.001575911940929 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.0011903085324490848 and mu_y2: -0.687491591356888\n",
      "50, loss is 0.03885488696964007 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.6820563652477667 and mu_y1: 1.0017142111755886 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.0013229174211262264 and mu_y2: -0.6820490302381915\n",
      "51, loss is 0.03826954943759929 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.6766327276505468 and mu_y1: 1.0018553138999327 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.0014584179667539163 and mu_y2: -0.6766398627942819\n",
      "52, loss is 0.0376913664308066 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.6712421593065805 and mu_y1: 1.001999135872765 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.001596725895974071 and mu_y2: -0.6712641083059088\n",
      "53, loss is 0.0371202983435412 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.66588469008948 and mu_y1: 1.0021455930609293 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.0017377571038127088 and mu_y2: -0.6659217808626475\n",
      "54, loss is 0.03655630442932689 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.6605603447367225 and mu_y1: 1.0022946016814058 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.0018814276964558856 and mu_y2: -0.6606128894463383\n",
      "55, loss is 0.03599934284239557 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.6552691429130875 and mu_y1: 1.0024460782423057 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.002027654032965217 and mu_y2: -0.6553374380145652\n",
      "56, loss is 0.03544937067876651 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.650011099274904 and mu_y1: 1.0025999395827516 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.002176352765915887 and mu_y2: -0.6500954255841419\n",
      "57, loss is 0.034906344016924 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.6447862235350843 and mu_y1: 1.0027561029116308 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.0023274408809420524 and mu_y2: -0.6448868463145692\n",
      "58, loss is 0.034370217958077376 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.6395945205289137 and mu_y1: 1.0029144858452106 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.002480835735176528 and mu_y2: -0.6397116895914338\n",
      "59, loss is 0.03384094666598714 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.6344359902805665 and mu_y1: 1.0030750064436083 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.002636455094573541 and mu_y2: -0.6345699401097165\n",
      "60, loss is 0.0333184834063426 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.6293106280703193 and mu_y1: 1.0032375832461065 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.0027942171701052483 and mu_y2: -0.629461577956981\n",
      "61, loss is 0.03280278058567662 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.624218424502431 and mu_y1: 1.0034021353053122 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.002954040652824499 and mu_y2: -0.6243865786964155\n",
      "62, loss is 0.032293789789803774 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.6191593655736567 and mu_y1: 1.0035685822201543 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.00311584474778812 and mu_y2: -0.6193449134496992\n",
      "63, loss is 0.03179146182176928 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.6141334327423664 and mu_y1: 1.0037368441677175 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.0032795492068366924 and mu_y2: -0.6143365489796689\n",
      "64, loss is 0.0312957467392959 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.6091406029982305 and mu_y1: 1.0039068419339146 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.0034450743602284697 and mu_y2: -0.6093614477727586\n",
      "65, loss is 0.030806593891717842 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.6041808489324436 and mu_y1: 1.0040784969429966 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.0036123411471266726 and mu_y2: -0.6044195681211895\n",
      "66, loss is 0.030323951956390146 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.5992541388084502 and mu_y1: 1.0042517312859058 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.0037812711449409534 and mu_y2: -0.5995108642048862\n",
      "67, loss is 0.029847768974563336 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.5943604366331376 and mu_y1: 1.0044264677474746 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.003951786597525289 and mu_y2: -0.5946352861730955\n",
      "68, loss is 0.029377992386713795 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.58949970222846 and mu_y1: 1.004602629832476 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.004123810442236012 and mu_y2: -0.5897927802256868\n",
      "69, loss is 0.0289145690673203 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.58467189130346 and mu_y1: 1.004780141790534 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.004297266335855033 and mu_y2: -0.5849832886941118\n",
      "70, loss is 0.02845744535907852 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.57987695552665 and mu_y1: 1.004958928639902 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.004472078679384641 and mu_y2: -0.5802067501220015\n",
      "71, loss is 0.028006567106545383 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.5751148425987163 and mu_y1: 1.0051389161901172 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.004648172641721485 and mu_y2: -0.5754630993453828\n",
      "72, loss is 0.027561879689205798 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.5703854963255097 and mu_y1: 1.0053200310635433 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.004825474182218549 and mu_y2: -0.5707522675724906\n",
      "73, loss is 0.027123328053955075 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.5656888566912865 and mu_y1: 1.0055022007158128 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.005003910072145065 and mu_y2: -0.56607418246316\n",
      "74, loss is 0.026690856746990895 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.5610248599321597 and mu_y1: 1.005685353455181 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.0051834079150553485 and mu_y2: -0.5614287682077754\n",
      "75, loss is 0.026264409945108893 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.5563934386097251 and mu_y1: 1.0058694184608064 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.005363896166078587 and mu_y2: -0.5568159456057616\n",
      "76, loss is 0.025843931486397055 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.5517945216848241 and mu_y1: 1.0060543257999701 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.005545304150142538 and mu_y2: -0.5522356321435955\n",
      "77, loss is 0.025429364900323995 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.5472280345914051 and mu_y1: 1.0062400064442516 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.005727562079145003 and mu_y2: -0.5476877420723218\n",
      "78, loss is 0.02502065343721762 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.5426938993104455 and mu_y1: 1.0064263922846755 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.005910601068087761 and mu_y2: -0.5431721864845557\n",
      "79, loss is 0.024617740097130265 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.5381920344438988 and mu_y1: 1.0066134161458467 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.006094353150188454 and mu_y2: -0.5386888733909533\n",
      "80, loss is 0.024220567658087555 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.533722355288626 and mu_y1: 1.0068010117990918 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.006278751290986629 and mu_y2: -0.5342377077961354\n",
      "81, loss is 0.02382907870371872 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.5292847739102782 and mu_y1: 1.0069891139746225 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.006463729401460794 and mu_y2: -0.5298185917740466\n",
      "82, loss is 0.0234432156502663 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.5248791992170885 and mu_y1: 1.0071776583727432 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.006649222350174017 and mu_y2: -0.5254314245427333\n",
      "83, loss is 0.02306292077297399 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.5205055370335436 and mu_y1: 1.0073665816741175 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.006835165974466103 and mu_y2: -0.5210761025385267\n",
      "84, loss is 0.02268813623185173 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.5161636901738915 and mu_y1: 1.007555821549118 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.007021497090710948 and mu_y2: -0.516752519489613\n",
      "85, loss is 0.022318804096817836 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.5118535585154547 and mu_y1: 1.0077453166662744 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.007208153503658123 and mu_y2: -0.5124605664889779\n",
      "86, loss is 0.021954866372218086 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.5075750390717118 and mu_y1: 1.0079350066998434 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.007395074014878142 and mu_y2: -0.5082001320667089\n",
      "87, loss is 0.021596265020722618 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.5033280260651138 and mu_y1: 1.0081248323365197 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.007582198430331272 and mu_y2: -0.5039711022616432\n",
      "88, loss is 0.021242941986601722 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.4991124109996006 and mu_y1: 1.0083147352813093 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.007769467567080067 and mu_y2: -0.4997733606923452\n",
      "89, loss is 0.020894839218381794 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.494928082732783 and mu_y1: 1.0085046582625856 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.00795682325916606 and mu_y2: -0.4956067886274013\n",
      "90, loss is 0.020551898690883974 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.490774927547762 and mu_y1: 1.0086945450363498 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.00814420836267134 and mu_y2: -0.49147126505501953\n",
      "91, loss is 0.020214062426647583 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.486652829224547 and mu_y1: 1.0088843403897174 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.008331566759985901 and mu_y2: -0.4873666667519196\n",
      "92, loss is 0.01988127251674127 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.4825616691110486 and mu_y1: 1.009073990143651 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.008518843363301842 and mu_y2: -0.4832928683515028\n",
      "93, loss is 0.01955347114096541 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.4785013261936109 and mu_y1: 1.0092634411549626 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.008705984117355603 and mu_y2: -0.4792497424112894\n",
      "94, loss is 0.01923060058744915 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.4744716771670556 and mu_y1: 1.0094526413176053 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.00889293600143952 and mu_y2: -0.4752371594796118\n",
      "95, loss is 0.01891260327164659 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.4704725965042096 and mu_y1: 1.0096415395632774 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.009079647030704038 and mu_y2: -0.4712549881615535\n",
      "96, loss is 0.018599421754736264 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.4665039565248885 and mu_y1: 1.0098300858613587 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.00926606625677194 and mu_y2: -0.4673030951841225\n",
      "97, loss is 0.018290998761428954 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.4625656274643084 and mu_y1: 1.0100182312182029 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.009452143767685928 and mu_y2: -0.4633813454606501\n",
      "98, loss is 0.01798727719718911 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.4586574775409014 and mu_y1: 1.0102059276758046 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.009637830687210877 and mu_y2: -0.459489602154405\n",
      "99, loss is 0.017688200164875222 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.4547793730235086 and mu_y1: 1.010393128309865 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.009823079173511984 and mu_y2: -0.45562772674141405\n",
      "100, loss is 0.017393710980805298 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.4509311782979293 and mu_y1: 1.0105797872272753 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.010007842417229972 and mu_y2: -0.45179557907248136\n",
      "101, loss is 0.017103753190253403 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.4471127559328 and mu_y1: 1.0107658595630389 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.010192074638974341 and mu_y2: -0.4479930174343971\n",
      "102, loss is 0.016818270582383946 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.4433239667447861 and mu_y1: 1.0109513014766562 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.010375731086255557 and mu_y2: -0.4442198986103298\n",
      "103, loss is 0.016537207204630384 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.4395646698630598 and mu_y1: 1.0111360701479875 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.010558768029876864 and mu_y2: -0.44047607793939353\n",
      "104, loss is 0.01626050737652543 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.4358347227930501 and mu_y1: 1.0113201237726184 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.010741142759806253 and mu_y2: -0.43676140937538543\n",
      "105, loss is 0.01598811570299002 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.432133981479443 and mu_y1: 1.0115034215567469 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.010922813580548849 and mu_y2: -0.4330757455446859\n",
      "106, loss is 0.015719977087088673 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.428462300368414 and mu_y1: 1.011685923711611 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.011103739806039825 and mu_y2: -0.42941893780331747\n",
      "107, loss is 0.015456036742258934 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.4248195324690796 and mu_y1: 1.0118675914474768 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.011283881754077622 and mu_y2: -0.4257908362931563\n",
      "108, loss is 0.015196240204022875 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.4212055294141468 and mu_y1: 1.0120483869672081 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.011463200740317075 and mu_y2: -0.42219128999729294\n",
      "109, loss is 0.014940533341188802 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.4176201415197518 and mu_y1: 1.0122282734594328 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.011641659071841668 and mu_y2: -0.41862014679453796\n",
      "110, loss is 0.014688862366551664 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.4140632178444696 and mu_y1: 1.0124072150913295 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.011819220040333957 and mu_y2: -0.4150772535130693\n",
      "111, loss is 0.014441173847100414 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.410534606247486 and mu_y1: 1.0125851770010483 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.01199584791486278 and mu_y2: -0.4115624559832181\n",
      "112, loss is 0.014197414713741264 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.4070341534459159 and mu_y1: 1.0127621252897872 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.012171507934305674 and mu_y2: -0.40807559908939167\n",
      "113, loss is 0.013957532270545402 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.4035617050712623 and mu_y1: 1.0129380270135384 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.012346166299424467 and mu_y2: -0.40461652682113075\n",
      "114, loss is 0.013721474203530235 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.4001171057250021 and mu_y1: 1.0131128501745268 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.01251979016461178 and mu_y2: -0.4011850823233003\n",
      "115, loss is 0.013489188588983127 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.3967001990332932 and mu_y1: 1.013286563712351 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.012692347629325786 and mu_y2: -0.397781107945413\n",
      "116, loss is 0.013260623901336883 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.3933108277007928 and mu_y1: 1.01345913749485 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.012863807729230174 and mu_y2: -0.3944044452900851\n",
      "117, loss is 0.013035729020605851 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.3899488335635817 and mu_y1: 1.0136305423087073 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.013034140427056017 and mu_y2: -0.39105493526062457\n",
      "118, loss is 0.012814453239392428 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.3866140576411883 and mu_y1: 1.01380074984981 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.013203316603201754 and mu_y2: -0.3877324181077524\n",
      "119, loss is 0.012596746269472827 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.3833063401877066 and mu_y1: 1.0139697327133792 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.013371308046087207 and mu_y2: -0.3844367334754582\n",
      "120, loss is 0.012382558247971822 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.3800255207420051 and mu_y1: 1.0141374643838843 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.013538087442277158 and mu_y2: -0.3811677204459917\n",
      "121, loss is 0.01217183974313566 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.376771438177023 and mu_y1: 1.0143039192247583 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.01370362836638962 and mu_y2: -0.37792521758399134\n",
      "122, loss is 0.011964541759712717 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.37354393074815 and mu_y1: 1.0144690724679282 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.013867905270803572 and mu_y2: -0.3747090629797541\n",
      "123, loss is 0.011760615743951344 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.37034283614069 and mu_y1: 1.0146329002031722 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.01403089347518052 and mu_y2: -0.3715190942916473\n",
      "124, loss is 0.011560013588224154 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.3671679915164061 and mu_y1: 1.0147953793673208 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.014192569155813933 and mu_y2: -0.3683551487876677\n",
      "125, loss is 0.011362687635288507 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.3640192335591483 and mu_y1: 1.0149564877333115 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.014352909334820097 and mu_y2: -0.3652170633861497\n",
      "126, loss is 0.011168590682192319 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.3608963985195628 and mu_y1: 1.0151162038991124 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.014511891869183698 and mu_y2: -0.3621046746956286\n",
      "127, loss is 0.010977675983834664 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.3577993222588842 and mu_y1: 1.015274507276526 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.014669495439670912 and mu_y2: -0.3590178190538617\n",
      "128, loss is 0.010789897256190643 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.354727840291815 and mu_y1: 1.015431378079885 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.014825699539622534 and mu_y2: -0.3559563325660129\n",
      "129, loss is 0.010605208679209603 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.3516817878284917 and mu_y1: 1.0155867973146535 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.01498048446363919 and mu_y2: -0.3529200511420061\n",
      "130, loss is 0.010423564899396087 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.348660999815543 and mu_y1: 1.0157407467659425 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.015133831296170379 and mu_y2: -0.34990881053305245\n",
      "131, loss is 0.010244921032082634 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.345665310976242 and mu_y1: 1.0158932089869515 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.015285721900018668 and mu_y2: -0.34692244636735775\n",
      "132, loss is 0.010069232663403531 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.3426945558497594 and mu_y1: 1.0160441672873484 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.01543613890477002 and mu_y2: -0.34396079418501563\n",
      "133, loss is 0.009896455851978535 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.3397485688295194 and mu_y1: 1.016193605721595 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.015585065695160846 and mu_y2: -0.34102368947209355\n",
      "134, loss is 0.009726547130315528 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.3368271842006663 and mu_y1: 1.0163415090772308 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.015732486399392048 and mu_y2: -0.33811096769391813\n",
      "135, loss is 0.00955946350594087 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.3339302361766465 and mu_y1: 1.0164878628631218 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.015878385877399908 and mu_y2: -0.33522246432756686\n",
      "136, loss is 0.00939516246226629 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.3310575589349127 and mu_y1: 1.0166326532976862 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.01602274970909336 and mu_y2: -0.3323580148935734\n",
      "137, loss is 0.009233601959200859 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.3282089866517572 and mu_y1: 1.0167758672971032 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.016165564182566844 and mu_y2: -0.3295174549868543\n",
      "138, loss is 0.009074740433516625 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.3253843535362813 and mu_y1: 1.0169174924635163 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.01630681628229755 and mu_y2: -0.3267006203068647\n",
      "139, loss is 0.008918536798976265 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.322583493863508 and mu_y1: 1.0170575170732354 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.016446493677335566 and mu_y2: -0.3239073466869911\n",
      "140, loss is 0.0087649504462312 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.3198062420066485 and mu_y1: 1.0171959300649498 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.01658458470949509 and mu_y2: -0.32113747012318966\n",
      "141, loss is 0.008613941242498037 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.3170524324685278 and mu_y1: 1.0173327210279552 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.016721078381554556 and mu_y2: -0.318390826801878\n",
      "142, loss is 0.008465469531021742 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.3143218999121788 and mu_y1: 1.017467880190407 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.016855964345473175 and mu_y2: -0.3156672531270899\n",
      "143, loss is 0.008319496130333176 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.311614479190618 and mu_y1: 1.0176013984075998 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.0169892328906311 and mu_y2: -0.3129665857469003\n",
      "144, loss is 0.008175982333308924 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.3089300053758042 and mu_y1: 1.0177332671502886 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.017120874932100117 and mu_y2: -0.3102886615791318\n",
      "145, loss is 0.008034889906040942 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.306268313786799 and mu_y1: 1.0178634784930485 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.01725088199895144 and mu_y2: -0.30763331783634934\n",
      "146, loss is 0.007896181086523669 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.303629240017132 and mu_y1: 1.0179920251026868 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.017379246222606927 and mu_y2: -0.305000392050154\n",
      "147, loss is 0.007759818583165789 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.3010126199613847 and mu_y1: 1.018118900226708 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.017505960325239697 and mu_y2: -0.30238972209478476\n",
      "148, loss is 0.007625765573134039 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2984182898410002 and mu_y1: 1.0182440976818397 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.0176310176082299 and mu_y2: -0.2998011462100375\n",
      "149, loss is 0.007493985700535959 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2958460862293342 and mu_y1: 1.0183676118426235 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.01775441194068108 and mu_y2: -0.29723450302351134\n",
      "150, loss is 0.007364443074448673 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.293295846075953 and mu_y1: 1.018489437630077 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.01787613774800229 and mu_y2: -0.2946896315721916\n",
      "151, loss is 0.0072371022668003245 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2907674067301913 and mu_y1: 1.0186095705004292 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.017996190000560925 and mu_y2: -0.29216637132337936\n",
      "152, loss is 0.007111928310110932 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2882606059639823 and mu_y1: 1.0187280064339366 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.01811456420241088 and mu_y2: -0.2896645621949775\n",
      "153, loss is 0.006988886695099062 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2857752819939685 and mu_y1: 1.0188447419237818 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.018231256380100494 and mu_y2: -0.287184044575143\n",
      "154, loss is 0.006867943368160687 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2833112735029073 and mu_y1: 1.0189597739650602 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.018346263071564412 and mu_y2: -0.2847246593413157\n",
      "155, loss is 0.006749064728726389 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2808684196603795 and mu_y1: 1.019073100043857 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.018459581315103335 and mu_y2: -0.28228624787863316\n",
      "156, loss is 0.006632217626502939 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2784465601428152 and mu_y1: 1.0191847181264198 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.01857120863845534 and mu_y2: -0.2798686520977422\n",
      "157, loss is 0.006517369358605228 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2760455351528475 and mu_y1: 1.0192946266484266 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.018681143047962256 and mu_y2: -0.27747171445201674\n",
      "158, loss is 0.0064044876665841225 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.273665185438004 and mu_y1: 1.0194028245043585 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.018789383017834404 and mu_y2: -0.27509527795419214\n",
      "159, loss is 0.006293540733355951 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2713053523087507 and mu_y1: 1.0195093110369724 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.018895927479516687 and mu_y2: -0.2727391861924264\n",
      "160, loss is 0.006184497180039075 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2689658776558965 and mu_y1: 1.019614086026882 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.019000775811158967 and mu_y2: -0.27040328334579783\n",
      "161, loss is 0.006077326062702765 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2666466039673734 and mu_y1: 1.0197171496822472 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.019103927827193327 and mu_y2: -0.2680874141992499\n",
      "162, loss is 0.005971996869033545 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2643473743444005 and mu_y1: 1.0198185026285744 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.019205383768020744 and mu_y2: -0.26579142415799273\n",
      "163, loss is 0.005868479514924102 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2620680325170472 and mu_y1: 1.01991814589863 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.019305144289809395 and mu_y2: -0.2635151592613716\n",
      "164, loss is 0.005766744340989501 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2598084228592035 and mu_y1: 1.0200160809224692 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.01940321045440678 and mu_y2: -0.2612584661962126\n",
      "165, loss is 0.005666762109015495 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.257568390402971 and mu_y1: 1.0201123095175824 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.01949958371936753 and mu_y2: -0.2590211923096553\n",
      "166, loss is 0.005568503998343516 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.255347780852487 and mu_y1: 1.020206833879158 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.019594265928098747 and mu_y2: -0.2568031856214818\n",
      "167, loss is 0.005471941602196789 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2531464405971902 and mu_y1: 1.0202996565704676 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.019687259300124382 and mu_y2: -0.2546042948359534\n",
      "168, loss is 0.005377046923951819 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2509642167245418 and mu_y1: 1.0203907805133712 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.01977856642147025 and mu_y2: -0.25242436935316337\n",
      "169, loss is 0.005283792373359555 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.248800957032214 and mu_y1: 1.020480208978945 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.019868190235170852 and mu_y2: -0.2502632592799162\n",
      "170, loss is 0.005192150762720107 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.246656510039754 and mu_y1: 1.0205679455782328 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.019956134031899286 and mu_y2: -0.24812081544014344\n",
      "171, loss is 0.005102095303015078 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2445307249997377 and mu_y1: 1.0206539942531216 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.02004240144072118 and mu_y2: -0.2459968893848647\n",
      "172, loss is 0.0050135996000012124 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2424234519084232 and mu_y1: 1.0207383592673434 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.020126996419973626 and mu_y2: -0.2438913334017045\n",
      "173, loss is 0.004926637650269028 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2403345415159146 and mu_y1: 1.0208210451976008 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.020209923248269836 and mu_y2: -0.24180400052397383\n",
      "174, loss is 0.004841183837269961 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2382638453358477 and mu_y1: 1.020902056924821 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.020291186515630177 and mu_y2: -0.2397347445393259\n",
      "175, loss is 0.00475721292731552 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2362112156546088 and mu_y1: 1.0209813996255357 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.02037079111474013 and mu_y2: -0.23768341999799558\n",
      "176, loss is 0.004674700065551565 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2341765055400962 and mu_y1: 1.0210590787633878 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.020448742232335584 and mu_y2: -0.2356498822206317\n",
      "177, loss is 0.0045936207719110824 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2321595688500355 and mu_y1: 1.021135100080766 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.020525045340715763 and mu_y2: -0.23363398730573123\n",
      "178, loss is 0.004513950937048342 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2301602602398598 and mu_y1: 1.021209469590567 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.020599706189384028 and mu_y2: -0.23163559213668444\n",
      "179, loss is 0.004435666818257546 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2281784351701646 and mu_y1: 1.021282193568084 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.020672730796816634 and mu_y2: -0.22965455438844012\n",
      "180, loss is 0.0043587450353786625 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2262139499137472 and mu_y1: 1.0213532785430248 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.02074412544235946 and mu_y2: -0.22769073253379957\n",
      "181, loss is 0.0042831625666932315 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.224266661562242 and mu_y1: 1.0214227312916544 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.020813896658252673 and mu_y2: -0.22574398584934796\n",
      "182, loss is 0.0042088967448128305 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2223364280323603 and mu_y1: 1.0214905588290668 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.02088205122178312 and mu_y2: -0.22381417442103202\n",
      "183, loss is 0.004135925252562583 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.220423108071746 and mu_y1: 1.021556768401583 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.020948596147564235 and mu_y2: -0.22190115914939232\n",
      "184, loss is 0.00406422611886223 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2185265612644547 and mu_y1: 1.0216213674792745 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.02101353867994316 and mu_y2: -0.22000480175445863\n",
      "185, loss is 0.00399377771460706 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.216646648036068 and mu_y1: 1.0216843637486142 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.021076886285534623 and mu_y2: -0.21812496478031657\n",
      "186, loss is 0.00392455874855092 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2147832296584522 and mu_y1: 1.0217457651052513 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.0211386466458812 and mu_y2: -0.21626151159935392\n",
      "187, loss is 0.0038565482631934198 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2129361682541682 and mu_y1: 1.0218055796469114 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.021198827650239362 and mu_y2: -0.21441430641619444\n",
      "188, loss is 0.0037897256306733684 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2111053268005454 and mu_y1: 1.0218638156664217 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.021257437388490744 and mu_y2: -0.21258321427132731\n",
      "189, loss is 0.0037240705486704614 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2092905691334264 and mu_y1: 1.021920481644858 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.02131448414417798 and mu_y2: -0.21076810104443994\n",
      "190, loss is 0.003659563036316967 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.207491759950591 and mu_y1: 1.0219755862448157 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.02136997638766442 and mu_y2: -0.20896883345746167\n",
      "191, loss is 0.0035961834301212834 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2057087648148699 and mu_y1: 1.022029138303803 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.0214239227694169 and mu_y2: -0.20718527907732653\n",
      "192, loss is 0.003533912379905021 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.203941450156956 and mu_y1: 1.0220811468277535 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.021476332113410844 and mu_y2: -0.20541730631846178\n",
      "193, loss is 0.0034727308447552356 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.2021896832779209 and mu_y1: 1.022131620984661 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.02152721341065677 and mu_y2: -0.20366478444501007\n",
      "194, loss is 0.0034126200889933464 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.200453332351445 and mu_y1: 1.0221805700983317 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.021576575812847318 and mu_y2: -0.20192758357279236\n",
      "195, loss is 0.0033535616781622227 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1987322664257722 and mu_y1: 1.0222280036422564 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.021624428626123876 and mu_y2: -0.2002055746710186\n",
      "196, loss is 0.003295537475032794 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1970263554253924 and mu_y1: 1.0222739312335984 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.021670781304961778 and mu_y2: -0.19849862956375322\n",
      "197, loss is 0.0032385296356315443 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1953354701524628 and mu_y1: 1.0223183626272994 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.021715643446173098 and mu_y2: -0.19680662093114232\n",
      "198, loss is 0.003182520605290098 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1936594822879758 and mu_y1: 1.0223613077102987 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.021759024783025945 and mu_y2: -0.19512942231040922\n",
      "199, loss is 0.003127493114718125 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1919982643926796 and mu_y1: 1.0224027764958676 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.021800935179479196 and mu_y2: -0.19346690809662512\n",
      "200, loss is 0.0030734301761006543 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1903516899077597 and mu_y1: 1.022442779118057 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.021841384624531557 and mu_y2: -0.1918189535432611\n",
      "201, loss is 0.0030203150792208516 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1887196331552878 and mu_y1: 1.0224813258262553 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.021880383226683776 and mu_y2: -0.19018543476252825\n",
      "202, loss is 0.002968131387609277 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.187101969338447 and mu_y1: 1.0225184269798584 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.021917941208512877 and mu_y2: -0.1885662287255119\n",
      "203, loss is 0.002916862934720542 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1854985745415378 and mu_y1: 1.022554093043049 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.021954068901357204 and mu_y2: -0.1869612132621061\n",
      "204, loss is 0.0028664938201382584 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1839093257297744 and mu_y1: 1.0225883345796827 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.021988776740111064 and mu_y2: -0.18537026706075443\n",
      "205, loss is 0.002817008405809087 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.182334100748875 and mu_y1: 1.0226211622482824 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022022075258127733 and mu_y2: -0.1837932696680032\n",
      "206, loss is 0.0027683913123066795 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1807727783244555 and mu_y1: 1.022652586797138 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022053975082229595 and mu_y2: -0.1822301014878724\n",
      "207, loss is 0.0027206274151262005 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1792252380612311 and mu_y1: 1.022682619059511 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022084486927824123 and mu_y2: -0.1806806437810507\n",
      "208, loss is 0.0026737018410101674 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1776913604420334 and mu_y1: 1.0227112699489405 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.02211362159412445 and mu_y2: -0.17914477866391945\n",
      "209, loss is 0.0026275999643061067 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1761710268266465 and mu_y1: 1.0227385504546531 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.02214138995947321 and mu_y2: -0.1776223891074115\n",
      "210, loss is 0.002582307403356789 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1746641194504734 and mu_y1: 1.0227644716370725 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022167802976768375 and mu_y2: -0.1761133589357099\n",
      "211, loss is 0.0025378100169233643 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1731705214230315 and mu_y1: 1.022789044623428 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.02219287166898976 and mu_y2: -0.17461757282479215\n",
      "212, loss is 0.002494093900642067 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1716901167262892 and mu_y1: 1.0228122806034619 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022216607124824872 and mu_y2: -0.17313491630082456\n",
      "213, loss is 0.0024511453835148233 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1702227902128457 and mu_y1: 1.022834190825232 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022239020494392796 and mu_y2: -0.1716652757384121\n",
      "214, loss is 0.0024089510244342154 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1687684276039603 and mu_y1: 1.0228547865910114 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022260122985064773 and mu_y2: -0.17020853835870836\n",
      "215, loss is 0.002367497608743182 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1673269154874366 and mu_y1: 1.02287407925328 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.02227992585738013 and mu_y2: -0.16876459222739085\n",
      "216, loss is 0.00232677214482975 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1658981413153675 and mu_y1: 1.0228920802108106 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.02229844042105624 and mu_y2: -0.16733332625250563\n",
      "217, loss is 0.002286761860757134 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1644819934017447 and mu_y1: 1.0229088009048446 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022315678031091146 and mu_y2: -0.16591463018218663\n",
      "218, loss is 0.0022474542009294413 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1630783609199387 and mu_y1: 1.0229242528153597 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022331650083957537 and mu_y2: -0.1645083946022534\n",
      "219, loss is 0.0022088368227932355 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1616871339000538 and mu_y1: 1.022938447457424 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.02234636801388672 and mu_y2: -0.16311451093369217\n",
      "220, loss is 0.0021708975935751263 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.160308203226164 and mu_y1: 1.0229513963776384 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.02235984328924123 and mu_y2: -0.16173287143002443\n",
      "221, loss is 0.002133624587055596 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1589414606334307 and mu_y1: 1.022963111150666 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.02237208740897477 and mu_y2: -0.16036336917456684\n",
      "222, loss is 0.00209700608037917 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.157586798705113 and mu_y1: 1.0229736033758439 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022383111899178146 and mu_y2: -0.15900589807758686\n",
      "223, loss is 0.0020610305509010645 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1562441108694677 and mu_y1: 1.0229828846738802 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022392928309709813 and mu_y2: -0.15766035287335822\n",
      "224, loss is 0.0020256866730703933 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.15491329139655 and mu_y1: 1.0229909666836323 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.02240154821090978 and mu_y2: -0.15632662911711964\n",
      "225, loss is 0.001990963315349976 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1535942353949142 and mu_y1: 1.022997861058966 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022408983190395495 and mu_y2: -0.15500462318194103\n",
      "226, loss is 0.0019568495371728336 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1522868388082206 and mu_y1: 1.023003579465694 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.02241524484993842 and mu_y2: -0.15369423225550058\n",
      "227, loss is 0.0019233345859353348 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1509909984117528 and mu_y1: 1.0230081335785919 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022420344802419973 and mu_y2: -0.1523953543367766\n",
      "228, loss is 0.001890407894026996 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1497066118088481 and mu_y1: 1.0230115350784927 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022424294668865544 and mu_y2: -0.1511078882326573\n",
      "229, loss is 0.0018580590758969424 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1484335774272463 and mu_y1: 1.0230137956494545 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022427106075555286 and mu_y2: -0.1498317335544724\n",
      "230, loss is 0.001826277925156958 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1471717945153586 and mu_y1: 1.0230149269760047 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022428790651210388 and mu_y2: -0.14856679071444942\n",
      "231, loss is 0.0017950544117210014 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1459211631384614 and mu_y1: 1.0230149407404554 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022429360024253563 and mu_y2: -0.14731296092209825\n",
      "232, loss is 0.0017643786789812317 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1446815841748197 and mu_y1: 1.023013848620292 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022428825820142478 and mu_y2: -0.1460701461805271\n",
      "233, loss is 0.0017342410410202931 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1434529593117397 and mu_y1: 1.0230116622856313 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.02242719965877485 and mu_y2: -0.14483824928269284\n",
      "234, loss is 0.0017046319798598684 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.142235191041559 and mu_y1: 1.023008393396749 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022424493151963994 and mu_y2: -0.14361717380758887\n",
      "235, loss is 0.0016755421427452546 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1410281826575714 and mu_y1: 1.0230040536016762 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022420717900983544 and mu_y2: -0.14240682411637345\n",
      "236, loss is 0.001646962339465903 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1398318382498978 and mu_y1: 1.0229986545338612 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.02241588549418016 and mu_y2: -0.14120710534844122\n",
      "237, loss is 0.0016188835397116953 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1386460627012955 and mu_y1: 1.0229922078098979 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022410007504652947 and mu_y2: -0.1400179234174408\n",
      "238, loss is 0.0015912968704648045 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1374707616829196 and mu_y1: 1.022984725027319 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022403095487998466 and mu_y2: -0.13883918500724124\n",
      "239, loss is 0.0015641936134269702 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1363058416500316 and mu_y1: 1.0229762177624515 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022395160980120038 and mu_y2: -0.13767079756784997\n",
      "240, loss is 0.001537565202481923 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1351512098376615 and mu_y1: 1.022966697568335 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.02238621549510026 and mu_y2: -0.1365126693112845\n",
      "241, loss is 0.0015114032211928322 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1340067742562259 and mu_y1: 1.0229561759727002 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022376270523135493 and mu_y2: -0.13536470920740087\n",
      "242, loss is 0.0014856994003344774 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1328724436871034 and mu_y1: 1.0229446644760087 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022365337528531197 and mu_y2: -0.1342268269796809\n",
      "243, loss is 0.0014604456154599453 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1317481276781711 and mu_y1: 1.0229321745495497 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.02235342794775695 and mu_y2: -0.13309893310098087\n",
      "244, loss is 0.001435633884501613 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1306337365393044 and mu_y1: 1.022918717633595 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022340553187560064 and mu_y2: -0.13198093878924352\n",
      "245, loss is 0.001411256365406148 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1295291813378416 and mu_y1: 1.0229043051356113 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.0223267246231366 and mu_y2: -0.13087275600317635\n",
      "246, loss is 0.0013873053538032908 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1284343738940172 and mu_y1: 1.0228889484285266 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.02231195359635877 and mu_y2: -0.12977429743789745\n",
      "247, loss is 0.0013637732807081097 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1273492267763645 and mu_y1: 1.0228726588490518 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022296251414057548 and mu_y2: -0.12868547652055176\n",
      "248, loss is 0.0013406527102565059 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1262736532970912 and mu_y1: 1.0228554476960543 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022279629346359478 and mu_y2: -0.1276062074058994\n",
      "249, loss is 0.0013179363374736474 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.125207567507429 and mu_y1: 1.022837326228986 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022262098625076575 and mu_y2: -0.12653640497187815\n",
      "250, loss is 0.0012956169860750813 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1241508841929595 and mu_y1: 1.0228183056663604 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022243670442148276 and mu_y2: -0.12547598481514213\n",
      "251, loss is 0.0012736876063001836 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1231035188689198 and mu_y1: 1.0227983971842805 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022224355948134416 and mu_y2: -0.1244248632465783\n",
      "252, loss is 0.001252141272777691 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1220653877754863 and mu_y1: 1.0227776119150158 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022204166250758186 and mu_y2: -0.12338295728680286\n",
      "253, loss is 0.0012309711824230074 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1210364078730428 and mu_y1: 1.0227559609456283 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022183112413498074 and mu_y2: -0.12235018466163927\n",
      "254, loss is 0.0012101706523669424 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.120016496837432 and mu_y1: 1.0227334553166438 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022161205454227798 and mu_y2: -0.12132646379757941\n",
      "255, loss is 0.0011897331179156253 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1190055730551922 and mu_y1: 1.0227101060207717 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.02213845634390322 and mu_y2: -0.12031171381722984\n",
      "256, loss is 0.0011696521305412375 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1180035556187833 and mu_y1: 1.0226859240016677 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022114876005295304 and mu_y2: -0.11930585453474449\n",
      "257, loss is 0.0011499213559032593 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1170103643217997 and mu_y1: 1.0226609201527423 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022090475311768165 and mu_y2: -0.11830880645124557\n",
      "258, loss is 0.0011305345718999173 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1160259196541757 and mu_y1: 1.022635105316013 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022065265086101207 and mu_y2: -0.1173204907502341\n",
      "259, loss is 0.0011114856667495034 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1150501427973833 and mu_y1: 1.0226084902809967 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022039256099354514 and mu_y2: -0.11634082929299153\n",
      "260, loss is 0.0010927686371012485 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1140829556196226 and mu_y1: 1.0225810857836464 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.022012459069776513 and mu_y2: -0.1153697446139739\n",
      "261, loss is 0.0010743775861753945 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.113124280671008 and mu_y1: 1.022552902505327 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.021984884661753006 and mu_y2: -0.11440715991619994\n",
      "262, loss is 0.001056306721932183 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1121740411787524 and mu_y1: 1.0225239510718311 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.021956543484796757 and mu_y2: -0.1134529990666344\n",
      "263, loss is 0.0010385503552693945 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.111232161042347 and mu_y1: 1.0224942420524339 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.021927446092576654 and mu_y2: -0.11250718659156791\n",
      "264, loss is 0.0010211028982481255 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.110298564828743 and mu_y1: 1.0224637859589862 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.021897602981985682 and mu_y2: -0.11156964767199463\n",
      "265, loss is 0.0010039588623464428 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1093731777675315 and mu_y1: 1.0224325932450449 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.02186702459224679 and mu_y2: -0.11064030813898892\n",
      "266, loss is 0.0009871128567406535 with sigma_x1: 1.0 and sigma_y1: 1.0 and mu_x1: 1.1084559257461275 and mu_y1: 1.022400674305039 and sigma_x2: 1.0 and sigma_y2: 1.0 and mu_x2: -0.021835721304055866 and mu_y2: -0.10971909446908214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1f2026407a0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_points_x_y = 10\n",
    "\n",
    "sigma_x_target1 = 1\n",
    "sigma_y_target1 = 1\n",
    "mu_x_target1 = 1\n",
    "mu_y_target1 = 1\n",
    "\n",
    "sigma_x_target2 = 1\n",
    "sigma_y_target2 = 1\n",
    "mu_x_target2 = 0\n",
    "mu_y_target2 = 0\n",
    "\n",
    "x = np.linspace(-5, 5, num_points_x_y)\n",
    "y = np.linspace(-5, 5, num_points_x_y)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = gaussian_2D(X, Y, sigma_x_target1, sigma_y_target1, mu_x_target1, mu_y_target1)\n",
    "Z += gaussian_2D(X, Y, sigma_x_target2, sigma_y_target2, mu_x_target2, mu_y_target2)\n",
    "\n",
    "sigma_x1 = 1\n",
    "sigma_y1 = 1\n",
    "mu_x1 = 2\n",
    "mu_y1 = 1\n",
    "\n",
    "sigma_x2 = 1\n",
    "sigma_y2 = 1\n",
    "mu_x2 = 0\n",
    "mu_y2 = -1\n",
    "\n",
    "lr = 0.1\n",
    "\n",
    "\n",
    "def descend(x, y, Z, sigma_x1, sigma_y1, mu_x1, mu_y1, sigma_x2, sigma_y2, mu_x2, mu_y2, lr):\n",
    "    dldsigma_x1 = 0.0\n",
    "    dldsigma_y1 = 0.0\n",
    "    dldmu_x1 = 0.0\n",
    "    dldmu_y1 = 0.0\n",
    "    dldsigma_x2 = 0.0\n",
    "    dldsigma_y2 = 0.0\n",
    "    dldmu_x2 = 0.0\n",
    "    dldmu_y2 = 0.0\n",
    "\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Zhat = gaussian_2D(X, Y, sigma_x1, sigma_y1, mu_x1, mu_y1)+gaussian_2D(X, Y, sigma_x2, sigma_y2, mu_x2, mu_y2)\n",
    "    gaus_grad_sigma_x1 = get_gaussian_grad_sigma_x(X, Y, sigma_x1, sigma_y1, mu_x1, mu_y1)\n",
    "    gaus_grad_sigma_y1 = get_gaussian_grad_sigma_y(X, Y, sigma_x1, sigma_y1, mu_x1, mu_y1)\n",
    "    gaus_grad_mu_x1 = get_gaussian_grad_mu_x(X, Y, sigma_x1, sigma_y1, mu_x1, mu_y1)\n",
    "    gaus_grad_mu_y1 = get_gaussian_grad_mu_y(X, Y, sigma_x1, sigma_y1, mu_x1, mu_y1)\n",
    "    gaus_grad_sigma_x2 = get_gaussian_grad_sigma_x(X, Y, sigma_x2, sigma_y2, mu_x2, mu_y2)\n",
    "    gaus_grad_sigma_y2 = get_gaussian_grad_sigma_y(X, Y, sigma_x2, sigma_y2, mu_x2, mu_y2)\n",
    "    gaus_grad_mu_x2 = get_gaussian_grad_mu_x(X, Y, sigma_x2, sigma_y2, mu_x2, mu_y2)\n",
    "    gaus_grad_mu_y2 = get_gaussian_grad_mu_y(X, Y, sigma_x2, sigma_y2, mu_x2, mu_y2)\n",
    "\n",
    "    #loss = (y-yhat)^2\n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(y)):\n",
    "            # # print(x[i], y[j])\n",
    "            # dldsigma_x1 += 2*(Z[i][j]-Zhat[i][j])*-1*gaus_grad_sigma_x1[i][j]\n",
    "            # dldsigma_y1 += 2*(Z[i][j]-Zhat[i][j])*-1*gaus_grad_sigma_y1[i][j]\n",
    "            dldmu_x1 += 2*(Z[i][j]-Zhat[i][j])*-1*gaus_grad_mu_x1[i][j]\n",
    "            dldmu_y1 += 2*(Z[i][j]-Zhat[i][j])*-1*gaus_grad_mu_y1[i][j]\n",
    "            # dldsigma_x2 += 2*(Z[i][j]-Zhat[i][j])*-1*gaus_grad_sigma_x2[i][j]\n",
    "            # dldsigma_y2 += 2*(Z[i][j]-Zhat[i][j])*-1*gaus_grad_sigma_y2[i][j]\n",
    "            dldmu_x2 += 2*(Z[i][j]-Zhat[i][j])*-1*gaus_grad_mu_x2[i][j]\n",
    "            dldmu_y2 += 2*(Z[i][j]-Zhat[i][j])*-1*gaus_grad_mu_y2[i][j]\n",
    "\n",
    "    sigma_x1 = sigma_x1 - lr*(1/100)*dldsigma_x1\n",
    "    sigma_y1 = sigma_y1 - lr*(1/100)*dldsigma_y1\n",
    "    mu_x1 = mu_x1 - lr*dldmu_x1\n",
    "    mu_y1 = mu_y1 - lr*dldmu_y1\n",
    "    sigma_x2 = sigma_x2 - lr*(1/100)*dldsigma_x2\n",
    "    sigma_y2 = sigma_y2 - lr*(1/100)*dldsigma_y2\n",
    "    mu_x2 = mu_x2 - lr*dldmu_x2\n",
    "    mu_y2 = mu_y2 - lr*dldmu_y2\n",
    "\n",
    "    return sigma_x1, sigma_y1, mu_x1, mu_y1, sigma_x2, sigma_y2, mu_x2, mu_y2\n",
    "\n",
    "\n",
    "loss_array = np.array([])\n",
    "mu_x_list1 = np.array([])\n",
    "mu_y_list1 = np.array([])\n",
    "mu_x_list2 = np.array([])\n",
    "mu_y_list2 = np.array([])\n",
    "loss = 1\n",
    "epoch = 0\n",
    "while loss > 1e-3:\n",
    "    sigma_x1, sigma_y1, mu_x1, mu_y1, sigma_x2, sigma_y2, mu_x2, mu_y2 = descend(x, y, Z, sigma_x1, sigma_y1, mu_x1, mu_y1, sigma_x2, sigma_y2, mu_x2, mu_y2, lr)\n",
    "    mu_x_list1 = np.append(mu_x_list1, mu_x1)\n",
    "    mu_y_list1 = np.append(mu_y_list1, mu_y1)\n",
    "    mu_x_list2 = np.append(mu_x_list2, mu_x2)\n",
    "    mu_y_list2 = np.append(mu_y_list2, mu_y2)\n",
    "    Zhat = gaussian_2D(X, Y, sigma_x1, sigma_y1, mu_x1, mu_y1)+gaussian_2D(X, Y, sigma_x2, sigma_y2, mu_x2, mu_y2)\n",
    "    loss = np.sum((Z-Zhat)**2)\n",
    "    loss_array = np.append(loss_array, loss)\n",
    "    print(f'{epoch}, loss is {loss} with sigma_x1: {sigma_x1} and sigma_y1: {sigma_y1} and mu_x1: {mu_x1} and mu_y1: {mu_y1} and sigma_x2: {sigma_x2} and sigma_y2: {sigma_y2} and mu_x2: {mu_x2} and mu_y2: {mu_y2}')\n",
    "    epoch += 1\n",
    "\n",
    "loss_x = np.linspace(0,len(loss_array)-1, len(loss_array))\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(121)\n",
    "plt.plot(loss_x, loss_array)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.contourf(X, Y, Z, cmap='viridis')\n",
    "plt.scatter(mu_x_list1, mu_y_list1, color='yellow', label='Scattered Points')\n",
    "plt.scatter(mu_x_list2, mu_y_list2, color='orange', label='Scattered Points')\n",
    "plt.scatter(mu_x_target1, mu_y_target1, marker=\"x\", color=\"red\")\n",
    "plt.scatter(mu_x_target2, mu_y_target2, marker=\"x\", color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 x: -4.0 y: -4.0\n",
      "0.04421442172644226\n",
      "[]\n",
      "[]\n",
      "1 x: -4.0 y: -3.111111111111111\n",
      "0.044196198353351805\n",
      "[]\n",
      "[]\n",
      "2 x: -4.0 y: -2.2222222222222223\n",
      "0.044243868624933264\n",
      "[]\n",
      "[]\n",
      "3 x: -4.0 y: -1.3333333333333335\n",
      "4.6151820681822034e-08\n",
      "[-4.]\n",
      "[-1.33333333]\n",
      "4 x: -4.0 y: -0.44444444444444464\n",
      "6.269932419417654e-10\n",
      "[-4. -4.]\n",
      "[-1.33333333 -0.44444444]\n",
      "5 x: -4.0 y: 0.44444444444444464\n",
      "7.588378025278461e-10\n",
      "[-4. -4. -4.]\n",
      "[-1.33333333 -0.44444444  0.44444444]\n",
      "6 x: -4.0 y: 1.333333333333333\n",
      "4.823077544919101e-08\n",
      "[-4. -4. -4. -4.]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333]\n",
      "7 x: -4.0 y: 2.2222222222222214\n",
      "0.044356042573079\n",
      "[-4. -4. -4. -4.]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333]\n",
      "8 x: -4.0 y: 3.1111111111111107\n",
      "0.20743809877891883\n",
      "[-4. -4. -4. -4.]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333]\n",
      "9 x: -4.0 y: 4.0\n",
      "0.20746136703939205\n",
      "[-4. -4. -4. -4.]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333]\n",
      "10 x: -3.111111111111111 y: -4.0\n",
      "0.04419619835335181\n",
      "[-4. -4. -4. -4.]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333]\n",
      "11 x: -3.111111111111111 y: -3.111111111111111\n",
      "4.0838571511506445e-10\n",
      "[-4.         -4.         -4.         -4.         -3.11111111]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111]\n",
      "12 x: -3.111111111111111 y: -2.2222222222222223\n",
      "1.2162511976140259e-12\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222]\n",
      "13 x: -3.111111111111111 y: -1.3333333333333335\n",
      "2.417870293026738e-13\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333]\n",
      "14 x: -3.111111111111111 y: -0.44444444444444464\n",
      "2.4898166908336976e-13\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444]\n",
      "15 x: -3.111111111111111 y: 0.44444444444444464\n",
      "5.118472630880982e-13\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444]\n",
      "16 x: -3.111111111111111 y: 1.333333333333333\n",
      "2.192511498792593e-12\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333]\n",
      "17 x: -3.111111111111111 y: 2.2222222222222214\n",
      "3.388901566281746e-11\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222]\n",
      "18 x: -3.111111111111111 y: 3.1111111111111107\n",
      "0.008657786498608266\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222]\n",
      "19 x: -3.111111111111111 y: 4.0\n",
      "0.20743809877891886\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222]\n",
      "20 x: -2.2222222222222223 y: -4.0\n",
      "0.04424386862493327\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222]\n",
      "21 x: -2.2222222222222223 y: -3.111111111111111\n",
      "1.2162511976140257e-12\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111]\n",
      "22 x: -2.2222222222222223 y: -2.2222222222222223\n",
      "1.519023250228161e-26\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222]\n",
      "23 x: -2.2222222222222223 y: -1.3333333333333335\n",
      "9.248660617530002e-15\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333]\n",
      "24 x: -2.2222222222222223 y: -0.44444444444444464\n",
      "3.9889136635817395e-14\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444]\n",
      "25 x: -2.2222222222222223 y: 0.44444444444444464\n",
      "1.638908675980046e-13\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444]\n",
      "26 x: -2.2222222222222223 y: 1.333333333333333\n",
      "1.2173459646719696e-12\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333]\n",
      "27 x: -2.2222222222222223 y: 2.2222222222222214\n",
      "0.00865778648937119\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333]\n",
      "28 x: -2.2222222222222223 y: 3.1111111111111107\n",
      "3.388901566281746e-11\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111]\n",
      "29 x: -2.2222222222222223 y: 4.0\n",
      "0.04435604257307898\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111]\n",
      "30 x: -1.3333333333333335 y: -4.0\n",
      "4.615182068182203e-08\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.        ]\n",
      "31 x: -1.3333333333333335 y: -3.111111111111111\n",
      "2.4178702930267383e-13\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111]\n",
      "32 x: -1.3333333333333335 y: -2.2222222222222223\n",
      "9.24866061753e-15\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222]\n",
      "33 x: -1.3333333333333335 y: -1.3333333333333335\n",
      "3.097492281894698e-29\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333]\n",
      "34 x: -1.3333333333333335 y: -0.44444444444444464\n",
      "1.4411091557118485e-14\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444]\n",
      "35 x: -1.3333333333333335 y: 0.44444444444444464\n",
      "2.0254871949150905e-13\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444]\n",
      "36 x: -1.3333333333333335 y: 1.333333333333333\n",
      "0.008657786489369426\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444]\n",
      "37 x: -1.3333333333333335 y: 2.2222222222222214\n",
      "1.21734596467197e-12\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222]\n",
      "38 x: -1.3333333333333335 y: 3.1111111111111107\n",
      "2.192511498792593e-12\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111]\n",
      "39 x: -1.3333333333333335 y: 4.0\n",
      "4.823077544919102e-08\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.        ]\n",
      "40 x: -0.44444444444444464 y: -4.0\n",
      "6.269932419417655e-10\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.        ]\n",
      "41 x: -0.44444444444444464 y: -3.111111111111111\n",
      "2.4898166908336976e-13\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111]\n",
      "42 x: -0.44444444444444464 y: -2.2222222222222223\n",
      "3.98891366358174e-14\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222]\n",
      "43 x: -0.44444444444444464 y: -1.3333333333333335\n",
      "1.4411091557118488e-14\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333]\n",
      "44 x: -0.44444444444444464 y: -0.44444444444444464\n",
      "6.168712078561944e-30\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444]\n",
      "45 x: -0.44444444444444464 y: 0.44444444444444464\n",
      "0.008657786489368996\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444]\n",
      "46 x: -0.44444444444444464 y: 1.333333333333333\n",
      "2.0254871949150908e-13\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333]\n",
      "47 x: -0.44444444444444464 y: 2.2222222222222214\n",
      "1.6389086759800463e-13\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222]\n",
      "48 x: -0.44444444444444464 y: 3.1111111111111107\n",
      "5.118472630880983e-13\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111]\n",
      "49 x: -0.44444444444444464 y: 4.0\n",
      "7.588378025278462e-10\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.        ]\n",
      "50 x: 0.44444444444444464 y: -4.0\n",
      "7.588378025278462e-10\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.        ]\n",
      "51 x: 0.44444444444444464 y: -3.111111111111111\n",
      "5.118472630880983e-13\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111]\n",
      "52 x: 0.44444444444444464 y: -2.2222222222222223\n",
      "1.6389086759800463e-13\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222]\n",
      "53 x: 0.44444444444444464 y: -1.3333333333333335\n",
      "2.0254871949150908e-13\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333]\n",
      "54 x: 0.44444444444444464 y: -0.44444444444444464\n",
      "0.008657786489368996\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333]\n",
      "55 x: 0.44444444444444464 y: 0.44444444444444464\n",
      "6.168712078561944e-30\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444]\n",
      "56 x: 0.44444444444444464 y: 1.333333333333333\n",
      "1.4411091557118488e-14\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333]\n",
      "57 x: 0.44444444444444464 y: 2.2222222222222214\n",
      "3.98891366358174e-14\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222]\n",
      "58 x: 0.44444444444444464 y: 3.1111111111111107\n",
      "2.4898166908336976e-13\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111]\n",
      "59 x: 0.44444444444444464 y: 4.0\n",
      "6.269932419417655e-10\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.        ]\n",
      "60 x: 1.333333333333333 y: -4.0\n",
      "4.823077544919102e-08\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.        ]\n",
      "61 x: 1.333333333333333 y: -3.111111111111111\n",
      "2.192511498792593e-12\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111]\n",
      "62 x: 1.333333333333333 y: -2.2222222222222223\n",
      "1.21734596467197e-12\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222]\n",
      "63 x: 1.333333333333333 y: -1.3333333333333335\n",
      "0.008657786489369426\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222]\n",
      "64 x: 1.333333333333333 y: -0.44444444444444464\n",
      "2.0254871949150905e-13\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444]\n",
      "65 x: 1.333333333333333 y: 0.44444444444444464\n",
      "1.4411091557118485e-14\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444]\n",
      "66 x: 1.333333333333333 y: 1.333333333333333\n",
      "3.097492281894698e-29\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333]\n",
      "67 x: 1.333333333333333 y: 2.2222222222222214\n",
      "9.24866061753e-15\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222]\n",
      "68 x: 1.333333333333333 y: 3.1111111111111107\n",
      "2.4178702930267383e-13\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111]\n",
      "69 x: 1.333333333333333 y: 4.0\n",
      "4.615182068182203e-08\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.        ]\n",
      "70 x: 2.2222222222222214 y: -4.0\n",
      "0.04435604257307898\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.        ]\n",
      "71 x: 2.2222222222222214 y: -3.111111111111111\n",
      "3.388901566281746e-11\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111]\n",
      "72 x: 2.2222222222222214 y: -2.2222222222222223\n",
      "0.008657786489371187\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111]\n",
      "73 x: 2.2222222222222214 y: -1.3333333333333335\n",
      "1.2173459646719696e-12\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333]\n",
      "74 x: 2.2222222222222214 y: -0.44444444444444464\n",
      "1.638908675980046e-13\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222  2.22222222]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333 -0.44444444]\n",
      "75 x: 2.2222222222222214 y: 0.44444444444444464\n",
      "3.9889136635817395e-14\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222  2.22222222  2.22222222]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333 -0.44444444  0.44444444]\n",
      "76 x: 2.2222222222222214 y: 1.333333333333333\n",
      "9.248660617530002e-15\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333]\n",
      "77 x: 2.2222222222222214 y: 2.2222222222222214\n",
      "1.519023250228161e-26\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222]\n",
      "78 x: 2.2222222222222214 y: 3.1111111111111107\n",
      "1.2162511976140257e-12\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222\n",
      "  2.22222222]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222\n",
      "  3.11111111]\n",
      "79 x: 2.2222222222222214 y: 4.0\n",
      "0.04424386862493327\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222\n",
      "  2.22222222]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222\n",
      "  3.11111111]\n",
      "80 x: 3.1111111111111107 y: -4.0\n",
      "0.20743809877891886\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222\n",
      "  2.22222222]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222\n",
      "  3.11111111]\n",
      "81 x: 3.1111111111111107 y: -3.111111111111111\n",
      "0.00865778649860826\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222\n",
      "  2.22222222]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222\n",
      "  3.11111111]\n",
      "82 x: 3.1111111111111107 y: -2.2222222222222223\n",
      "3.388901566281746e-11\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222\n",
      "  2.22222222  3.11111111]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222\n",
      "  3.11111111 -2.22222222]\n",
      "83 x: 3.1111111111111107 y: -1.3333333333333335\n",
      "2.192511498792593e-12\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222\n",
      "  2.22222222  3.11111111  3.11111111]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222\n",
      "  3.11111111 -2.22222222 -1.33333333]\n",
      "84 x: 3.1111111111111107 y: -0.44444444444444464\n",
      "5.118472630880982e-13\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222\n",
      "  2.22222222  3.11111111  3.11111111  3.11111111]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222\n",
      "  3.11111111 -2.22222222 -1.33333333 -0.44444444]\n",
      "85 x: 3.1111111111111107 y: 0.44444444444444464\n",
      "2.4898166908336976e-13\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222\n",
      "  2.22222222  3.11111111  3.11111111  3.11111111  3.11111111]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222\n",
      "  3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444]\n",
      "86 x: 3.1111111111111107 y: 1.333333333333333\n",
      "2.417870293026738e-13\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222\n",
      "  2.22222222  3.11111111  3.11111111  3.11111111  3.11111111  3.11111111]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222\n",
      "  3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333]\n",
      "87 x: 3.1111111111111107 y: 2.2222222222222214\n",
      "1.2162511976140259e-12\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222\n",
      "  2.22222222  3.11111111  3.11111111  3.11111111  3.11111111  3.11111111\n",
      "  3.11111111]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222\n",
      "  3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333\n",
      "  2.22222222]\n",
      "88 x: 3.1111111111111107 y: 3.1111111111111107\n",
      "4.0838571511506445e-10\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222\n",
      "  2.22222222  3.11111111  3.11111111  3.11111111  3.11111111  3.11111111\n",
      "  3.11111111  3.11111111]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222\n",
      "  3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111]\n",
      "89 x: 3.1111111111111107 y: 4.0\n",
      "0.04419619835335181\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222\n",
      "  2.22222222  3.11111111  3.11111111  3.11111111  3.11111111  3.11111111\n",
      "  3.11111111  3.11111111]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222\n",
      "  3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111]\n",
      "90 x: 4.0 y: -4.0\n",
      "0.20746136703939205\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222\n",
      "  2.22222222  3.11111111  3.11111111  3.11111111  3.11111111  3.11111111\n",
      "  3.11111111  3.11111111]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222\n",
      "  3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111]\n",
      "91 x: 4.0 y: -3.111111111111111\n",
      "0.20743809877891883\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222\n",
      "  2.22222222  3.11111111  3.11111111  3.11111111  3.11111111  3.11111111\n",
      "  3.11111111  3.11111111]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222\n",
      "  3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111]\n",
      "92 x: 4.0 y: -2.2222222222222223\n",
      "0.04435604257307899\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222\n",
      "  2.22222222  3.11111111  3.11111111  3.11111111  3.11111111  3.11111111\n",
      "  3.11111111  3.11111111]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222\n",
      "  3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111]\n",
      "93 x: 4.0 y: -1.3333333333333335\n",
      "4.823077544919101e-08\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222\n",
      "  2.22222222  3.11111111  3.11111111  3.11111111  3.11111111  3.11111111\n",
      "  3.11111111  3.11111111  4.        ]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222\n",
      "  3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111 -1.33333333]\n",
      "94 x: 4.0 y: -0.44444444444444464\n",
      "7.588378025278461e-10\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222\n",
      "  2.22222222  3.11111111  3.11111111  3.11111111  3.11111111  3.11111111\n",
      "  3.11111111  3.11111111  4.          4.        ]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222\n",
      "  3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111 -1.33333333 -0.44444444]\n",
      "95 x: 4.0 y: 0.44444444444444464\n",
      "6.269932419417654e-10\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222\n",
      "  2.22222222  3.11111111  3.11111111  3.11111111  3.11111111  3.11111111\n",
      "  3.11111111  3.11111111  4.          4.          4.        ]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222\n",
      "  3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111 -1.33333333 -0.44444444  0.44444444]\n",
      "96 x: 4.0 y: 1.333333333333333\n",
      "4.6151820681822034e-08\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222\n",
      "  2.22222222  3.11111111  3.11111111  3.11111111  3.11111111  3.11111111\n",
      "  3.11111111  3.11111111  4.          4.          4.          4.        ]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222\n",
      "  3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333]\n",
      "97 x: 4.0 y: 2.2222222222222214\n",
      "0.044243868624933264\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222\n",
      "  2.22222222  3.11111111  3.11111111  3.11111111  3.11111111  3.11111111\n",
      "  3.11111111  3.11111111  4.          4.          4.          4.        ]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222\n",
      "  3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333]\n",
      "98 x: 4.0 y: 3.1111111111111107\n",
      "0.044196198353351805\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222\n",
      "  2.22222222  3.11111111  3.11111111  3.11111111  3.11111111  3.11111111\n",
      "  3.11111111  3.11111111  4.          4.          4.          4.        ]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222\n",
      "  3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333]\n",
      "99 x: 4.0 y: 4.0\n",
      "0.04421442172644226\n",
      "[-4.         -4.         -4.         -4.         -3.11111111 -3.11111111\n",
      " -3.11111111 -3.11111111 -3.11111111 -3.11111111 -3.11111111 -2.22222222\n",
      " -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222 -2.22222222\n",
      " -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333 -1.33333333\n",
      " -1.33333333 -1.33333333 -1.33333333 -0.44444444 -0.44444444 -0.44444444\n",
      " -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444 -0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444  0.44444444\n",
      "  0.44444444  0.44444444  0.44444444  1.33333333  1.33333333  1.33333333\n",
      "  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333  1.33333333\n",
      "  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222  2.22222222\n",
      "  2.22222222  3.11111111  3.11111111  3.11111111  3.11111111  3.11111111\n",
      "  3.11111111  3.11111111  4.          4.          4.          4.        ]\n",
      "[-1.33333333 -0.44444444  0.44444444  1.33333333 -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222 -3.11111111\n",
      " -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333  3.11111111\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -1.33333333 -0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -4.         -3.11111111 -2.22222222 -1.33333333  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111  4.         -4.         -3.11111111 -2.22222222\n",
      " -0.44444444  0.44444444  1.33333333  2.22222222  3.11111111  4.\n",
      " -3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333  2.22222222\n",
      "  3.11111111 -2.22222222 -1.33333333 -0.44444444  0.44444444  1.33333333\n",
      "  2.22222222  3.11111111 -1.33333333 -0.44444444  0.44444444  1.33333333]\n"
     ]
    }
   ],
   "source": [
    "#Gradient Descent\n",
    "\n",
    "x_test_array = np.linspace(-4,4,10)\n",
    "y_test_array = np.linspace(-4,4,10)\n",
    "iteration = 0\n",
    "successful_points_x = np.array([])\n",
    "successful_points_y = np.array([])\n",
    "\n",
    "for x_test in x_test_array:\n",
    "    for y_test in y_test_array:\n",
    "        print(iteration, \"x:\", x_test, \"y:\", y_test)\n",
    "        iteration += 1\n",
    "        num_points_x_y = 10\n",
    "\n",
    "        sigma_x_target1 = 1\n",
    "        sigma_y_target1 = 1\n",
    "        mu_x_target1 = 1\n",
    "        mu_y_target1 = 1\n",
    "\n",
    "        sigma_x_target2 = 1\n",
    "        sigma_y_target2 = 1\n",
    "        mu_x_target2 = 0\n",
    "        mu_y_target2 = 0\n",
    "\n",
    "        x = np.linspace(-5, 5, num_points_x_y)\n",
    "        y = np.linspace(-5, 5, num_points_x_y)\n",
    "\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = gaussian_2D(X, Y, sigma_x_target1, sigma_y_target1, mu_x_target1, mu_y_target1)\n",
    "        Z += gaussian_2D(X, Y, sigma_x_target2, sigma_y_target2, mu_x_target2, mu_y_target2)\n",
    "\n",
    "        sigma_x1 = 1\n",
    "        sigma_y1 = 1\n",
    "        mu_x1 = x_test\n",
    "        mu_y1 = y_test\n",
    "\n",
    "        sigma_x2 = 1\n",
    "        sigma_y2 = 1\n",
    "        mu_x2 = -x_test\n",
    "        mu_y2 = -y_test\n",
    "\n",
    "        lr = 0.1\n",
    "\n",
    "\n",
    "        def descend(x, y, Z, sigma_x1, sigma_y1, mu_x1, mu_y1, sigma_x2, sigma_y2, mu_x2, mu_y2, lr):\n",
    "            dldsigma_x1 = 0.0\n",
    "            dldsigma_y1 = 0.0\n",
    "            dldmu_x1 = 0.0\n",
    "            dldmu_y1 = 0.0\n",
    "            dldsigma_x2 = 0.0\n",
    "            dldsigma_y2 = 0.0\n",
    "            dldmu_x2 = 0.0\n",
    "            dldmu_y2 = 0.0\n",
    "\n",
    "            X, Y = np.meshgrid(x, y)\n",
    "            Zhat = gaussian_2D(X, Y, sigma_x1, sigma_y1, mu_x1, mu_y1)+gaussian_2D(X, Y, sigma_x2, sigma_y2, mu_x2, mu_y2)\n",
    "            gaus_grad_sigma_x1 = get_gaussian_grad_sigma_x(X, Y, sigma_x1, sigma_y1, mu_x1, mu_y1)\n",
    "            gaus_grad_sigma_y1 = get_gaussian_grad_sigma_y(X, Y, sigma_x1, sigma_y1, mu_x1, mu_y1)\n",
    "            gaus_grad_mu_x1 = get_gaussian_grad_mu_x(X, Y, sigma_x1, sigma_y1, mu_x1, mu_y1)\n",
    "            gaus_grad_mu_y1 = get_gaussian_grad_mu_y(X, Y, sigma_x1, sigma_y1, mu_x1, mu_y1)\n",
    "            gaus_grad_sigma_x2 = get_gaussian_grad_sigma_x(X, Y, sigma_x2, sigma_y2, mu_x2, mu_y2)\n",
    "            gaus_grad_sigma_y2 = get_gaussian_grad_sigma_y(X, Y, sigma_x2, sigma_y2, mu_x2, mu_y2)\n",
    "            gaus_grad_mu_x2 = get_gaussian_grad_mu_x(X, Y, sigma_x2, sigma_y2, mu_x2, mu_y2)\n",
    "            gaus_grad_mu_y2 = get_gaussian_grad_mu_y(X, Y, sigma_x2, sigma_y2, mu_x2, mu_y2)\n",
    "\n",
    "            #loss = (y-yhat)^2\n",
    "            for i in range(len(x)):\n",
    "                for j in range(len(y)):\n",
    "                    # # print(x[i], y[j])\n",
    "                    # dldsigma_x1 += 2*(Z[i][j]-Zhat[i][j])*-1*gaus_grad_sigma_x1[i][j]\n",
    "                    # dldsigma_y1 += 2*(Z[i][j]-Zhat[i][j])*-1*gaus_grad_sigma_y1[i][j]\n",
    "                    dldmu_x1 += 2*(Z[i][j]-Zhat[i][j])*-1*gaus_grad_mu_x1[i][j]\n",
    "                    dldmu_y1 += 2*(Z[i][j]-Zhat[i][j])*-1*gaus_grad_mu_y1[i][j]\n",
    "                    # dldsigma_x2 += 2*(Z[i][j]-Zhat[i][j])*-1*gaus_grad_sigma_x2[i][j]\n",
    "                    # dldsigma_y2 += 2*(Z[i][j]-Zhat[i][j])*-1*gaus_grad_sigma_y2[i][j]\n",
    "                    dldmu_x2 += 2*(Z[i][j]-Zhat[i][j])*-1*gaus_grad_mu_x2[i][j]\n",
    "                    dldmu_y2 += 2*(Z[i][j]-Zhat[i][j])*-1*gaus_grad_mu_y2[i][j]\n",
    "\n",
    "            sigma_x1 = sigma_x1 - lr*(1/100)*dldsigma_x1\n",
    "            sigma_y1 = sigma_y1 - lr*(1/100)*dldsigma_y1\n",
    "            mu_x1 = mu_x1 - lr*dldmu_x1\n",
    "            mu_y1 = mu_y1 - lr*dldmu_y1\n",
    "            sigma_x2 = sigma_x2 - lr*(1/100)*dldsigma_x2\n",
    "            sigma_y2 = sigma_y2 - lr*(1/100)*dldsigma_y2\n",
    "            mu_x2 = mu_x2 - lr*dldmu_x2\n",
    "            mu_y2 = mu_y2 - lr*dldmu_y2\n",
    "\n",
    "            return sigma_x1, sigma_y1, mu_x1, mu_y1, sigma_x2, sigma_y2, mu_x2, mu_y2\n",
    "\n",
    "\n",
    "        loss_array = np.array([])\n",
    "        mu_x_list1 = np.array([])\n",
    "        mu_y_list1 = np.array([])\n",
    "        mu_x_list2 = np.array([])\n",
    "        mu_y_list2 = np.array([])\n",
    "        loss = 1\n",
    "        epoch = 0\n",
    "        while 5000 > epoch:\n",
    "            sigma_x1, sigma_y1, mu_x1, mu_y1, sigma_x2, sigma_y2, mu_x2, mu_y2 = descend(x, y, Z, sigma_x1, sigma_y1, mu_x1, mu_y1, sigma_x2, sigma_y2, mu_x2, mu_y2, lr)\n",
    "            mu_x_list1 = np.append(mu_x_list1, mu_x1)\n",
    "            mu_y_list1 = np.append(mu_y_list1, mu_y1)\n",
    "            mu_x_list2 = np.append(mu_x_list2, mu_x2)\n",
    "            mu_y_list2 = np.append(mu_y_list2, mu_y2)\n",
    "            Zhat = gaussian_2D(X, Y, sigma_x1, sigma_y1, mu_x1, mu_y1)+gaussian_2D(X, Y, sigma_x2, sigma_y2, mu_x2, mu_y2)\n",
    "            loss = np.sum((Z-Zhat)**2)\n",
    "            loss_array = np.append(loss_array, loss)\n",
    "            print(f'{epoch}, loss is {loss} with sigma_x1: {sigma_x1} and sigma_y1: {sigma_y1} and mu_x1: {mu_x1} and mu_y1: {mu_y1} and sigma_x2: {sigma_x2} and sigma_y2: {sigma_y2} and mu_x2: {mu_x2} and mu_y2: {mu_y2}')\n",
    "            epoch += 1\n",
    "\n",
    "        if loss < 0.001:\n",
    "            successful_points_x = np.append(successful_points_x, x_test)\n",
    "            successful_points_y = np.append(successful_points_y, y_test)\n",
    "\n",
    "        print(loss)\n",
    "        print(successful_points_x)\n",
    "        print(successful_points_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2079cd600e0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.contourf(X, Y, Z, cmap='viridis')\n",
    "plt.scatter(successful_points_x, successful_points_y, color='yellow', label='Scattered Points')\n",
    "\n",
    "plt.scatter(mu_x_target1, mu_y_target1, marker=\"x\", color=\"red\")\n",
    "plt.scatter(mu_x_target2, mu_y_target2, marker=\"x\", color=\"red\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
